{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7028ba9-e90a-42dd-afb1-4d9214c3180e",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ff3ba8-8a9e-442e-b98f-fad1fc830043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict as dd\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, DebertaV2ForSequenceClassification\n",
    "from transformers import BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from transformers.optimization import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, average_precision_score\n",
    "import logging\n",
    "\n",
    "import utils\n",
    "import settings\n",
    "\n",
    "### add \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "import gc\n",
    "import json\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "global is_clean, fuzz_ratio, model_name\n",
    "model_name = 'roberta-base'\n",
    "is_clean = False\n",
    "fuzz_ratio = 80\n",
    "NFOLDS = 3\n",
    "MAX_SEQ_LENGTH = 512\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d74f1-8917-438a-b325-273f14ef00eb",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d29b6820-3a4d-4dea-b4d7-5b42552a56e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to clean RAM & vRAM\n",
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    # ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "def clean_text_line(line): \n",
    "    ## 得到 Abstract 信息\n",
    "    out_text = re.sub('<[^>]*>', '', line)\n",
    "    out_text = re.sub(r'\\t+', '\\t', out_text)\n",
    "    out_text = re.sub(r'\\n+', '\\n', out_text)\n",
    "    out_text = re.sub(r'[\\n\\t]+', '\\n', out_text)\n",
    "    return out_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BertInputItem(object):\n",
    "    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "\n",
    "def convert_examples_to_inputs(example_texts, example_labels, max_seq_length, tokenizer, verbose=0):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        # Create a list of token ids\n",
    "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "        if len(input_ids) > max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "\n",
    "        # All our tokens are in the first input segment (id 0).\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_id))\n",
    "        \n",
    "    return input_items\n",
    "\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size, num_workers=8)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc747a-2adb-43cd-b1fa-383ddd53fada",
   "metadata": {},
   "source": [
    "# 生成 test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f56fdb-c4ed-4ef2-a955-5047e8522c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_kddcup_test_submission_bert(fold, model_name=\"deberta\"):\n",
    "    print(\"model name\", model_name)\n",
    "    data_dir = join(settings.DATA_TRACE_DIR, \"PST\")\n",
    "    papers = utils.load_json(data_dir, \"paper_source_trace_test_wo_ans.json\")\n",
    "\n",
    "    if model_name == \"bert\":\n",
    "        BERT_MODEL = \"bert-base-uncased\"\n",
    "    elif model_name == \"scibert\":\n",
    "        BERT_MODEL = './bert_models/scibert_scivocab_uncased/'\n",
    "    elif model_name == 'roberta-base':\n",
    "        BERT_MODEL = './bert_models/dsp_roberta_base_dapt_cs_tapt_sciie_3219/'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "    sub_example_dict = utils.load_json(data_dir, \"submission_example_test.json\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device\", device)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL, num_labels = 2)\n",
    "    OUTPUT_DIR = join(settings.OUT_DIR, \"kddcup\", model_name, f'num_fold={NFOLDS}',f'fold_{fold}')\n",
    "    model.load_state_dict(torch.load(join(OUTPUT_DIR, \"pytorch_model.bin\")))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    xml_dir = join(data_dir, \"paper-xml\")\n",
    "    sub_dict = {}\n",
    "\n",
    "    for paper in tqdm(papers):\n",
    "        cur_pid = paper[\"_id\"]\n",
    "        file = join(xml_dir, cur_pid + \".xml\")\n",
    "        f = open(file, encoding='utf-8')\n",
    "        xml = f.read()\n",
    "        bs = BeautifulSoup(xml, \"xml\")\n",
    "        f.close()\n",
    "\n",
    "        references = bs.find_all(\"biblStruct\")\n",
    "        bid_to_title = {}\n",
    "        n_refs = 0\n",
    "        for ref in references:\n",
    "            if \"xml:id\" not in ref.attrs:\n",
    "                continue\n",
    "            bid = ref.attrs[\"xml:id\"]\n",
    "            if ref.analytic is None:\n",
    "                continue\n",
    "            if ref.analytic.title is None:\n",
    "                continue\n",
    "            bid_to_title[bid] = ref.analytic.title.text.lower()\n",
    "            b_idx = int(bid[1:]) + 1\n",
    "            if b_idx > n_refs:\n",
    "                n_refs = b_idx\n",
    "\n",
    "        bib_to_contexts = utils.find_bib_context(xml)\n",
    "        bib_sorted = [\"b\" + str(ii) for ii in range(n_refs)]\n",
    "        \n",
    "        y_score = [0] * n_refs\n",
    "\n",
    "        assert len(sub_example_dict[cur_pid]) == n_refs\n",
    "        # continue\n",
    "\n",
    "        contexts_sorted = [\" \".join(bib_to_contexts[bib]) for bib in bib_sorted]\n",
    "        contexts_sorted = [clean_text_line(line) for line in contexts_sorted]  ## 清洗数据 \n",
    "\n",
    "        test_features = convert_examples_to_inputs(contexts_sorted, y_score, MAX_SEQ_LENGTH, tokenizer)\n",
    "        test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        predicted_scores = []\n",
    "        for step, batch in enumerate(test_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                r = model(input_ids, attention_mask=input_mask,token_type_ids=segment_ids, labels=label_ids)\n",
    "                tmp_eval_loss = r[0]\n",
    "                logits = r[1]\n",
    "\n",
    "            cur_pred_scores = logits[:, 1].to('cpu').numpy()\n",
    "            predicted_scores.extend(cur_pred_scores)\n",
    "        \n",
    "        for ii in range(len(predicted_scores)):\n",
    "            bib_idx = int(bib_sorted[ii][1:])\n",
    "            y_score[bib_idx] = float(utils.sigmoid(predicted_scores[ii]))\n",
    "        \n",
    "        sub_dict[cur_pid] = y_score\n",
    "    utils.dump_json(sub_dict, OUTPUT_DIR, f\"test_submission_{model_name}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b53c4-82b5-4ea7-8b2a-8b653748d7a8",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3c43f8-15ec-44bc-800c-6ac39c09c366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 15:32:19,494 loading paper_source_trace_test_wo_ans.json ...\n",
      "2024-06-12 15:32:19,503 paper_source_trace_test_wo_ans.json loaded\n",
      "2024-06-12 15:32:19,592 loading submission_example_test.json ...\n",
      "2024-06-12 15:32:19,595 submission_example_test.json loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name roberta-base\n",
      "device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./bert_models/dsp_roberta_base_dapt_cs_tapt_sciie_3219/ and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|                                                                                          | 0/394 [00:05<?, ?it/s]\n",
      "2024-06-12 15:32:25,457 dumping test_submission_roberta-base.json ...\n",
      "2024-06-12 15:32:25,459 test_submission_roberta-base.json dumped.\n",
      "2024-06-12 15:32:25,470 loading paper_source_trace_test_wo_ans.json ...\n",
      "2024-06-12 15:32:25,483 paper_source_trace_test_wo_ans.json loaded\n",
      "2024-06-12 15:32:25,573 loading submission_example_test.json ...\n",
      "2024-06-12 15:32:25,576 submission_example_test.json loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name roberta-base\n",
      "device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./bert_models/dsp_roberta_base_dapt_cs_tapt_sciie_3219/ and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|                                                                                          | 0/394 [00:03<?, ?it/s]\n",
      "2024-06-12 15:32:29,875 dumping test_submission_roberta-base.json ...\n",
      "2024-06-12 15:32:29,876 test_submission_roberta-base.json dumped.\n",
      "2024-06-12 15:32:29,882 loading paper_source_trace_test_wo_ans.json ...\n",
      "2024-06-12 15:32:29,890 paper_source_trace_test_wo_ans.json loaded\n",
      "2024-06-12 15:32:29,977 loading submission_example_test.json ...\n",
      "2024-06-12 15:32:29,979 submission_example_test.json loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name roberta-base\n",
      "device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./bert_models/dsp_roberta_base_dapt_cs_tapt_sciie_3219/ and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|                                                                                          | 0/394 [00:03<?, ?it/s]\n",
      "2024-06-12 15:32:34,569 dumping test_submission_roberta-base.json ...\n",
      "2024-06-12 15:32:34,570 test_submission_roberta-base.json dumped.\n",
      "2024-06-12 15:32:34,576 loading test_submission_roberta-base.json ...\n",
      "2024-06-12 15:32:34,577 test_submission_roberta-base.json loaded\n",
      "2024-06-12 15:32:34,577 loading test_submission_roberta-base.json ...\n",
      "2024-06-12 15:32:34,578 test_submission_roberta-base.json loaded\n",
      "2024-06-12 15:32:34,579 loading test_submission_roberta-base.json ...\n",
      "2024-06-12 15:32:34,579 test_submission_roberta-base.json loaded\n",
      "2024-06-12 15:32:34,580 dumping test_submission_roberta-base.json ...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'out/kddcup/roberta-base/num_fold=3/fold_final\\\\test_submission_roberta-base.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     sub_example_dict[key] \u001b[38;5;241m=\u001b[39m (sub_example_dict[key] \u001b[38;5;241m/\u001b[39m NFOLDS)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     24\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout/kddcup/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/num_fold=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNFOLDS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/fold_final\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_example_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mout/kddcup/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/num_fold=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mNFOLDS\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/fold_final\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_submission_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Code_HXL\\001_PST_biendata\\utils.py:28\u001b[0m, in \u001b[0;36mdump_json\u001b[1;34m(obj, wfdir, wfname)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump_json\u001b[39m(obj, wfdir, wfname):\n\u001b[0;32m     27\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdumping \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m, wfname)\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwfdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m wf:\n\u001b[0;32m     29\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(obj, wf, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m dumped.\u001b[39m\u001b[38;5;124m'\u001b[39m, wfname)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'out/kddcup/roberta-base/num_fold=3/fold_final\\\\test_submission_roberta-base.json'"
     ]
    }
   ],
   "source": [
    "for fold in range(NFOLDS):\n",
    "    gen_kddcup_test_submission_bert(fold, model_name=model_name)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "## 初始化 json 文件\n",
    "submit_data_dir = f'out/kddcup/{model_name}/num_fold={NFOLDS}/fold_{fold}'\n",
    "sub_example_dict = utils.load_json(submit_data_dir, f\"test_submission_{model_name}.json\")\n",
    "\n",
    "## 读取 剩余文件并进行 相加  \n",
    "for fold in range(1, NFOLDS): \n",
    "    ## 每次读取 \n",
    "    submit_data_dir = f'out/kddcup/{model_name}/num_fold={NFOLDS}/fold_{fold}'\n",
    "    sub_dict = utils.load_json(submit_data_dir, f\"test_submission_{model_name}.json\") \n",
    "    \n",
    "    ## 将 sub_dict[key] + sub_example_dict[key] \n",
    "    for key, value in sub_dict.items():\n",
    "        sub_example_dict[key] = np.add(sub_example_dict[key], value) \n",
    "\n",
    "## 进行均值处理  \n",
    "for key, value in sub_example_dict.items():\n",
    "    sub_example_dict[key] = (sub_example_dict[key] / NFOLDS).tolist()\n",
    "\n",
    "os.makedirs(f'out/kddcup/{model_name}/num_fold={NFOLDS}/fold_final', exist_ok=True)\n",
    "utils.dump_json(sub_example_dict, f'out/kddcup/{model_name}/num_fold={NFOLDS}/fold_final', f\"test_submission_{model_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afdf3a-6044-425d-be2b-7111fbffd7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
