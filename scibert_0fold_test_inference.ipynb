{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d79b278-6059-49f7-8e44-5d25bd8ed7be",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec03efe9-70a1-4193-87b1-7f2b4c804d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict as dd\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertForSequenceClassification, AutoModelForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers.optimization import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, average_precision_score\n",
    "import logging\n",
    "\n",
    "import utils\n",
    "import settings\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import gc\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from awp import AWP\n",
    "from PST_model import * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db278c8-1f2b-44a7-ae96-f8524c430d3a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c63a0e7-44b3-4cb9-98c1-e8ccdee23db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个字典来存储配置参数\n",
    "config_dict = {\n",
    "    \"GRADIENT_ACCUMULATION_STEPS\": 1,\n",
    "    \"NUM_TRAIN_EPOCHS\": 20,\n",
    "    \"LEARNING_RATE\": 2e-5,\n",
    "    \"WARMUP_PROPORTION\": 0.1,\n",
    "    \"MAX_GRAD_NORM\": 1000,\n",
    "    'differential_learning_rate': 5e-4,\n",
    "    'differential_learning_rate_layers': 'head',\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"seed\": 42,\n",
    "    \"MAX_SEQ_LENGTH\": 512,\n",
    "    'model_name': 'scibert',  # roberta-base, deberta-base, scibert\n",
    "    'clean_flag': True,\n",
    "    'train_mask': False,\n",
    "    'dist': 200,\n",
    "    'optim_strategy': 'normal',  # normal, llrd\n",
    "    'PATIENCE': 3,\n",
    "    'Debug': False,\n",
    "    'scheduler': 'cosine',  # linear, cosine\n",
    "    'amp': True,\n",
    "    'pool': 'ConcatPool', # WLP, GeM, Mean, ConcatPool, AP\n",
    "    'loss_function': 'CrossEntropy',\n",
    "    'BATCH_SIZE': 8,\n",
    "    'awp_enable': True,\n",
    "    'awp_start_epoch': 2,\n",
    "    'layer_start': 9,\n",
    "    'reinit_n_layers': 0,\n",
    "}\n",
    "\n",
    "# 将字典转换为 SimpleNamespace 对象\n",
    "cfg = SimpleNamespace(**config_dict)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg.device = device\n",
    "\n",
    "\n",
    "\n",
    "# 日志\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be0d36-f923-4775-a204-34b65bc03e8a",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ec86b0-2495-4bf2-95cc-a8fa9fcb4623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "class BertInputItem(object):\n",
    "    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "\n",
    "def random_masking(text, tokenizer, max_length=512, mask_ratio=0.15):\n",
    "    # 对文本进行分词\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # 确保分词后的序列长度小于最大序列长度\n",
    "    tokens = tokens[:(max_length - 2)]  # 减2是因为要加上[CLS]和[SEP]标记\n",
    "\n",
    "    # 计算需要掩码的Token数量\n",
    "    num_tokens = len(tokens)\n",
    "    num_to_mask = int(mask_ratio * num_tokens)\n",
    "\n",
    "    # 随机选择Token进行掩码\n",
    "    indices_to_mask = np.random.choice(range(num_tokens), num_to_mask, replace=False)\n",
    "\n",
    "    # 将选中的Token替换为[MASK]\n",
    "    for i in sorted(indices_to_mask, reverse=True):\n",
    "        tokens[i] = tokenizer.mask_token\n",
    "\n",
    "    # 添加BERT的序列标记\n",
    "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "\n",
    "    # 将Token转换为ID\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "def convert_examples_to_inputs(example_texts, example_labels, max_seq_length, tokenizer, mask, verbose=0):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    # print(f'Mask Flag:{mask}')\n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        # Create a list of token ids\n",
    "        # 分词和token化\n",
    "        # 随机掩码\n",
    "        if mask:\n",
    "            ratio = 0.15\n",
    "            input_ids = random_masking(text, tokenizer, max_seq_length, mask_ratio=ratio)\n",
    "            # print(f'Input have been masked with ratio {ratio}')\n",
    "        else:\n",
    "            input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "            if len(input_ids) > max_seq_length:\n",
    "                input_ids = input_ids[:max_seq_length]\n",
    "        # All our tokens are in the first input segment (id 0).\n",
    "        segment_ids = [0] * len(input_ids)  # 只有一个序列\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        # 确保序列长度一致\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_id))\n",
    "        \n",
    "    return input_items\n",
    "\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87387baf-6338-4d98-b80d-8c54348705b6",
   "metadata": {},
   "source": [
    "# Generate Test Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8742536e-0065-4529-a2d4-e190861cc7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_kddcup_test_submission_bert(cfg):\n",
    "    print(\"model name\", cfg.model_name)\n",
    "    print(f'The length of context text:{cfg.dist}')\n",
    "    cfg.class_weight = torch.Tensor([0.5500, 5.5000]).to(device)\n",
    "    data_dir = join(settings.DATA_TRACE_DIR, \"PST\")\n",
    "    papers = utils.load_json(data_dir, \"paper_source_trace_test_wo_ans.json\")  # 读取test paper id\n",
    "\n",
    "    if cfg.model_name == \"deberta-base\":\n",
    "        model_path = './bert_models/deberta_v3_base'\n",
    "\n",
    "    elif cfg.model_name == \"scibert\":\n",
    "        model_path = './bert_models/scibert_scivocab_uncased'\n",
    "\n",
    "    elif cfg.model_name == 'roberta-base':\n",
    "        model_path = './bert_models/dsp_roberta_base_dapt_cs_tapt_sciie_3219'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    sub_example_dict = utils.load_json(data_dir, \"submission_example_test.json\")  # 提交模板template\n",
    "    print(\"device\", cfg.device)\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = Net(cfg, model_path=model_path)\n",
    "    OUTPUT_DIR = join(settings.OUT_DIR, \"kddcup\", cfg.model_name, 'num_fold=0')\n",
    "    model.load_state_dict(torch.load(join(OUTPUT_DIR, \"pytorch_model.bin\")))\n",
    "    model.to(cfg.device)\n",
    "    model.eval()\n",
    "    xml_dir = join(data_dir, \"paper-xml\")\n",
    "    sub_dict = {}\n",
    "\n",
    "    for paper in tqdm(papers):\n",
    "        cur_pid = paper[\"_id\"]\n",
    "        file = join(xml_dir, cur_pid + \".xml\")\n",
    "        f = open(file, encoding='utf-8')\n",
    "        xml = f.read()\n",
    "        bs = BeautifulSoup(xml, \"xml\")\n",
    "        f.close()\n",
    "\n",
    "        references = bs.find_all(\"biblStruct\")\n",
    "        bid_to_title = {}\n",
    "        n_refs = 0\n",
    "        for ref in references:\n",
    "            if \"xml:id\" not in ref.attrs:\n",
    "                continue\n",
    "            bid = ref.attrs[\"xml:id\"]\n",
    "            if ref.analytic is None:\n",
    "                continue\n",
    "            if ref.analytic.title is None:\n",
    "                continue\n",
    "            bid_to_title[bid] = ref.analytic.title.text.lower()  # 标题\n",
    "            b_idx = int(bid[1:]) + 1\n",
    "            if b_idx > n_refs:\n",
    "                n_refs = b_idx\n",
    "\n",
    "        bib_to_contexts = utils.find_bib_context(xml, clean_flag=cfg.clean_flag, dist=cfg.dist)\n",
    "        bib_sorted = [\"b\" + str(ii) for ii in range(n_refs)]  # 按顺序的bid\n",
    "        \n",
    "        y_score = [0] * n_refs\n",
    "\n",
    "        assert len(sub_example_dict[cur_pid]) == n_refs\n",
    "        # continue\n",
    "\n",
    "        contexts_sorted = [\" \".join(bib_to_contexts[bib]) for bib in bib_sorted]\n",
    "\n",
    "        test_features = convert_examples_to_inputs(contexts_sorted, y_score, cfg.MAX_SEQ_LENGTH, cfg.tokenizer, mask=False)\n",
    "        test_dataloader = get_data_loader(test_features, cfg.MAX_SEQ_LENGTH, 64, shuffle=False)\n",
    "\n",
    "        predicted_scores = []\n",
    "\n",
    "        with torch.inference_mode(mode=True):\n",
    "            for step, batch in enumerate(test_dataloader):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                # input_ids, input_mask, segment_ids, label_ids = batch\n",
    "                inputs = {}\n",
    "                inputs['input_ids'] = batch[0]\n",
    "                inputs['attention_mask'] = batch[1]\n",
    "                inputs['segment_ids'] = batch[2]\n",
    "                inputs['target'] = batch[3]\n",
    "\n",
    "                with autocast():  # 放在循环内部\n",
    "                    output_dict = model(inputs)\n",
    "                    # tmp_eval_loss = r[0]\n",
    "                    logits = output_dict['logits']\n",
    "\n",
    "                cur_pred_scores = logits[:, 1].to('cpu').numpy()\n",
    "                predicted_scores.extend(cur_pred_scores)\n",
    "                del inputs\n",
    "                clean_memory()\n",
    "        for ii in range(len(predicted_scores)):\n",
    "            bib_idx = int(bib_sorted[ii][1:])\n",
    "            # print(\"bib_idx\", bib_idx)\n",
    "            y_score[bib_idx] = float(utils.sigmoid(predicted_scores[ii]))\n",
    "        \n",
    "        sub_dict[cur_pid] = y_score\n",
    "    utils.dump_json(sub_dict, OUTPUT_DIR, f\"test_submission_{cfg.model_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187705c2-06ab-48e1-91d1-0b93b2e357cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 15:24:12,422 loading paper_source_trace_test_wo_ans.json ...\n",
      "2024-06-12 15:24:12,431 paper_source_trace_test_wo_ans.json loaded\n",
      "2024-06-12 15:24:12,462 loading submission_example_test.json ...\n",
      "2024-06-12 15:24:12,464 submission_example_test.json loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "model name scibert\n",
      "The length of context text:200\n",
      "device cuda\n",
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "Linear(in_features=3072, out_features=2, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/394 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[0;32m      3\u001b[0m utils\u001b[38;5;241m.\u001b[39mseed_everything(cfg\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mgen_kddcup_test_submission_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mgen_kddcup_test_submission_bert\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# tmp_eval_loss = r[0]\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 85\u001b[0m cur_pred_scores \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     86\u001b[0m predicted_scores\u001b[38;5;241m.\u001b[39mextend(cur_pred_scores)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clean_memory()\n",
    "fold = 0 \n",
    "utils.seed_everything(cfg.seed)\n",
    "\n",
    "gen_kddcup_test_submission_bert(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0923490-b47e-4ec4-9771-8bc8227553bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a9e85-467d-4d72-a657-6e8f47f11902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
