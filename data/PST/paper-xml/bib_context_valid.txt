h is still a major obstacle to be overcome. So far, much of the current work on attacking graph neural networks has concentrated on node classification task [12]</ref>, [13]</ref>, [14]</ref>, [15]</ref>. In order to fool a classifier and misclassify specific nodes, attackers ence attack strategy is adopted.</p><p>In this paper, we focus on the targeted attack that aims to make a specific node (e.g., a person in social networks) misclassified. In this scenario, Dai et al. [13]</ref> study the adversarial attack on graph structure data and propose a gradient-based method, namely GradArgmax, which modifies links based on gradients of a surr a surrogate model despite being used frequently in previous works. Inspired by Simplified Graph Convolutional Network (SGC) [17]</ref> and gradient-based attack methods [13]</ref>, [15]</ref>, we propose a novel Simplified Gradient-based Attack (SGA) framework for effective and efficient adversarial attack of the existing models are optimized with gradient, along or against the direction of it is an efficient way to generate destructive adversarial examples. Focusing on the targeted attack, Dai et al. [13]</ref> propose GradArgmax, which extracts gradients of the surrogate model, and flips edges with the largest magnitude of the gradient to generate adversarial exampl mily</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Vanilla Graph Convolution Network (GCN)</head><p>Since a number of existing works [12]</ref>, [13]</ref>, [15]</ref>, [25]</ref> use vanilla GCN [8]</ref> as a surrogate m on the targeted attack in node classification task, here we briefly introduce other proposed state-of-the-art targeted attack methods: Nettack [12]</ref> and GradArgmax [13]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Nettack</head><p>Similar to SGC, Nettack uses a linear variant of two-layer GCN as a surro lity p 2 between attacker nodes and other nodes in the graph. Besides, there is a constraint that only nodes belonging to the same class/different classes will be disconnected/connected. • GradArgmax [13]</ref>. Since the attack budget ∆ is defined as the degrees of target node t, the original GradArgmax will remove all edges connected with t for direct attack, which
ead n="6.1">Experimental Settings</head><p>Datasets. We evaluate the performance of our method on four well-known datasets: Citeseer, Cora, Pubmed [39]</ref> and Reddit [40]</ref>. The first three are commonly citation networks on node classification tasks, where nodes are documents and edges among them are citation relations. The last ck on several commonly used graph neural networks: GCN [8]</ref>, SGC [17]</ref>, GAT [41]</ref>, GraphSAGE [40]</ref>, ClusterGCN [42]</ref>. For each target model, our method is compared with other adversarial attack methods.</p><p>• GCN <ref t </p><p>• GAT [41]</ref>. GAT enhances GCN by leveraging a masked self-attention mechanism to specifying different weights to different neighbor nodes.</p><p>• GraphSAGE [40]</ref>. GraphSAGE is a general inductive framework, which uniformly samples a set of neighbors with a fixed size, instead of using a full-neighborhood set during tra
methods. Despite the great success, deep learning models have been proved vulnerable against perturbations. Specifically, Szegedy et al. [3]</ref> and Goodfellow et al. [4]</ref> have found that deep learning models may be easily fooled, when a small perturbation (usually unnoticeable for humans) is applied to the images. The perturbed e d><p>Increasing attention has been paid on the robustness and security of deep learning models, there has been a surge of interests in the adversarial attacks [3]</ref>, [4]</ref>, [20]</ref>, [21]</ref>, [22]</ref>. The obtained results suggest t
cts of adversarial attacks on graph data. As the graph data is unable and meaningless to be converted to continuous form, the impacts on the graph data are unable to be measured with 2 -norm or ∞norm [16]</ref>, which is distinct from that on image data. This makes the evaluation of the attack impacts a difficult problem to solve.</p><p>In this work, we aim to tackle bility to avoid the detection. Unlike the continuous data that lies in Euclidean Space, attackers can evaluate the attack impacts by measuring the changes before and after attack via 2 norm or ∞ norm [16]</ref>. However, it is difficult to quantify the attack impacts on graph data that lies in such a non-Euclidean Space.</p><p>An important property of a graph is the
l. [15]</ref> utilize the metagradients to solve the bi-level problem underlying the challenge of poisoning attacks (a.k.a, training-time attacks). Similarly, Xu et al. [25]</ref> propose PGD structure attack that conducts gradient attacks from a perspective of first-order optimization.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0" ph Convolution Network (GCN)</head><p>Since a number of existing works [12]</ref>, [13]</ref>, [15]</ref>, [25]</ref> use vanilla GCN [8]</ref> as a surrogate model to conduct attacks, thus we first introduce GCN and further draw attention on SGC
"bibr" target="#b8">[9]</ref>. Undoubtedly, graph plays a crucial role in many high impact applications in the world [8]</ref>, [10]</ref>, [11]</ref>. Therefore, the importance of the robustness of deep learning models on graph data must not be emphasized too much. However, the adversarial examples do have
ests in the adversarial attacks [3]</ref>, [4]</ref>, [20]</ref>, [21]</ref>, [22]</ref>. The obtained results suggest that deep learning models are prone to adversarial examples and could be easily fooled by them even under restricted black-box a
ead n="6.1">Experimental Settings</head><p>Datasets. We evaluate the performance of our method on four well-known datasets: Citeseer, Cora, Pubmed [39]</ref> and Reddit [40]</ref>. The first three are commonly citation networks on node classification tasks, where nodes are documents and edges among them are citation relations. The last ck on several commonly used graph neural networks: GCN [8]</ref>, SGC [17]</ref>, GAT [41]</ref>, GraphSAGE [40]</ref>, ClusterGCN [42]</ref>. For each target model, our method is compared with other adversarial attack methods.</p><p>• GCN <ref t </p><p>• GAT [41]</ref>. GAT enhances GCN by leveraging a masked self-attention mechanism to specifying different weights to different neighbor nodes.</p><p>• GraphSAGE [40]</ref>. GraphSAGE is a general inductive framework, which uniformly samples a set of neighbors with a fixed size, instead of using a full-neighborhood set during tra
text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>R ECENTLY, with the enormous advancement of deep learning, many domains like speech recognition [1]</ref> and visual object recognition [2]</ref>, have achieved a dramatic improvement out of the state-of-the-art methods. Despite the gre
="bibr" target="#b7">[8]</ref>, [9]</ref>. Undoubtedly, graph plays a crucial role in many high impact applications in the world [8]</ref>, [10]</ref>, [11]</ref>. Therefore, the importance of the robustness of deep learning models on graph data must not be emphasized too much.
3">A (sub0) = A (sub) , V (sub0) = V (sub) , E (sub0) = E (sub) .</formula><p>At each time i+1, we flip one edge e = (u, v) ∈ E (subi) with largest magnitude of gradient that fullfils the constraints [35]</ref>: the edges connected to it should be considered as well.</p><formula xml:id="formula_24">Connect (u, v), if ∇ G (sub i ) &gt; 0 and A (subi) u,v = 0 Disconnec
in dynamics to sample from a sequence of decreasing noise scales during generation. Denoising diffusion probabilistic modeling (DDPM) (Sohl-Dickstein et al., 2015;</ref>Ho et al., 2020)</ref> trains a sequence of probabilistic models to reverse each step of the noise corruption, using knowledge of the functional form of the reverse dist s et al., 2017;</ref>Goyal et al., 2017)</ref>, have proven effective at generation of images (Song &amp; Ermon, 2019;</ref>2020;</ref>Ho et al., 2020)</ref>, audio (Chen et al., 2020;</ref>Kong et al., 2020)</ref>, graphs <ref type="bibr" tar sing a single unconditional score-based model without re-training.</p><p>Unified picture: The methods of SMLD and DDPM can be unified into our framework as discretizations of different SDEs. Although Ho et al. (2020)</ref> has reported higher sample quality than Song &amp; Ermon (2019;</ref>2020)</ref>, we show that with better archi to performing ancestral sampling from the graphical model ś N i"1 p θ px i´1 | x i q. The objective Eq. ( 3</ref>) described here is equivalent to L simple in Ho et al. (2020)</ref>, but we re-write it in a slightly different form to expose more similarity to Eq. (1). Like Eq. (1), Eq. ( <ref type="formula" target="#formula_3" ated in the same way (excluding models evaluated with variational dequantization (Ho et al., 2019)</ref> or discrete data). Main results: (i) For the same DDPM model in Ho et al. (2020)</ref>, we obtain better bits/dim compared to the upper bound given by ELBO, since our likelihoods are exact; (ii) Using the same architecture, we traine AR-10 is 10.23 (Song &amp; Ermon, 2020)</ref>, whereas for DDPM it is 3.17 (Ho et al., 2020)</ref>. With PC samplers and the same model architecture in Ho et al. (2020)</ref>, the gaps can be reduced, but score-based models trained with the VE SDE still perform slightly worse (see Tab. 1). This raises the question of wh min `tp βmax ´β min qqxdt `b βmin `tp βmax ´β min qdw,<label>(28)</label></formula><p>where xp0q " p data pxq. In our experiments, we let βmin " 0.1 and βmax " 20, which correspond to the settings in Ho et al. (2020)</ref>. The perturbation kernel is given by</p><formula xml:id="formula_36">p 0t pxptq | xp0qq " N ´xptq; e ´1 4 t 2 p βmax´βminq´1 2 t βmin xp0q, I ´Ie FLOW SAMPLING WITH BLACK-BOX ODE SOLVERS</head><p>For producing figures in Fig. 4</ref>, we use a DDPM model trained on 256 ˆ256 CelebA-HQ with the same settings in Ho et al. (2020)</ref>. We use the RK45 ODE solver (Dormand &amp; Prince, 1980)</ref> provided by scipy.integrate.solve_ivp in all cases. latent space manipulation in Fig. 7</ref>, including interpolation and temperature scaling. The model tested here is a DDPM model trained with the same settings in Ho et al. (2020)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 UNIQUELY IDENTIFIABLE ENCODING</head><p>As a sanity check, we train two models (deno e, the original ancestral sampler of Eq. ( 4</ref>) is essentially a different discretization to the same reverse-time SDE. This unifies the sampling method in Ho et al. (2020)</ref> as a numerical solver to the reverse-time VP SDE in our continuous framework.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F ANCESTRAL 0 Ñ x 1 Ñ ¨¨¨Ñ x N , where</p><formula xml:id="formula_54">ppx i | x i´1 q " N px i ; x i´1 , pσ 2 i ´σ2 i´1 qIq, i " 1, 2, ¨¨¨, N.</formula><p>Here we assume σ 0 " 0 to simplify notations. Following Ho et al. (2020)</ref>, we can compute</p><formula xml:id="formula_55">qpx i´1 | x i , x 0 q " N ˆxi´1 ; σ 2 i´1 σ 2 i x i `´1 ´σ2 i´1 σ 2 i ¯x0 , σ 2 i´1 pσ 2 i ´σ2 i´1 `σi z. We can therefore parameterize µ θ px i , iq via</p><formula xml:id="formula_57">µ θ px i , iq " x i `pσ 2 i ´σ2 i´1 qs θ px i , iq,</formula><p>where s θ px i , iq is to estimate z{σ i . As in Ho et al. (2020)</ref>, we let τ i "</p><formula xml:id="formula_58">c σ 2 i´1 pσ 2 i ´σ2 i´1 q σ 2 i .</formula></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Th estral sampling method for SMLD models.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>G ADDITIONAL DETAILS ON PREDICTOR-CORRECTOR SAMPLERS</head><p>Training We use the same architecture in Ho et al. (2020)</ref> for our score-based models. For the VE SDE, we train a model with the original SMLD objective in Eq. ( 1</ only sampler using 2000 steps) which requires 2000 noise scales, we need to interpolate between 1000 noise scales at test time. The specific architecture of the noise-conditional score-based model in Ho et al. (2020)</ref> uses sinusoidal positional embeddings for conditioning on integer time steps. This allows us to interpolate between noise scales at test time in a on their FID scores averaged over checkpoints after 0.5M iterations. The FIDs are computed on 50k samples with TF-GAN. For sampling, we use the PC sampler discretized at 1000 noise scales. We follow Ho et al. (2020)</ref> for optimization, including the learning rate, gradient clipping, and learning rate warm-up schedules. Unless otherwise noted, all models are trai Unless otherwise noted, all models are trained with the original SMLD objective Eq. ( 1</ref>) and use a batch size of 128. Our architecture is mostly based on Ho et al. (2020)</ref>. We additionally search over the following components to explore the potential of score-based models trained with VE perturbations.</p><p>• Upsamp al blocks achieves an FID of 2.45 on CIFAR-10. Here in order to match the convention used in Karras et al. (2018)</ref>; Song &amp; Ermon (2019)</ref>; Ho et al. (2020)</ref>, the FID value here is the lowest over the course of training, rather than the average over checkpoints after 0.5M iterations (as done in our arch re, and should be jointly tuned as part of the design choices.</p><p>To further improve the NCSN++ model upon conditioning on continuous time variables, we change positional embeddings, the layers in Ho et al. (2020)</ref> for conditioning on discrete time steps, to random Fourier feature embeddings, as advocated in Tancik et al. (2020) ype="bibr">(Chen et al., 2019)</ref> 3.28 46.37 FFJORD (Grathwohl et al., 2018)</ref> 3.40 -Flow++ (Ho et al., 2019)</ref> 3.29 -DDPM (L) (Ho et al., 2020)</ref> ď 3.70 13.51 DDPM (Lsimple) (Ho et al., 2020)</ref> ď 3.75 3.17   (Song &amp; Ermon, 2019)</ref> 4">(Grathwohl et al., 2018)</ref> 3.40 -Flow++ (Ho et al., 2019)</ref> 3.29 -DDPM (L) (Ho et al., 2020)</ref> ď 3.70 13.51 DDPM (Lsimple) (Ho et al., 2020)</ref> ď 3.75 3.17   (Song &amp; Ermon, 2019)</ref> 25.32 8.87 ˘.12 NCSNv2 (Song &amp; Ermon, 2020)</ref> 10.87 8.40 ˘ ="bibr" target="#b17">(Ho et al., 2020)</ref> ď 3.75 3.17   (Song &amp; Ermon, 2019)</ref> 25.32 8.87 ˘.12 NCSNv2 (Song &amp; Ermon, 2020)</ref> 10.87 8.40 ˘.07 DDPM (Ho et al., 2020)</ref> 3.17 9.46 ˘.11 Exact likelihood computation Leveraging the connection to neural ODEs, we can compute the density defined by Eq. ( <ref type="form framework, there is a performance gap reported in previous papers. The best FID values of SMLD models on CIFAR-10 is 10.23 (Song &amp; Ermon, 2020)</ref>, whereas for DDPM it is 3.17 (Ho et al., 2020)</ref>. With PC samplers and the same model architecture in Ho et al. (2020)</ref>, the gaps can be reduced, but score-ba sampling methods (that are based on the discretization strategy in Eq. ( 41</ref>)) reverse diffusion samplers.</p><p>Note that the ancestral sampling of DDPM (Ho et al., 2020)</ref> (Eq. ( 4</ref>)) matches its reverse diffusion counterpart when β i Ñ 0 for all i (which happens when ∆t

downsampling images with anti-aliasing based on Finite Impulse Response (FIR) (Zhang, 2019)</ref>. We follow the same implementation and hyper-parameters in StyleGAN-2 (Karras et al., 2020b)</ref>. • Rescaling all skip connections by 1 { ? 2. This has been demonstrated effective in several works, including ProgressiveGAN <ref type="bib

downsampling images with anti-aliasing based on Finite Impulse Response (FIR) (Zhang, 2019)</ref>. We follow the same implementation and hyper-parameters in StyleGAN-2 (Karras et al., 2020b)</ref>. • Rescaling all skip connections by 1 { ? 2. This has been demonstrated effective in several works, including ProgressiveGAN <ref type="bib

e="bibr">2020;</ref>Ho et al., 2020)</ref>, audio (Chen et al., 2020;</ref>Kong et al., 2020)</ref>, graphs (Niu et al., 2020)</ref>, and shapes (Cai et al., 2020)</ref>. However, the ˚Work done during an internship at Google Brain. practical perf

/ref>, audio (Chen et al., 2020;</ref>Kong et al., 2020)</ref>, graphs (Niu et al., 2020)</ref>, and shapes (Cai et al., 2020)</ref>. However, the ˚Work done during an internship at Google Brain. practical performance of these two model classes is often quite different for reas
following components to explore the potential of score-based models trained with VE perturbations.</p><p>• Upsampling and downsampling images with anti-aliasing based on Finite Impulse Response (FIR) (Zhang, 2019)</ref>. We follow the same implementation and hyper-parameters in StyleGAN-2 (Karras et al., 2020b)</ref>. • Rescaling all sk
get="#b24">(Kingma &amp; Dhariwal, 2018)</ref> 3.35 -MintNet (Song et al., 2019b)</ref> 3.32 -Residual Flow (Chen et al., 2019)</ref> 3.28 46.37 FFJORD (Grathwohl et al., 2018)</ref> 3.40 -Flow++ (Ho et al., 2019)</ref> 3.29 -DDPM (L) (Ho et al., 2020)</ref> tq as a function of t can be obtained by solving the probability flow ODE in Eq. ( 33</ref>). In many cases computing ∇ ¨f θ px, tq is expensive, so we follow Grathwohl et al. (2018)</ref> to estimate it with the Skilling-Hutchinson trace estimator (Skilling, 1989;</ref><ref type="bibr" target="# (Dormand &amp; Prince, 1980)</ref> provided by scipy.integrate.solve_ivp in all cases. The bits/dim values in Tab. 2 are computed with atol=1e-5 and rtol=1e-5, same as Grathwohl et al. (2018)</ref>. To give the results for DDPM (probability flow) and DDPM cont. (probability flow) in Tab. 2, we average the bits/dim obtained on the test
oes not use a denoising step at the end of sampling, while the latter does. In all experiments of this paper we ensure there is a single denoising step at the end of sampling, using Tweedie's formula (Efron, 2011)</ref>.</p><p>Ad-hoc interpolation methods for noise scales Models in this experiment are all trained with 1000 noise scales. To get results for P2000 (pred
CSN++ on CIFAR-10, we proceed to test it on 1024 ˆ1024 CelebA-HQ (Karras et al., 2018)</ref>, a task that was previously only achievable by some GAN models and VQ-VAE-2 (Razavi et al., 2019)</ref>. We used a batch size of 8, increased the EMA rate to 0.9999, and trained the NCSN++ model with the continuous objective (Eq. ( <ref type="fo
e="bibr">2020;</ref>Ho et al., 2020)</ref>, audio (Chen et al., 2020;</ref>Kong et al., 2020)</ref>, graphs (Niu et al., 2020)</ref>, and shapes (Cai et al., 2020)</ref>. However, the ˚Work done during an internship at Google Brain. practical perf


ion abilities to the family of score-based generative models.</p><p>While our proposed sampling approaches improve results and enable more efficient sampling, they remain slower at sampling than GANs (Goodfellow et al., 2014)</ref> on the same datasets. Identifying ways of combining the stable learning of score-based generative models with the fast sampling of implic
following components to explore the potential of score-based models trained with VE perturbations.</p><p>• Upsampling and downsampling images with anti-aliasing based on Finite Impulse Response (FIR) (Zhang, 2019)</ref>. We follow the same implementation and hyper-parameters in StyleGAN-2 (Karras et al., 2020b)</ref>. • Rescaling all sk

s expensive, so we follow Grathwohl et al. (2018)</ref> to estimate it with the Skilling-Hutchinson trace estimator (Skilling, 1989;</ref>Hutchinson, 1990)</ref>.</p><p>In particular, we have</p><formula xml:id="formula_42">∇ ¨f θ px, tq " E pp q r T ∇ fθ px, tq s,<label>(35)</label></formula><p>where ∇ fθ
="bibr" target="#b21">(Karras et al., 2019)</ref> and StyleGAN-2 (Karras et al., 2020b)</ref>.</p><p>• Replacing the original residual blocks in DDPM with residual blocks from BigGAN (Brock et al., 2018)</ref>. • Increasing the number of residual blocks per resolution from 2 to 4.</p><p>• Incorporating progressive growing architectures. We consider tw
get="#b24">(Kingma &amp; Dhariwal, 2018)</ref> 3.35 -MintNet (Song et al., 2019b)</ref> 3.32 -Residual Flow (Chen et al., 2019)</ref> 3.28 46.37 FFJORD (Grathwohl et al., 2018)</ref> 3.40 -Flow++ (Ho et al., 2019)</ref> 3.29 -DDPM (L) (Ho et al., 2020)</ref> tq as a function of t can be obtained by solving the probability flow ODE in Eq. ( 33</ref>). In many cases computing ∇ ¨f θ px, tq is expensive, so we follow Grathwohl et al. (2018)</ref> to estimate it with the Skilling-Hutchinson trace estimator (Skilling, 1989;</ref><ref type="bibr" target="# (Dormand &amp; Prince, 1980)</ref> provided by scipy.integrate.solve_ivp in all cases. The bits/dim values in Tab. 2 are computed with atol=1e-5 and rtol=1e-5, same as Grathwohl et al. (2018)</ref>. To give the results for DDPM (probability flow) and DDPM cont. (probability flow) in Tab. 2, we average the bits/dim obtained on the test
r" target="#b20">[21]</ref> nor the maximum likelihood estimation (MLE) method for existing invertible neural networks [15,</ref>16,</ref>29,</ref>4]</ref> could achieve our goal, since the model distribution doesn't exist here, meanwhile these methods don't guide the distribu lns="http://www.tei-c.org/ns/1.0"><head n="2.2">Invertible Neural Network</head><p>The invertible neural network (INN) [15,</ref>16,</ref>29,</ref>32,</ref>22,</ref>8,</ref>13]</ref> i (MLE), i.e., max ? E q(x) [log f -1 ? # [p(y, z)]], which is widely adopted by prevalent flow-based generative models [15,</ref>16,</ref>29,</ref>4]</ref>. It is equivalent to minimizing the Kullback-Leibler (KL) divergence KL(q(x), f -1 ? # [p(y, z)]). The mentioned models e
nterpart can significantly save the storage, efficiently utilize the bandwidth [12,</ref>37,</ref>54,</ref>48,</ref>34]</ref> and easily fit for screens with different resolution while maintaining visually valid information <ref type="bibr" targ
lknown as a non-injective mapping, meaning that there could exist multiple possible HR images resulting in the same downscaled LR image. Hence, this inverse task is usually considered to be ill-posed [24,</ref>55,</ref>17]</ref>.</p><p>Many efforts have been made to mitigate this ill-posed problem, but the
ood method for training. Due to such flexibility, INN architectures are also used for many variational inference tasks [44,</ref>30,</ref>10]</ref>.</p><p>INN is composed of invertible blocks. In this study, we employ the invertible architecture in [16]</ref>. For the l-th blo
n. Normally, these methods suffer from resulting over-smoothed images since the high-frequency details are suppressed. Therefore, several detail-preserving or structurally similar downscaling methods [31,</ref>42,</ref>51,</ref>52,</ref>38]</ref
igh-frequency details are suppressed. Therefore, several detail-preserving or structurally similar downscaling methods [31,</ref>42,</ref>51,</ref>52,</ref>38]</ref> are proposed recently. Besides those perceptual-oriented downscaling methods, i ef>, and Urban100 [23]</ref>. Following the setting in [36]</ref>, we quantitatively evaluate the peak noise-signal ratio (PSNR) and SSIM [51]</ref> on the Y channel of images represented in the YCbCr (Y, Cb, Cr) color space. Due to space constraint, we leave training strategy details in the appendix. ? ML
ood method for training. Due to such flexibility, INN architectures are also used for many variational inference tasks [44,</ref>30,</ref>10]</ref>.</p><p>INN is composed of invertible blocks. In this study, we employ the invertible architecture in [16]</ref>. For the l-th blo
n. Normally, these methods suffer from resulting over-smoothed images since the high-frequency details are suppressed. Therefore, several detail-preserving or structurally similar downscaling methods [31,</ref>42,</ref>51,</ref>52,</ref>38]</ref
nterpart can significantly save the storage, efficiently utilize the bandwidth [12,</ref>37,</ref>54,</ref>48,</ref>34]</ref> and easily fit for screens with different resolution while maintaining visually valid information <ref type="bibr" targ

ersarial training techniques of generative adversarial nets (GANs) [21]</ref> nor the maximum likelihood estimation (MLE) method for existing invertible neural networks [15,</ref>16,</ref>29,</ref>4]</ref> could achieve our goal, since the model ications and the task is to generate new HR images for LR ones.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Invertible Neural Network</head><p>The invertible neural network (INN) [15,</ref>16,</ref>29,</ref>32,</ref>22,</ref eature maps after the Haar Transformation as input, a stack of InvBlocks is used to further abstract the LR and latent representations. We leverage the general coupling layer architecture proposed in [15,</ref>16]</ref>, i.e. Eqs. (1,</ref>3)</ref>.</p><p>Utilizing the coupling label></formula><p>A related training method is the maximum likelihood estimation (MLE), i.e., max ? E q(x) [log f -1 ? # [p(y, z)]], which is widely adopted by prevalent flow-based generative models [15,</ref>16,</ref>29,</ref>4]</ref>. It is equivalent to minimizing the Kull ble architecture in [16]</ref>. For the l-th block, input h l is split into h l 1 and h l 2 along the channel axis, and they undergo the additive affine transformations [15]</ref>:</p><formula xml:id="formula_0">h l+1 1 = h l 1 + ?(h l 2 ), h l+1 2 = h l 2 + ?(h l+1 1 ),<label>(1)</label></formula><p>where ?, ? are arbitrary functions.
the available ARM technology. This approach offers a scalable system with minimal performance loss due to maintaining cache coherency. A notable proposed scalable system architecture is described in [34]</ref> in which, NAND flash is used as main memory technology and DRAM as a cache for flash, allowing a substantial increase in main memory capacity with negligible
ss mature of the non volatile Memory technologies due to its physical nature, can offer higher density but non uniform access latency. Other promising technologies include CeRam, nanotube or Skyrmion [52]</ref> based devices.</p><p>Currently, processors do not uniformly have native provision for the persistence in main memory which is a trait of NVM. Assuming that fu
cing the overall overhead. Over the years, the pure software and language implementations of DSM systems focused on reducing memory update cost for increased system scalability whereas virtualization [61]</ref> was utilized to share the available resources for increased flexibility. In the first examples where the DSM moved into the hypervisor it simply presented rem
ss mature of the non volatile Memory technologies due to its physical nature, can offer higher density but non uniform access latency. Other promising technologies include CeRam, nanotube or Skyrmion [52]</ref> based devices.</p><p>Currently, processors do not uniformly have native provision for the persistence in main memory which is a trait of NVM. Assuming that fu
of performance compared to conventional DRAM [74]</ref>, [10]</ref>. On the other hand, new interfaces such as High Bandwidth Memory (HBM) [36]</ref>  [58]</ref> and Hybrid Memory Cube (HMC) [60]</ref>  [66]</ref> o
to be occupied by ReRAM logic, directly pointing to the need for designing much larger cores, a task that is already difficult as we already described in Section 2.1.</p><p>Phase Change Memory (PCM) [63]</ref> offers higher memory density but also higher write latency and low endurance, however, as this is a significant research area, newer technologies such as Doma
to be occupied by ReRAM logic, directly pointing to the need for designing much larger cores, a task that is already difficult as we already described in Section 2.1.</p><p>Phase Change Memory (PCM) [63]</ref> offers higher memory density but also higher write latency and low endurance, however, as this is a significant research area, newer technologies such as Doma
e high speed serial I/O already present.</p><p>Research has shown that NV Main Memory (NVMM) improves application performance significantly over flash-based SSDs and HDDs, without application changes [76]</ref>. Table 1</ref> summarizes the characteristics of NVM technologies, compared to DRAM [51]</ref ement Unit (SMMU)</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of Memory technologies properties[76]</ref>. We can see the larger density supported by NVMs over DRAM. Other NVMs include the Memristor, STTM, FeRAM, and MRAM..</figDesc><table><row><cell></cell><cell>
in favour of the processor resulting in performance losses due to processor data starvation. Caches fill the gap between the slower main memory and the large data capacity demands of the applications [37]</ref>, but due to the relative limited size of caches, memory accesses are still very frequent with applications often still requiring to access a byte of memory fo
n significantly accelerate data movement, and has also implemented additional features (such as transfer QoS) [31]</ref>  [45]</ref> [59] [44]</ref>  [48]</ref>. The majority of data-centre applications are I/O [11]</ref> and memory-bound <ref t
t="#b71">[72]</ref>, that can benefit from hardware accelerated interconnect, with explicit data referencing semantics of a shared memory system. Examples of such implementations include, BXI by Atos [26]</ref> and ConnectX by Mellanox [73]</ref>, that combine proprietary interconnects and hardware primitives that can be mapped directly
inst the Minnesota Timberwolves . On February 3 , 2012 , he was named to the 2012 All -NBA First Team . On March 7 , 2012 , he was named one of five finalists for the Naismith Award , which is 0.064  (Baevski and Auli, 2019;</ref>Radford et al., 2019)</ref>. We perform experiments at the word level.</p><p>Training We train on fixed-lengt
on (Fan et al., 2018)</ref>, contextual text completion (Radford et al., 2019)</ref>, language modeling (for k = 0), and dialogue modeling (Zhang et al., 2018)</ref> where x 1:k is a dialogue history and a continuation is a next utterance.</p><p>Given p θ and a prefix x 1:k , finding the optimal continuatio
a set of human-generated utterances and model-generated responses indicate a discrepancy between the human and model word distributions. This does not appear to be rectified by training on more data (Radford et al., 2019)</ref>. Recent fixes involve modifying the decoding strategy using sampling or more sophisticated beam search variants. However, these decoding str ribution and level of repetition in model generations compared to human text. These issues are not remedied by simply increasing the amount of the training data; e.g. largescale GPT-2 language models (Radford et al., 2019)</ref> display the same issues.</p><p>Improved Decoding Algorithms Several methods have been proposed to rectify these issues. The primary ones inv vior of neural language models due to its generality. For instance, sequence completion encompasses story generation (Fan et al., 2018)</ref>, contextual text completion (Radford et al., 2019)</ref>, language modeling (for k = 0), and dialogue modeling (Zhang et al., 2018)</ref> where x 1:k is a dialogue hi ecially with deterministic decoding. The problem is seen by observing samples in Appendix Table 4</ref>, which</p><p>shows completions from the state-of-the-art GPT-2 language model (Radford et al., 2019)</ref>. Greedy decoding as well as top-k and nucleus sampling exhibit degenerate repetition (with a certain hyperparameter setting), although greed ates. This indicates that the proposed sequence-level fine-tuning can be a cheap, effective way to improve existing pre-trained language models. We demonstrate this by fine-tuning a pre-trained GPT-2 (Radford et al., 2019)</ref> language model with sequence-level unlikelihood, using a comparable experimental setup to §6 (details in Appendix C). Fine-tuning with unlik luation, being superior to the current state-of-the-art approaches.</p><p>Table 4</ref>: Top: Degenerate repetition in completions from a state-of-the-art large-scale language model (Radford et al., 2019)</ref>. The examples contain single-word repetitions, phrase-level repetitions, and structural repetitions where some tokens within a repeating phr aevski and Auli (2019) but with standard embedding and softmax layers. Our proposed method is architecture agnostic; we choose this one as a representative of recent large-scale language models, e.g. Radford et al. (2019)</ref>. LUL-token+seq , and German . In the first verse , the protagonist sings about being a " girl who 's been in love with someone else " , while was named to the 2012 All -NBA First Team . On March 7 , 2012 , he was named one of five finalists for the Naismith Award , which is 0.064  (Baevski and Auli, 2019;</ref>Radford et al., 2019)</ref>. We perform experiments at the word level.</p><p>Training We train on fixed-length contiguous sequences, in our case of length 1,536, which w
search have been explored (Li et al., 2016;</ref>Vijayakumar et al., 2018;</ref>Kulikov et al., 2018;</ref>Holtzman et al., 2018)</ref> which can decrease a model's level of repetition by selecting candidates that are unlike previously chosen ones. Separately, hard or soft bea
>INTRODUCTION</head><p>Neural text generation is a vital tool in a wide range of natural language applications. However, the standard approach -training a sequence to sequence model, e.g. Transformer (Vaswani et al., 2017)</ref>, to maximize log-likelihood and approximately decoding the most likely sequence -is known to be flawed. Generated text in open-ended applica ref type="foot" target="#foot_1">2</ref> </p><p>Model Architecture Recent large-scale language models are based on the Transformer architecture, a multi-layer feed-forward network with self-attention (Vaswani et al., 2017)</ref>. We use a 16-layer Transformer with 8 attention heads, embedding dimension 1024, and fully-connected dimension 4096; the architecture is bas
ote xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Code and trained models are available at https://github.com/facebookresearch/ unlikelihood_training; implemented with Fairseq(Ott et al., 2019)</ref>.</note> 		</body> 		<back> 			<div type="references">  				<listBibl>  <biblStruct xml:id="b0"> 	<analytic> 		<title level="a" type="main">Adapt
>INTRODUCTION</head><p>Neural text generation is a vital tool in a wide range of natural language applications. However, the standard approach -training a sequence to sequence model, e.g. Transformer (Vaswani et al., 2017)</ref>, to maximize log-likelihood and approximately decoding the most likely sequence -is known to be flawed. Generated text in open-ended applica ref type="foot" target="#foot_1">2</ref> </p><p>Model Architecture Recent large-scale language models are based on the Transformer architecture, a multi-layer feed-forward network with self-attention (Vaswani et al., 2017)</ref>. We use a 16-layer Transformer with 8 attention heads, embedding dimension 1024, and fully-connected dimension 4096; the architecture is bas
search have been explored (Li et al., 2016;</ref>Vijayakumar et al., 2018;</ref>Kulikov et al., 2018;</ref>Holtzman et al., 2018)</ref> which can decrease a model's level of repetition by selecting candidates that are unlike previously chosen ones. Separately, hard or soft bea
#fig_0">1</ref>). Such behavior has been linked to generations being judged as dull by humans because rare words can add engaging specificity (Weston et al., 2018;</ref>See et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">THE UNLIKELIHOOD TRAINING OBJECTIVE</head><p>We now describe unlikelihood trainin
target="#b10">(Holtzman et al., 2019)</ref> rather than a modeling deficiency, or that (iii) a training objective relying on fixed corpora cannot take into account the real goal of using the language (Choi, 2018)</ref>. Our work shows that, while the above may be factors, a primary factor is the use of the likelihood objective itself, as we demonstrate that degenerati
a set of human-generated utterances and model-generated responses indicate a discrepancy between the human and model word distributions. This does not appear to be rectified by training on more data (Radford et al., 2019)</ref>. Recent fixes involve modifying the decoding strategy using sampling or more sophisticated beam search variants. However, these decoding str ribution and level of repetition in model generations compared to human text. These issues are not remedied by simply increasing the amount of the training data; e.g. largescale GPT-2 language models (Radford et al., 2019)</ref> display the same issues.</p><p>Improved Decoding Algorithms Several methods have been proposed to rectify these issues. The primary ones inv vior of neural language models due to its generality. For instance, sequence completion encompasses story generation (Fan et al., 2018)</ref>, contextual text completion (Radford et al., 2019)</ref>, language modeling (for k = 0), and dialogue modeling (Zhang et al., 2018)</ref> where x 1:k is a dialogue hi ecially with deterministic decoding. The problem is seen by observing samples in Appendix Table 4</ref>, which</p><p>shows completions from the state-of-the-art GPT-2 language model (Radford et al., 2019)</ref>. Greedy decoding as well as top-k and nucleus sampling exhibit degenerate repetition (with a certain hyperparameter setting), although greed ates. This indicates that the proposed sequence-level fine-tuning can be a cheap, effective way to improve existing pre-trained language models. We demonstrate this by fine-tuning a pre-trained GPT-2 (Radford et al., 2019)</ref> language model with sequence-level unlikelihood, using a comparable experimental setup to §6 (details in Appendix C). Fine-tuning with unlik luation, being superior to the current state-of-the-art approaches.</p><p>Table 4</ref>: Top: Degenerate repetition in completions from a state-of-the-art large-scale language model (Radford et al., 2019)</ref>. The examples contain single-word repetitions, phrase-level repetitions, and structural repetitions where some tokens within a repeating phr aevski and Auli (2019) but with standard embedding and softmax layers. Our proposed method is architecture agnostic; we choose this one as a representative of recent large-scale language models, e.g. Radford et al. (2019)</ref>. LUL-token+seq , and German . In the first verse , the protagonist sings about being a " girl who 's been in love with someone else " , while was named to the 2012 All -NBA First Team . On March 7 , 2012 , he was named one of five finalists for the Naismith Award , which is 0.064  (Baevski and Auli, 2019;</ref>Radford et al., 2019)</ref>. We perform experiments at the word level.</p><p>Training We train on fixed-length contiguous sequences, in our case of length 1,536, which w
samples, which may cause the model hard to tune. How to generate training samples effectively is still a challenge for training diversification models.</p><p>To tackle this problem, inspired by IRGAN [19]</ref>, we introduce Generative Adversarial Network (GAN) [10]</ref> into search result diversification. Generator generates negative t target="#b12">[13]</ref> introduces the GAN to the text sequence generation area combined with Monte Carlo search. It is also used in the traditional information retrieval area, Wang proposed IR-GAN [19]</ref> which consists of two information retrieval models in it. Comparing to other information retrieval models, IRGAN's generator can provide negative training sam ability calculated by:</p><formula xml:id="formula_7">𝐷 𝜙 (𝑑 |𝑞, 𝑆) = 𝜎 𝑓 𝜙 (𝑑 |𝑞, 𝑆) = exp(𝑓 𝜙 (𝑑 |𝑞, 𝑆)) 1 + exp(𝑓 𝜙 (𝑑 |𝑞, 𝑆)) .<label>(7)</label></formula><p>Please note that different from IRGAN [19]</ref>, DVGAN-doc has an additional component 𝑆 to represent the former selected documents.</p><p>As 𝑆 contain order information, it is required to be ranked.</p></d ></formula><p>3.2.2 Optimizing Generator. As GAN is put into practice in the contiguous area firstly, it is difficult to calculate the generator gradient due to its discrete nature. Inspired by IRGAN [19]</ref>, we generate negative document set 𝐷 ′ by selecting the documents from the candidate document set with the highest scores. Formally, the gradient of the gener
nderlying an ambiguous or a broad query. In recent years, many search result diversification approaches have been proposed [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</re type="bibr" target="#b25">[26]</ref>, PAMM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref>18,</ref>25]</ref> stress the relevance between the docume fication is an effective way to solve the problem of query ambiguity, many models have been proposed to solve this problem [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</re milarities between documents, explicit approaches regard the query as several subtopics, and explicitly leverage subtopics to determine the diversity of results [6,</ref>12,</ref>17,</ref>18]</ref>. Most explicit approaches focus on the subtopic coverage of results, by calcula type="bibr" target="#b17">18]</ref> and PM2 [5,</ref>6,</ref>9]</ref> and supervised approaches such as DSSA [12]</ref>.</p><p>Studies have shown that supervised approaches [12,</ref>23,</ref><ref type="bibr" target= ts not covering the subtopics. PM2 [6]</ref> is another unsupervised explicit method calculating the distribution by counting the relevant document of the subtopic. DSSA [12]</ref> introduces the machine learning method into explicit approaches. It calculates the distribution using the RNN and attention mechanism <ref type="bibr" target= available documents based on the query 𝑞 and the selected document ranking 𝑆 or the candidate document 𝐶 to fool the discriminator. So it also needs a score function. In our method we adapt the DSSA [12]</ref> score function for the generator. We introduce the score function in the form of Eq. ( 2</ref>):</p><formula xml:id="formula_18">𝑓 𝜃 (𝑑 𝑡 former section. We use the generator as the model to generate the final document ranking result.</p><p>In the training process, we first train R-LTR [26]</ref> and DSSA [12]</ref> respectively using MLE loss in both ways. It is because our framework needs a warm start to avoid the deviation in the training process. Then we train them by "bibr" target="#b21">[22]</ref>, R-LTR [26]</ref>, PAMM [6]</ref>, R-LTR-NTN, PAMM-NTN [24]</ref>, and DSSA [12]</ref> as supervised baseline methods. Top 20 results of Lemur are used to train the supervised methods. Top 50(𝑍 ) results of Lemur are used for diversity re-rankin 1 to 10.</p><p>DSSA. DSSA is the supervised explicit method. We use LSTM [8]</ref> as the RNN cell for comparison. In our experiments, we conduct the list-pairwise loss [12]</ref> to train DSSA method. The feature vector 1 http://playbigdata.ruc.edu.cn/dou/hdiv/ 2 Lemur service: http://boston.lti.cs.cmu.edu/Services/clueweb09 batch/ is bibr" target="#b5">6,</ref>9]</ref> and supervised approaches such as DSSA [12]</ref>.</p><p>Studies have shown that supervised approaches [12,</ref>23,</ref>24,</ref>26</ref>] are able to outperform the heuristic a
In recent years, many search result diversification approaches have been proposed [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</r MM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref>18,</ref>25]</ref> stress the relevance between the documents and the subtopics of the query, whic e problem of query ambiguity, many models have been proposed to solve this problem [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</r pproaches regard the query as several subtopics, and explicitly leverage subtopics to determine the diversity of results [6,</ref>12,</ref>17,</ref>18]</ref>. Most explicit approaches focus on the subtopic coverage of results, by calculating subtopic distribution based on rank pic distribution measures and document-subtopic relevance measures. Similar to implicit approaches, explicit diversification approaches can also be categorized into heuristic approaches such as xQuAD [17,</ref>18]</ref> and PM2 [5,</ref>6,</ref>9]<
ersification approaches have been proposed [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref>18,</ref>25]</ref> stress the relevance between the documents and the subtopics of the query, which infers that the selected document shou s have been proposed to solve this problem [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ btopic relevance measures. Similar to implicit approaches, explicit diversification approaches can also be categorized into heuristic approaches such as xQuAD [17,</ref>18]</ref> and PM2 [5,</ref>6,</ref>9]</ref> and supervised approaches such as D ype="bibr" target="#b23">24,</ref>26</ref>] are able to outperform the heuristic approaches [1,</ref>6,</ref>18]</ref> by learning an optimized ranking function. However, the large number of candidate documents with only few subtopic-relevant documents in it may cause the probl btopics, and explicitly leverage subtopics to determine the diversity of results [6,</ref>12,</ref>17,</ref>18]</ref>. Most explicit approaches focus on the subtopic coverage of results, by calculating subtopic distribution based on ranked documents. The score function for exp ontains the document-subtopic information of previous documents. The 𝑆 rel function reflects the 𝑑's relevance to the query 𝑞 and the 𝑆 sub function reflects the 𝑑's relevance to the subtopics. xQuAD [18]</ref> is one of the representative methods of unsupervised explicit approaches. It defines the subtopic distribution by calculating the probability of the selected -c.org/ns/1.0"><head n="5.3">Baseline Models</head><p>We compare DVGAN with several existing diversification methods. We use Lemur as our non-diversified baseline method. We use xQuAD, TxQuAD, HxQuAD [18]</ref>, PM2 [6]</ref>, TPM2 [5]</ref>, and HPM2 [9]</ref> as our unsupervis
f type="bibr" target="#b16">17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>.</p><p>Most previous methods of diversification can be described as the following procedure. At each iteration, the document with the highest score graded by iously selected documents. The diversification score function of implicit approaches can be handcrafted rules such as MMR [1]</ref> or a supervised measure such as R-LTR [26]</ref>, PAMM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,< upervised diversification model is how to sample enough high-quality training data that contain an appropriate number of relevant documents from the candidate document set. Some methods such as R-LTR [26]</ref> only use the top documents in the ideal rankings while other methods such as PAMM [23]</ref> sample the training rankings by ju mple the training rankings by judging it through diversification evaluation metrics. However, none of the existing approaches solve this problem completely. The quality of training data used by R-LTR [26]</ref> is high but its quantity is too small to train the model which may lead to underfit. The quantity of the training dataset used by PAMM <ref type="bibr" target f type="bibr" target="#b16">17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>. Depending on whether the subtopics of query are explicitly modeled and the form of score function, existing diversification approaches can be categorized int implicit methods replace the 𝑆 rel and 𝑆 div with more complex function and design loss function to use the machine learning method to improve the performance. The relational learning-to-rank (R-LTR) [26]</ref> replaces the 𝑆 div score by using the relationship matrix between document 𝑑 and selected documents 𝑆. And the loss function is inspired by the learning to ra rankings from the negative ones. Thus, the discriminator needs a score function to calculate score for document 𝑑 given the query 𝑞 and selected document ranking 𝑆. In our method, we adapt the R-LTR [26]</ref> score function for discriminator. We introduce the score function 𝑓 𝜙 (𝑑 𝑖 |𝑞, 𝑆) in the form of Eq. ( 1</ref>):</p><f te the diversified search result as we show in the former section. We use the generator as the model to generate the final document ranking result.</p><p>In the training process, we first train R-LTR [26]</ref> and DSSA [12]</ref> respectively using MLE loss in both ways. It is because our framework needs a warm start to avoid the devia >, TPM2 [5]</ref>, and HPM2 [9]</ref> as our unsupervised baseline methods. We use ListMLE [22]</ref>, R-LTR [26]</ref>, PAMM [6]</ref>, R-LTR-NTN, PAMM-NTN [24]</ref>, and DSSA [12]</re ed implicit methods. For the diversity feature, we use the same four features in Table 2</ref> with two more features: linkbased diversity and URL-based diversity in [26]</ref>, for PAMM, we use 𝛼-nDCG@20 as the optimization metrics and tune the number of positive rankings 𝑙 + and negative rankings 𝑙 − per query. We tune the function ivided into explicit approaches and implicit approaches. The implicit approaches [1,</ref>23,</ref>24,</ref>26]</ref> emphasize the novelty of the documents, which infers that the selected document should be different from the previously selected documents. The diversification target="#b11">[12]</ref>.</p><p>Studies have shown that supervised approaches [12,</ref>23,</ref>24,</ref>26</ref>] are able to outperform the heuristic approaches [1,</ref>6,</ref>18]
ole document ranking in discriminator calculated by Eq. ( 4</ref>) using Plackett-Luce model and the 𝐸 is the diversification metrics such as 𝛼-NDCG and ERR-IA [2]</ref>. The form of ℑ is inspired by PAMM [23]</ref> method which aims to maximize the margin between positive and negative rankings ins ssumed to be uniform.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>Among all the evaluation metrics [2-4, 20, 21]</ref>, we use ERR-IA [2]</ref>, 𝛼-NDCG [4]</ref>, and NRBP [3]</ref> as our diversity evaluation metrics. They measure the document hat (1). ideal sampling is helpful for discriminator to distinguish the positive and negative rankings but makes it hard for generator to imitate the real distribution of data because it is too ideal (2)</ref>. random sampling makes it easy to imitate for generator but can be confusing for discriminator to distinguish the positive and negative rankings and may provide
etrieval models in it. Comparing to other information retrieval models, IRGAN's generator can provide negative training samples with higher quality. In the personalized search area, Lu proposed PSGAN [15]</ref> inspired by IRGAN. Our framework is inspired by the former two models. However, we combine the idea of minimax game with the method in diversification search.
ts that cover different user intents underlying an ambiguous or a broad query. In recent years, many search result diversification approaches have been proposed [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>< oaches can also be categorized into heuristic approaches such as xQuAD [17,</ref>18]</ref> and PM2 [5,</ref>6,</ref>9]</ref> and supervised approaches such as DSSA [12]</ref>.</p><p>Studies have shown that supervised e="bibr" target="#b22">23,</ref>24,</ref>26</ref>] are able to outperform the heuristic approaches [1,</ref>6,</ref>18]</ref> by learning an optimized ranking function. However, the large number of candidate documents with only few subtopic-releva tion</head><p>As search result diversification is an effective way to solve the problem of query ambiguity, many models have been proposed to solve this problem [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>< supervised measure such as R-LTR [26]</ref>, PAMM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref>18,</ref>25]</ref> inly model document novelty based on similarities between documents, explicit approaches regard the query as several subtopics, and explicitly leverage subtopics to determine the diversity of results [6,</ref>12,</ref>17,</ref>18]</ref>. Most explicit approaches focus on the s is one of the representative methods of unsupervised explicit approaches. It defines the subtopic distribution by calculating the probability of the selected documents not covering the subtopics. PM2 [6]</ref> is another unsupervised explicit method calculating the distribution by counting the relevant document of the subtopic. DSSA [12] ead><p>We compare DVGAN with several existing diversification methods. We use Lemur as our non-diversified baseline method. We use xQuAD, TxQuAD, HxQuAD [18]</ref>, PM2 [6]</ref>, TPM2 [5]</ref>, and HPM2 [9]</ref> as our unsupervised baseline methods. We use ListMLE <ref type=" and HPM2 [9]</ref> as our unsupervised baseline methods. We use ListMLE [22]</ref>, R-LTR [26]</ref>, PAMM [6]</ref>, R-LTR-NTN, PAMM-NTN [24]</ref>, and DSSA [12]</ref> as supervised baseline methods. Top 20 result
nderfit. The quantity of the training dataset used by PAMM [23]</ref> is large enough but the quality of it depends on some hyper-parameters such as the range of 𝛼-nDCG [4]</ref> of negative ranking samples, which may cause the model hard to tune. How to generate training samples effectively is still a challenge for training diversificat et to form the selected document ranking 𝑆. However, recall that in the DVGAN-doc method, we require that 𝑆 is ranked. So the sampler also needs to re-rank 𝑆 by the diversification metric like 𝛼-nDCG [4]</ref>. In practice, half of the selected document ranking 𝑆 is sampled from the ideal ranking, and the other half of the 𝑆 is sampled in the second random way. In bot ://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>Among all the evaluation metrics [2-4, 20, 21]</ref>, we use ERR-IA [2]</ref>, 𝛼-NDCG [4]</ref>, and NRBP [3]</ref> as our diversity evaluation metrics. They measure the document ranking by calculating the coverage of each sub sing explicit and implicit features called DSSA+R-LTR, which also uses the whole results of Lemur to train. We use 5-fold cross validation to tune the parameters in all experiments based on 𝛼-nDCG@20 [4]</ref>. A brief introduction to these baselines is as follows.</p><p>Lemur. We use the non-diversified results as our baseline. They are produced by the Indri engine b
ed [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>.</p><p>Most previous methods of div core function of implicit approaches can be handcrafted rules such as MMR [1]</ref> or a supervised measure such as R-LTR [26]</ref>, PAMM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref><re evant documents from the candidate document set. Some methods such as R-LTR [26]</ref> only use the top documents in the ideal rankings while other methods such as PAMM [23]</ref> sample the training rankings by judging it through diversification evaluation metrics. However, none of the existing approaches solve this problem completely. ing data used by R-LTR [26]</ref> is high but its quantity is too small to train the model which may lead to underfit. The quantity of the training dataset used by PAMM [23]</ref> is large enough but the quality of it depends on some hyper-parameters such as the range of 𝛼-nDCG [4]</ref> of negative ranking em [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>. Depending on whether the subtopics ments 𝑆. And the loss function is inspired by the learning to rank which is aiming to maximize the probability of optimal rankings. Based on the same score function of R-LTR, Xia et al. proposed PAMM [23]</ref> in which loss function is designed to directly maximize the score margin of positive and negative rankings. Furthermore, Neural Tensor Network (NTN) <ref type a" target="#formula_4">4</ref>) using Plackett-Luce model and the 𝐸 is the diversification metrics such as 𝛼-NDCG and ERR-IA [2]</ref>. The form of ℑ is inspired by PAMM [23]</ref> method which aims to maximize the margin between positive and negative rankings instead of directly judging the rankings respectively.</p></div> <div xmlns="h ∼𝑝 true (𝑙 + |𝑞,𝐶),𝑙 − ∼𝑝 𝜃 (𝑙 − |𝑞,𝐶) [D 𝜙 (𝑙 + |𝑞, 𝐶) − D 𝜙 (𝑙 − |𝑞, 𝐶)) ≤ 𝐸 (𝑙 + |𝑞, 𝐶) − 𝐸 (𝑙 − |𝑞, 𝐶)] .<label>(11)</label></formula><p>The loss function of the discriminator is inspired by PAMM [23]</ref> method which is aiming to maximize the margin between the positive and negative rankings.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">O cuments. According to the score function, approaches of diversification can be divided into explicit approaches and implicit approaches. The implicit approaches [1,</ref>23,</ref>24,</ref>26]</ref> emphasize the novelty of the documents, which infers that the selected document r" target="#b8">9]</ref> and supervised approaches such as DSSA [12]</ref>.</p><p>Studies have shown that supervised approaches [12,</ref>23,</ref>24,</ref>26</ref>] are able to outperform the heuristic approaches [
>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>.</p><p>Most previous methods of diversification can be described as the foll fted rules such as MMR [1]</ref> or a supervised measure such as R-LTR [26]</ref>, PAMM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref><ref type="bib >6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>. Depending on whether the subtopics of query are explicitly modeled and the sed PAMM [23]</ref> in which loss function is designed to directly maximize the score margin of positive and negative rankings. Furthermore, Neural Tensor Network (NTN) [24]</ref> was introduced into search result diversification to measure document similarity automatically. In our framework, we use the score function of the R-LTR in di pervised baseline methods. We use ListMLE [22]</ref>, R-LTR [26]</ref>, PAMM [6]</ref>, R-LTR-NTN, PAMM-NTN [24]</ref>, and DSSA [12]</ref> as supervised baseline methods. Top 20 results of Lemur are used to train the supervised methods. Top 50(𝑍 , approaches of diversification can be divided into explicit approaches and implicit approaches. The implicit approaches [1,</ref>23,</ref>24,</ref>26]</ref> emphasize the novelty of the documents, which infers that the selected document should be different from the previously approaches such as DSSA [12]</ref>.</p><p>Studies have shown that supervised approaches [12,</ref>23,</ref>24,</ref>26</ref>] are able to outperform the heuristic approaches [1,</ref>6,
ersification approaches have been proposed [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref>18,</ref>25]</ref> stress the relevance between the documents and the subtopics of the query, which infers that the selected document shou s have been proposed to solve this problem [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ btopic relevance measures. Similar to implicit approaches, explicit diversification approaches can also be categorized into heuristic approaches such as xQuAD [17,</ref>18]</ref> and PM2 [5,</ref>6,</ref>9]</ref> and supervised approaches such as D ype="bibr" target="#b23">24,</ref>26</ref>] are able to outperform the heuristic approaches [1,</ref>6,</ref>18]</ref> by learning an optimized ranking function. However, the large number of candidate documents with only few subtopic-relevant documents in it may cause the probl btopics, and explicitly leverage subtopics to determine the diversity of results [6,</ref>12,</ref>17,</ref>18]</ref>. Most explicit approaches focus on the subtopic coverage of results, by calculating subtopic distribution based on ranked documents. The score function for exp ontains the document-subtopic information of previous documents. The 𝑆 rel function reflects the 𝑑's relevance to the query 𝑞 and the 𝑆 sub function reflects the 𝑑's relevance to the subtopics. xQuAD [18]</ref> is one of the representative methods of unsupervised explicit approaches. It defines the subtopic distribution by calculating the probability of the selected -c.org/ns/1.0"><head n="5.3">Baseline Models</head><p>We compare DVGAN with several existing diversification methods. We use Lemur as our non-diversified baseline method. We use xQuAD, TxQuAD, HxQuAD [18]</ref>, PM2 [6]</ref>, TPM2 [5]</ref>, and HPM2 [9]</ref> as our unsupervis
is still a challenge for training diversification models.</p><p>To tackle this problem, inspired by IRGAN [19]</ref>, we introduce Generative Adversarial Network (GAN) [10]</ref> into search result diversification. Generator generates negative training samples instead of using handcrafted rules for discriminator to train and discriminat . In this paper, we will have a preliminary study on this.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Generative Adversarial Network</head><p>Generative Adversarial Network(GAN) [10]</ref> is initially used in the area of computer vision to generate pictures that are similar to realistic. There are two models in the Generative Adversarial Network
/ref>, PM2 [6]</ref>, TPM2 [5]</ref>, and HPM2 [9]</ref> as our unsupervised baseline methods. We use ListMLE [22]</ref>, R-LTR [26]</ref>, PAMM [6]</ref>, R-LTR-NTN, PAMM-NTN [24]</ref>,
ed [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>.</p><p>Most previous methods of div core function of implicit approaches can be handcrafted rules such as MMR [1]</ref> or a supervised measure such as R-LTR [26]</ref>, PAMM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref><re evant documents from the candidate document set. Some methods such as R-LTR [26]</ref> only use the top documents in the ideal rankings while other methods such as PAMM [23]</ref> sample the training rankings by judging it through diversification evaluation metrics. However, none of the existing approaches solve this problem completely. ing data used by R-LTR [26]</ref> is high but its quantity is too small to train the model which may lead to underfit. The quantity of the training dataset used by PAMM [23]</ref> is large enough but the quality of it depends on some hyper-parameters such as the range of 𝛼-nDCG [4]</ref> of negative ranking em [1,</ref>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>. Depending on whether the subtopics ments 𝑆. And the loss function is inspired by the learning to rank which is aiming to maximize the probability of optimal rankings. Based on the same score function of R-LTR, Xia et al. proposed PAMM [23]</ref> in which loss function is designed to directly maximize the score margin of positive and negative rankings. Furthermore, Neural Tensor Network (NTN) <ref type a" target="#formula_4">4</ref>) using Plackett-Luce model and the 𝐸 is the diversification metrics such as 𝛼-NDCG and ERR-IA [2]</ref>. The form of ℑ is inspired by PAMM [23]</ref> method which aims to maximize the margin between positive and negative rankings instead of directly judging the rankings respectively.</p></div> <div xmlns="h ∼𝑝 true (𝑙 + |𝑞,𝐶),𝑙 − ∼𝑝 𝜃 (𝑙 − |𝑞,𝐶) [D 𝜙 (𝑙 + |𝑞, 𝐶) − D 𝜙 (𝑙 − |𝑞, 𝐶)) ≤ 𝐸 (𝑙 + |𝑞, 𝐶) − 𝐸 (𝑙 − |𝑞, 𝐶)] .<label>(11)</label></formula><p>The loss function of the discriminator is inspired by PAMM [23]</ref> method which is aiming to maximize the margin between the positive and negative rankings.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">O cuments. According to the score function, approaches of diversification can be divided into explicit approaches and implicit approaches. The implicit approaches [1,</ref>23,</ref>24,</ref>26]</ref> emphasize the novelty of the documents, which infers that the selected document r" target="#b8">9]</ref> and supervised approaches such as DSSA [12]</ref>.</p><p>Studies have shown that supervised approaches [12,</ref>23,</ref>24,</ref>26</ref>] are able to outperform the heuristic approaches [
>6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>.</p><p>Most previous methods of diversification can be described as the foll fted rules such as MMR [1]</ref> or a supervised measure such as R-LTR [26]</ref>, PAMM [23]</ref>, and NTN [24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref><ref type="bib >6,</ref>12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>. Depending on whether the subtopics of query are explicitly modeled and the sed PAMM [23]</ref> in which loss function is designed to directly maximize the score margin of positive and negative rankings. Furthermore, Neural Tensor Network (NTN) [24]</ref> was introduced into search result diversification to measure document similarity automatically. In our framework, we use the score function of the R-LTR in di pervised baseline methods. We use ListMLE [22]</ref>, R-LTR [26]</ref>, PAMM [6]</ref>, R-LTR-NTN, PAMM-NTN [24]</ref>, and DSSA [12]</ref> as supervised baseline methods. Top 20 results of Lemur are used to train the supervised methods. Top 50(𝑍 , approaches of diversification can be divided into explicit approaches and implicit approaches. The implicit approaches [1,</ref>23,</ref>24,</ref>26]</ref> emphasize the novelty of the documents, which infers that the selected document should be different from the previously approaches such as DSSA [12]</ref>.</p><p>Studies have shown that supervised approaches [12,</ref>23,</ref>24,</ref>26</ref>] are able to outperform the heuristic approaches [1,</ref>6,
Metrics</head><p>Among all the evaluation metrics [2-4, 20, 21]</ref>, we use ERR-IA [2]</ref>, 𝛼-NDCG [4]</ref>, and NRBP [3]</ref> as our diversity evaluation metrics. They measure the document ranking by calculating the coverage of each subtopic of the query. Consistent with existing work
ole document ranking in discriminator calculated by Eq. ( 4</ref>) using Plackett-Luce model and the 𝐸 is the diversification metrics such as 𝛼-NDCG and ERR-IA [2]</ref>. The form of ℑ is inspired by PAMM [23]</ref> method which aims to maximize the margin between positive and negative rankings ins ssumed to be uniform.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>Among all the evaluation metrics [2-4, 20, 21]</ref>, we use ERR-IA [2]</ref>, 𝛼-NDCG [4]</ref>, and NRBP [3]</ref> as our diversity evaluation metrics. They measure the document hat (1). ideal sampling is helpful for discriminator to distinguish the positive and negative rankings but makes it hard for generator to imitate the real distribution of data because it is too ideal (2)</ref>. random sampling makes it easy to imitate for generator but can be confusing for discriminator to distinguish the positive and negative rankings and may provide
ef type="bibr" target="#b11">12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>.</p><p>Most previous methods of diversification can be described as the following procedure. At each iteration, the d ef type="bibr" target="#b11">12,</ref>17,</ref>18,</ref>[23]</ref>[24]</ref>[25]</ref>[26]</ref>. Depending on whether the subtopics of query are explicitly modeled and the form of score function, existing diversif b23">[24]</ref>. The explicit approaches [6,</ref>12,</ref>17,</ref>18,</ref>25]</ref> stress the relevance between the documents and the subtopics of the query, which infers that the selected document should cover the subtopics which the previou

nderfit. The quantity of the training dataset used by PAMM [23]</ref> is large enough but the quality of it depends on some hyper-parameters such as the range of 𝛼-nDCG [4]</ref> of negative ranking samples, which may cause the model hard to tune. How to generate training samples effectively is still a challenge for training diversificat et to form the selected document ranking 𝑆. However, recall that in the DVGAN-doc method, we require that 𝑆 is ranked. So the sampler also needs to re-rank 𝑆 by the diversification metric like 𝛼-nDCG [4]</ref>. In practice, half of the selected document ranking 𝑆 is sampled from the ideal ranking, and the other half of the 𝑆 is sampled in the second random way. In bot ://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>Among all the evaluation metrics [2-4, 20, 21]</ref>, we use ERR-IA [2]</ref>, 𝛼-NDCG [4]</ref>, and NRBP [3]</ref> as our diversity evaluation metrics. They measure the document ranking by calculating the coverage of each sub sing explicit and implicit features called DSSA+R-LTR, which also uses the whole results of Lemur to train. We use 5-fold cross validation to tune the parameters in all experiments based on 𝛼-nDCG@20 [4]</ref>. A brief introduction to these baselines is as follows.</p><p>Lemur. We use the non-diversified results as our baseline. They are produced by the Indri engine b
Metrics</head><p>Among all the evaluation metrics [2-4, 20, 21]</ref>, we use ERR-IA [2]</ref>, 𝛼-NDCG [4]</ref>, and NRBP [3]</ref> as our diversity evaluation metrics. They measure the document ranking by calculating the coverage of each subtopic of the query. Consistent with existing work
items. The queue-based framework also offers simple yet efficient implementations for complex self-supervised tasks, e.g., discriminating whether two subsequences come from the same user's behaviors [36]</ref>. We further improve upon CLRec and propose Multi-CLRec, which employs a multi-queue design for more accurate user-intention aware bias reduction.</p><p>Our me head n="4.2">Computational Advantages of CLRec</head><p>Table 7</ref>: Task u2i is the regular task where 𝑥 is a sequence of clicks and 𝑦 is the next click to be predicted. Task u2u [36]</ref> adds an auxiliary loss where 𝑥 and 𝑦 are both sequences from the same user (before and after a sampled timestamp), which is co-trained with task u2i. HR1@50 a ve items in total as it draws samples from both a main queue and an additional secondary queue.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Complex Pretext Tasks</head><p>In task u2u [36]</ref>, 𝑥 and 𝑦 are both sequences from the same user, before and after a sampled timestamp, respectively. Intuitively, pre-training a recommender to solve task u2u
target="#b27">[28]</ref>, has become an essential part of many live industrial systems with its enhanced expressiveness.</p><p>Typical large-scale DCG models [14,</ref>17,</ref>32,</ref>61]</ref> regard the problem of identifying the most relevant items to the users as estim
t a multistage pipeline, where the first stage, namely candidate generation, is responsible for retrieving a few hundred relevant entities from a billion scale corpus. Deep candidate generation (DCG) [14]</ref>, a paradigm that learns vector representations of the entities to enable fast k-nearest neighbor retrieval [28]</ref>, has beco expensive to incorporate rich features for the negative samples. The existing systems hence usually choose to not encode features for the negative examples except for simple features such as item IDs [14]</ref>, even though rich features for the negative samples are demonstrated to be beneficial [4]</ref>. CLRec achieves great efficiency arest neighbor retrieval [28]</ref>, has become an essential part of many live industrial systems with its enhanced expressiveness.</p><p>Typical large-scale DCG models [14,</ref>17,</ref>32,</ref>61]</ref> regard the problem of identifying the softmax in general outperforms other approximations such as NCE [18]</ref> and negative sampling [38]</ref> when the vocabulary is large [14,</ref>26,</ref>33,</ref>37]</ref>.</p><p>Contrastive Loss. We study the ere are many empirical results that report better performance with a multinomial candidate generation method than a multivariate bernoulli one, especially with a large set of items for recommendation [14,</ref>26,</ref>32,</ref>33]</ref>. Our empirical results in Table <ref t ns/1.0"><head n="5">RELATED WORK</head><p>Deep Candidate Generation. Deep candidate generation methods are widely deployed in industrial systems, e.g., YouTube [10,</ref>14,</ref>27]</ref>, Taobao [32,</ref>35,</ref><ref type="bibr" target="#b58"
> proposes momentum update for stabilizing the training loss. We however observe no additional gain with MoCo.</p><p>Table 9</ref>: Results on public benchmarks preprocessed by HPMN [40]</ref>. We follow HPMN [40]</ref> and use AUC as the metric. The clicks in the training and the test set of each benchmark happen befo ss. We however observe no additional gain with MoCo.</p><p>Table 9</ref>: Results on public benchmarks preprocessed by HPMN [40]</ref>. We follow HPMN [40]</ref> and use AUC as the metric. The clicks in the training and the test set of each benchmark happen before and after a certain timestamp, respectively. There henc .7770 0.8934 RUM [13]</ref> 0.7464 0.8370 LSTM [23]</ref> 0.7765 0.8681 SHAN [55]</ref> 0.7763 0.8828 HPMN [40]</ref> 0   </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Reproducible Experiments on Public Data</head><p>In addition to the experiments on large
ressive enough to fit the target distribution arbitrarily close. Note that 𝜙 𝜃 (𝑥, 𝑦) is indeed expressive enough since we implement it as a neural network, due to the universal approximation theorem [15,</ref>24]</ref>. The two losses hence have the same global optima. □</p></div>			</div> 			<div type="references">  				<listBibl>  <b
essential part of many live industrial systems with its enhanced expressiveness.</p><p>Typical large-scale DCG models [14,</ref>17,</ref>32,</ref>61]</ref> regard the problem of identifying the most relevant items to the users as estimating a multinomial distribution travers candidate generation method than a multivariate bernoulli one, especially with a large set of items for recommendation [14,</ref>26,</ref>32,</ref>33]</ref>. Our empirical results in Table 2</ref>, where the negative sampling baselines follow the multivariat our main online results conducted in these heavy-traffic scenarios, with billions of page views each day. During the at least four months' A/B testing, CLRec has been consistently outperforming MIND [32]</ref>, the previous state-or-art baseline, in terms of the fairness metrics such as aggregated diversity and average popularity index, as well as the user engagemen n terms of the fairness metrics such as aggregated diversity and average popularity index, as well as the user engagement metrics such as click-through rate and average dwell time. Compared with MIND [32]</ref>, which is the previous state-of-art DCG baseline deployed in the system, CLRec tends to recommend items with a lower popularity index while being more attract ation methods are widely deployed in industrial systems, e.g., YouTube [10,</ref>14,</ref>27]</ref>, Taobao [32,</ref>35,</ref>59,</ref>61]</ref>, and Pinterest <ref type="bibr" target eved items. These previous methods tend to under-explore items from the less popular interests. Many have also noticed this issue and proposed their solutions, such as using multiple interest vectors [32,</ref>35]</ref> or multiple interest sub-models [61]</ref>. Our result (Figure <ref type="figure" targe
ns/1.0"><head>Method</head><p>Amazon UserBehavior DNN 0.7546 0.7460 SVD++ [31]</ref> 0.7155 0.8371 GRU4Rec [21]</ref> 0.7760 0.8471 Caser [47]</ref> 0.7582 0.8745 DIEN [60]</ref> 0.7770 0.8934 RUM [13]</ref> 0.7464 0.8370 LSTM <ref type="bibr" t
.7582 0.8745 DIEN [60]</ref> 0.7770 0.8934 RUM [13]</ref> 0.7464 0.8370 LSTM [23]</ref> 0.7765 0.8681 SHAN [55]</ref> 0.7763 0.8828 HPMN [40]</ref> 0   </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Reproducible Experiments on
requires computing softmax looping over a million-or even billion-scale collection of items, is computationally infeasible. Among the various sampling-based approximation strategies, sampled-softmax [6,</ref>26]</ref> usually outperforms the binary-cross-entropy based approximations such as NCE [18]</ref> f contrastive loss we will investigate is similar to sampled softmax. We thus recap sampled softmax here and will show that the minor difference is crucial. There are many variants of sampeld softmax [6,</ref>26]</ref>, among which the following variant is integrated by TensorFlow [1]</ref> and commonly used f type="bibr" target="#b55">[56]</ref> that makes the instances in a batch share the same large set of negative samples, does not perform well in our settings. CLRec's improvement over sampledsoftmax [6,</ref>26]</ref> w.r.t. the offline metric HitRate@50 is negligible. However, CLRec achieves significant improvement regarding the click- ef>61]</ref>, and Pinterest [56]</ref>. The existing methods explicitly sample negative examples from a pre-defined proposal distribution [6,</ref>26,</ref>38]</ref>. The proposal distribution not only affects convergence, but also has a signific
tion arbitrarily close. Note that 𝜙 𝜃 (𝑥, 𝑦) is indeed expressive enough since we implement it as a neural network, due to the universal approximation theorem [15,</ref>24]</ref>. The two losses hence have the same global optima. □</p></div>			</div> 			<div type="references">  				<listBibl>  <biblStruct xml:id="b0"> 	<analytic> 		<tit
eviate the selection bias related with the items' impression counts in the history. However, sampling will still incur non-negligible overheads, e.g. communication costs, in a distributed environment [45]</ref>. Sampling also cannot guarantee that every item will be sampled in an epoch. We thus adopt a queue-based design [19]</ref> that is proportional to the item's degree, i.e., degree(𝑦) 0.75 as recommended in [38]</ref>. We use a distributed version of the sampling strategy based on the alias method [45]</ref>, which is provided by AliGraph [62]</ref>. We tune 𝐿 from 8 to 2, 560 and report the best.</p><p>Shared negative sampling <ref
nt architectural choices. Since relevance matching is fundamentally a matching task, most recent neural architectures, such as DRMM (Guo et al., 2016)</ref> and Co-PACRR (Hui et al., 2018)</ref>, adopt an interaction-based design. They operate directly on the similarity matrix obtained from products of query and document embeddings and b
y modeled through distributed representations for similarity learning. Various neural network architectures, e.g., Siamese networks (He et al., 2016)</ref> and attention (Seo et al., 2017;</ref>Tay et al., 2019b)</ref>, have been proposed to model semantic similarity using diverse techniques.</p><p>A core p and textual similarity measurement, require more semantic understanding and contextual reasoning rather than specific term matches. Context-aware representation learning, such as co-attention methods (Seo et al., 2017)</ref>, has been proved effective in many benchmarks. Though improvements have been shown from adding exact match signals into representation learning, b ∈ R F ×F ,</formula><p>and the REP operator converts the input vector to a R n×m matrix by repeating elements in the missing dimen-sions. Softmax col is the column-wise softmax operator. Similar to Seo et al. (2017)</ref>, we perform co-attention from two directions: query-to-context and context-to-query, as follows:</p><formula xml:id="formula_8">Ũq = A T U q Ũc = ntence encoders that incorporate word context and sentence order for better sentence representations; (2) interaction and attention mecha-nisms (Tay et al., 2019b;</ref>Seo et al., 2017;</ref>Parikh et al., 2016;</ref>Conneau et al., 2017;</ref>Go
arity learning. Various neural network architectures, e.g., Siamese networks (He et al., 2016)</ref> and attention (Seo et al., 2017;</ref>Tay et al., 2019b)</ref>, have been proposed to model semantic similarity using diverse techniques.</p><p>A core problem of information retrieval (IR) is relevance match ually comprise three major components: (1) sequential sentence encoders that incorporate word context and sentence order for better sentence representations; (2) interaction and attention mecha-nisms (Tay et al., 2019b;</ref>Seo et al., 2017;</ref>Parikh et al., 2016;</ref>Con
matching, we aim to capture semantic matching signals via co-attention mechanisms on intermediate query and context representations. Our semantic matching method behaves similarly to the transformer (Vaswani et al., 2017)</ref>, which also uses attention (specifically, self-attention) over hierarchical blocks to capture semantics at different granularities.</p><p>Gi
. We report mean average precision (MAP) and mean reciprocal rank (MRR). Paraphrase Identification. This task is to identify whether two sentences are paraphrases of each other. We use the TwitterURL (Lan et al., 2017)</ref> dataset with 50k sentence pairs. We report the unweighted average of F1 scores on the positive and negative classes (macro-F1). Semantic Textual
train than the contextual encoder. Additionally, the use of CNN layers allows us to explicitly control the window size for phrase modeling, which has been shown to be critical for relevance matching (Dai et al., 2018;</ref>Rao et al., 2019)</ref>. On the other hand, the contextual encoder enables us to obtain long-distance contextual re
ed into representation-based and interactionbased approaches, discussed below:</p><p>Early neural IR models mainly focus on representation-based modeling between the query and documents, such as DSSM (Huang et al., 2013)</ref>, C-DSSM (Shen et al., 2014)</ref>, and SM-CNN (Severyn and Moschitti, 2015)</ref>. These meth-
arity learning. Various neural network architectures, e.g., Siamese networks (He et al., 2016)</ref> and attention (Seo et al., 2017;</ref>Tay et al., 2019b)</ref>, have been proposed to model semantic similarity using diverse techniques.</p><p>A core problem of information retrieval (IR) is relevance match ually comprise three major components: (1) sequential sentence encoders that incorporate word context and sentence order for better sentence representations; (2) interaction and attention mecha-nisms (Tay et al., 2019b;</ref>Seo et al., 2017;</ref>Parikh et al., 2016;</ref>Con
on representation-based modeling between the query and documents, such as DSSM (Huang et al., 2013)</ref>, C-DSSM (Shen et al., 2014)</ref>, and SM-CNN (Severyn and Moschitti, 2015)</ref>. These meth-Label SM Score RM Score HCAN Score Sample Pair 1 1, 0.9119 0, 0.9353 1, 0.5496 -How does it feel to kill a human ? -How d
"#b31">(Tay et al., 2019b;</ref>Seo et al., 2017;</ref>Parikh et al., 2016;</ref>Conneau et al., 2017;</ref>Gong et al., 2018)</ref> to emphasize salient word pair interactions;</p><p>(3) structure modeling (Chen et al., 2017b)</ref>.</p></div> <di
king models: DRMM (Guo et al., 2016)</ref>, DUET (Mitra et al., 2017)</ref>, K-NRM (Xiong et al., 2017b)</ref>, and PACRR (Hui et al., 2017)</ref>. For the neural baselines, we used implementations in MatchZoo.2</ref> For L2R, we used LambdaMART (Burges, 20
for a variety of NLP tasks. For example, in paraphrase identification, SM is used to determine whether two sentences or phrases convey the same meaning. In question answering or reading comprehension (Xiong et al., 2017a;</ref>Tay et al., 2019a)</ref>, SM can help identify the correct answer span given a question. Semantic understanding
for a variety of NLP tasks. For example, in paraphrase identification, SM is used to determine whether two sentences or phrases convey the same meaning. In question answering or reading comprehension (Xiong et al., 2017a;</ref>Tay et al., 2019a)</ref>, SM can help identify the correct answer span given a question. Semantic understanding
in many NLP and IR applications (He and Lin, 2016;</ref>Sutskever et al., 2014;</ref>Yin et al., 2016;</ref>Rao et al., 2017b)</ref>. Current neural models for IR can be divided into representation-based and interactionbased approaches, discussed below:</p><p>Early neural IR m

and STS tasks, we compared against the following baselines: InferSent (Conneau et al., 2017)</ref>, ESIM (Chen et al., 2017b)</ref>, DecAtt (Parikh et al., 2016)</ref>, and PWIM (He and Lin, 2016)</ref>. Additionally, we report state-of-the-arts results on each dataset from publ ence order for better sentence representations; (2) interaction and attention mecha-nisms (Tay et al., 2019b;</ref>Seo et al., 2017;</ref>Parikh et al., 2016;</ref>Conneau et al., 2017;</ref>Gong et al., 2018)</ref> to emphasize salient word pair
ns</head><p>For the answer selection, paraphrase identification, and STS tasks, we compared against the following baselines: InferSent (Conneau et al., 2017)</ref>, ESIM (Chen et al., 2017b)</ref>, DecAtt (Parikh et al., 2016)</ref>, and PWIM (He and Lin, 2016)</ref>. Additional ., 2016;</ref>Conneau et al., 2017;</ref>Gong et al., 2018)</ref> to emphasize salient word pair interactions;</p><p>(3) structure modeling (Chen et al., 2017b)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we examine the relationship between relevance
proposed HCAN model on three NLP tasks and two IR datasets, as follows: Answer Selection. This task is to rank candidate answer sentences based on their similarity to the question. We use the TrecQA (Wang et al., 2007)</ref> dataset (raw version)1</ref> with 56k question-answer pairs. We report mean average precision (MAP) and mean
matching, we aim to capture semantic matching signals via co-attention mechanisms on intermediate query and context representations. Our semantic matching method behaves similarly to the transformer (Vaswani et al., 2017)</ref>, which also uses attention (specifically, self-attention) over hierarchical blocks to capture semantics at different granularities.</p><p>Gi
ww.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural networks have achieved great success in many NLP tasks, such as question answering (Rao et al., 2016;</ref>Chen et al., 2017a)</ref>, paraphrase detection (Wang et al., 2017)</ref>, and textual semantic similarity modeling <ref type="bibr" target eo et al., 2017)</ref>, has been proved effective in many benchmarks. Though improvements have been shown from adding exact match signals into representation learning, for example, the Dr.QA model of Chen et al. (2017a)</ref> concatenates exact match scores to word embeddings, it remains unclear to what extent relevance matching signals can further improve models prim
(He and Lin, 2016)</ref>. Additionally, we report state-of-the-arts results on each dataset from published literature. We also include the current state-of-the-art BERT (Devlin et al., 2019)</ref> results on each dataset.</p><p>For the tweet search task, we mostly follow the experimental setting in Rao et a
c.org/ns/1.0"><head n="5.1">Neural Relevance Matching</head><p>Recently, deep learning has achieved great success in many NLP and IR applications (He and Lin, 2016;</ref>Sutskever et al., 2014;</ref>Yin et al., 2016;</ref>Rao et al., 2017b)</ref>. Current neural models for IR
ppending phrases such as "the correct answer is "), allowing pretrained LMs to solve them without any or with only very few labeled examples (Radford et al., 2019;</ref>Schick and Schütze, 2020a)</ref>.</p><p>Very recently, Brown et al. (2020)</ref> introduced GPT-3, a pretrained LM with an enormous 175 bil arios.</p><p>• It does not scale to more than a few examples as the context window of most LMs is limited to a few hundred tokens.</p><p>An alternative to priming is pattern-exploiting training (PET) (Schick and Schütze, 2020a)</ref>, which combines the idea of reformulating tasks as cloze questions with regular gradient-based finetuning. While PET additionally requi ibr">Ettinger, 2020, i.a.)</ref>.</p><p>As finding ways to reformulate tasks as cloze questions that are understood well by LMs is difficult (Jiang et al., 2019)</ref>, Schick and Schütze (2020a)</ref> propose PET, a method that uses knowledge distillation (Hinton et al., 2015)</ref> to easily combine seve <p>CB (De Marneffe et al., 2019)</ref> and RTE (Dagan et al., 2006)</ref> are textual entailment tasks like MNLI, so we use PVPs similar to Schick and Schütze (2020a)</ref>. For a premise p and hypothesis h, we use</p><formula xml:id="formula_6">h? | , p , "h"? | , "p" , h? | . p , "h"? | . "p"</formula><p>a he best-performing MLM on SuperGLUE when training is performed on the regular, full size training sets. 5 We run PET on the FewGLUE training sets for all SuperGLUE tasks using the exact same setup as Schick and Schütze (2020a)</ref>. For COPA, WSC and ReCoRD, we use our proposed modification of PET to support verbalizers mapping labels to multiple tokens; for all oth sing any patterns), and with a fully unsupervised model (Table 3</ref>). Given 32 examples, PET clearly outperforms both baselines, which is in line with findings by Schick and Schütze (2020a)</ref>.</p><p>We next compare PET directly to priming. However, we cannot do so using ALBERT as it, like most pretrained MLMs, is only able to We provide inputs to the final PET model in the format s | n where | is the boundary between two text segments and mark p in s with asterisks.</p><p>MultiRC Deviating from the hyperparameters used by Schick and Schütze (2019)</ref>, we use a maximum sequence length of 512 tokens for MultiRC both during training and inference because we found many passages to be much
i-c.org/ns/1.0"><head n="4.1">Tasks</head><p>Below, we describe each of the SuperGLUE tasks and our corresponding PVPs. We use a vertical bar (|) to mark boundaries between text segments.</p><p>BoolQ (Clark et al., 2019)</ref> is a QA task where each example consists of a passage p and a yes/no question q. We use the following patterns:</p><p>• p. Question: q? Answer:
ersion of PET uses masked language models (Devlin et al., 2019)</ref> to assign probabilities to sequences of text; this is similar to using them in a generative fashion (Wang and Cho, 2019)</ref> and has previously been investigated by Salazar et al. (2020)</ref> and Ghazvini
note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">While our approach can easily be adapted to models capable of doing conditional generation with bidirectional context (e.g.,Lewis et al., 2020;</ref>Raffel et al., 2019)</ref>, we stick with MLMs as they are more lightweight and we found them to perform better o
ersion of PET uses masked language models (Devlin et al., 2019)</ref> to assign probabilities to sequences of text; this is similar to using them in a generative fashion (Wang and Cho, 2019)</ref> and has previously been investigated by Salazar et al. (2020)</ref> and Ghazvini
ead><p>Enabling LMs to perform zero-shot learning by providing task descriptions was proposed by Radford et al. (2019)</ref> and has been applied to text classification (Puri and Catanzaro, 2019)</ref>, commonsense knowledge mining (Davison et al., 2019)</ref> and argumentative relation classification <ref
tion (Puri and Catanzaro, 2019)</ref>, commonsense knowledge mining (Davison et al., 2019)</ref> and argumentative relation classification (Opitz, 2019)</ref>. It is also commonly used for probing the knowledge contained within LMs (Trinh and Le, 2018;</ref><ref type="bibr" ta
e (1) (a) "s 1 " ( ) "s 2 "</p><p>For the first two patterns, we use yes as verbalization for words used in the same sense and no for other words; for the third pattern, we use b and 2.</p><p>For WSC (Levesque et al., 2011)</ref>, each example consists of a sentence s with a marked pronoun p and noun n, and the task is to determine whether p refers to n. We follow pr
that WSC is different from other tasks in that it requires free-form completion. This in turn requires some modifications during training and inference that are discussed in Appendix A.</p><p>MultiRC (Khashabi et al., 2018</ref>) is a QA task. Given a passage p, a question q and an answer candidate a, the task is to decide whether a is a correct answer for q. We use
ion classification (Opitz, 2019)</ref>. It is also commonly used for probing the knowledge contained within LMs (Trinh and Le, 2018;</ref>Petroni et al., 2019;</ref>Talmor et al., 2019;</ref>Schick and Schütze, 2020b;</ref>Ettin
t on GPT-3's performance. 3</ref> We thus create new training sets by randomly selecting 32 examples for each task using a fixed random seed. Following previous work (Raffel et al., 2019;</ref>Brown et al., 2020)</ref>, we select only positive examples for WSC; for both MultiRC and ReCoRD, we follow <ref ibr" target="#b16">(Levesque et al., 2011)</ref>, each example consists of a sentence s with a marked pronoun p and noun n, and the task is to determine whether p refers to n. We follow previous work (Raffel et al., 2019;</ref>Brown et al., 2020)</ref> and treat WSC as a generative task. We highlight p in s by putting it in asterisks and se the sequence w: s 1 | s 2 as input for the final sequence classification model, where | marks the boundary between two text segments.</p><p>WSC Unlike other SuperGLUE tasks, the WSC formulation of Raffel et al. (2019)</ref> and Brown et al. (2020)</ref> requires free-form completion, meaning that for each sentence s and pronoun p, we d&gt; token. For inference, we always just add a single mask token to ensure consistent results across multiple evaluations and perform greedy decoding as described in Section 3.</p><p>We then follow Raffel et al. (2019)</ref> to map the output produced by the LM to a label y ∈ {true, false}.</p><p>For distillation, given an unlabeled example x we set s p (y | x) = 1 -3 primed with 32 randomly selected examples and for PET / iPET with ALBERT-xxlarge-v2 after training on FewGLUE. State-of-the-art results when using the regular, full size training sets for all tasks(Raffel et al., 2019)</ref> are shown in italics.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Params BoolQ</cell><cell>CB</cell><cell cols="4">COPA RTE "2" xml:id="foot_0">While our approach can easily be adapted to models capable of doing conditional generation with bidirectional context (e.g.,Lewis et al., 2020;</ref>Raffel et al., 2019)</ref>, we stick with MLMs as they are more lightweight and we found them to perform better on simple cloze tasks in preliminary experiments.</note>
head>II. METHODS</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. USMPep: Universal Sequence Models for Peptide Binding Prediction</head><p>The approach builds on the UDSMProt-framework [12]</ref> and related work in natural language processing [13]</ref>. We distinguish two variants of our approach, either train the regre he model is finetuned on the regression task of MHC binding prediction by replacing the output layer with a concat pooling layer and two fully connected layers. The setup closely follows that used in [12]</ref>, where protein properties were predicted. The smaller dataset sizes and shorter sequence lengths in the peptide setting (in comparison to protein classificati lding up large contexts and were accounted for by the reduction of the number of layers from 3 to 1, of the number of hidden units from 1150 to 64 and of the embedding size from 400 to 50. Similar to [12]</ref>, the training procedure included 1-cycle learning rate scheduling [15]</ref> and discriminative learning rates <ref type="bibr" o one MHC molecule. These results stress that further efforts might be required to truly leverage the potential of unlabeled peptide data in order to observe similar improvements as seen for proteins [12]</ref> in particular for small datasets.  Turning to MHC Class II binding prediction, we aim to demonstrate the universality of our approach beyond its applicability age sites. Second, even we evaluated on protein data, the protein language model only reaches an accuarcy of 0.137, which is is considerably lower than the accuracy of 0.41 reported in the literature [12]</ref>. This effect is a direct consequence of the considerably smaller model size (1 instead of 3 layers; 64 instead of 1150 hidden units; embedding size of 50 inst

contrasted with reporting the mean or the median of the respective performance measures across all alleles, which is the default evaluation metric for related tasks such as remote homology detection [20]</ref> or transcription factor binding site prediction [21]</ref>. The difference between both evaluation approaches is related to the

iversal Sequence Models for Peptide Binding Prediction</head><p>The approach builds on the UDSMProt-framework [12]</ref> and related work in natural language processing [13]</ref>. We distinguish two variants of our approach, either train the regression from scratch or employ language model pretraining. A language model tries to predict 50. Similar to [12]</ref>, the training procedure included 1-cycle learning rate scheduling [15]</ref> and discriminative learning rates [13]</ref> during finetuning. Target variables for the regression model were log-transformed half-maximal inhibitory concentration (IC 50 )-values and a modified MSE los

d a dataset of simulated proteasome-cleaved peptides to pretrain USMpep on a large corpus of unlabeled sequences. We filtered the SwissProt release 2018 10 for the human proteome and employed NetChop [23]</ref> to obtain proteasome cleavage sites for these proteins. The stochastic process of protein slicing was modeled by cutting with the cleavage probability provide
ualitative data.</p><p>Dropout rate, the number of training epochs, hidden layers, hidden units and embedding dimensions, were set based on selected alleles of a particular MHC class I dataset (Kim14 [16]</ref>, see the detailed description below) by using the score on one of the provided cross-validation folds. The learning rate was determined based on range tests < tails listed in Tab. II). These datasets comprise peptide sequences and the corresponding binding affinities to specific MHC alleles. a) Kim14: is a commonly used binding affinity dataset compiled by [16]</ref>, available on the Immune Epitope Database (IEDB)1</ref>  [17]</ref>, and is split into a non- his performance deficiency and found that it could be traced back to a single allele, HLA-B-3801, which is peculiar in the sense that 172 of the 176 test set samples fall into a single Hobohl cluster [16]</ref> of sequences with more than 80% sequence similarity, i.e. show a particularly high sequence identity that is not seen in other test datasets. These 172 sample
bibr" target="#b12">[13]</ref> during finetuning. Target variables for the regression model were log-transformed half-maximal inhibitory concentration (IC 50 )-values and a modified MSE loss function [8]</ref> that allows to incorporate qualitative data.</p><p>Dropout rate, the number of training epochs, hidden layers, hidden units and embedding dimensions, were set b on two further MHC I datasets, which we refer to as HPV and IEDB 16. The training data of the tools reported in the literature vary in size and compilation. We trained our models on data provided by [8]</ref> and refer to this dataset as MHCFlurry18. It is assembled from an IEDB snapshot of December 2017 and the Kim14 dataset.</p><p>b) HPV: is a recently published da sons: In order to investigate how the predictive power of our approach depends on the size of the training data set, we trained and tested our model on the Kim14 BD2009 and Blind data. The authors of [8]</ref> kindly provided us with the Blind predictions of their tool trained on BD2009, which allow for a direct comparison with a state-ofthe-art tool. Corresponding tr ictions of their tool trained on BD2009, which allow for a direct comparison with a state-ofthe-art tool. Corresponding training routines are by now also available in the code repository accompanying [8]</ref>.</p><p>First, we compare the prediction success measured by AUC ROC and Spearman r computed across all alleles (Fig. 3</ref>)
performance. We fix hyperparameters only once and use standard benchmark datasets to assess the model performance. We provide, amongst others, evaluation results on the recently published HPV dataset [9]</ref>, demonstrating an excellent performance, which strongly suggests that the measured model performance generalizes to unseen peptide data.</p><p>Recurrent archite aset.</p><p>b) HPV: is a recently published dataset and consists of 743 affinity measurements of peptides derived from two human paillomavirus 16 (HPV16) proteins binding to seven HLA class I alleles [9]</ref>. Peptides were considered as binders if they had IC 50 -values below 100 000 nM. For peptides classified as non-binders, quantitative measurements are not avail (threshold for binders &lt; 100 000 nM) on single alleles and across all alleles (mean and overall). The scores for literature approaches were calculated based on peptide-wise predictions provided in [9]</ref>. NetMHC tools, MHCFlurry, SMMPMBEC and consensus and our scores for the different versions of USMPep. This is supplemented by mean AUC ROC and mean Spearman r c circumvented by a performance evaluation on a dataset of different origin that has so far not been used to train MHC prediction tools. This applies to the recently released HPV binding affinity data [9]</ref>. However, in this benchmark, it is not possible to disentangle superior prediction performance due to larger amounts of training data from algorithmic advances are only quantitative measurements for the peptides considered as binders, we chose to evaluate the predictive performance only based on AUC ROC. We report the performance of all models considered in [9]</ref> and our tools measured by AUC ROC in Tab. III, where we used the predictions provided by [9]</ref>. Our USMPep tools show an excel ased on AUC ROC. We report the performance of all models considered in [9]</ref> and our tools measured by AUC ROC in Tab. III, where we used the predictions provided by [9]</ref>. Our USMPep tools show an excellent prediction performance. For three out of seven alleles an USMPep-model even reaches the highest AUC ROC. All neural-network-
, we trained and tested USMPep on MHC class II binding data: d) Wang10: is an experimental binding affinity dataset from the IEDB site2</ref> based on the dataset by [18]</ref>. We used it to train our prediction tools.</p><p>e) IEDB16 II: is a MHC II test dataset provided by [2]</ref> from the same IEDB
via multi-channel CNN and gets a representation of a user by aggregating her clicked news history with different weights. However, these methods (Wu et al., 2019b;</ref>Zhu et al., 2019;</ref>An et al., 2019)</ref> usually focus on news contents, and seldom consider the collaborative signal in the form of h ype="bibr" target="#b10">(Huang et al., 2013</ref>) is a content-based deep neural network to rank a set of documents given a query. Some works (Wang et al., 2018;</ref>Zhu et al., 2019)</ref> propose to improve news representations via external knowledge, and learn representations of users from their browsed news using an attention mod d w, entity e, and entity type c. n 1 and n 2 are the dimension of word (entity) and entity-type embeddings. These embeddings can be pre-trained from a large corpus or randomly initialized. Following (Zhu et al., 2019)</ref>, we define the profile embedding</p><formula xml:id="formula_1">P = [e 1 , g(c 1 ), e 2 , g(c 2 ), • • • , e p , g(c p )] T where P ∈ R 2p×n 1 . n a news representation h d from news content including news title T and profile P . The content-based news representations would be taken as initial input embeddings of our model GNUD. Following DAN (Zhu et al., 2019)</ref>, we use two parallel convolutional neural networks (PCNN) taking the title T and profile P of news as input to learn the title-level and profile rom a Norwegian news portal to evaluate our model. We use two datasets named Adressa-1week and Adressa-10week, which respectively collect news click logs as long as 1 week and 10 weeks. Following DAN (Zhu et al., 2019)</ref>, we just select user id, news id, time-stamp, the title and profile of news to build our datasets, and preprocess the data by removing the stopw s recommendation framework fusing semanticlevel and knowledge-level representations. We model the news title and profile as semantic-level and knowledge-level representations, respectively.</p><p>DAN (Zhu et al., 2019)</ref>, a deep attention neural network for news recommendation which can capture the dynamic diversity of news and user's interests, and consider the
l information measuring dependency between two random variables in information theory to strengthen the relationship between the preference factors and the disentangled embeddings.</p><p>According to (Yang et al., 2018)</ref>, the mutual information maximization can be converted to the following form.</p><p>Given the representation of a user u in k-th (1 ≤ k ≤ K) lat
of u, we should only use the neighboring news articles d which connect with user u due to the preference factor k instead of all the neighbors. In this work, we apply a neighborhood routing algorithm (Ma et al., 2019a)</ref> to identify the subset of neighboring news that actually connect to u due to the preference factor k.</p><p>Neighborhood routing algorithm. The

t="#b10">(Huang et al., 2013)</ref>, a deep structured semantic model. In our experiments, we model the user's clicked news as the query and the candidate news as the documents.</p><p>Wide &amp; Deep (Cheng et al., 2016)</ref>, a deep model for recommendation which combines a (Wide) linear model and (Deep) feed-forward neural network. We also use the concatenation of
ndation methods focus on, and rely heavily on news contents. Few news recommendation models consider the user-news interaction graph structure which encodes useful highorder connectivity information. Hu et al. (2020)</ref> modeled the user-news interactions as a graph and proposed a graph convolution based model combining long-term and short-term interests, which demo /ref>, a deep attention neural network for news recommendation which can capture the dynamic diversity of news and user's interests, and consider the users' click sequence information.</p><p>GNewsRec (Hu et al., 2020)</ref>, a graph neural network based method combining long-term and short term interest modeling for news recommendation.</p><p>All the baselines are ini
al., 2013)</ref>, which has been successfully applied in the field of computer vision (Kim and Mnih, 2018;</ref>Gidaris et al., 2018;</ref>Hsieh et al., 2018)</ref>. β−VAE (Higgins et al., 2017)</ref> is a deep unsupervised generative approach that can automatically discover the
ulti-view learning framework. An et al. (2019)</ref> considered both titles and topic categories of news, and learned both long-and shortterm user representations, while Wu et al. (2019c)</ref> represented them by multi-head attention mechanism. However, these works seldom mine highorder structure information.</p><p>Graph neural networks
ndation methods focus on, and rely heavily on news contents. Few news recommendation models consider the user-news interaction graph structure which encodes useful highorder connectivity information. Hu et al. (2020)</ref> modeled the user-news interactions as a graph and proposed a graph convolution based model combining long-term and short-term interests, which demo /ref>, a deep attention neural network for news recommendation which can capture the dynamic diversity of news and user's interests, and consider the users' click sequence information.</p><p>GNewsRec (Hu et al., 2020)</ref>, a graph neural network based method combining long-term and short term interest modeling for news recommendation.</p><p>All the baselines are ini
information.</p><p>Graph neural networks. Recently, graph neu-ral networks (GNN) (Kipf and Welling, 2016;</ref>Hamilton et al., 2017;</ref>Veličković et al., 2017)</ref> have received growing attentions in graph embedding because of its powerful representation learning based on node features and graph struc
ulti-view learning framework. An et al. (2019)</ref> considered both titles and topic categories of news, and learned both long-and shortterm user representations, while Wu et al. (2019c)</ref> represented them by multi-head attention mechanism. However, these works seldom mine highorder structure information.</p><p>Graph neural networks
eriments</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Experimental Settings</head><p>Datasets. We conduct experiments on the realworld online news datasets Adressa (Gulla et al., 2017)</ref> 2 from a Norwegian news portal to evaluate our model. We use two datasets named Adressa-1week and Adressa-10week, which respectively collect ne
ndation methods focus on, and rely heavily on news contents. Few news recommendation models consider the user-news interaction graph structure which encodes useful highorder connectivity information. Hu et al. (2020)</ref> modeled the user-news interactions as a graph and proposed a graph convolution based model combining long-term and short-term interests, which demo /ref>, a deep attention neural network for news recommendation which can capture the dynamic diversity of news and user's interests, and consider the users' click sequence information.</p><p>GNewsRec (Hu et al., 2020)</ref>, a graph neural network based method combining long-term and short term interest modeling for news recommendation.</p><p>All the baselines are ini

eld of computer vision (Kim and Mnih, 2018;</ref>Gidaris et al., 2018;</ref>Hsieh et al., 2018)</ref>. β−VAE (Higgins et al., 2017)</ref> is a deep unsupervised generative approach that can automatically discover the independent latent factors of variation in unsupervised data,
reference disentanglement. Disentangled representation learning. Disentangled representation learning aims to identify and disentangle different latent explanatory factors hidden in the observed data (Bengio et al., 2013)</ref>, which has been successfully applied in the field of computer vision (Kim and Mnih, 2018;</ref><ref type="bibr"
ser by aggregating her clicked news history with different weights. However, these methods (Wu et al., 2019b;</ref>Zhu et al., 2019;</ref>An et al., 2019)</ref> usually focus on news contents, and seldom consider the collaborative signal in the form of high-order connectivity underlying the user-news intera ormativeness on news content for different users. Wu et al. (2019a)</ref> exploited different types of news information with an attentive multi-view learning framework. An et al. (2019)</ref> considered both titles and topic categories of news, and learned both long-and shortterm user representations, while <ref type="bibr" target="#b28"
users and news. Recently, many deep learning based methods have been proposed to automatically learn informative user and news representations (Okura et al., 2017;</ref>Wang et al., 2018)</ref>. For instance, DKN (Wang et al., 2018)</ref> learns knowledge-aware news representation via multi-channel CNN and ed to automatically learn informative user and news representations (Okura et al., 2017;</ref>Wang et al., 2018)</ref>. For instance, DKN (Wang et al., 2018)</ref> learns knowledge-aware news representation via multi-channel CNN and gets a representation of a user by aggregating her clicked news history wi ei-c.org/ns/1.0"><head>Methods</head><p>Adressa DMF (Xue et al., 2017)</ref>, a CF based deep matrix factorization model without considering the news content.</p><p>DKN (Wang et al., 2018)</ref>, a deep content based news recommendation framework fusing semanticlevel and knowledge-level representations. We model the news title and profi the recommendation performance. For example, DSSM (Huang et al., 2013</ref>) is a content-based deep neural network to rank a set of documents given a query. Some works (Wang et al., 2018;</ref>Zhu et al., 2019)</ref> propose to improve news representations via external knowledge, and learn representations
ld-start problem since news are often substituted frequently. Many works attempt to take advantage of rich content information, effectively improving the recommendation performance. For example, DSSM (Huang et al., 2013</ref>) is a content-based deep neural network to rank a set of documents given a query. Some works (Wang et al., 2018; pplying two parallel CNNs to word sequences in news titles and profiles respectively and concatenate them as news features. The user representation is learned from the user's news history.</p><p>DSSM (Huang et al., 2013)</ref>, a deep structured semantic model. In our experiments, we model the user's clicked news as the query and the candidate news as the documents.<
ld-start problem since news are often substituted frequently. Many works attempt to take advantage of rich content information, effectively improving the recommendation performance. For example, DSSM (Huang et al., 2013</ref>) is a content-based deep neural network to rank a set of documents given a query. Some works (Wang et al., 2018; pplying two parallel CNNs to word sequences in news titles and profiles respectively and concatenate them as news features. The user representation is learned from the user's news history.</p><p>DSSM (Huang et al., 2013)</ref>, a deep structured semantic model. In our experiments, we model the user's clicked news as the query and the candidate news as the documents.<
field, which has been widely explored in recent years. Learning better user and news representations is a central task for news recommendation. Traditional collaborative filtering (CF) based methods (Wang and Blei, 2011)</ref> often utilize historical interactions between users and news to define the objective function for model training, aiming to predict a persona
information.</p><p>Graph neural networks. Recently, graph neu-ral networks (GNN) (Kipf and Welling, 2016;</ref>Hamilton et al., 2017;</ref>Veličković et al., 2017)</ref> have received growing attentions in graph embedding because of its powerful representation learning based on node features and graph struc
ant task that aims at learning a nonlinear mapping to reconstruct high-resolution (HR) images from low-resolution (LR) images. Based on DNNs, many methods have been proposed to improve SR performance [51,</ref>26,</ref>10,</ref>12,</ref>49]</ref ve the SR performance, one can design effective models by increasing the model capacity, e.g., EDSR [26]</ref>, DBPN [16]</ref>, and RCAN [51]</ref>. However, these methods still suffer from the large space issue of possible mapping functions, resulting in the limited performance without producing sharp te ris et al. [16]</ref> propose a backprojection network (DBPN) that consists of several up-and down-sampling layers to iteratively produce LR and HR images. Zhang et al. [51]</ref> propose the channel attention mechanism to build a deep model called RCAN to further improve the performance of SR. However, these methods still have a very l × upscaling (See Figure 3</ref>) and 3 blocks for 8× upscaling. Unlike the baseline U-Net, we build each basic block using B residual channel attention block (RCAB) [51]</ref> to improve the model capacity. Following [39,</ref>23]</ref>, we add additional outputs to produ P, D) ∈ H dual :</p><p>closed-loop, according to the architecture design of the primal model, there are 2 dual models for 4× SR and 3 dual models for 8× SR, respectively. Let B be the number of RCABs [51]</ref> and F be the number of base feature channels. For 4× SR, we set B = 30 and F = 16 for DRN-S and B = 40 and F = 20 for DRN-L. For 8× SR, we set B = 30 and F = including the interpolation-based approaches [19]</ref> and reconstructionbased methods [16,</ref>25,</ref>51]</ref>. Haris et al. [16]</ref> propose a backprojection network (DBPN) that consists of several up-and down-sampling layers to iterati put patches of size 48 × 48 from LR images and the corresponding HR patches as the paired training data, and augment the training data following the method in [26,</ref>51]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>As shown in Table</head><p>Test data. For quantitative comparison on paired data, we evaluate differe
sing interest in learning super-resolution models without paired data in the unsupervised setting [43,</ref>54]</ref>. Based on Cycle-GAN [56]</ref>, Yuan et al. [43]</ref> propose a CinCGAN model to generate HR images without paired data. Recently, some blind SR methods <ref opposite mappings simultaneously to enhance the performance of language translation. Recently, this scheme has also been used to perform image translation without paired training data, e.g., CycleGAN [56]</ref> and DualGAN [42]</ref>. Specifically, a cycle consistency loss is proposed to avoid the mode collapse issue of GAN methods <ref r" target="#b45">[43,</ref>56]</ref> use a cycle consistency loss to avoid the possible mode collapse issue when solving the under-constrained image translation problem [56]</ref>. Unlike these methods, we seek to improve the performance of our SR model by adding an extra constraint, which reduces the possible function space by mapping train a DRN-Adapt model for each kind of unpaired data, i.e., Nearest data, BD data, and video frames collected from YouTube. Thus, there are 3 DRN-adapt models in total. And We also train a CinCGAN [56]</ref> model for each kind of unpaired data for comparison. Based on pretrained DRN-S, We train our DRN-Adapt models with a learning rate of 10 −4 and the data ratio GAN [56]</ref> and DualGAN [42]</ref>. Specifically, a cycle consistency loss is proposed to avoid the mode collapse issue of GAN methods [56,</ref>4,</ref>5]</ref> and help minimize the distribution divergence. However, these methods cannot be di m CycleGAN based SR Methods</head><p>There are several differences and advantages of DRN compared to CycleGAN based SR methods. First, Cycle-GAN based methods [43,</ref>56]</ref> use a cycle consistency loss to avoid the possible mode collapse issue when solving the under-constrained image translation problem <ref type="bibr" target="#b
On the contrary, our dual regression scheme seeks to adapt SR models to new LR data by exploiting both the real-world LR data and the paired synthetic data.</p><p>Dual learning. Dual learning methods [17,</ref>40,</ref>41,</ref>53]</ref> contain a primal model and a dual mode
line methods. 44,</ref>6]</ref> and many other applications [7,</ref>50,</ref>52,</ref>11,</ref>20]</ref>. Recently, image super-resolution (SR) has become an important task that aims a
b8">6]</ref> and many other applications [7,</ref>50,</ref>52,</ref>11,</ref>20]</ref>. Recently, image super-resolution (SR) has become an important task that aims at learning a nonlinear mapping to reconstruct high-resolution (HR) images from l
wo limitations.</p><p>First, learning the mapping from LR to HR images is typically an ill-posed problem since there exist infinitely many HR images that can be downscaled to obtain the same LR image [36]</ref>. Thus, the space of the possible functions that map LR to HR images becomes extremely large. As a result, the learning performance can be limited since learni
ref> and DualGAN [42]</ref>. Specifically, a cycle consistency loss is proposed to avoid the mode collapse issue of GAN methods [56,</ref>4,</ref>5]</ref> and help minimize the distribution divergence. However, these methods cannot be directly applied to the standard SR problem get="#b16">[14,</ref>9,</ref>13,</ref>15]</ref>, image generation [11,</ref>4]</ref>, and image restoration [10,</ref>12]</ref>. In this paper, we propose a novel Dual Regression Netwo
GAN [56]</ref>, Yuan et al. [43]</ref> propose a CinCGAN model to generate HR images without paired data. Recently, some blind SR methods [2,</ref>55]</ref> were proposed to learn the unknown degradation methods. However, these methods often totally discard the paired syntheti 1, for each iteration, we first sample m unpaired realworld data from S U and n paired synthetic data from S P , respectively. Then, we train our model end-to-end by minimizing the objective in Eqn. (2)</ref>. For convenience, we define the data ratio of unpaired data as</p><formula xml:id="formula_2">ρ = m/(m + n).<label>(3)</label></formula><p>Since paired syntheti


rison of the images produced by the state-of-the-art methods for 8× SR. Our dual regression scheme is able to produce sharper images than the baseline methods. 44,</ref>6]</ref> and many other applications [7,</ref>50,</ref>52,</ref><ref type="bib
downsampling operation, which is much simpler than the primal task for learning the upscaling mapping. Thus, we design the dual model with only two convolution layers and a LeakyReLU activation layer [28]</ref>, which has much lower computation cost than the primal model but works well in practice (See results in Section 5).</p></div> <div xmlns="http://www.tei-c.org
div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Architecture Design of DRN</head><p>We build our DRN upon the design of U-Net for superresolution [22,</ref>31]</ref> (See Figure 3</ref>). Our DRN model consists of two parts: a primal network and a dual network. We present the details for e
of real-world unpaired data. Different from the supervised setting, we first consider a toy case where we evaluate SR models on the LR images with different degradation methods (e.g., Nearest and BD [48]</ref>). During training, we can only access the LR images but not their corresponding HR images. Then, we also apply our method to LR raw video frames from YouTube.
represent the convolution layer with the stride of 2. Following the settings of EDSR [26]</ref>, we build the Upsampler with one convolution layer and one pixel-shuffle [33]</ref> layer to upscale the feature maps. Moreover, we use h and w to represent the height and width of the input LR images. Thus, the shape of output images should
olution in such a large space is very hard. To improve the SR performance, one can design effective models by increasing the model capacity, e.g., EDSR [26]</ref>, DBPN [16]</ref>, and RCAN [51]</ref>. However, these methods still suffer from the large space issue of possible mapping functions, resulting i "bibr" target="#b21">[19]</ref> and reconstructionbased methods [16,</ref>25,</ref>51]</ref>. Haris et al. [16]</ref> propose a backprojection network (DBPN) that consists of several up-and down-sampling layers to iteratively produce LR and HR images. Zhang et al. <ref type=" super-resolution. Many efforts have been made to improve the performance of SR, including the interpolation-based approaches [19]</ref> and reconstructionbased methods [16,</ref>25,</ref>51]</ref>. Haris et al. [16]</ref> propose a backprojecti iv> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training Method</head><p>Training method on paired data. Given paired training data, we follow the learning scheme of supervised SR methods [16,</ref>26]</ref> and train model by minimizing Eqn. ( 1</ref>). More details are shown in Secti
olution in such a large space is very hard. To improve the SR performance, one can design effective models by increasing the model capacity, e.g., EDSR [26]</ref>, DBPN [16]</ref>, and RCAN [51]</ref>. However, these methods still suffer from the large space issue of possible mapping functions, resulting i "bibr" target="#b21">[19]</ref> and reconstructionbased methods [16,</ref>25,</ref>51]</ref>. Haris et al. [16]</ref> propose a backprojection network (DBPN) that consists of several up-and down-sampling layers to iteratively produce LR and HR images. Zhang et al. <ref type=" super-resolution. Many efforts have been made to improve the performance of SR, including the interpolation-based approaches [19]</ref> and reconstructionbased methods [16,</ref>25,</ref>51]</ref>. Haris et al. [16]</ref> propose a backprojecti iv> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training Method</head><p>Training method on paired data. Given paired training data, we follow the learning scheme of supervised SR methods [16,</ref>26]</ref> and train model by minimizing Eqn. ( 1</ref>). More details are shown in Secti
possible space of the mapping functions to improve the training of SR models becomes an important problem.</p><p>Second, it is hard to obtain a promising SR model when the paired data are unavailable [43,</ref>54]</ref>. Note that most SR methods rely on the paired training data, i.e., HR images with their Bicubic-degraded LR counterpar or realworld applications can be very challenging. More critically, if we directly apply existing SR models to real-world data, they often incur a severe adaptation problem and yield poor performance [43,</ref>54]</ref>. Therefore, how to effectively exploit the unpaired data to adapt SR models to real-world applications becomes an urge v xmlns="http://www.tei-c.org/ns/1.0"><head>Unsupervised super-resolution.</head><p>There is an increasing interest in learning super-resolution models without paired data in the unsupervised setting [43,</ref>54]</ref>. Based on Cycle-GAN [56]</ref>, Yuan et al. [43]</ref> p orld LR data. More critically, the degradation methods of LR images are often unknown, making this problem very challenging. In this case, existing SR models often incur the severe adaptation problem [43,</ref>54]</ref>. To alleviate this issue, we propose an efficient algorithm to adapt SR models to the new LR data. The training algori rg/ns/1.0"><head n="3.4.">Differences from CycleGAN based SR Methods</head><p>There are several differences and advantages of DRN compared to CycleGAN based SR methods. First, Cycle-GAN based methods [43,</ref>56]</ref> use a cycle consistency loss to avoid the possible mode collapse issue when solving the under-constrained image transl ut paired data in the unsupervised setting [43,</ref>54]</ref>. Based on Cycle-GAN [56]</ref>, Yuan et al. [43]</ref> propose a CinCGAN model to generate HR images without paired data. Recently, some blind SR methods [2,</ref><ref type="bibr" tar



, UR-BAN100 [21]</ref> and MANGA109 [29]</ref>. Two commonly used image quality metrics are adopted as the metrics, such as PSNR and SSIM [38]</ref>. Following [37]</ref>, we train our models on DIV2K [34]</ref> and Flickr2K <ref type="bibr" tar
argeted UAPs without original training data, as shown in Figure 1</ref>. Our proposed approach is more practical because the training data is generally inaccessible to the attacker [32]</ref>. Our contributions can be summarized as follows:</p><p>• We propose to treat the DNN logits as a vector for feature representation. These logit vectors can be g to fool only a subset of classes. The above mentioned universal attacks require utilization of the original training data. However, in practice the attacker often has no access to the training data [32]</ref>. To overcome this limitation, Mopuri et al. propose to generate universal perturbation without training data [32]</ref>. Howeve ttacker often has no access to the training data [32]</ref>. To overcome this limitation, Mopuri et al. propose to generate universal perturbation without training data [32]</ref>. However, their approach is specifically designed for non-targeted attacks by maximizing the activation scores in every layer, and their performance is inferi type="bibr" target="#b29">30,</ref>5]</ref> and universal (i.e. image-agnostic) attacks [27,</ref>19,</ref>32,</ref>26,</ref>35,</ref>46,</ref>34]</ref>
egorized under image-dependent attacks [42,</ref>14,</ref>22,</ref>30,</ref>5]</ref> and universal (i.e. image-agnostic) attacks [27,</ref>19,</ref>32,</ ngle perturbation to attack most images. Image-dependent attack techniques have been explored in a variety of works ranging from optimization based techniques [42,</ref>5]</ref> to FGSM related techniques [14,</ref>22,</ref>7,</ref><ref type="bibr is case, the proxy data can be either a random source dataset or the original training data, depending on data availability. Note that similar techniques of clamping the logits have also been used in [5]</ref>, however, their motivation is to obtain minimum-magnitude (image-dependent) perturbations. While the target logit in loss function L t CL1 is increased, the log eted fooling ratio (%) and targeted fooling ratio (%) obtained for 5 runs and target class 'sea lion'. ± 0.6 55.4 ± 1.0 70.8 ± 1.5 55.2 ± 2.2 89.1 ± 0.3 75.9 ± 0.9 87.9 ± 0.5 70.8 ± 1.1 78.2 ± 0.9 66.5</ref> ± 1.3 LL 89.2 ± 0.4 47.1 ± 1.1 71.6 ± 0.8 56.9 ± 1.1 91.0 ± 0.3 79.0 ± 0.6 90.8 ± 0.2 73.1 ± 0.8 80.1 ± 0.8 69.1 ± 0.4</figDesc><table><row><cell>Loss</cell><cell
ataset. Some previous explanations, ranging from limited training data induced over-fitting [39,</ref>44]</ref> to robustness under noise [11,</ref>12,</ref>6]</ref>, are well aligned with their framework [17]</ref>
ng from limited training data induced over-fitting [39,</ref>44]</ref> to robustness under noise [11,</ref>12,</ref>6]</ref>, are well aligned with their framework [17]</ref>. The concept of non-robust features is a
er-fitting [39,</ref>44]</ref> to robustness under noise [11,</ref>12,</ref>6]</ref>, are well aligned with their framework [17]</ref>. The concept of non-robust features is also implicitly explored in other works <
ng from limited training data induced over-fitting [39,</ref>44]</ref> to robustness under noise [11,</ref>12,</ref>6]</ref>, are well aligned with their framework [17]</ref>. The concept of non-robust features is a
46">47]</ref>. However, DNNs are also known to be vulnerable to adversarial attacks [42,</ref>37]</ref>. A wide variety of previous works [14,</ref>43,</ref>44,</ref>21,</ref>33,</ref chniques have been explored in a variety of works ranging from optimization based techniques [42,</ref>5]</ref> to FGSM related techniques [14,</ref>22,</ref>7,</ref>45]</ref>. Universal adversarial perturbations (UA nation of adversarial vulnerability. Goodfellow et al. attribute the reason of adversarial examples to the local linearity of DNNs, and support their claim by their proposed simple yet effective FGSM [14]</ref>. However, this linearity hypothesis is not fully compatible with the existence of adversarial examples which violate local linearity <ref type="bibr" target=" ef type="bibr" target="#b17">18]</ref>.</p><p>Existing adversarial attack methods. The existing attacks are commonly categorized under image-dependent attacks [42,</ref>14,</ref>22,</ref>30,</ref>5]</ref> and universal (i.e. image-agnostic) attac
numerous applications, ranging from image classification [16,</ref>48]</ref> to motion regression [8,</ref>47]</ref>. However, DNNs are also known to be vulnerable to adversarial attacks [42,</ref>37]</ref>. A wide
"><head n="1.">Introduction</head><p>Deep neural networks (DNNs) have shown impressive performance in numerous applications, ranging from image classification [16,</ref>48]</ref> to motion regression [8,</ref>47]</ref>. However, DNNs are also known to be vulnerable to adversar
e proxy datasets. In Algorithm 1, we set the number of iterations to 1000, use loss function L t CL2 and a learning rate of 0.005 with batch-size 32. As the proxy datasets, we use images from MS-COCO [23]</ref> and Pascal VOC [9]</ref>, two widely used object detection datasets, and Places365 [50]</ref>, a
/p><p>Existing adversarial attack methods. The existing attacks are commonly categorized under image-dependent attacks [42,</ref>14,</ref>22,</ref>30,</ref>5]</ref> and universal (i.e. image-agnostic) attacks [27,</ of works ranging from optimization based techniques [42,</ref>5]</ref> to FGSM related techniques [14,</ref>22,</ref>7,</ref>45]</ref>. Universal adversarial perturbations (UAPs) were first proposed by <ref type="bib
dress the challenges in learning from distant supervision, our approach leverages the power of pre-trained language models (e.g., ELMo (Peters et al., 2018)</ref>, BERT (Devlin et al., 2019)</ref>, XLnet (Yang et al., 2019)</ref>) which are particularly attractive to this task due to the following merits: F power to capture general semantics and syntactic information effectively. These language models have achieved state-of-the-art performance in many popular NLP benchmarks with appropriate fine-tuning (Devlin et al., 2019;</ref>Liu et al., 2019b;</ref>Yang et al., 2019;</ref>La "#tab_2">2</ref> presents the F 1 scores, precision and recall for all methods. Note that our implementations of the fully supervised NER methods attain very close to the state-of-the-art performance (Devlin et al., 2019;</ref>Limsopatham and Collier, 2016)</ref>. Our results are summarized as follows:</p><p>• For all five datasets, our
rks with appropriate fine-tuning (Devlin et al., 2019;</ref>Liu et al., 2019b;</ref>Yang et al., 2019;</ref>Lan et al., 2020b;</ref>Raffel et al., 2019)</ref>, which demonstrates their strong ability in modeling the text data.</p><p>To fully harn rg/ns/1.0"><head n="2.2">Pre-trained Language Model</head><p>Pre-trained language models, such as BERT and its variants (e.g., RoBERTa (Liu et al., 2019b)</ref>, ALBERT (Lan et al., 2020b)</ref> and T5 (Raffel et al., 2019)</ref>), have achieved state-of-the-art performance in many natural language underst
ed types (e.g., locations, persons, organizations)</ref>. It is a core task in knowledge extraction and is important to various downstream applications such as user interest modeling (Karatay and Karagoz, 2015)</ref>, question answering (Khalid et al., 2008)</ref> and dialogue systems (Bowd
></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B Baseline Settings</head><p>For the baselines, we implement LSTM-CNN-CRF with Pytorch 15 and use the pre-trained 100 dimension GloVe Embeddings (Pennington et al., 2014)</ref> as the input vector. Then, we set the dimension of character-level embeddings to 30 and feed them into a 2D convolutional neural network
ions, etc. Formally, given a sentence with N tokens X = [x 1 , ..., x N ], an entity is a span of tokens s = [x i , ..., x j ] (0 ≤ i ≤ j ≤ N ) associated with an entity type. Based on the BIO schema (Li et al., 2012)</ref>, NER is typically formulated as a sequence labeling task of assigning a sequence of labels Y = [y 1 , ..., y N ] to the sentence X. Specifically,
nner. The stacked self-attention modules of the Table 1</ref>: Existing Gazetteer Matching Performance on Open-Domain (Sang and De Meulder, 2003;</ref>Strauss et al., 2016)</ref> and Biomedical Domain NER Datasets (Shang et al., 2018)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1

>Ni et al. Ni et al. (2017)</ref> use heuristic rules to filter out sentences with low matching quality. However, this filtering strategy improves the precision at the expense of lowering the recall. Cao et al. Cao et al. (2019)</ref> attempt to induce labels for entity mentions based on their occurrence popularity in the concept taxonomy, which can suffer from labeli r" target="#b35">(Shang et al., 2018)</ref> trains the model by assigning ambiguous tokens with all possible labels and then maximizing the overall likelihood using a fuzzy LSTM-CRF model; (iii) LRNT (Cao et al., 2019)</ref> is the state-of-the-art model for low-resource named tagging, which applies partial-CRFs on high-quality data with non-entity sampling. When comp
he initialization, we can efficiently adapt the pre-trained BERT to the target NER task using stochastic gradient-type algorithms, e.g., ADAM (Kingma and Ba, 2014;</ref>Liu et al., 2020)</ref>. Following Raffel et al. (2019)</ref>, our adaptation process updates the entire model including both the NER clas
ions, etc. Formally, given a sentence with N tokens X = [x 1 , ..., x N ], an entity is a span of tokens s = [x i , ..., x j ] (0 ≤ i ≤ j ≤ N ) associated with an entity type. Based on the BIO schema (Li et al., 2012)</ref>, NER is typically formulated as a sequence labeling task of assigning a sequence of labels Y = [y 1 , ..., y N ] to the sentence X. Specifically,
Yang et al., 2018;</ref>Shang et al., 2018)</ref>, but they still require a considerable amount of annotated tokens or external tools. To address the label noise issue, Ni et al. Ni et al. (2017)</ref> use heuristic rules to filter out sentences with low matching quality. However, this filtering strategy improves the precision at the ex
, our proposed robust training method, unlike the previous works in this arena [11,</ref>28,</ref>37,</ref>8]</ref>, regularizes the spectral norm of the weight matrix at each individual layer based on certain Lyapunov conditions, independently from other layers. Our layer-wis ons' responses to the inputs. The closest to our work are the results given in [11,</ref>28,</ref>37,</ref>8]</ref>. [8]</ref> utilizes Lipschitz properties of the DNN to improve robustness against adversarial attacks. Unlike <ref type="bibr" targ arization against a single threshold β. All the previous works on this subject [11,</ref>28,</ref>37,</ref>8]</ref>, keep β constant across layers. These harder constraints over-regularize and thus impair the DNNs ability against attacks. Our results outlined in Appendix K sho t to our work are the results given in [11,</ref>28,</ref>37,</ref>8]</ref>. [8]</ref> utilizes Lipschitz properties of the DNN to improve robustness against adversarial attacks. Unlike [8]</ref>, our approach does no rget="#b36">37,</ref>8]</ref>. [8]</ref> utilizes Lipschitz properties of the DNN to improve robustness against adversarial attacks. Unlike [8]</ref>, our approach does not require a predetermined set of hyper-parameters to prove robustness. Our analysis provides a range of possible values which determine dif ess comparison between our proposed approach and the works given in [11]</ref>, [28]</ref>, [37]</ref> and [8]</ref>. [28]</ref>, [11]</ref> propose training networks with the same spectral regularization enforced a ntire network where ρ(W l ) ≤ β for l = 1, ..., n and β is a constant. We select 3 values of β from their papers: β = 1.0, 1.6, 2.0. The 2 works given in [37]</ref> and [8]</ref> may be seen as subsets of the works given in [28]</ref> and [11]</ref>, where ρ(W l ) ≤ β for l =
usually adopted to show that all the data points inside an p ball around a sample data point have the same prediction [36,</ref>21,</ref>7,</ref>9]</ref>. The bounds provided by these methods are usually loose, and the computational costs associated with them increase exponent
IFAR10, SVHN and ImageNet). Appendix L contains the details on hyperparameters and training process for the above architecture and data set combinations. The experiments are implemented in TensorFlow [1]</ref> and the code will be made readily available. We test the DNNs against the fast gradient method (FGM) attack [15]</ref> with Frobe
tness analysis of a ResNet building block</head><p>The following represents the input-output mapping of a building block l for incremental inputs u l2 , u l1 and outputs y l2 , y l1 in a ResNet layer [17]</ref>, where y li = u li + F(u li , {W l }),</p><formula xml:id="formula_29">M l = (u l2 − u l1 ) T (y l2 − y l1 ) − δ l (y l2 − y l1 ) T (y l2 − y l1 ) − ν l (u l2
onal costs associated with them increase exponentially with the size of the network. These approaches are only applicable to parts of the input space for which feasible solutions exist. Works such as [39]</ref> have empirically shown that bounding a layer's response to the input generally improves robustness. Works such as [35,</ref><re
25]</ref> with 100 iterations, α = 0.02 and the same range of epsilons. Further, we show in Appendix J that our approach provides improved robustness against the Carlini &amp; Wagner (C&amp;W) attack [6]</ref>. Our robust Lyapunov training method regularizes the spectral norm of a layer l so that, ρ(W l ) ≤ β where</p><formula xml:id="formula_14">β = 1 δ 2 l + 2|ν l |
fenses, complex optimization schemes are usually adopted to show that all the data points inside an p ball around a sample data point have the same prediction [36,</ref>21,</ref>7,</ref>9]</ref>. The bounds provided by these methods are usually loose, and the computational cost
#b4">5,</ref>2,</ref>31]</ref>. While optimal defenses have been developed for simple linear models [3,</ref>24]</ref>, the over-parameterized nature of DNNs and the complexity of surfaces learned during training make the development of robust solutions against the adversary di
#b4">5,</ref>2,</ref>31]</ref>. While optimal defenses have been developed for simple linear models [3,</ref>24]</ref>, the over-parameterized nature of DNNs and the complexity of surfaces learned during training make the development of robust solutions against the adversary di
usually adopted to show that all the data points inside an p ball around a sample data point have the same prediction [36,</ref>21,</ref>7,</ref>9]</ref>. The bounds provided by these methods are usually loose, and the computational costs associated with them increase exponent
tness analysis of a ResNet building block</head><p>The following represents the input-output mapping of a building block l for incremental inputs u l2 , u l1 and outputs y l2 , y l1 in a ResNet layer [17]</ref>, where y li = u li + F(u li , {W l }),</p><formula xml:id="formula_29">M l = (u l2 − u l1 ) T (y l2 − y l1 ) − δ l (y l2 − y l1 ) T (y l2 − y l1 ) − ν l (u l2
stract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The majority of the research efforts on improving VAEs [1,</ref>2]</ref> is dedicated to the statistical challenges, such as reducing the gap between approximate and true posterior distributions /formula><p>where q(z z z &lt;l |x x x) := l−1 i=1 q(z z z i |x x x, z z z &lt;i ) is the approximate posterior up to the (l − 1) th group. The objective is trained using the reparameterization trick [1,</ref>2]</ref>.</p><p>The main question here is how to implement the conditionals in p(x x x, z z z) and q(z z z|x x x) using neural netw /1.0"><head n="2">Background</head><p>In this section, we review VAEs, their hierarchical extension, and bidirectional encoder networks [4]</ref>.</p><p>The goal of VAEs [1]</ref> is to train a generative model in the form of p(x x x, z z z) = p(z z z)p(x x x|z z z) where p(z z z) is a prior distribution over latent variables z z z and p(

</ref>23]</ref>, or tackling posterior collapse [24,</ref>25,</ref>26,</ref>27]</ref>. The role of neural network architectures for VAEs is somewhat overlooked, as most previous work borrows the architectures from classification tasks.</p><p>Fig
Activation: The Swish activation [47]</ref>, f (u) = u 1+e −u , has been recently shown promising results in many applications [48,</ref>49]</ref>. We also observe that the combination of BN and Swish outperforms WN and ELU activation [50]</ref> used by the previous works <r
is dedicated to the statistical challenges, such as reducing the gap between approximate and true posterior distributions [3,</ref>4,</ref>5,</ref>6,</ref>7,</ref>8,</ref>9,</ref><ref type= ue posterior p(z z z|x x x) is in general intractable, the generative model is trained with the aid of an approximate posterior distribution or encoder q(z z z|x x x).</p><p>In deep hierarchical VAEs [5,</ref>9,</ref>4,</ref>42,</ref>43]</ref>, to
te posterior distribution or encoder q(z z z|x x x).</p><p>In deep hierarchical VAEs [5,</ref>9,</ref>4,</ref>42,</ref>43]</ref>, to increase the expressiveness of both the approximate posterior and prior, the latent variables are partitioned into > <div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Implementation Details</head><p>Warming-up the KL Term: Similar to the previous work, we warm-up the KL term at the beginning of training [42]</ref>. Formally, we optimize the following objective: E q(z z z|x x x) [log p(x x x|z z z)] − βKL(q(z z z|x x x)||p(z z z)) , where β is annealed from 0 to 1 at the
/ref> models have omitted BN as they observed that "the noise introduced by batch normalization hurts performance" [4]</ref> and have relied on weight normalization (WN) [46]</ref> instead. In our early experiments, we observed that the negative impact of BN is during evaluation, not training. Because of the slow-moving running statistic
<p>For visualizing generated samples on challenging datasets such as CelebA HQ, it is common to lower the temperature of the prior to samples from the potentially high probability region in the model [61]</ref>. This is done by scaling down the standard deviation of the Normal distributions in each conditional in the prior, and it often improves the quality of the sa .2 in the appendix.</p><p>Fig. 4</ref> visualizes the samples generated by NVAE along with the samples from MaCow [66]</ref> and Glow [61]</ref> on CelebA HQ for comparison. As we can see, NVAE produces high quality and diverse samples on all datasets even with small temperatures. We encourage the inte conds (56 ms/image). MaCow [66]</ref> reports 434.2 ms/image in a similar batched-sampling experiment (∼ 8× slower).  [66]</ref> and Glow [61]</ref> are shown for comparison (images are from the original publications). NVAE generates diverse high quality samples even with a small temperature, and it exhibi ef type="bibr" target="#b72">[73]</ref>, CelebA HQ [28]</ref>, and FFHQ 256×256 [74]</ref>. For all the datasets but FFHQ, we follow Glow [61]</ref> for the train and test splits. In FFHQ, we use 63K images for training, and 7K for test.</p><p>Images in FFHQ and CelebA HQ are downsampled to 256 × 256 pixel K images for training, and 7K for test.</p><p>Images in FFHQ and CelebA HQ are downsampled to 256 × 256 pixels, and are quantized in 5 bits per pixel/channel to have a fair comparison with prior work [61]</ref>.</p><p>Hyperparameters: Given a large number of datasets and the heavy compute requirements, we do not exhaustively optimize the hyperparameters. In our early :</head><label>4</label><figDesc>Figure 4: (a)-(e) Sampled images from NVAE with the temperature in prior (t). (f)-(g) A few images generated by MaCow[66]</ref> and Glow[61]</ref> are shown for comparison (images are from the original publications). NVAE generates diverse high quality samples even with a small temperature, and it exhibi
tp://www.tei-c.org/ns/1.0"><head n="4.1">Main Quantitative Results</head><p>We examine NVAE on the dynamically binarized MNIST [71]</ref>, CIFAR-10 [72], ImageNet 32×32 [73]</ref>, CelebA HQ 256×256 [28]</ref>, and FFHQ 256×256 [74]</ref> datasets. All the datasets except FFH e the memory. Please see our code for additional details.</p><p>Datasets: We examine NVAE on the dynamically binarized MNIST [71]</ref>, CIFAR-10 [72], ImageNet 32 × 32 [73]</ref>, CelebA HQ [28]</ref>, and FFHQ 256×256 [74]</ref>. For all the datasets but FFHQ, we follow Glo
z z|x x x).</p><p>In deep hierarchical VAEs [5,</ref>9,</ref>4,</ref>42,</ref>43]</ref>, to increase the expressiveness of both the approximate posterior and prior, the latent variables are partitioned into disjoint groups, z z z = {z z z 1 , z z
ref type="bibr" target="#b16">[17,</ref>18,</ref>19,</ref>20,</ref>21,</ref>22,</ref>23]</ref>, or tackling posterior collapse [24,</ref>25,</ref><ref t
">[51]</ref> to the extent that it can be worse than naive software execution [53]</ref>. (iii) Designing a hardware for a fixed modest-sized parameter, e.g., n = 2 12  [54]</ref>. However, encryption parameters determine the security-level and the maximum number of consecutive multiplications that one can perform on ciphertext, both of s undergone several years of performance optimizations. We measure the performance of SEAL on a single-threaded Intel Xeon(R) Silver 4108 running at 1.80 GHz; which is a similar CPU used in prior art [54]</ref>. The single-thread baseline is used by prior art for measuring the performance (non-CKKS schemes) [54]</ref>. In addition, SEAL nning at 1.80 GHz; which is a similar CPU used in prior art [54]</ref>. The single-thread baseline is used by prior art for measuring the performance (non-CKKS schemes) [54]</ref>. In addition, SEAL is thread-safe but not multithreaded due to the complex data dependencies, hence, we cannot compare to a multi-threaded execution. In gener izes of 2 15 . However, due to the massive off-chip data transfer, their design does not yield superior performance compared to CPU execution.</p><p>Perhaps, the closest work to ours is by Roy et al. [54]</ref> in which authors propose an architecture for BFV scheme and implement their design on Xilinx Zynq UltraScale+ MPSoC ZCU102. In order to avoid off-chip memory fficient, offering more than two orders of magnitude performance improvement compared to Microsoft SEAL running on Intel Xeon Silver 4108 at 1.8 GHz (note that similar processor is used compared with [54]</ref> running at identical frequency).</p><p>FPGA-based Co-Processors. Designing co-processors has also been studied in the literature. These co-processors work in high response delay and (ii) on-chip BRAM with few megabits of capacity but very fast response time and high throughput.</p><p>As has been shown by prior art [53,</ref>54]</ref>, leveraging off-chip memory to store intermediate results significantly reduces the overall performance due to high delays between subsequent reads and writes.
vel operations are performed on the CPU-side, which makes the coprocessors of limited practical use. (ii) Storing intermediate results on off-chip memory, which significantly degrades the performance [51]</ref> to the extent that it can be worse than naive software execution [53]</ref>. (iii) Designing a hardware for a fixed modest-size vides 25? performance improvement over CPU. However, authors assume unlimited memory bandwidth which renders off-chip memory accesses free of cost and is not a realistic assumption. P?ppelmann et al. [51]</ref> have also proposed an architecture for YASHE scheme. Since ciphertexts are prohibitively large to be stored on on-chip memory, authors propose to leverage the
, is a function from R q to R d which transforms an element a ? R q into A ? R d , a vector of small polynomials such that a = ?g, A? (mod q). We integrate the RNS-friendly gadget decomposition from [8,</ref>36]</ref>.</p><p>CKKS Subroutines. We briefly review relevant subroutines: ? CKKS.Setup(?): For a security parameter ?, set a ring
ustomized hardware for non-CKKS schemes have taken one of these approaches: (i) Designing co-processors that only accelerate certain low-level ring operations [14,</ref>19,</ref>20,</ref>30,</ref>39,</ref>61]</ref> per watt of power than FPGAs by design. Therefore, FPGAs are more suitable candidates for highperformance and low-power secure computation.</p><p>Acceleration of YASHE and LTV Schemes. Several works [19,</ref>20,</ref>23,</ref>27,</ref>49,</ref
1</formula><p>p i . This choice of gadget decomposition contributes to a fast key switching and high noise growth. With the special modulus p and a rescaling at the end of key switching, explained in [15]</ref>, key switching is almost noise-free.</p><p>? KeySwitch(ct, ksk): Given a ciphertext ct = (c 0 , c 1 ) ? R 2 q ? decryptable with secret key s and a key switch
bibr" target="#b49">48,</ref>59</ref>]. Wang et al. [59]</ref> have proposed the first GPU acceleration of FHE that targets Gentry-Halevi [34]</ref> scheme. Subsequent improvements are reported in [60]</ref>. In [58]</ref>, a GPU-based implement
processors has also been studied in the literature. These co-processors work in conjunction with CPUs and accelerate one or more of the homomorphic operations [20,</ref>37,</ref>39,</ref>41,</ref>46,</ref>47]</ref> bibr" target="#b40">39,</ref>41,</ref>46,</ref>47]</ref>. In [46]</ref> and [37,</ref>47]</ref>, authors focus on designing hardware architecture for the encryption operation only, by leveraging Karatsuba and Comba
ed the first GPU acceleration of FHE that targets Gentry-Halevi [34]</ref> scheme. Subsequent improvements are reported in [60]</ref>. In [58]</ref>, a GPU-based implementation of BGV scheme [11]</ref> is introduced. In [6]</ref>, a comprehensive
ref type="bibr" target="#b14">[14,</ref>19,</ref>20,</ref>30,</ref>39,</ref>61]</ref>; high-level operations are performed on the CPU-side, which makes the coprocessors of limited practical use. (ii) Storing intermediate results on off-chip memo based on FPGAs or ASICs -that can be used to accelerate homomorphic operations [13,</ref>28,</ref>29,</ref>61,</ref>62]</ref>. In [14]</ref>, a large-integer multiplier and a Barrett modular reduction are proposed
Designing co-processors that only accelerate certain low-level ring operations [14,</ref>19,</ref>20,</ref>30,</ref>39,</ref>61]</ref>; high-level operations are performed on the CPU-side, which makes the coprocess
"#b10">[10]</ref> and LTV [45]</ref> schemes or their variants. These constructions -based on an overstretched NTRU assumption -are subject to a subfield lattice attack [3]</ref> and are no longer secure. In [52]</ref>, an architecture for YASHE scheme is proposed that provides 25? performance improvement o
ion with reflections is formulated as, where M, B, and R represent observed mixture images with reflections, background, and reflection images, respectively. Here, α and β are the mixing coefficients [5,</ref>27,</ref>26]</ref>.</p><formula xml:id="formula_0">M = αB + βR,<label>(1)</label></formula><p>Refle e images and the associated background as well as reflection, which may contribute to more realistic generation results and clearer separation results. Moreover, we introduce the gradient constraints [5,</ref>26]</ref> to make the model learning more effective, in which the edge map estimation is elegantly dealt with as an auxiliary task ced. Finally, the training strategy is presented.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Framework of the Proposed Scheme</head><p>In contrast to the conventional pipelines [5,</ref>29,</ref>24]</ref> that treat the image generation and separation as two independent stages, we com ) → M, where the non-linear mappings can produces more realistic reflection appearances (first to third columns in Figure 4</ref> 1 ) than previous linear functions [5,</ref>26,</ref>17,</ref>1]</ref> with fixed coefficients.</p><p>Separator ( rator for the mixture images by leveraging multi-task learning to estimate the background, reflection, and the background edge map (E) concurrently. Instead of one-toone framework in previous methods [5,</ref>29]</ref>, our separator learns the mapping function as S : M → (B, R, E), where the multi-task learning framework models the imag the mapping function to generate a mixture image. It's not trivial to learn this function accurately. Recently, deep learning based reflection removal methods [24,</ref>5]</ref> with better generalization ability have been proposed to address the limitations arising from the handcrafted image priors. However, most existing methods work i ls by improperly handling the mutual effects of two phases in training models.</p><p>In contrast with previous methods [24,</ref>13,</ref>5]</ref>, that heavily rely on the simplified model in Equation 1 and regard the image generation and separation as two independent stages, the proposed model leverages t mouli et al. [4]</ref> proposed a two-stage deep learning approach to learn the edge features of the reflections with the light field camera. The framework introduced in [5]</ref> exploited the edge information when training the whole network to better preserve the image details. Though the deep learning based methods can better capture t k to generate the mixture images, a separator network to separate the mixture image into background and reflection, and three discriminator networks to produce the adversarial losses. Existing method [5]</ref> can be treated as a special instance of our method when the generator is simplified as a linear function.</p><p>As shown in Figure <ref type="figure" target="#f ataset. The comparison methods include Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, and FY17 [5]</ref>. The yellow boxes highlight some noticeable differences.</p><p>Table 1</ref>. Quantitative evaluation results on SIR 2 with the state-ofthe-ar p>LB14 [17]</ref> 0.801 0.829 21.77 WS16 [26]</ref> 0.833 0.877 22.39 NR17 [1]</ref> 0.832 0.882 23.70 FY17 [5]</ref> 0.820 0.871 22.51 CycleGAN [30]</ref> 0.794 0.813 20.10 Zhang18 [29]</ref> 0.842 0.885 24.01 Wan18 mage reflection removal methods, including Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 [26]</ref>, and LB14 [17]</ref>. For a fair co </cell><cell>24.32</cell></row></table></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Efficiency comparisons with FY17[5]</ref>, Zhang18[29]</ref> and Wan18[24]</ref> of an image with size 224 × 288 on a single Titan XP GPU.</
ture images with reflections, background, and reflection images, respectively. Here, α and β are the mixing coefficients [5,</ref>27,</ref>26]</ref>.</p><formula xml:id="formula_0">M = αB + βR,<label>(1)</label></formula><p>Reflection removal aims at removing the reflections R from M, such that the visibili as well as reflection, which may contribute to more realistic generation results and clearer separation results. Moreover, we introduce the gradient constraints [5,</ref>26]</ref> to make the model learning more effective, in which the edge map estimation is elegantly dealt with as an auxiliary task via a multi-task learning structure. W removing the reflections R from M, such that the visibility of the background scenes B is enhanced. In this scenario, image priors such as different blur levels between the background and reflection [26,</ref>17]</ref>, ghosting effects [22]</ref>, and the non-local similarity in the images <ref type="bib n produces more realistic reflection appearances (first to third columns in Figure 4</ref> 1 ) than previous linear functions [5,</ref>26,</ref>17,</ref>1]</ref> with fixed coefficients.</p><p>Separator (S). We perform a disentanglement in the aluation results on SIR 2 with the state-ofthe-arts methods using three different error metrics.</p><p>SSIM r SSIM PSNR(dB)</p><p>LB14 [17]</ref> 0.801 0.829 21.77 WS16 [26]</ref> 0.833 0.877 22.39 NR17 [1]</ref> 0.832 0.882 23.70 FY17 [5]</ref> 0.820 0.871 22.51 CycleGAN <ref Zhang18 [29]</ref>, CycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 [26]</ref>, and LB14 [17]</ref>. For a fair comparison, we use the codes provided by their authors and set the parameters as suggested in
e to the ill-posed nature, different priors have been employed to exploit the properties of the background and reflection layers, including the sparsity prior [15,</ref>14]</ref>, the blur level differences between the background and reflection layer [17]</ref>, the ghosting effects <ref type="bibr" target
where M, B, and R represent observed mixture images with reflections, background, and reflection images, respectively. Here, α and β are the mixing coefficients [5,</ref>27,</ref>26]</ref>.</p><formula xml:id="formula_0">M = αB + βR,<label>(1)</label></formula><p>Reflection removal aims at removing the refl various factors and much beyond the straightforward linear combination. For example, either non-uniform lighting conditions [12]</ref> or the non-flat surface of glass [27]</ref> may make Equation 1 invalid. As such, a general image formation with reflections is given by,</p><formula xml:id="formula_1">M = G(B, R),<label>(2)</label></f
that the visibility of the background scenes B is enhanced. In this scenario, image priors such as different blur levels between the background and reflection [26,</ref>17]</ref>, ghosting effects [22]</ref>, and the non-local similarity in the images [25]</ref>, have been ex flection layers, including the sparsity prior [15,</ref>14]</ref>, the blur level differences between the background and reflection layer [17]</ref>, the ghosting effects [22]</ref> and the Laplacian data fidelity term [1]</ref>. Other methods in fferences.</p><p>Table 1</ref>. Quantitative evaluation results on SIR 2 with the state-ofthe-arts methods using three different error metrics.</p><p>SSIM r SSIM PSNR(dB)</p><p>LB14 [17]</ref> 0.801 0.829 21.77 WS16 [26]</ref> 0.833 0.877 22.39 NR17 [1]</ref> 0.832 0.882 23.70 FY17 <ref ty ycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 [26]</ref>, and LB14 [17]</ref>. For a fair comparison, we use the codes provided by their authors and set the parameters as suggested in their original papers, and we follow the same traini earances (first to third columns in Figure 4</ref> 1 ) than previous linear functions [5,</ref>26,</ref>17,</ref>1]</ref> with fixed coefficients.</p><p>Separator (S). We perform a disentanglement in the separator for the mixture images by lev
f type="bibr" target="#b0">[1]</ref>. Other methods in this area remove reflections by virtue of multiple images. By exploiting different image correlation cues [2,</ref>6]</ref>, the modelling based methods using the multiple images show more reliable results. However, the requirements for specific capturing conditions hinder such method
everages the mutual benefits of the image generation and separation in a joint learning manner to improve the robustness. It is worthy to note that traditional cycle-consistent network, like CycleGAN [30]</ref>, cannot be directly applied to reflection removal, as its original setup of one-to-one mapping problem is less comprehensive for modeling the process of refle </ref>, a GAN framework where two generators share weights to learn the joint distribution of images in cross domains.</p><p>It is worthy to mention that some existing mature frameworks like CycleGAN [30]</ref> and DiscoGAN [10]</ref> are limited in handling reflection removal problem. They are only capable of learning the relationship b n the SIR2</ref> dataset. The comparison methods include Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, and FY17 [5]</ref>. The yellow boxes highlight some noticeable differences.</p><p>Table 1</ref>. Quantitative WS16 [26]</ref> 0.833 0.877 22.39 NR17 [1]</ref> 0.832 0.882 23.70 FY17 [5]</ref> 0.820 0.871 22.51 CycleGAN [30]</ref> 0.794 0.813 20.10 Zhang18 [29]</ref> 0.842 0.885 24.01 Wan18 [24]</ref> 0.854 0.891 24.08 Eq. ( is compared with seven state-ofthe-art single image reflection removal methods, including Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 [26]</ref>, and LB14 <ref typ rns the translation task in a supervised manner using cGANs [20]</ref>. To alleviate the problem of obtaining data pairs, unpaired image-to-image translation frameworks [30,</ref>10,</ref>18]</ref> have been proposed. UNIT [18]</ref> combines var hese two cycles, aiming to incorporate the cycle-consistent constraints to guide the training procedure. Moreover, in contrast with the classical cycle-consistent  model with the one-to-one framework [30,</ref>10]</ref>, we propose a joint mapping mechanism based on the additive relationship between the mixture image, the background, and
presented.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Framework of the Proposed Scheme</head><p>In contrast to the conventional pipelines [5,</ref>29,</ref>24]</ref> that treat the image generation and separation as two independent stages, we come up with a unified model, such that th ing multi-task learning to estimate the background, reflection, and the background edge map (E) concurrently. Instead of one-toone framework in previous methods [5,</ref>29]</ref>, our separator learns the mapping function as S : M → (B, R, E), where the multi-task learning framework models the image separation process in a more reasonab the reflection removal results on four wild scenes in the SIR2</ref> dataset. The comparison methods include Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, and FY17 [5]</ref>. The yellow boxes highlight some noticeable differences. 7 [1]</ref> 0.832 0.882 23.70 FY17 [5]</ref> 0.820 0.871 22.51 CycleGAN [30]</ref> 0.794 0.813 20.10 Zhang18 [29]</ref> 0.842 0.885 24.01 Wan18 [24]</ref> 0.854 0.891 24.08 Eq. ( 1</ref> </p></div> <div xmln ng. The sizes of mini-batch and momentum are set to 4 and 0.9, respectively. Figure 7</ref>. Perceptual study results on the whole SIR 2 dataset for the three best methods (Zhang18 [29]</ref>, Wan18 [24]</ref>, and ours) in terms of the quantitative scores in Table 1</ref>. The stastistics are obtain tate-of-the-art Methods</head><p>The proposed method is compared with seven state-ofthe-art single image reflection removal methods, including Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 <ref typ the-art methods. Moreover, when testing the models across datasets with different collecting protocols (e.g., the dataset of SIR 2 [23]</ref> and the dataset of Zhang18 [29]</ref>), we have observed that the dataset gap problem is worth further investigating to achieve consistently good performance on diverse real-world scenes. Meanwhil <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Efficiency comparisons with FY17[5]</ref>, Zhang18[29]</ref> and Wan18[24]</ref> of an image with size 224 × 288 on a single Titan XP GPU.</figDesc><table><row><cell></cell><cell cols="2">
f type="bibr" target="#b0">[1]</ref>. Other methods in this area remove reflections by virtue of multiple images. By exploiting different image correlation cues [2,</ref>6]</ref>, the modelling based methods using the multiple images show more reliable results. However, the requirements for specific capturing conditions hinder such method
reflection is quite complicated, as it is influenced by the interactions of various factors and much beyond the straightforward linear combination. For example, either non-uniform lighting conditions [12]</ref> or the non-flat surface of glass [27]</ref> may make Equation 1 invalid. As such, a general image formation with reflections is
nd reflection [26,</ref>17]</ref>, ghosting effects [22]</ref>, and the non-local similarity in the images [25]</ref>, have been explored. However, these low-level image priors are constrained by limited phenomena causing reflections, which may often be impractical in real-wo
units (relative to three tasks) is employed in the separator to improve the reflection removal ability. For the discriminator networks, we use 70 × 70 PatchGANs [9,</ref>16]</ref> which can be applied to arbitrarily-sized images in a fully convolutional fashion.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Loss Funct
units (relative to three tasks) is employed in the separator to improve the reflection removal ability. For the discriminator networks, we use 70 × 70 PatchGANs [9,</ref>16]</ref> which can be applied to arbitrarily-sized images in a fully convolutional fashion.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Loss Funct
better capture the image properties, the conventional two-stage framework ignores the intrinsic correlations, which largely limits their performances.</p><p>Generative Adversarial Networks (GAN). GAN [7]</ref> has become one of the most successful approaches for imageto-image translation problems. In GANs, two networks are adversarially trained simultaneously, where t
nd reflection [26,</ref>17]</ref>, ghosting effects [22]</ref>, and the non-local similarity in the images [25]</ref>, have been explored. However, these low-level image priors are constrained by limited phenomena causing reflections, which may often be impractical in real-wo
differences between the background and reflection layer [17]</ref>, the ghosting effects [22]</ref> and the Laplacian data fidelity term [1]</ref>. Other methods in this area remove reflections by virtue of multiple images. By exploiting different image correlation cues [2,</r three different error metrics.</p><p>SSIM r SSIM PSNR(dB)</p><p>LB14 [17]</ref> 0.801 0.829 21.77 WS16 [26]</ref> 0.833 0.877 22.39 NR17 [1]</ref> 0.832 0.882 23.70 FY17 [5]</ref> 0.820 0.871 22.51 CycleGAN [30]</ref> 0.794 0.813 20.10 Zhang18 <r 18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 [26]</ref>, and LB14 [17]</ref>. For a fair comparison, we use the codes provided by their a re 4</ref> 1 ) than previous linear functions [5,</ref>26,</ref>17,</ref>1]</ref> with fixed coefficients.</p><p>Separator (S). We perform a disentanglement in the separator for the mixture images by leveraging multi-task learning to estimate
nd reflection [26,</ref>17]</ref>, ghosting effects [22]</ref>, and the non-local similarity in the images [25]</ref>, have been explored. However, these low-level image priors are constrained by limited phenomena causing reflections, which may often be impractical in real-wo
d manner, which requires abundant paired training data, i.e., in the form of a triplet of {M, B, R} containing perfectly registered images from the same scene. The recently proposed benchmark dataset [23]</ref> is an example. Due to the high cost in capturing the real-world paired data, synthetic mixture images are often applied in accordance with the traditional rep benchmark dataset with state-of-the-art reflection removal methods. All results are evaluated in terms of both quantitative scores and visual quality. Due to the regional properties of the reflection [23]</ref>, we also adopt SSIMr [21]</ref> to assess the quality by focusing on local reflections.  </p></div> <div xmlns="http://www.tei- formed with three different error metrics. The results are summarized in Table 1</ref>, where the numbers displayed are the mean values over all 100 sets of wild images in the SIR 2 [23]</ref> dataset. In particular, Ours + Eq. ( 1</ref>) means that we set a random variable and use the data with probability 0. tp://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Discussions</head><p>In this paper, we propose a novel approach to jointly generate and separate reflections. Based on the public dataset SIR 2 [23]</ref> and the proposed real-world dataset, our method outperforms state-of-the-art methods in terms of both the quantitative and subjective quality.</p><p>There rem es the background details, which performs better than other state-of-the-art methods. Moreover, when testing the models across datasets with different collecting protocols (e.g., the dataset of SIR 2 [23]</ref> and the dataset of Zhang18 [29]</ref>), we have observed that the dataset gap problem is worth further investigating to achieve Unpaired Reflection Removal Dataset</head><p>In principle, the traditional triplet of {M, B, R} (mixture image, background image and reflection image) can be captured in a "remove-and-occlude" manner [23,</ref>28]</ref>: 1) Taking a photo of the mixture image through the glass; 2) capturing an image of the background scenes by removing training framework, paired pixelwise correspondence is not required when collecting image dataset. So we capture 4000+ images, which allows for a much larger scale than those used in existing methods [23,</ref>28]</ref>. Finally, we build a dataset containing 4027 images under various scenes, and example images are shown in Figure <ref rsity and generality over existing datasets in the following aspects:</p><p>• Devices. Besides using the high-end devices (e.g., the DSLR camera with fully manual control model) like previous methods [23,</ref>28]</ref>, we also use the cameras on different types of mobile phones (iphone 8, iphone X, etc.) to capture images. • Illuminat
where M, B, and R represent observed mixture images with reflections, background, and reflection images, respectively. Here, α and β are the mixing coefficients [5,</ref>27,</ref>26]</ref>.</p><formula xml:id="formula_0">M = αB + βR,<label>(1)</label></formula><p>Reflection removal aims at removing the refl various factors and much beyond the straightforward linear combination. For example, either non-uniform lighting conditions [12]</ref> or the non-flat surface of glass [27]</ref> may make Equation 1 invalid. As such, a general image formation with reflections is given by,</p><formula xml:id="formula_1">M = G(B, R),<label>(2)</label></f
differences between the background and reflection layer [17]</ref>, the ghosting effects [22]</ref> and the Laplacian data fidelity term [1]</ref>. Other methods in this area remove reflections by virtue of multiple images. By exploiting different image correlation cues [2,</r three different error metrics.</p><p>SSIM r SSIM PSNR(dB)</p><p>LB14 [17]</ref> 0.801 0.829 21.77 WS16 [26]</ref> 0.833 0.877 22.39 NR17 [1]</ref> 0.832 0.882 23.70 FY17 [5]</ref> 0.820 0.871 22.51 CycleGAN [30]</ref> 0.794 0.813 20.10 Zhang18 <r 18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 [26]</ref>, and LB14 [17]</ref>. For a fair comparison, we use the codes provided by their a re 4</ref> 1 ) than previous linear functions [5,</ref>26,</ref>17,</ref>1]</ref> with fixed coefficients.</p><p>Separator (S). We perform a disentanglement in the separator for the mixture images by leveraging multi-task learning to estimate
hand-crafted priors without learning. Due to the ill-posed nature, different priors have been employed to exploit the properties of the background and reflection layers, including the sparsity prior [15,</ref>14]</ref>, the blur level differences between the background and reflection layer [17]</ref>, the
presented.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Framework of the Proposed Scheme</head><p>In contrast to the conventional pipelines [5,</ref>29,</ref>24]</ref> that treat the image generation and separation as two independent stages, we come up with a unified model, such that th ing multi-task learning to estimate the background, reflection, and the background edge map (E) concurrently. Instead of one-toone framework in previous methods [5,</ref>29]</ref>, our separator learns the mapping function as S : M → (B, R, E), where the multi-task learning framework models the image separation process in a more reasonab the reflection removal results on four wild scenes in the SIR2</ref> dataset. The comparison methods include Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, and FY17 [5]</ref>. The yellow boxes highlight some noticeable differences. 7 [1]</ref> 0.832 0.882 23.70 FY17 [5]</ref> 0.820 0.871 22.51 CycleGAN [30]</ref> 0.794 0.813 20.10 Zhang18 [29]</ref> 0.842 0.885 24.01 Wan18 [24]</ref> 0.854 0.891 24.08 Eq. ( 1</ref> </p></div> <div xmln ng. The sizes of mini-batch and momentum are set to 4 and 0.9, respectively. Figure 7</ref>. Perceptual study results on the whole SIR 2 dataset for the three best methods (Zhang18 [29]</ref>, Wan18 [24]</ref>, and ours) in terms of the quantitative scores in Table 1</ref>. The stastistics are obtain tate-of-the-art Methods</head><p>The proposed method is compared with seven state-ofthe-art single image reflection removal methods, including Wan18 [24]</ref>, Zhang18 [29]</ref>, CycleGAN [30]</ref>, FY17 [5]</ref>, NR17 [1]</ref>, WS16 <ref typ the-art methods. Moreover, when testing the models across datasets with different collecting protocols (e.g., the dataset of SIR 2 [23]</ref> and the dataset of Zhang18 [29]</ref>), we have observed that the dataset gap problem is worth further investigating to achieve consistently good performance on diverse real-world scenes. Meanwhil <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Efficiency comparisons with FY17[5]</ref>, Zhang18[29]</ref> and Wan18[24]</ref> of an image with size 224 × 288 on a single Titan XP GPU.</figDesc><table><row><cell></cell><cell cols="2">
of hierarchical clustering and item hierarchy information which limits its application in unsupervised learning for computing meaningful and interpretable clusters on input graphs. On the other hand, [22]</ref> proposes an approach that automatically constructs an easyto-interpret taxonomy on a large-scale bi-partite graph in a unsupervised manner, facilitating an ef anding features in graph classification and clustering, and becomes prevailing in several scenarios such as link prediction, e-commerce recommendation, etc, [19]</ref>, [22]</ref>. There are some recent works that learn hierarchical graph representations by combining GNNs with different clustering processes. In particular, the recently el and individualized user preference respectively. Another intriguing application of hierarchical graph representation is e-commerce taxonomy for offering a personalized dynamic shopping navigation. [22]</ref> illstrates a topic-driven hierarchical taxonomy based on user-item bi-partite graph in presence of query interactions effectively expressing user intention. I elements, D k denotes the concatenation of the titles of all items belonging to the same topic t k .</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experiments and Results</head><p>SHOAL [22]</ref> is Alibaba's current topic-driven taxonomy solution deployed on Taobao platform, which also considers a hierarchical graph-based strategy but only uses a well archical separating capacity.</p><p>2) Offline Experimental Results: To investigate the model effectiveness, we compare our proposed method with Alibaba's current topic-driven taxonomy solution SHOAL [22]</ref>. In the parameter setting, we set the level number of the hierarchical structure L = 4 according to the observation of natural ontology level of items in the
al graph collaborative filtering do not consider underlying usercommunity interactions or user hierarchy which have shown an advantageous performance over paradigms using user-item interactions alone [19]</ref>- [21]</ref>.</p><p>Generally speaking, GNN methods are inherently flat and do not learn hierarchical representations of graphs. hieve prevailing results on graph classification benchmarks. Nonetheless, generating a hierarchical representation involves extensive and unscalable computation with the adjacent matrix of the graph. [19]</ref> learns a hierarchical representation of graphs by decomposing user information into two orthogonal spaces, each of which represents information captured by co l representations of graph enjoys its outstanding features in graph classification and clustering, and becomes prevailing in several scenarios such as link prediction, e-commerce recommendation, etc, [19]</ref>, [22]</ref>. There are some recent works that learn hierarchical graph representations by combining GNNs with different cluster ity level and individualized user preference respectively. CGNN can be considered as a special case of our proposed method, which fixes the number of user levels to 2. The parameter of CGNN refers to [19]</ref>. • DIN: A popular deep neural network method without graph structure information and hierarchical information in the e-commerce system. DIN can be regarded as
9]</ref>- [21]</ref>.</p><p>Generally speaking, GNN methods are inherently flat and do not learn hierarchical representations of graphs. On one hand, it demonstrates in [20]</ref> that hierarchical representations of graphs can be combined with various graph neural network architectures in an end-to-end fashion to achieve prevailing res 21">[22]</ref>. There are some recent works that learn hierarchical graph representations by combining GNNs with different clustering processes. In particular, the recently proposed approach DIFFPOOL [20]</ref>, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architec 30">[31]</ref>, [32]</ref> illustrate a user's community-level embedding to be effective in graph classification tasks, in addition to a user's individual embedding. In [20]</ref>, authors make some efforts in effectively co-training two embeddings by decomposing user information into two orthogonal spaces, each of which represents info efficiently with hierarchical user preferences and hierarchical item attractiveness to predict real-world e-commerce tasks of such large scale, including [30]</ref> and [20]</ref>. Our baseline algorithms are as follows:</p><p>• CGNN: A graph neural network method learns two user embeddings for prediction by decomposing user information
bit similar preference on items. Intuitively, integrating user-item interactions into the embedding function could contribute to making better user preference prediction. An approach named HOP-Rec in [29]</ref> performs random walks to enrich the interactions of a user with multi-hop connected items, which is beneficial to obtain better embeddings by partially captur
Note that the original keywords and titles of both queries and items in taxonomy task are composed of texts, which allows us to exploit the widely used natural language processing technique, word2vec [35]</ref>, to embed the original features of queries and items into the same latent space. Thus, the Bipartite Graph Neural Network applied on query-item graphs is slig
, and item recommendation.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph-based Collaborative Filtering</head><p>Another line of research [27]</ref>, [28]</ref> exploits the user-item interaction graph to infer user preference in a collaborative fashion, assuming behaviorally similar users would exhibit similar prefer

erated, the topic is probably associated with a set of items and each item will be connected with a number of queries. To make the topic more interpretive, we follow the similar strategy described in [37]</ref> to find the most representative query as the description for a specific topic. The topic description matching method mainly considers two factors for calculat


ing graph as a computation graph and generate individual node embeddings by passing, transforming, and aggregating node feature information across the graph [23]</ref>- [26]</ref>. The generated node embeddings are widely used as input to any prediction tasks, e.g., for node classification, link prediction, and item recommendation.</p><
bit similar preference on items. Intuitively, integrating user-item interactions into the embedding function could contribute to making better user preference prediction. An approach named HOP-Rec in [29]</ref> performs random walks to enrich the interactions of a user with multi-hop connected items, which is beneficial to obtain better embeddings by partially captur

bit similar preference on items. Intuitively, integrating user-item interactions into the embedding function could contribute to making better user preference prediction. An approach named HOP-Rec in [29]</ref> performs random walks to enrich the interactions of a user with multi-hop connected items, which is beneficial to obtain better embeddings by partially captur
, and item recommendation.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph-based Collaborative Filtering</head><p>Another line of research [27]</ref>, [28]</ref> exploits the user-item interaction graph to infer user preference in a collaborative fashion, assuming behaviorally similar users would exhibit similar prefer

rix of the graph. Consequently, it is computationally expensive that make it less popular in handling large-scale graphs [30]</ref>. On the other hand, some researchers [31]</ref>, [32]</ref> illustrate a user's community-level embedding to be effective in graph classification tasks, in addition to a user'
nd preference ranking [6]</ref>. More specific, collaborative filtering assumes that behaviorally similar users would exhibit similar preference on items, and vice versa [7]</ref>. As a result, users and items are vectorized as embeddings to reconstruct historical interactions for efficiently predicting user preference. Recently, graph ne
sider underlying usercommunity interactions or user hierarchy which have shown an advantageous performance over paradigms using user-item interactions alone [19]</ref>- [21]</ref>.</p><p>Generally speaking, GNN methods are inherently flat and do not learn hierarchical representations of graphs. On one hand, it demonstrates in <ref type=

nd preference ranking [6]</ref>. More specific, collaborative filtering assumes that behaviorally similar users would exhibit similar preference on items, and vice versa [7]</ref>. As a result, users and items are vectorized as embeddings to reconstruct historical interactions for efficiently predicting user preference. Recently, graph ne

., for node classification, link prediction, and item recommendation.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph-based Collaborative Filtering</head><p>Another line of research [27]</ref>, [28]</ref> exploits the user-item interaction graph to infer user preference in a collaborative fashion, assuming behaviorally
node embeddings of non-linear interactions in tasks such as node classification and link prediction [8]</ref>- [17]</ref>. In particular, [18]</ref> proposes a neural graph collaborative filtering method to explicitly integrate the user-item interactions into the embedding process, which is able to encode
y, the taxonomy results are very sensitive to the number of clusters that we set to be coarsened at each level. In order to generate a better clustering result, we exploit the Calinski-Harabasz Index [36]</ref> to maximize the between-cluster variance and minimize the within-cluster variance, the objective function can be formulated as</p><formula xml:id="formula_15"
node embeddings of non-linear interactions in tasks such as node classification and link prediction [8]</ref>- [17]</ref>. In particular, [18]</ref> proposes a neural graph collaborative filtering method to explicitly integrate the user-item interactions into the embedding process, which is able to encode
node embeddings of non-linear interactions in tasks such as node classification and link prediction [8]</ref>- [17]</ref>. In particular, [18]</ref> proposes a neural graph collaborative filtering method to explicitly integrate the user-item interactions into the embedding process, which is able to encode

sider underlying usercommunity interactions or user hierarchy which have shown an advantageous performance over paradigms using user-item interactions alone [19]</ref>- [21]</ref>.</p><p>Generally speaking, GNN methods are inherently flat and do not learn hierarchical representations of graphs. On one hand, it demonstrates in <ref type=
y, the taxonomy results are very sensitive to the number of clusters that we set to be coarsened at each level. In order to generate a better clustering result, we exploit the Calinski-Harabasz Index [36]</ref> to maximize the between-cluster variance and minimize the within-cluster variance, the objective function can be formulated as</p><formula xml:id="formula_15"

, and item recommendation.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph-based Collaborative Filtering</head><p>Another line of research [27]</ref>, [28]</ref> exploits the user-item interaction graph to infer user preference in a collaborative fashion, assuming behaviorally similar users would exhibit similar prefer
records in Taobao #2 dataset. Table VI summarizes the statistics of samples in datasets.</p><p>We adopt the area under the receiver operator curve (AUC) to evaluate the performance of all the methods [33]</ref>. AUC is the most popular evaluation metric on prediction tasks in both research and industry area. Larger AUC means better performance.  2) Compared Algorithm
>Zhong et al., 2019)</ref> and dialogue system (Madotto et al., 2018)</ref>, but also some early works use text as additional information (Xie et al., 2016;</ref>An et al., 2018)</ref> or jointly train the knowledge and text embedding in the same space <ref type="bibr" target "#b40">(Trouillon et al., 2016)</ref> adopt complex operations based on it. RotatE (Sun et al., 2019a)</ref> combines the advantages of both of them. Among these works, Xie et al. (2016)</ref> propose to utilize entity descriptions as an external information source and introduce an entity description encoder to enhance the TransE score
xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pre-trained language representation models (PLMs) such as ELMo (Peters et al., 2018a)</ref>, BERT (Devlin et al., 2019a)</ref> and XLNet (Yang et al., 2019)</ref> learn effective language representations from large-scale nonstructural an
pe="bibr" target="#b41">(Vaswani et al., 2017)</ref> as its encoder, Radford et al. (2018)</ref> demonstrate a pre-trained generative model (GPT) and its effects, while Devlin et al. (2019b)</ref> release a pre-trained deep Bidirectional Encoder Representation from Transformers (BERT), achieving state-of-the-arts on dozens of benchmarks r" target="#b10">Devlin et al. (2019b)</ref> release a pre-trained deep Bidirectional Encoder Representation from Transformers (BERT), achieving state-of-the-arts on dozens of benchmarks.</p><p>After Devlin et al. (2019b)</ref>, similar pre-trained encoders spring up recently. Yang et al. (2019)</ref> propose a permutation language mode LMs as our text encoders to extract entity representations from their descriptions.</p><p>For L LM , many alternatives for pre-trained language representation can be used, e.g., masked language model (Devlin et al., 2019b)</ref>. Note that those two tasks only share the text encoder and for each mini-batch, text sampled for L KE and L LM is not (necessarily) the same [CLS], x 1 , x 2 , ..., x N , [EOS],</formula><p>where [CLS] and [EOS] are two special tokens. Model output at [CLS] is often used as the sentence representation.</p><p>PLM Objective Inspired by BERT (Devlin et al., 2019b)</ref>, MLM randomly selects 15% of input tokens, among which 80% are masked with the special mark [MASK], 10% are replaced by another random token nstream Tasks</head><p>Like all BERT-like models, we fine-tune KEPLER on downstream tasks and use [CLS] output for sentence-level prediction and the outputs of all tokens for sequence labelling tasks (Devlin et al., 2019b)</ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Wikidata5m</head><p>We construct a new large-scale knowledge graph dataset w in experiments.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Structure</head><p>We use the transformer architecture (Vaswani et al., 2017)</ref> as in (Devlin et al., 2019b;</ref>Liu et al., 2019c)</ref>, which we will not address in details. To be more specific, we use RoBERTaBASE codes

</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pre-trained language representation models (PLMs) such as ELMo (Peters et al., 2018a)</ref>, BERT (Devlin et al., 2019a)</ref> and XLNet (Yang et al., 2019)</ref> learn ef
</ref> show that more data and more sophisticated parameter tuning would benefit pretrained encoders a lot and release a new state-ofthe-art model (Roberta). Other works explore how to add more tasks (Liu et al., 2019b)</ref> and more Knowledge Graph Embeddings In recent years knowledge embeddings have been extensively studied through predicting missing links in grap
-training procedure, we only use the English Wikipedia corpus to save time and also for a fair comparison with previous knowledgeenhanced PLMs (Zhang et al., 2019;</ref>Peters et al., 2019)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NLP Tasks</head><p>In this section, we introduce how our KEPLER can be used
sify relation types between two given entities from text. We evaluate our model and baselines on two commonlyused datasets: TACRED (Zhang et al., 2017)</ref> and FewRel (Han et al., 2018)</ref>. TACRED covers 42 relation types and contains 106,264 sentences. FewRel is a few-shot relation classification dataset, which has 100 relations a xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Accuracies (%) on FewRel dataset. "Proto" indicates Prototypical Networks(Snell et al., 2017)</ref> used inHan et al. (2018)</ref>. "PAIR" is proposed inGao et al. (2019)</ref> and "MTB" is from Baldini Soares et al. (2019).</figDesc><table><row
for richer semantic meanings under different circumstances.</p><p>Apart from those methods using pre-trained word embeddings as input features, there is another trend exploring pre-trained encoders. Dai and Le (2015)</ref> first propose to train an auto-encoder on unlabeled data, and then fine-tune it on downstream tasks. Howard and Rud
of pre-training in NLP. Early works focus on distributed word representation (Collobert and Weston, 2008;</ref>Mikolov et al., 2013;</ref>Pennington et al., 2014)</ref>, many of which are still often adopted in current models as word embeddings for their ability to capture syntactic and semantic informatio
ks. However, they are typically lack of factual world knowledge (Petroni et al., 2019;</ref>Logan et al., 2019)</ref>.</p><p>Recent works (Zhang et al., 2019;</ref>Peters et al., 2017;</ref>Liu et al., 2019a)</ref> utilize entity embeddings of large-scale kno ref> parameters to initialize our model.</p><p>In our pre-training procedure, we only use the English Wikipedia corpus to save time and also for a fair comparison with previous knowledgeenhanced PLMs (Zhang et al., 2019;</ref>Peters et al., 2019)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NLP Tasks</head><p 64 sentences. FewRel is a few-shot relation classification dataset, which has 100 relations and 700 instances for each relation.</p><p>Here we follow the relation extraction finetuning procedure from Zhang et al. (2019)</ref>, where four special tokens are added before and after entity mentions in the sentence to highlight where the entities are. Then we take the [CL lassify given entity mentions into pre-defined entity types. For this task, we evaluate all the models on OpenEntity (Choi et al., 2018)</ref> following the setting from Zhang et al. (2019)</ref>, which focuses on nine general entity types. Evaluation results are demonstrated in Table 7</ref>. For now we
p>Pre-trained Language Model There has been a long history of pre-training in NLP. Early works focus on distributed word representation (Collobert and Weston, 2008;</ref>Mikolov et al., 2013;</ref>Pennington et al., 2014)</ref>, many of which are still often adopted in current models as word embeddings for mlns="http://www.tei-c.org/ns/1.0"><head>KE Objective</head><p>We use the loss formula from (Sun et al., 2019b)</ref> as our KE objective, which takes negative sampling (Mikolov et al., 2013)</ref> for efficient optimization:</p><formula xml:id="formula_3">L = − log σ(γ − d r (h, t)) − n i=1 1 n log σ(d r (h i , t i ) − γ),<label>(3)</l
ie et al., 2016;</ref>An et al., 2018)</ref> or jointly train the knowledge and text embedding in the same space (Wang et al., 2014;</ref>Toutanova et al., 2015;</ref>Han et al., 2016;</ref>Cao et al., 2017</ref>Cao
s="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Pre-trained Language Model There has been a long history of pre-training in NLP. Early works focus on distributed word representation (Collobert and Weston, 2008;</ref>Mikolov et al., 2013;</ref>Pennington et al., 2014)</ref>, many of which a
sify relation types between two given entities from text. We evaluate our model and baselines on two commonlyused datasets: TACRED (Zhang et al., 2017)</ref> and FewRel (Han et al., 2018)</ref>. TACRED covers 42 relation types and contains 106,264 sentences. FewRel is a few-shot relation classification dataset, which has 100 relations a xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Accuracies (%) on FewRel dataset. "Proto" indicates Prototypical Networks(Snell et al., 2017)</ref> used inHan et al. (2018)</ref>. "PAIR" is proposed inGao et al. (2019)</ref> and "MTB" is from Baldini Soares et al. (2019).</figDesc><table><row
s="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Pre-trained Language Model There has been a long history of pre-training in NLP. Early works focus on distributed word representation (Collobert and Weston, 2008;</ref>Mikolov et al., 2013;</ref>Pennington et al., 2014)</ref>, many of which a
n="5.1">Pre-training settings</head><p>In experiments, we choose RoBERTa (Liu et al., 2019c)</ref> as our base model and implement our methods in the fairseq framework (Ott et al., 2019)</ref> for pre-training. Due to the computing resource limit, we choose RoBERTa BASE architecture and use the released roberta.base<ref type="foot" tar
bibr" target="#b47">(Zaremoodi et al., 2018)</ref>, reading comprehension (Mihaylov and Frank, 2018;</ref>Zhong et al., 2019)</ref> and dialogue system (Madotto et al., 2018)</ref>, but also some early works use text as additional information (Xie et al., 2016;</ref><ref type="bibr" target f> and dialogue system (Madotto et al., 2018)</ref>, but also some early works use text as additional information (Xie et al., 2016;</ref>An et al., 2018)</ref> or jointly train the knowledge and text embedding in the same space (Wang et al., 2014;</ref><ref type="bibr" targe
t embedding in the same space (Wang et al., 2014;</ref>Toutanova et al., 2015;</ref>Han et al., 2016;</ref>Cao et al., 2017</ref>Cao et al., , 2018))</ref>.</p><p>In this paper, we propose to learn knowledge embedding and language representation w
ods have a strong connection with NLP models. There are not only many works integrating knowledge embeddings into NLP models to improve the performance of NLP applications such as machine translation (Zaremoodi et al., 2018)</ref>, reading comprehension (Mihaylov and Frank, 2018;</ref>Zhong et al., 2019)</ref> and dialo
es et al., 2013)</ref> treats tail entities as translations of heads, while DistMult (Yang et al., 2015)</ref> use matrix multiplications as score functions and ComplEx (Trouillon et al., 2016)</ref> adopt complex operations based on it. RotatE (Sun et al., 2019a)</ref> combines the advantages of both of t ransE (Bordes et al., 2013)</ref> 109370 0.253 0.170 0.311 0.392 DistMult (Yang et al., 2015)</ref> 211030 0.253 0.208 0.278 0.334 ComplEx (Trouillon et al., 2016)</ref>  prediction task.</p><p>We conduct 5 knowledge graph embedding models , including TransE (Bordes et al., 201 We conduct 5 knowledge graph embedding models , including TransE (Bordes et al., 2013)</ref>, Dist-Mult (Yang et al., 2015)</ref>, ComplEx (Trouillon et al., 2016)</ref>, SimplE (Kazemi and Poole, 2018) and Ro-tatE (Sun et al., 2019b)</ref>. Because their original implementati
-training procedure, we only use the English Wikipedia corpus to save time and also for a fair comparison with previous knowledgeenhanced PLMs (Zhang et al., 2019;</ref>Peters et al., 2019)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NLP Tasks</head><p>In this section, we introduce how our KEPLER can be used
for richer semantic meanings under different circumstances.</p><p>Apart from those methods using pre-trained word embeddings as input features, there is another trend exploring pre-trained encoders. Dai and Le (2015)</ref> first propose to train an auto-encoder on unlabeled data, and then fine-tune it on downstream tasks. Howard and Rud

w.tei-c.org/ns/1.0"><head>Entity Typing</head><p>Entity typing requires models to classify given entity mentions into pre-defined entity types. For this task, we evaluate all the models on OpenEntity (Choi et al., 2018)</ref> following the setting from Zhang et al. (2019)</ref>, which focuses on nine general entity types. Evaluation resu
ie et al., 2016;</ref>An et al., 2018)</ref> or jointly train the knowledge and text embedding in the same space (Wang et al., 2014;</ref>Toutanova et al., 2015;</ref>Han et al., 2016;</ref>Cao et al., 2017</ref>Cao
SE) while staying a little bit advanced over other competitive methods (even if they use a LARGE architecture).</p><p>Our model has also shown strength on FewRel dataset. We use Prototypical Networks (Snell et al., 2017)</ref> and PAIR (Gao et al., 2019)</ref> as the base frameworks and try out different kinds of pretrained models as en figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Accuracies (%) on FewRel dataset. "Proto" indicates Prototypical Networks(Snell et al., 2017)</ref> used inHan et al. (2018)</ref>. "PAIR" is proposed inGao et al. (2019)</ref> and
ods have a strong connection with NLP models. There are not only many works integrating knowledge embeddings into NLP models to improve the performance of NLP applications such as machine translation (Zaremoodi et al., 2018)</ref>, reading comprehension (Mihaylov and Frank, 2018;</ref>Zhong et al., 2019)</ref> and dialo
ks. However, they are typically lack of factual world knowledge (Petroni et al., 2019;</ref>Logan et al., 2019)</ref>.</p><p>Recent works (Zhang et al., 2019;</ref>Peters et al., 2017;</ref>Liu et al., 2019a)</ref> utilize entity embeddings of large-scale kno ref> parameters to initialize our model.</p><p>In our pre-training procedure, we only use the English Wikipedia corpus to save time and also for a fair comparison with previous knowledgeenhanced PLMs (Zhang et al., 2019;</ref>Peters et al., 2019)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NLP Tasks</head><p 64 sentences. FewRel is a few-shot relation classification dataset, which has 100 relations and 700 instances for each relation.</p><p>Here we follow the relation extraction finetuning procedure from Zhang et al. (2019)</ref>, where four special tokens are added before and after entity mentions in the sentence to highlight where the entities are. Then we take the [CL lassify given entity mentions into pre-defined entity types. For this task, we evaluate all the models on OpenEntity (Choi et al., 2018)</ref> following the setting from Zhang et al. (2019)</ref>, which focuses on nine general entity types. Evaluation results are demonstrated in Table 7</ref>. For now we
for richer semantic meanings under different circumstances.</p><p>Apart from those methods using pre-trained word embeddings as input features, there is another trend exploring pre-trained encoders. Dai and Le (2015)</ref> first propose to train an auto-encoder on unlabeled data, and then fine-tune it on downstream tasks. Howard and Rud
selected positions.</p><p>We adopt the pre-trained checkpoint of RoBERTaBASE for the initialization of our model. However, we still keep MLM as one of our objectives to avoid catastrophic forgetting (McCloskey and Cohen, 1989)</ref> while training towards the KRL loss. Note that experiments show that only further pre-training from RoBERTaBASE checkpoint does not bri
sify relation types between two given entities from text. We evaluate our model and baselines on two commonlyused datasets: TACRED (Zhang et al., 2017)</ref> and FewRel (Han et al., 2018)</ref>. TACRED covers 42 relation types and contains 106,264 sentences. FewRel is a few-shot relation classification dataset, which has 100 relations a xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Accuracies (%) on FewRel dataset. "Proto" indicates Prototypical Networks(Snell et al., 2017)</ref> used inHan et al. (2018)</ref>. "PAIR" is proposed inGao et al. (2019)</ref> and "MTB" is from Baldini Soares et al. (2019).</figDesc><table><row
w.tei-c.org/ns/1.0"><head>Entity Typing</head><p>Entity typing requires models to classify given entity mentions into pre-defined entity types. For this task, we evaluate all the models on OpenEntity (Choi et al., 2018)</ref> following the setting from Zhang et al. (2019)</ref>, which focuses on nine general entity types. Evaluation resu
</head><p>Co-training is a semi-supervised model that can use a large amount of unlabeled data to train model, which can help to improve the accuracy of the classifier when there are few labeled data [25]</ref>. Co-training needs to analyze data from two different "perspectives". It requires that the data set has two relatively independent feature sets, and the two a
e="bibr" target="#b19">[20]</ref> use data collected by mobile phones (including cell phone call data and SMS data), they build a classification model to recognize people's daily stress. Xiong et al. [17]</ref> use linear regression to analyze the correlation between different behavioral habits and people social anxiety through college students' GPS and POI data. Can 1 ), (x 2 , y 2 )) = (x 1 x 2 ) 2 + cos 2 ( x 1 + x 2 2 )(y 1 y 2 ) 2<label>(2</label></formula></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>) Conversational Features</head><p>From Lu's work [17]</ref>, it has been known that the conversational information of the user's environment can be used to predict the user's stress level, which shows that the sound in
nd the long-term psychological indicators rather than the short-term indicators. As we mentioned before, the short-term mental health (such as stress level) assessment is very important. Zhang et al. [27]</ref> used a factor graph model to predict people's mood by using smartphone sensing data and app usage. They proposed a method for assessing short-term emotions an niversal model more personalized. In addition, we use co-training to tackle the label insufficiency issues which is not considered by Wang's and Zhang's works [7]</ref>, [27]</ref>. This makes our approach more practical in short-term mental status inference, as people do not need to continuously report their mental status as labels.</p>
lns="http://www.tei-c.org/ns/1.0"><head>B. Emotional Assessment Based on Social Networks</head><p>Another type of work can assess people's emotions by their behavior on the social network. Lin et al. [11]</ref> use a deep sparse neural network to assess people's psychological pressure based on people's Weibo data; Lin et al. [12]</ref>
ives. In order to enrich user experience, more and more sensors (such as acceleration sensors, acoustic sensors, etc.) have been integrated into mobile phones [5]</ref>, [6]</ref>. In daily life, mobile phones can continuously record a lot of sensing data related to people's daily-life behavior, including activities, location information,
10</p><p>Wi-Fi location Wi-Fi AP location these studies, only one type of phone sensing data is used. In contrast, we utilize multiple types of data to study the stress detection problem. Wang et al. [7]</ref> extract multidimensional features from the StudentLife dataset, use linear regression to analyze the relationship between a variety of psychological indicators, tures and relative features to make the universal model more personalized. In addition, we use co-training to tackle the label insufficiency issues which is not considered by Wang's and Zhang's works [7]</ref>, [27]</ref>. This makes our approach more practical in short-term mental status inference, as people do not need to continuously need to continuously report their mental status as labels.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DATASET AND PROBLEM DEFINITION</head><p>We use open source dataset StudentLife [7]</ref> to train the model. StudentLife dataset is a dataset from Dartmouth, which contains 49 students' data in 10-weeks. The dataset has four parts: sensor data, EMA
e="bibr" target="#b19">[20]</ref> use data collected by mobile phones (including cell phone call data and SMS data), they build a classification model to recognize people's daily stress. Xiong et al. [17]</ref> use linear regression to analyze the correlation between different behavioral habits and people social anxiety through college students' GPS and POI data. Can 1 ), (x 2 , y 2 )) = (x 1 x 2 ) 2 + cos 2 ( x 1 + x 2 2 )(y 1 y 2 ) 2<label>(2</label></formula></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>) Conversational Features</head><p>From Lu's work [17]</ref>, it has been known that the conversational information of the user's environment can be used to predict the user's stress level, which shows that the sound in
ext data, and user behavior. The data is automatically collected by smartphones in users' daily lives. EMA data is ecological momentary assessment data, which is always used to reflect human behavior [26]</ref>. During the collection phase, lots of EMA questions were sent to students. The EMA reports reflect students' daily emotions. In this paper, we use stress EMAs

nd the long-term psychological indicators rather than the short-term indicators. As we mentioned before, the short-term mental health (such as stress level) assessment is very important. Zhang et al. [27]</ref> used a factor graph model to predict people's mood by using smartphone sensing data and app usage. They proposed a method for assessing short-term emotions an niversal model more personalized. In addition, we use co-training to tackle the label insufficiency issues which is not considered by Wang's and Zhang's works [7]</ref>, [27]</ref>. This makes our approach more practical in short-term mental status inference, as people do not need to continuously report their mental status as labels.</p>
ext data, and user behavior. The data is automatically collected by smartphones in users' daily lives. EMA data is ecological momentary assessment data, which is always used to reflect human behavior [26]</ref>. During the collection phase, lots of EMA questions were sent to students. The EMA reports reflect students' daily emotions. In this paper, we use stress EMAs
ovy, 2016;</ref>Lample et al., 2016;</ref>Zhang et al., 2018;</ref>Gui et al., 2019b)</ref>.</p><p>Recently, Transformer (Vaswani et al., 2017</ref>) began to prevail in various NLP tasks, like machine translation (Vaswani et al., 2017)</ref>, language modeli ="bibr" target="#b12">Gui et al., 2019b)</ref>.</p><p>Recently, Transformer (Vaswani et al., 2017</ref>) began to prevail in various NLP tasks, like machine translation (Vaswani et al., 2017)</ref>, language modeling (Radford et al., 2018)</ref>, and pretraining models (Devlin was based on Transformer (Devlin et al., 2018)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Transformer</head><p>Transformer was introduced by (Vaswani et al., 2017)</ref>, which was mainly based on self-attention. It achieved great success in various NLP tasks. Since the self-attention mechanism used in the Tr , position embeddings were used (Vaswani et al., 2017;</ref>Devlin et al., 2018)</ref>. Instead of using the sinusoidal position embedding (Vaswani et al., 2017)</ref> and learned absolute position embedding, Shaw et al. (2018)</ref> argued that the distance between two tokens elation could be better considered.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Transformer Encoder Architecture</head><p>We first introduce the Transformer encoder proposed in (Vaswani et al., 2017)</ref>. The Transformer encoder takes in an matrix H ∈ R l×d , where l is the sequence length, d is the input dimension. Then three learnable matri f f ×d , b 1 ∈ R d f f , b 2 ∈ R d . d f f is a hyper-parameter.</formula><p>Other components of the Transformer encoder includes layer normalization and Residual connection, we use them the same as (Vaswani et al., 2017)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Position Embedding</head><p>The self-attention is not aware of the posit sition Embedding</head><p>The self-attention is not aware of the positions of different tokens, making it unable to capture the sequential characteristic of languages. In order to solve this problem, (Vaswani et al., 2017)</ref> suggested to use position embeddings generated by sinusoids of varying frequency. The tth token's position embedding can be represented by t mbedding makes Transformer have an ability to model the position of a token and the distance of each two tokens. For any fixed offset k, P E t+k can be represented by a linear transformation of P E t (Vaswani et al., 2017)</ref>. In TENER, Transformer encoder is used not only to extract the word-level contextual information, but also to encode character-level informa lf-attention. It achieved great success in various NLP tasks. Since the self-attention mechanism used in the Transformer is unaware of positions, to avoid this shortage, position embeddings were used (Vaswani et al., 2017;</ref>Devlin et al., 2018)</ref>. Instead of using the sinusoidal position embedding (
an entity in a sentence and assigning a class for this entity. NER has been widely studied in the field of natural language processing (NLP) because of its potential assistance in question generation (Zhou et al., 2017)</ref>, relation extraction (Miwa and Bansal, 2016)</ref>, and coreference resolution (Fr
rget="#b26">(Pennington et al., 2014;</ref>Mikolov et al., 2013)</ref>. And when contextual word embeddings are combined, the performance of NER models will boost a lot (Peters et al., 2017</ref>(Peters et al., , 2018;;</ref>Akbik et al., 2018)</ref>. ELMo introduced by <ref t
6">(Huang et al., 2015;</ref>Ma and Hovy, 2016;</ref>Lample et al., 2016;</ref>Chiu and Nichols, 2016;</ref>Chen et al., 2019;</ref>Zhang et al., 2018;</ref>Gui et al., 2019b)</ref>. The difference between various NER models mainl Chiu and Nichols, 2016;</ref>Lample et al., 2016;</ref>Ma and Hovy, 2016;</ref>Strubell et al., 2017;</ref>Chen et al., 2019)</ref>.</p><p>Almost all neural-based NER models used pretrained word embeddings, like Word2vec and Glove (Pennington et roblems of data sparsity and outof-vocabulary (OOV), most NER models adopted the CNN character encoder (Ma and Hovy, 2016;</ref>Ye and Ling, 2018;</ref>Chen et al., 2019)</ref> to represent words. Compared to BiLSTM based character encoder (Lample et al., 2016;</ref><ref type="bibr" target= OntoNotes 5.0 is an English NER dataset whose corpus comes from different domains, such as telephone conversation, newswire. We exclude the New Testaments portion since there is no named entity in it (Chen et al., 2019;</ref>Chiu and Nichols, 2016)</ref>. This dataset has eleven entity names and seven value types, like CARDINAL, MONEY, LO
2011)</ref>, various neural models have been introduced to avoid hand-crafted features (Huang et al., 2015;</ref>Ma and Hovy, 2016;</ref>Lample et al., 2016)</ref>.</p><p>NER is usually viewed as a sequence labeling task, the neural models usually contain three components: word embedding layer, context en ontain three components: word embedding layer, context encoder layer, and decoder layer (Huang et al., 2015;</ref>Ma and Hovy, 2016;</ref>Lample et al., 2016;</ref>Chiu and Nichols, 2016;</ref>Chen et al., 2019;</ref>Zhang et al., Owing to BiLSTM's high power to learn the contextual representation of words, it has been adopted by the majority of NER models as the encoder (Ma and Hovy, 2016;</ref>Lample et al., 2016;</ref>Zhang et al., 2018;</ref>Gui et al., 2019b)</ref>.</p><p>Recently, Transformer <ref type="bibr" apitalization and n-gram, is important in recognizing named entities, CNN and BiLSTM have been used to extract character-level informa-tion (Chiu and Nichols, 2016;</ref>Lample et al., 2016;</ref>Ma and Hovy, 2016;</ref>Strubell et al., 2017;</ref><ref type="bibr" target="#b3" esentation with character-level information. The previous work has proved that character encoder is necessary to capture the character-level features and alleviate the out-of-vocabulary (OOV) problem (Lample et al., 2016;</ref>Ma and Hovy, 2016;</ref>Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b3 " target="#b22">(Ma and Hovy, 2016;</ref>Ye and Ling, 2018;</ref>Chen et al., 2019)</ref> to represent words. Compared to BiLSTM based character encoder (Lample et al., 2016;</ref>Ghaddar and Langlais, 2018)</ref>, CNN is more efficient. Since Transformer can also fully exploit the GPU's pa
coder layer, and decoder layer (Huang et al., 2015;</ref>Ma and Hovy, 2016;</ref>Lample et al., 2016;</ref>Chiu and Nichols, 2016;</ref>Chen et al., 2019;</ref>Zhang et al., 2018;</ref>Gui et al., 20 capture the character-level features and alleviate the out-of-vocabulary (OOV) problem (Lample et al., 2016;</ref>Ma and Hovy, 2016;</ref>Chiu and Nichols, 2016;</ref>Xin et al., 2018)</ref>. In NER, CNN is commonly used as the character encoder. However, we argue that CNN is NER. In (Huang et al., 2015)</ref>, BiLSTM-CRF was introduced to solve sequence labeling questions. Since then, the BiLSTM has been extensively used in the field of NER (Chiu and Nichols, 2016;</ref>Dong et al., 2016;</ref>Yang et al., 2018;</ref> -CNN).</p><p>Since the word shape information, such as the capitalization and n-gram, is important in recognizing named entities, CNN and BiLSTM have been used to extract character-level informa-tion (Chiu and Nichols, 2016;</ref>Lample et al., 2016;</ref>Ma and Hovy, 2016;</ref><ref type="bibr" target="#b3 mes from different domains, such as telephone conversation, newswire. We exclude the New Testaments portion since there is no named entity in it (Chen et al., 2019;</ref>Chiu and Nichols, 2016)</ref>. This dataset has eleven entity names and seven value types, like CARDINAL, MONEY, LOC.</p><p>(3) Weischedel ( 2011</ref
an entity in a sentence and assigning a class for this entity. NER has been widely studied in the field of natural language processing (NLP) because of its potential assistance in question generation (Zhou et al., 2017)</ref>, relation extraction (Miwa and Bansal, 2016)</ref>, and coreference resolution (Fr
eling questions. Since then, the BiLSTM has been extensively used in the field of NER (Chiu and Nichols, 2016;</ref>Dong et al., 2016;</ref>Yang et al., 2018;</ref>Ma and Hovy, 2016)</ref>. Despite BiLSTM's great success in the NER task, it has to compute token representations
ER was built based on text in Chinese social media Sina Weibo (Peng and Dredze, 2015)</ref>, and it contained 4 kinds of entities.</p><p>(6) Resume NER was annotated by (Zhang and Yang, 2018)</ref>.</p><p>Their statistics are listed in Table 1</ref>. For all datasets, we replace all digits with "0", and ly initialized character embeddings. More details on models' hyper-parameters can be found in the supplementary material. For Chinese, we used the character embedding and bigram embedding released by (Zhang and Yang, 2018)</ref>. All pretrained embeddings are finetuned during training. In order to reduce the impact of randomness, we ran all of our experiments at leas rformance was used to evaluate the test set. The hyper-parameter search range and other settings can be found in the supplementary material. Codes are available at https://github. com/fastnlp/TENER.  (Zhang and Yang, 2018)</ref> and (Gui et al., 2019a)</ref>, respectively. "w/ scale" means TENER using the scaled attention in Eq.( <ref t
b40">(Zhou et al., 2017)</ref>, relation extraction (Miwa and Bansal, 2016)</ref>, and coreference resolution (Fragkou, 2017)</ref>. Since (Collobert et al., 2011)</ref>, various neural models have been introduced to avoid hand-crafted features (Huang et al., 2015;</ref><ref ty e six NER datasets, we achieve state-of-the-art performance among models without considering the pre-trained language models or designed features.</p><p>2 Related Work 2.1 Neural Architecture for NER Collobert et al. (2011)</ref> utilized the Multi-Layer Perceptron (MLP) and CNN to avoid using taskspecific features to tackle different sequence labeling tasks, such as
he long-range context, which is the weakness of RNNs. Moreover, Transformer has better parallelism ability than RNNs. However, in the NER task, Transformer encoder has been reported to perform poorly (Guo et al., 2019)</ref>, our experiments also confirm this result. Therefore, it is intriguing to explore the reason why Transformer does not work well in NER task.</p> ison between different NER models on English NER datasets is shown in Table 3</ref>. The poor performance of the Transformer in the NER datasets was also reported by (Guo et al., 2019)</ref>. Although performance of the Transformer is higher than (Guo et al., 2019)</ref>, it still lags behind the BiLSTM /ref>. The poor performance of the Transformer in the NER datasets was also reported by (Guo et al., 2019)</ref>. Although performance of the Transformer is higher than (Guo et al., 2019)</ref>, it still lags behind the BiLSTM-based models (Ma and Hovy, 2016)</ref>. Nonetheless, the performance is massivel
text simplification. Concurrent work further shows the success of search-based unsupervised text generation for paraphrasing (Liu et al., 2020)</ref> and summa-rization (Schumann et al., 2020)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>In this section, we first provide an overview of our approac
algorithm, and design search objective and search actions specifically for text simplification. Concurrent work further shows the success of search-based unsupervised text generation for paraphrasing (Liu et al., 2020)</ref> and summa-rization (Schumann et al., 2020)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">
l., 2016)</ref>. Further, syntactic information was also considered in the PBMT framework, for example, constituency trees (Zhu et al., 2010)</ref> and dependency trees (Bingel and Søgaard, 2016)</ref>. Narayan and Gardent (2014)</ref> performed probabilistic sentence splitting and deletion, followed by MT-
uire considerable human effort to obtain.</p><p>In previous work, researchers have addressed some of the above issues. For example, Alva-Manchego et al. (2017)</ref> and Dong et al. (2019)</ref> explicitly model simplification operators such as word insertion and deletion. Although these approaches are more controllable and interpretable st set for annotation and considered a subset of baselines. For our model variants, we chose RM+EX+LS+RO, considering both validation settings (GM and SARI).</p><p>We followed the evaluation setup in Dong et al. (2019)</ref>, and measure the adequacy (How much meaning from the original sentence is preserved?), simplicity (Is the output simper than the original sentenc )</ref>; and Access, which is based on the transformer architecture (Martin et al., 2019)</ref>. Finally, we compare with a supervised edit-based neural model, Edit-NTS (Dong et al., 2019)</ref>.</p><p>We evaluate our model with a different subset of operations, i.e., removal (RM), extraction (EX), reordering (RO), and lexical substituti he quality of a candidate sentence: the Flesch-Kincaid grade level (FKGL) evaluating the ease of reading, as well as the average length of the sentence.</p><p>A few recent text simplification studies (Dong et al., 2019;</ref>Kriz et al., 2019)</ref> did not use BLEU for evaluation, noticing that the complex sentence itself achieves a hig ication achieves a SARI score around 26-27, outperforming quite a few supervised methods. Further, we experiment with SARI-based validation (denoted by †), following the setting of most previous work (Dong et al., 2019;</ref>Guo et al., 2018)</ref>. We achieve 30.44 SARI, which is competitive with state-of-the-art supervised methods.</p><
et al. (2018)</ref> proposed edit-based style transfer without parallel supervision. They replaced style-specific phrases with those in the target style, which are retrieved from the training corpus. Miao et al. (2019)</ref> used Metropolis-Hastings sampling for constrained sentence generation. In this paper, we model text generation as a search algorithm, and design uage model (f eslor ). This measures the language fluency and structural simplicity of a candidate sentence.</p><p>A probabilistic language model (LM) is often used as an estimate of sentence fluency (Miao et al., 2019)</ref>. In our work, we make two important modifications to a plain LM.</p><p>First, we replace an LM's estimated sentence probability with the syntac
hough these approaches are more controllable and interpretable than standard Seq2Seq models, they still require large volumes of aligned data to learn these operations. To deal with the second issue, Surya et al. (2019)</ref> recently proposed an unsupervised neural text simplification approach based on the paradigm of style transfer. However, their model is hard to el training data; also, their edits are only at the word level. By contrast, our method works at both word and phrase levels in an unsupervised manner.</p><p>For unsupervised sentence simplification, Surya et al. (2019)</ref> adopted style-transfer techniques, using adversarial and denoising auxiliary losses for content reduction and lexical simplification. However, duce-250. As discussed in Section 4.4, this simple heuristic demonstrates the importance of balancing different automatic evaluation metrics.</p><p>For unsupervised competing methods, we compare with Surya et al. (2019)</ref>, which is inspired by unsupervised neural machine translation. They proposed two variants, UNMT and UNTS, but their results are only available
rget="#b36">(Wubben et al., 2012;</ref>Xu et al., 2016)</ref>. Further, syntactic information was also considered in the PBMT framework, for example, constituency trees (Zhu et al., 2010)</ref> and dependency trees (Bingel and Søgaard, 2016)</ref>. Narayan and Gardent (2014)</
of three rewrite operations: adding, deleting, and keeping. The individual F1-scores of these operations are reported in the columns "Add," "Delete," and "Keep."</p><p>We also compute the BLEU score (Papineni et al., 2002)</ref> to measure the closeness between a candidate and a reference. Xu et al. (2016)</ref> and <ref type="bibr" ta
uire considerable human effort to obtain.</p><p>In previous work, researchers have addressed some of the above issues. For example, Alva-Manchego et al. (2017)</ref> and Dong et al. (2019)</ref> explicitly model simplification operators such as word insertion and deletion. Although these approaches are more controllable and interpretable st set for annotation and considered a subset of baselines. For our model variants, we chose RM+EX+LS+RO, considering both validation settings (GM and SARI).</p><p>We followed the evaluation setup in Dong et al. (2019)</ref>, and measure the adequacy (How much meaning from the original sentence is preserved?), simplicity (Is the output simper than the original sentenc )</ref>; and Access, which is based on the transformer architecture (Martin et al., 2019)</ref>. Finally, we compare with a supervised edit-based neural model, Edit-NTS (Dong et al., 2019)</ref>.</p><p>We evaluate our model with a different subset of operations, i.e., removal (RM), extraction (EX), reordering (RO), and lexical substituti he quality of a candidate sentence: the Flesch-Kincaid grade level (FKGL) evaluating the ease of reading, as well as the average length of the sentence.</p><p>A few recent text simplification studies (Dong et al., 2019;</ref>Kriz et al., 2019)</ref> did not use BLEU for evaluation, noticing that the complex sentence itself achieves a hig ication achieves a SARI score around 26-27, outperforming quite a few supervised methods. Further, we experiment with SARI-based validation (denoted by †), following the setting of most previous work (Dong et al., 2019;</ref>Guo et al., 2018)</ref>. We achieve 30.44 SARI, which is competitive with state-of-the-art supervised methods.</p><
ntence simplification is relevant in various real-world and downstream applications. For instance, it can benefit people with autism (Evans et al., 2014)</ref>, dyslexia (Rello et al., 2013)</ref>, and low-literacy skills (Watanabe et al., 2009)</ref>. It can also serve as a preprocessing step to improve pa
ords such as named entities. 2</ref>Second, we use a syntax-aware LM, i.e., in addition to words, we use part-of-speech (POS) and dependency tags as inputs to the LM (Zhao et al., 2018b)</ref>. For a word w i , the input to the syntaxaware LM is [e(w i ); p(w i ); d(w i )], where e(w i ) is the word embedding, p(w i ) is the POS tag
which our model first chooses to delete a sentence fragment, followed by reordering the remaining fragments and replacing a word with a simpler synonym.</p><p>We evaluate our approach on the Newsela (Xu et al., 2015)</ref> and WikiLarge (Zhang and Lapata, 2017)</ref> corpora. Experiments show that our approach outperforms previous unsu lexical simplification.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We use the Newsela (Xu et al., 2015)</ref> and the Wiki-Large datasets (Zhang and Lapata, 2017)</ref> for evaluating our model.</p><p>Newsela is a collection
's estimated sentence probability with the syntactic log-odds ratio (SLOR, Pauls and Klein, 2012)</ref>, to better measure fluency and human acceptability. According to Lau et al. (2017)</ref>, SLOR shows the best correlation to human acceptability of a sentence, among many sentence probability-based scoring functions. SLOR was also sho
f>, SLOR shows the best correlation to human acceptability of a sentence, among many sentence probability-based scoring functions. SLOR was also shown to be effective in unsupervised text compression (Kann et al., 2018)</ref>.</p><p>Given a trained language model (LM) and a sentence s, SLOR is defined as</p><formula xml:id="formula_0">SLOR(s) = 1 |s| (ln(P LM (s)) − l
gs for POS tags and dependency tags are 150-dimensional, also initialized randomly. We fine-tune all embeddings during training.</p><p>We use the Averaged Stochastic Gradient Descent (ASGD) algorithm (Polyak and Juditsky, 1992)</ref> to train the LM, with 0.4 as the dropout and 32 as the batch size. For the Newsela dataset, the thresholds r op in the scoring function
uted in a fixed order.</p><p>Unsupervised edit-based approaches have recently been explored for natural language generation tasks, such as style transfer, paraphrasing, and sentence error correction. Li et al. (2018)</ref> proposed edit-based style transfer without parallel supervision. They replaced style-specific phrases with those in the target style, which are re
tence is translated to a simple one. Such simplification systems are typically trained in a supervised way by either phrase-based machine translation (PBMT, Wubben et al., 2012;</ref>Narayan and Gardent, 2014;</ref>Xu et al., 2016)</ref> or neural machine translation (NMT, Zhang and Lapata red in the PBMT framework, for example, constituency trees (Zhu et al., 2010)</ref> and dependency trees (Bingel and Søgaard, 2016)</ref>. Narayan and Gardent (2014)</ref> performed probabilistic sentence splitting and deletion, followed by MT-based paraphrasing. Nisioi et al. ef>, which re-ranks sentences generated by PBMT for diverse simplifications; SBMT-SARI (Xu et al., 2016)</ref>, which uses an external paraphrasing database; and Hybrid (Narayan and Gardent, 2014)</ref>, which uses a combination of PBMT and discourse representation structures. Next, we compare our method with neural machine translation
tes by fluency, adequacy, and simplicity. Guo et al. (2018)</ref> showed that simplification benefits from multi-task learning with paraphrase and entailment generation. Martin et al. (2019)</ref> enhanced the transformer architecture with conditioning parameters such as length, lexical and syntactic complexity.  2019 ef>; S2S-All-FA, which a reranking based model focussing on lexical simplification (Kriz et al., 2019)</ref>; and Access, which is based on the transformer architecture (Martin et al., 2019)</ref>. Finally, we compare with a supervised edit-based neural model, Edit-NTS (Dong et al., 2019)</ref>.</p><p>We ev
br" target="#b35">(Watanabe et al., 2009)</ref>. It can also serve as a preprocessing step to improve parsers (Chandrasekar et al., 1996)</ref> and summarization systems (Klebanov et al., 2004)</ref>.</p><p>Recent efforts in sentence simplification have been influenced by the success of machine translation. In fact, the simplification ta
ords such as named entities. 2</ref>Second, we use a syntax-aware LM, i.e., in addition to words, we use part-of-speech (POS) and dependency tags as inputs to the LM (Zhao et al., 2018b)</ref>. For a word w i , the input to the syntaxaware LM is [e(w i ); p(w i ); d(w i )], where e(w i ) is the word embedding, p(w i ) is the POS tag
ords such as named entities. 2</ref>Second, we use a syntax-aware LM, i.e., in addition to words, we use part-of-speech (POS) and dependency tags as inputs to the LM (Zhao et al., 2018b)</ref>. For a word w i , the input to the syntaxaware LM is [e(w i ); p(w i ); d(w i )], where e(w i ) is the word embedding, p(w i ) is the POS tag
. For instance, it can benefit people with autism (Evans et al., 2014)</ref>, dyslexia (Rello et al., 2013)</ref>, and low-literacy skills (Watanabe et al., 2009)</ref>. It can also serve as a preprocessing step to improve parsers (Chandrasekar et al., 1996)</ref> and summariza
> are some of the simple, efficient, and light-weight data prefetchers employed at the L1 level. Well-established and recent spatial L2 prefetchers (prefetchers that prefetch within a spatial region) [33]</ref>, [13]</ref>, [14]</ref>, [38]</ref>, <ref type="bibr" target="#b1 trides within a spatial region providing competitive coverage. Prefetchers like variable length delta prefetching (VLDP) [45]</ref> and signature path prefetching (SPP) [33]</ref> are well known delta prefetchers. VLDP stores the history of deltas to predict future deltas. SPP is a state-of-theart delta prefetcher that predicts the non- d source codes of the state-of-theart techniques are available on the public domain. Recent prefetching proposals [11]</ref>, [14]</ref>, [33]</ref> have also been coded and evaluated with ChampSim, helping the community for a fair comparison of techniques. Table II</ref> Patch, Bingo, and IPCP perform on the same scale. It is well known that spatial prefetchers fail to improve performance for server workloads like CloudSuite [14]</ref>, [33]</ref>, [53]</ref>, [58]</ref>, [59]</ref> and additional prefetchers <r
six phases [1]</ref>, [5]</ref>) benchmarks. We also use a set of Convolutional Neural Networks (CNNs) and a Recurrent Neural Network (RNN) [19]</ref>, [21]</ref>, [22]</ref>, [36]</ref>, <ref type="bibr" target="#b3
, [58]</ref>, [59]</ref> and additional prefetchers [12]</ref>, [24]</ref>, [52]</ref>, [58]</ref>, [59]</ref> can be used on top of IPCP to improve the performance. As IPCP demands l
L1 level. Well-established and recent spatial L2 prefetchers (prefetchers that prefetch within a spatial region) [33]</ref>, [13]</ref>, [14]</ref>, [38]</ref>, [11]</ref>, [45]</ref> have pushed the limits of dat etcher with low accuracy can pollute the small L1-D.</p><p>The problem: State-of-the-art spatial prefetchers [45]</ref> [33], [11]</ref>, [14]</ref>, [13]</ref> are designed specifically for L2's access patterns.</p><p>Prefetchers like SMS [47]< ardware overhead without compromising coverage.</p><p>Prefetch filters/throttlers: To further improve the effectiveness of hardware prefetchers, prefetch filters like Perceptron-Prefetch-Filter (PPF) [14]</ref> and Evicted-Prefetch-Filter (EPF) [43]</ref> have been proposed. Apart from filters, there are aggressiveness controllers (thro e utility of metadata transfer in Section VI-B2. The metadata does not contain the IP because the IP of the request is passed to the L2. IP information has been used extensively at the L2 and the LLC [14]</ref> [56], [60]</ref>, [25]</ref>, [29]</ref>, <ref type="bibr" target mand of 740 bytes at the L1 and 895 bytes for the entire cache hierarchy. This is a significant improvement compared to lightweight versions of MLOP [44]</ref>, SPP+PPF [14]</ref>, and Bingo [11]</ref> that </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. IPCP and DOL</head><p>DOL <ref type="bi above points are the primary reasons for DOL's poor performance compared to state-of-the-art spatial prefetchers [11]</ref>, [13]</ref>, [14]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EVALUATION</head><p>We evaluate IPCP with an extensively modified ChampSim <ref type="bibr" targ and prefetching techniques as the fine-tuned source codes of the state-of-theart techniques are available on the public domain. Recent prefetching proposals [11]</ref>, [14]</ref>, [33]</ref> have also been coded and evaluated with ChampSim, helping the community for a fair comparison of techniques. Table [11]</ref> is implemented with 37.5GBps DRAM bandwidth, fixed latency DRAM. So with 12GBps it is unable to perform to its peak). Also, for L2 prefetching, SPP with PPF [14]</ref> and DSPatch [13]</ref> (SPP+Perceptron+DSPatch) provides better performance than SPP+PPF and SPP+DSPatch<ref type="foot" target etchers fail. On average, SPP+Perceptron+DSPatch, Bingo, and IPCP perform on the same scale. It is well known that spatial prefetchers fail to improve performance for server workloads like CloudSuite [14]</ref>, [33]</ref>, [53]</ref>, [58]</ref>, <ref type="bibr" target="#b5
six phases [1]</ref>, [5]</ref>) benchmarks. We also use a set of Convolutional Neural Networks (CNNs) and a Recurrent Neural Network (RNN) [19]</ref>, [21]</ref>, [22]</ref>, [36]</ref>, <ref type="bibr" target="#b3
]</ref>, [5]</ref>) benchmarks. We also use a set of Convolutional Neural Networks (CNNs) and a Recurrent Neural Network (RNN) [19]</ref>, [21]</ref>, [22]</ref>, [36]</ref>, [37]</ref>, <ref type="bibr" target="#b4
" target="#b15">[16]</ref>, [20]</ref>, [30]</ref>, [31]</ref>, [39]</ref>- [41]</ref>, [50]</ref> that control the prefetch degree and prefetch distance based on prefetch metrics like accuracy, coverage, LLC pollu
entire SPEC CPU 2017 suite) and 500 mixes containing only the memory-intensive traces.</p><p>Evaluated Prefetching Techniques: We compare the effectiveness of IPCP with L1 prefetchers like NL, Stream [51]</ref>, BOP, VLDP, SPP, DSPatch, MLOP, TSKID, DOL, SMS, and Bingo. Table III</ref> provides the details of top four multi-level pre
L1 level. Well-established and recent spatial L2 prefetchers (prefetchers that prefetch within a spatial region) [33]</ref>, [13]</ref>, [14]</ref>, [38]</ref>, [11]</ref>, [45]</ref> have pushed the limits of dat etcher with low accuracy can pollute the small L1-D.</p><p>The problem: State-of-the-art spatial prefetchers [45]</ref> [33], [11]</ref>, [14]</ref>, [13]</ref> are designed specifically for L2's access patterns.</p><p>Prefetchers like SMS [47]< ardware overhead without compromising coverage.</p><p>Prefetch filters/throttlers: To further improve the effectiveness of hardware prefetchers, prefetch filters like Perceptron-Prefetch-Filter (PPF) [14]</ref> and Evicted-Prefetch-Filter (EPF) [43]</ref> have been proposed. Apart from filters, there are aggressiveness controllers (thro e utility of metadata transfer in Section VI-B2. The metadata does not contain the IP because the IP of the request is passed to the L2. IP information has been used extensively at the L2 and the LLC [14]</ref> [56], [60]</ref>, [25]</ref>, [29]</ref>, <ref type="bibr" target mand of 740 bytes at the L1 and 895 bytes for the entire cache hierarchy. This is a significant improvement compared to lightweight versions of MLOP [44]</ref>, SPP+PPF [14]</ref>, and Bingo [11]</ref> that </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. IPCP and DOL</head><p>DOL <ref type="bi above points are the primary reasons for DOL's poor performance compared to state-of-the-art spatial prefetchers [11]</ref>, [13]</ref>, [14]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EVALUATION</head><p>We evaluate IPCP with an extensively modified ChampSim <ref type="bibr" targ and prefetching techniques as the fine-tuned source codes of the state-of-theart techniques are available on the public domain. Recent prefetching proposals [11]</ref>, [14]</ref>, [33]</ref> have also been coded and evaluated with ChampSim, helping the community for a fair comparison of techniques. Table [11]</ref> is implemented with 37.5GBps DRAM bandwidth, fixed latency DRAM. So with 12GBps it is unable to perform to its peak). Also, for L2 prefetching, SPP with PPF [14]</ref> and DSPatch [13]</ref> (SPP+Perceptron+DSPatch) provides better performance than SPP+PPF and SPP+DSPatch<ref type="foot" target etchers fail. On average, SPP+Perceptron+DSPatch, Bingo, and IPCP perform on the same scale. It is well known that spatial prefetchers fail to improve performance for server workloads like CloudSuite [14]</ref>, [33]</ref>, [53]</ref>, [58]</ref>, <ref type="bibr" target="#b5
re are temporal prefetchers [54]</ref>, [55]</ref>, [24]</ref>, [12]</ref>, [59]</ref>, [58]</ref> that target irregular but temporal accesses. In general, spatial prefetchers demand less storage (closer to tens of target="#b23">[24]</ref>, and Domino [12]</ref> track the temporal order of accesses. Usually, temporal prefetchers demand hundreds of KBs. Recently, Managed ISB (MISB) [59]</ref> and Triage [58]</ref> have optimized the hardware overhead without compromising coverage.</p><p>Prefetch filters/throttlers: To " target="#b59">[60]</ref>, [25]</ref>, [29]</ref>, [11]</ref>, [24]</ref>, [59]</ref>. However, if a hardware vendor does not wish to communicate IP information to L2 (as mentioned in [34]</ref>), then IPCP provid r workloads like CloudSuite [14]</ref>, [33]</ref>, [53]</ref>, [58]</ref>, [59]</ref> and additional prefetchers [12]</ref>, [24]</ref>, [52]</ref>, <r and additional prefetchers [12]</ref>, [24]</ref>, [52]</ref>, [58]</ref>, [59]</ref> can be used on top of IPCP to improve the performance. As IPCP demands less than 900 bytes, all the temporal prefetchers can use IPCP as their spatial counter
Apart from filters, there are aggressiveness controllers (throttlers) [16]</ref>, [20]</ref>, [30]</ref>, [31]</ref>, [39]</ref>- [41]</ref>, [50]</ref> that control the prefetch deg
rget="#b19">(Yu et al. 2017)</ref>, dialogue (Li et al. 2017)</ref>. Some following literature modifies the framework for the purpose of the adversarial training. IRGAN (Wang et al. 2017)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminaries Problem Formulation</head><p>Given an author name reference a, let P a self-training strategy is added to our discriminative model, which uses top-relevant papers as positive samples iteratively. And to make the generative module aware of relation information, following (Wang et al. 2018a)</ref>, we design a random walk based generating strategy. Given a paper p k , we design two modules as follows:</p><p>) ) ) )</p><p>) ) )</p><p>)</p> e content information and relation information and to support the researches which study the author name disambiguation task using content information, we construct a new dataset collected from AceKG (Wang et al. 2018b</ref>). The benchmark dataset consists of 130,655 papers from 17,816 distinguished authors. Each sample has the relation information and content infor
ritten by the same author. Thus constructing the network becomes the critical part of these methods, e.g., paper network (Zhang et al. 2018)</ref>, paper-author network (Zhang and Al Hasan 2017)</ref>. However, either complicated feature engineering or the supervision (Zhang et al. 2018</ref>) is required.
e network. They account that papers connected in the network are likely to be written by the same author. Thus constructing the network becomes the critical part of these methods, e.g., paper network (Zhang et al. 2018)</ref>, paper-author network (Zhang and Al Hasan 2017)</ref>. However, either complicated feature engineering or the su d><p>To evaluate the proposed method, we collect two real-world author name disambiguation datasets for experiments: • AMiner-AND1</ref> . The dataset is released by (Zhang et al. 2018)</ref>, which contains 500 author names for training and 100 author names for testing. We construct the heterogeneous network including papers, co-aut "bibr" target="#b21">(Zhang et al. 2018)</ref>, paper-author network (Zhang and Al Hasan 2017)</ref>. However, either complicated feature engineering or the supervision (Zhang et al. 2018</ref>) is required.</p><p>The two categories of methods are like the two sides of the same coin. The first introduces supervision but cannot process h >: This model trains a function to measure the similarity between each pair of papers using the carefully designed pairwise features, including author names, titles, institute names etc.</p><p>AMiner (Zhang et al. 2018</ref>): This model designs a supervised global stage to fine-tune the word2vec result, and designs an unsupervised local stage based on the first stag del with several state-of-the-art models on AMiner-AND and AceKG-AND. In the experiment on AMiner-AND, we use 100 names for testing and compare the result with the results of other models reported in (Zhang et al. 2018</ref>). In the experiment on AceKG-AND, we sample 85 names for testing. Since Louppe et al. and AMiner are supervised algorithms, the results from 5-f

o combine them together to build a unified model which can eliminate the requirement of labeled samples and complicated feature engineering to some extent. Inspired by generative adversarial networks (Goodfellow et al. 2014)</ref>, we may combine the two categories in an adversarial way. In this paper, we propose a unified framework with discriminative module and gene e network in an unsupervised way. We implement it by the reward from the discriminative model in an adversarial framework. Generative Adversarial Networks. Recently, generative adversarial nets (GAN) (Goodfellow et al. 2014</ref>) has attracted a great deal of attention. Original purpose of GAN is to generate data from the underlying true distribution, e.g., image <re
to generate data from the underlying true distribution, e.g., image (Denton et al. 2015)</ref>, sequence (Yu et al. 2017)</ref>, dialogue (Li et al. 2017)</ref>. Some following literature modifies the framework for the purpose of the adversarial training. IRGAN (Wang et al. 2
ify the similarity among papers, content information and relation information are used. The former includes title, abstract, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage supervised learning ambiguation. To measure the similarity among papers, the existing methods can be divided into two categories according to the information they focus on. The first are based on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref>Yoshida
o combine them together to build a unified model which can eliminate the requirement of labeled samples and complicated feature engineering to some extent. Inspired by generative adversarial networks (Goodfellow et al. 2014)</ref>, we may combine the two categories in an adversarial way. In this paper, we propose a unified framework with discriminative module and gene e network in an unsupervised way. We implement it by the reward from the discriminative model in an adversarial framework. Generative Adversarial Networks. Recently, generative adversarial nets (GAN) (Goodfellow et al. 2014</ref>) has attracted a great deal of attention. Original purpose of GAN is to generate data from the underlying true distribution, e.g., image <re
and relation information are used. The former includes title, abstract, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage supervised learning algorithms to learn the pairwise similarity function the existing methods can be divided into two categories according to the information they focus on. The first are based on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref>Yoshida et al. 2010)</ref>, which usually solve the problem
o combine them together to build a unified model which can eliminate the requirement of labeled samples and complicated feature engineering to some extent. Inspired by generative adversarial networks (Goodfellow et al. 2014)</ref>, we may combine the two categories in an adversarial way. In this paper, we propose a unified framework with discriminative module and gene e network in an unsupervised way. We implement it by the reward from the discriminative model in an adversarial framework. Generative Adversarial Networks. Recently, generative adversarial nets (GAN) (Goodfellow et al. 2014</ref>) has attracted a great deal of attention. Original purpose of GAN is to generate data from the underlying true distribution, e.g., image <re
e pairwise similarity functions. However, they solve the problem in a local way, which means that they cannot measure the high-order connections among papers. Methods focusing on relation information (Kanani, McCallum, and Pal 2007;</ref>Bekkerman and McCallum 2005)</ref> usually solve the problem on the bibliographic network, where the r
attracted a great deal of attention. Original purpose of GAN is to generate data from the underlying true distribution, e.g., image (Denton et al. 2015)</ref>, sequence (Yu et al. 2017)</ref>, dialogue (Li et al. 2017)</ref>. Some following literature modifies the framework for the purpose of the adversari
N) (Goodfellow et al. 2014</ref>) has attracted a great deal of attention. Original purpose of GAN is to generate data from the underlying true distribution, e.g., image (Denton et al. 2015)</ref>, sequence (Yu et al. 2017)</ref>, dialogue (Li et al. 2017)</ref>. Some following
ify the similarity among papers, content information and relation information are used. The former includes title, abstract, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage supervised learning ambiguation. To measure the similarity among papers, the existing methods can be divided into two categories according to the information they focus on. The first are based on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref>Yoshida
ang et al. 2015)</ref> tries to preserve both of first-order and second-order network structures. Some literature explores NRL on heterogeneous networks (Tang, Qu, and Mei 2015;</ref>Dong, Chawla, and Swami 2017)</ref>. However, existing algorithms are designed to preserve the topology information of the network in an unsupervised way. We implement it

of author name ambiguity becomes evident in many practical scenarios, e.g., scholar searching, influence evaluating and mentor recommendation, which raises the necessity of author name disambiguation (Smalheiser and Torvik 2009)</ref>.</p><p>Author name disambiguation is to split the papers under the same name into several homogeneous groups, which has attracted subs HIN. Once the discriminator cannot distinguish whether the papers are selected by the generator, the generator is guided to find the rules to select the homogeneous papers. To update θ G , we follow (Schulman et al. 2015)</ref> to compute the gradient of V (G, D) by policy gradient:</p><formula xml:id="formula_10">∇ θ G V (G, D) = pi∈P E p∼G(•|p k ) [∇ θ G log G(p|p

of author name ambiguity becomes evident in many practical scenarios, e.g., scholar searching, influence evaluating and mentor recommendation, which raises the necessity of author name disambiguation (Smalheiser and Torvik 2009)</ref>.</p><p>Author name disambiguation is to split the papers under the same name into several homogeneous groups, which has attracted subs HIN. Once the discriminator cannot distinguish whether the papers are selected by the generator, the generator is guided to find the rules to select the homogeneous papers. To update θ G , we follow (Schulman et al. 2015)</ref> to compute the gradient of V (G, D) by policy gradient:</p><formula xml:id="formula_10">∇ θ G V (G, D) = pi∈P E p∼G(•|p k ) [∇ θ G log G(p|p

of author name ambiguity becomes evident in many practical scenarios, e.g., scholar searching, influence evaluating and mentor recommendation, which raises the necessity of author name disambiguation (Smalheiser and Torvik 2009)</ref>.</p><p>Author name disambiguation is to split the papers under the same name into several homogeneous groups, which has attracted subs HIN. Once the discriminator cannot distinguish whether the papers are selected by the generator, the generator is guided to find the rules to select the homogeneous papers. To update θ G , we follow (Schulman et al. 2015)</ref> to compute the gradient of V (G, D) by policy gradient:</p><formula xml:id="formula_10">∇ θ G V (G, D) = pi∈P E p∼G(•|p k ) [∇ θ G log G(p|p

o combine them together to build a unified model which can eliminate the requirement of labeled samples and complicated feature engineering to some extent. Inspired by generative adversarial networks (Goodfellow et al. 2014)</ref>, we may combine the two categories in an adversarial way. In this paper, we propose a unified framework with discriminative module and gene e network in an unsupervised way. We implement it by the reward from the discriminative model in an adversarial framework. Generative Adversarial Networks. Recently, generative adversarial nets (GAN) (Goodfellow et al. 2014</ref>) has attracted a great deal of attention. Original purpose of GAN is to generate data from the underlying true distribution, e.g., image <re
and relation information are used. The former includes title, abstract, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage supervised learning algorithms to learn the pairwise similarity function the existing methods can be divided into two categories according to the information they focus on. The first are based on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref>Yoshida et al. 2010)</ref>, which usually solve the problem
and relation information are used. The former includes title, abstract, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage supervised learning algorithms to learn the pairwise similarity function the existing methods can be divided into two categories according to the information they focus on. The first are based on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref>Yoshida et al. 2010)</ref>, which usually solve the problem
a local way, which means that they cannot measure the high-order connections among papers. Methods focusing on relation information (Kanani, McCallum, and Pal 2007;</ref>Bekkerman and McCallum 2005)</ref> usually solve the problem on the bibliographic network, where the relation information is represented as edges on the network. They acc
of author name ambiguity becomes evident in many practical scenarios, e.g., scholar searching, influence evaluating and mentor recommendation, which raises the necessity of author name disambiguation (Smalheiser and Torvik 2009)</ref>.</p><p>Author name disambiguation is to split the papers under the same name into several homogeneous groups, which has attracted subs HIN. Once the discriminator cannot distinguish whether the papers are selected by the generator, the generator is guided to find the rules to select the homogeneous papers. To update θ G , we follow (Schulman et al. 2015)</ref> to compute the gradient of V (G, D) by policy gradient:</p><formula xml:id="formula_10">∇ θ G V (G, D) = pi∈P E p∼G(•|p k ) [∇ θ G log G(p|p

e pairwise similarity functions. However, they solve the problem in a local way, which means that they cannot measure the high-order connections among papers. Methods focusing on relation information (Kanani, McCallum, and Pal 2007;</ref>Bekkerman and McCallum 2005)</ref> usually solve the problem on the bibliographic network, where the r

o combine them together to build a unified model which can eliminate the requirement of labeled samples and complicated feature engineering to some extent. Inspired by generative adversarial networks (Goodfellow et al. 2014)</ref>, we may combine the two categories in an adversarial way. In this paper, we propose a unified framework with discriminative module and gene e network in an unsupervised way. We implement it by the reward from the discriminative model in an adversarial framework. Generative Adversarial Networks. Recently, generative adversarial nets (GAN) (Goodfellow et al. 2014</ref>) has attracted a great deal of attention. Original purpose of GAN is to generate data from the underlying true distribution, e.g., image <re

a local way, which means that they cannot measure the high-order connections among papers. Methods focusing on relation information (Kanani, McCallum, and Pal 2007;</ref>Bekkerman and McCallum 2005)</ref> usually solve the problem on the bibliographic network, where the relation information is represented as edges on the network. They acc
ref type="bibr" target="#b13">[14,</ref>19,</ref>21,</ref>28,</ref>40,</ref>42,</ref>43]</ref>.</p><p>Both personalized search and entity-oriented search leverage information beyond the current query to better unde s information needs. Their advantages also naturally reinforce each other. One key challenge of entity-oriented search is the difficulty of query entity linking. Queries are often short and ambiguous [42]</ref>, making query entity linking a challenging task: A recent study shows that state-of-the-art entity linking techniques only have 50% accuracy on web queries <r eries [41]</ref>. Using such noisy query entities in ranking often requires manual annotations [12]</ref> or soft linking/diversification [42]</ref>. Personalization provides a natural way to help resolve the ambiguity in query entity linking: For example, in Fig. 1</ref> e personalized entity annotations enable KEPS to construct entity enhanced user profiles, using a memory network that represents user's search preferences in the word-entity duet representation space [42]</ref>. KEPS then conducts personalized ranking to adapt document ranking to satisfy user's information need, using the personalized search intent and the knowledge r" target="#b40">[41]</ref> consider the bags of entity representations in search model, and the interaction between bags of word representations and bags of entity representations is also studied in [42]</ref>. Neuralbased search model EDRM [21]</ref> study the interaction between word vectors and entity vectors. Our model KEPS is also
tate-of-the-art entity linking techniques only have 50% accuracy on web queries [41]</ref>. Using such noisy query entities in ranking often requires manual annotations [12]</ref> or soft linking/diversification [42]</ref>. Personalization provides a natural way to help resolve the ambiguity in query entit . Some take entities contained in the query or document as a kind of relevance ranking features, such as term weight in queries according to entity descriptions [8,</ref>12]</ref>. There are also some researches using entities as connections between the documents and queries for better matching. Liu et al. 
lementation Details. The dimension of pre-trained word embedding and entity embedding are 50. The vocabulary size of entities and words is 723,073 and 124,056. We train the word embedding using GloVe [27]</ref>, taking the query texts and document titles in the search log as training corpus. We train the entity embedding using TransE [5]
#b31">32]</ref> studied personalized click features, and Dou et al. [13]</ref> proposed P-Click using click features to improve personalized ranking effect. Other works [3,</ref>9,</ref>17,</ref>23,</ref>29,</ref><re
as been applied in personalized search [16,</ref>18,</ref>22,</ref>25,</ref>30]</ref>. It significantly improved personalization by learning the effective representations of user profiles and other personalized features from user's history. Ge e
xt representation and ranking accuracy [14,</ref>19,</ref>21,</ref>28,</ref>40,</ref>42,</ref>43]</ref>.</p><p>Both personalized search and entity-oriented search leverage information 1">12]</ref>. There are also some researches using entities as connections between the documents and queries for better matching. Liu et al. [19]</ref> and Xiong et al. [40]</ref> takes the entity as a latent space and learn query-document matching relevance through the latent space. Ensan et al. [14]</ref
ed the topics features from user's search history to predicted document relevance. Click features and topic features are combined and studied in some researches [4,</ref>6,</ref>33,</ref>38,</ref>39]</ref>. Bennett et al. <ref type="bibr" target=" queries with larger click entropy, we can see KEPS can better conduct personalization on the queries tend to be ambiguous. This meets our experimental expectations.   only short-term history in Tab. 6</ref> We can see memory networks also have certain advantages in dealing with short-term history. These results show memory networks are effective especially in preserv
d P-Click using click features to improve personalized ranking effect. Other works [3,</ref>9,</ref>17,</ref>23,</ref>29,</ref>34,</ref>35,</ref>38]</ref>
Bennett et al. [4]</ref> proposed SLTB to combine the two types of features using learning to rank.</p><p>Recently, deep learning has been applied in personalized search [16,</ref>18,</ref>22,</ref>25,</ref>30]</ref term and long-term history separately is effective because history in the current session tends to reflect user's session search intent, while the previous history may reflect user's global interests [16,</ref>22]</ref>.</p><p>Suppose a query ? has ? entity mentions (text string in query that may refer to certain entity), we denote the et to 100 dimensions. The setting of CNN layers and kernel functions in PEDRM are consistent with EDRM [21]</ref>.</p><p>Evaluation Metrics. Following the previous work [16,</ref>22]</ref>, we use MAP, MRR, P@K (precision in the top k positions) and AR (average ranking position of relevant documents) to ev ig. 5b</ref>.</p><p>From Fig. 5b</ref>, we still have that the effect of PEDRM is similar on both types of queries. However we find that different from stated in [16,</ref>22]</ref>, the personalization models perform better on queries with entropy less than 1. This may be because we count the impro r on queries with entropy less than 1. This may be because we count the improvement on MAP over the original ranking based on BM25, which is less efficient than the ranking from search engine used in [16,</ref>22]</ref>. Compared with SLTB, we can still see HRNN, HRNN-Entity and PSGAN have more improvement on queries with click entropy rget="#b21">22]</ref>. Compared with SLTB, we can still see HRNN, HRNN-Entity and PSGAN have more improvement on queries with click entropy no less than 1, which is consistent with the previous works [16,</ref>22]</ref>. KEPS has significant improvement over the baselines on both two types of queries, and the gain on queries with less c bibr" target="#b29">30]</ref>. It significantly improved personalization by learning the effective representations of user profiles and other personalized features from user's history. Ge et al. HRNN [16]</ref> proposed to use a hierarchical RNN to model user's profile. PSGAN [22]</ref> proposed a generative adversarial network framewor s.</p><p>We define the historical search sequence in the current session as short-term history ? ? , while that in previous sessions before the current session as long-term history ? ? following HRNN [16]</ref>:</p><formula xml:id="formula_1">? ? = [? ? 1 , ..., ? ? |? ? | ] = [? ? , ...? ? ? -1 ], ? ? = [? ? 1 , ..., ? ? |? ? | ] = [? , .</formula><p>., ? 1 ? 1 , .. ="bibr" target="#b3">[4]</ref> using click features and topic features, which is the state-of-art personalization model using traditional features; and the model based on deep learning: HRNN (HRNN+QA [16]</ref>) using hierarchical RNN and PSGAN (we choose the document-selection based model [22]</ref>) using adversarial training. To make alized models which further enhances the personalized effect.</p><p>Another challenge in personalized search is that many search logs are not publicly available [4,</ref>16,</ref>22,</ref>25,</ref>34]</ref>. In the released dataset from Yandex <r
s [42]</ref>, making query entity linking a challenging task: A recent study shows that state-of-the-art entity linking techniques only have 50% accuracy on web queries [41]</ref>. Using such noisy query entities in ranking often requires manual annotations [12]</ref> or soft linking/diversification <ref t Raviv et al. [28]</ref> used a language model to balance the entity-based and term-based information. Some researches also utilize entity representations. Xiong et al. [41]</ref> consider the bags of entity representations in search model, and the interaction between bags of word representations and bags of entity representations is al
d P-Click using click features to improve personalized ranking effect. Other works [3,</ref>9,</ref>17,</ref>23,</ref>29,</ref>34,</ref>35,</ref>38]</ref>
ich click features and topic features according to user's historical searches and clicks, which are effective in personalized search. Specifically, some works [13,</ref>32]</ref> studied personalized click features, and Dou et al. [13]</ref> proposed P-Click using click features to improve personalized ran
lementation Details. The dimension of pre-trained word embedding and entity embedding are 50. The vocabulary size of entities and words is 723,073 and 124,056. We train the word embedding using GloVe [27]</ref>, taking the query texts and document titles in the search log as training corpus. We train the entity embedding using TransE [5]
tei-c.org/ns/1.0"><p>search utilizes the explicit semantics, e.g. entities and relations from knowledge graphs, in search systems and effectively improves the text representation and ranking accuracy [14,</ref>19,</ref>21,</ref>28,</ref>40,</ref rget="#b18">[19]</ref> and Xiong et al. [40]</ref> takes the entity as a latent space and learn query-document matching relevance through the latent space. Ensan et al. [14]</ref> used a probability model to model the semantic entity linking of documents and queries. Raviv et al. [28]</ref> used a language
Bennett et al. [4]</ref> proposed SLTB to combine the two types of features using learning to rank.</p><p>Recently, deep learning has been applied in personalized search [16,</ref>18,</ref>22,</ref>25,</ref>30]</ref term and long-term history separately is effective because history in the current session tends to reflect user's session search intent, while the previous history may reflect user's global interests [16,</ref>22]</ref>.</p><p>Suppose a query ? has ? entity mentions (text string in query that may refer to certain entity), we denote the et to 100 dimensions. The setting of CNN layers and kernel functions in PEDRM are consistent with EDRM [21]</ref>.</p><p>Evaluation Metrics. Following the previous work [16,</ref>22]</ref>, we use MAP, MRR, P@K (precision in the top k positions) and AR (average ranking position of relevant documents) to ev ig. 5b</ref>.</p><p>From Fig. 5b</ref>, we still have that the effect of PEDRM is similar on both types of queries. However we find that different from stated in [16,</ref>22]</ref>, the personalization models perform better on queries with entropy less than 1. This may be because we count the impro r on queries with entropy less than 1. This may be because we count the improvement on MAP over the original ranking based on BM25, which is less efficient than the ranking from search engine used in [16,</ref>22]</ref>. Compared with SLTB, we can still see HRNN, HRNN-Entity and PSGAN have more improvement on queries with click entropy rget="#b21">22]</ref>. Compared with SLTB, we can still see HRNN, HRNN-Entity and PSGAN have more improvement on queries with click entropy no less than 1, which is consistent with the previous works [16,</ref>22]</ref>. KEPS has significant improvement over the baselines on both two types of queries, and the gain on queries with less c bibr" target="#b29">30]</ref>. It significantly improved personalization by learning the effective representations of user profiles and other personalized features from user's history. Ge et al. HRNN [16]</ref> proposed to use a hierarchical RNN to model user's profile. PSGAN [22]</ref> proposed a generative adversarial network framewor s.</p><p>We define the historical search sequence in the current session as short-term history ? ? , while that in previous sessions before the current session as long-term history ? ? following HRNN [16]</ref>:</p><formula xml:id="formula_1">? ? = [? ? 1 , ..., ? ? |? ? | ] = [? ? , ...? ? ? -1 ], ? ? = [? ? 1 , ..., ? ? |? ? | ] = [? , .</formula><p>., ? 1 ? 1 , .. ="bibr" target="#b3">[4]</ref> using click features and topic features, which is the state-of-art personalization model using traditional features; and the model based on deep learning: HRNN (HRNN+QA [16]</ref>) using hierarchical RNN and PSGAN (we choose the document-selection based model [22]</ref>) using adversarial training. To make alized models which further enhances the personalized effect.</p><p>Another challenge in personalized search is that many search logs are not publicly available [4,</ref>16,</ref>22,</ref>25,</ref>34]</ref>. In the released dataset from Yandex <r
es.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Personalized Web Search. In addition to search result diversification [36,</ref>37]</ref>, personalized search is another way to address the problem of vauge queries to search engines. Personalized search has been widely studied for its ability to m
f>9,</ref>17,</ref>23,</ref>29,</ref>34,</ref>35,</ref>38]</ref> extracted the topics features from user's search history to predicted document relevance. Click features and topic feat
ks [3,</ref>9,</ref>17,</ref>23,</ref>29,</ref>34,</ref>35,</ref>38]</ref> extracted the topics features from user's search history to predicted document y search logs are not publicly available [4,</ref>16,</ref>22,</ref>25,</ref>34]</ref>. In the released dataset from Yandex 1</ref> , the text contents of queries and documents have been encrypted, making it impo
lementation Details. The dimension of pre-trained word embedding and entity embedding are 50. The vocabulary size of entities and words is 723,073 and 124,056. We train the word embedding using GloVe [27]</ref>, taking the query texts and document titles in the search log as training corpus. We train the entity embedding using TransE [5]
as been applied in personalized search [16,</ref>18,</ref>22,</ref>25,</ref>30]</ref>. It significantly improved personalization by learning the effective representations of user profiles and other personalized features from user's history. Ge e
="bibr" target="#b12">[13]</ref> proposed P-Click using click features to improve personalized ranking effect. Other works [3,</ref>9,</ref>17,</ref>23,</ref>29,</ref>34,</ref>35,</ref>
xt representation and ranking accuracy [14,</ref>19,</ref>21,</ref>28,</ref>40,</ref>42,</ref>43]</ref>.</p><p>Both personalized search and entity-oriented search leverage information 1">12]</ref>. There are also some researches using entities as connections between the documents and queries for better matching. Liu et al. [19]</ref> and Xiong et al. [40]</ref> takes the entity as a latent space and learn query-document matching relevance through the latent space. Ensan et al. [14]</ref
<abstract> <div xmlns="http://www.tei-c.org/ns/1.0"><p>We design and implement a ready-to-use library in PyTorch for performing micro-batch pipeline parallelism with checkpointing proposed by GPipe [11]</ref>. In particular, we develop a set of design components to enable pipeline-parallel gradient computation in PyTorch's defineby-run and eager execution environme f more powerful hardwares. It is observed that increased capacity of DNN effectively has improved the performance. For example, AmoebaNet-B [23]</ref> scaled with GPipe [11]</ref> has 557 million parameters and has achieved top-1 accuracy 84.4% which was state-of-the-arts result at the time, and GPT-2 [22] -2 [22]</ref> is a Transformer-based [28]</ref> language model which has 1.5 billion parameters (see Figure 1</ref> of [11]</ref> for the effect of model scaling). However, training such a massive model is very resource intensive. One can mitigate this issue by reducing the size of the m "bibr" target="#b28">29]</ref>. Among them, pipeline parallelism a way to accelerate neural network training by combining model parallelism with data pipelining, either in synchronous way as in GPipe [11]</ref> or in asynchronous way as in [12]</ref>, PipeDream [9]</ref>, and XPipe <ref type="bibr" target=" In addition to this, it is enforced that F i,j must be completed before executing F i+1,j and B i,j must be completed before executing B i−1,j .</p><p>In addition to the micro-batch pipelining, GPipe [11]</ref> further reduces the memory requirement by utilizing gradient checkpointing for each B i,j . Since jth device executes B i,j</p><formula xml:id="formula_4">F 1 div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance Benchmarks</head><p>To demonstrate the efficiency of torchgpipe, we report performance benchmarks similar to that conducted by GPipe [11]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">AmoebaNet-D Speed Benchmark</head><p>We measured the throughput of AmoebaNet-D with variou n) where m ∈ {1, 4, 32} and n ∈ {2, 4, 8}. When m = 1, we used checkpointing to all micro-batches5</ref> to make a fair comparison of loss due to checkpointing with [11]</ref>. The model we used is our implementation of a sequential version of AmoebaNet-D in PyTorch 6</ref> .</p><p>The model is trai ipeline parallelism nor checkpointing, and Pipeline-1, - Table 2</ref>: Speed benchmark on AmoebaNet-D (18,</ref>256)</ref>.</p><p>In [11]</ref>, Cloud TPUv3s were used while we used NVIDIA Tesla P40 GPUs in our experiments. with the corresponding number of partitions. The hyperparameters determining t .tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduced torchgpipe, a ready-touse library in PyTorch for micro-batch pipeline parallelism with checkpointing proposed by GPipe [11]</ref>. This library is designed and implemented in PyTorch's define-by-run and eager execution environment. Ablation study and performance benchmarks presented in S [16,</ref>14,</ref>26,</ref>12,</ref>9,</ref>11,</ref>7]</ref>, and recent lines of research questions how to find an optimal strategy [15,</ref><ref typ
sing the performance by pruning the model [8,</ref>1]</ref>, designing more efficient architectures [10,</ref>27]</ref>, architecture search under resource constraints [3]</ref>, and many more.</p><p>We may wonder a rather direct approach is possibl
ch a massive model is very resource intensive. One can mitigate this issue by reducing the size of the model without losing the performance by pruning the model [8,</ref>1]</ref>, designing more efficient architectures [10,</ref>27]</ref>, architecture search under resource cons
pipeline parallelism in such environment, and demonstrate the efficiency of torchgpipe by conducting the speed and memory benchmarks on AmoebaNet-D [23]</ref> and U-Net [24]</ref> when trained with the library.</p><p>The rest of the paper is organized as follows. In Section 2, we discuss how the forward and backward passes can be decomp on.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">U-Net Memory Benchmark</head><p>To evaluate the effectiveness of torchgpipe for models with long skip connections, we used U-Net [24]</ref> for 2dimensional segmentation. The version of U-Net we used has five down-sampling layers and five up-sampling layers, and two hyper-parameters B and C determ tion. Channels are doubled after each down-sampling layers (or halved after each up-sampling layers, respectively). Our implementation of U-Net is rather symmetric than the original model proposed in [24]</ref> for effective balancing.</p><p>We conducted an experiment to measure the ability of torchgpipe for training a bigger model. For 1, 2, 4 and 8 GPUs, we found m
eural networks (DNNs) in a scalable way and by development of more powerful hardwares. It is observed that increased capacity of DNN effectively has improved the performance. For example, AmoebaNet-B [23]</ref> scaled with GPipe [11]</ref> has 557 million parameters and has achieved top-1 accuracy 84.4% which was state-of-the-arts resul t each component is necessary to fully benefit from pipeline parallelism in such environment, and demonstrate the efficiency of torchgpipe by conducting the speed and memory benchmarks on AmoebaNet-D [23]</ref> and U-Net [24]</ref> when trained with the library.</p><p>The rest of the paper is organized as follows. In Section 2, we discu
">12,</ref>9,</ref>11,</ref>7]</ref>, and recent lines of research questions how to find an optimal strategy [15,</ref>19,</ref>18,</ref>29]</ref>. Among them, pipeline parallelism a wa
pipeline parallelism in such environment, and demonstrate the efficiency of torchgpipe by conducting the speed and memory benchmarks on AmoebaNet-D [23]</ref> and U-Net [24]</ref> when trained with the library.</p><p>The rest of the paper is organized as follows. In Section 2, we discuss how the forward and backward passes can be decomp on.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">U-Net Memory Benchmark</head><p>To evaluate the effectiveness of torchgpipe for models with long skip connections, we used U-Net [24]</ref> for 2dimensional segmentation. The version of U-Net we used has five down-sampling layers and five up-sampling layers, and two hyper-parameters B and C determ tion. Channels are doubled after each down-sampling layers (or halved after each up-sampling layers, respectively). Our implementation of U-Net is rather symmetric than the original model proposed in [24]</ref> for effective balancing.</p><p>We conducted an experiment to measure the ability of torchgpipe for training a bigger model. For 1, 2, 4 and 8 GPUs, we found m
sing the performance by pruning the model [8,</ref>1]</ref>, designing more efficient architectures [10,</ref>27]</ref>, architecture search under resource constraints [3]</ref>, and many more.</p><p>We may wonder a rather direct approach is possibl
e="bibr" target="#b0">1]</ref>, designing more efficient architectures [10,</ref>27]</ref>, architecture search under resource constraints [3]</ref>, and many more.</p><p>We may wonder a rather direct approach is possible: can we train a massive model fast enough, given a large pool of devices? One obstacle
">12,</ref>9,</ref>11,</ref>7]</ref>, and recent lines of research questions how to find an optimal strategy [15,</ref>19,</ref>18,</ref>29]</ref>. Among them, pipeline parallelism a wa
eural networks (DNNs) in a scalable way and by development of more powerful hardwares. It is observed that increased capacity of DNN effectively has improved the performance. For example, AmoebaNet-B [23]</ref> scaled with GPipe [11]</ref> has 557 million parameters and has achieved top-1 accuracy 84.4% which was state-of-the-arts resul t each component is necessary to fully benefit from pipeline parallelism in such environment, and demonstrate the efficiency of torchgpipe by conducting the speed and memory benchmarks on AmoebaNet-D [23]</ref> and U-Net [24]</ref> when trained with the library.</p><p>The rest of the paper is organized as follows. In Section 2, we discu
er information can be aggregated in an effective way for better predictions.</p><p>There are some works (Xu et al., 2018b;</ref>Liao et al., 2019;</ref>Klicpera et al., 2018;</ref>Li et al., 2019)</ref> that tried to address this issue partially, and the discussion can refer to Appendix A. ep convolution network to extract high-level representation for vision tasks. This insight has been empirically demonstrated in many recent works (Wu et al., 2019;</ref>Klicpera et al., 2018;</ref>Xu et al., 2018a)</ref>, showing that a two-layer fully-connected neural networks is a better choice in the implementation. org/ns/1.0"><head n="2.2">COMPARISON WITH EXISTING METHODS</head><p>Connection with PPNP and APPNP. We also established a strong connection between AdaGCN and previous state-of-the-art PPNP and APPNP (Klicpera et al., 2018)</ref> method that leverages personalized pagerank to reconstruct graph convolutions in order to use information from a large and adjustable neigh eset statistics are summarized in Table 1</ref>. Recent graph neural networks suffer from overfitting to a single splitting of training, validation and test datasets (Klicpera et al., 2018)</ref>. To address this problem, inspired by (Klicpera et al., 2018)</ref>, we test all approaches on multiple rand ral networks suffer from overfitting to a single splitting of training, validation and test datasets (Klicpera et al., 2018)</ref>. To address this problem, inspired by (Klicpera et al., 2018)</ref>, we test all approaches on multiple random splits and initialization to conduct a rigorous study. Detailed dataset splittings are provided raph Convolution (SGC) (Wu et al., 2019)</ref> in Figure 3</ref>. In Table 2</ref>, we employ the same baselines as (Klicpera et al., 2018)</ref>: V.GCN (vanilla GCN) (Kipf &amp; Welling, 2017) and GCN with our early stopping, N-GCN (network of GCN) (Abu-El-Haija et a ompare AdaGCN with FastGCN (Chen et al., 2018)</ref> and GraphSAGE (Hamilton et al., 2017)</ref>. We refer to the result of baselines from (Klicpera et al., 2018)</ref> / and the implementation of AdaGCN is adapted from APPNP. For AdaGCN, after the line search on hyper-parameters, we set h = 5000 hidden uni
Average accuracy across different label rates with 20 splittings of datasets under 100 runs.with APPNP, showing more efficiency on graphs with few labeled nodes. Inspired by the Layer Effect on graphs(Sun et al., 2019)</ref>, we argue that the increase of layers in AdaGCN can result in more benefits on the efficient propagation of label signals especially on graphs w
tionship between different orders of neighbors, it is a natural choice to incorporate boosting algorithm into the design of deep graph models. As an important realization of boosting theory, AdaBoost (Freund et al., 1999)</ref> is extremely easy to implement and keeps competitive in terms of both practical performance and computational cost <ref type="bibr" target="# </head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSIONS AND CONCLUSION</head><p>One potential concern is that AdaBoost (Hastie et al., 2009;</ref>Freund et al., 1999</ref>) is established on i.i.d. hypothesis while graphs have inherent data-dependent property. Fortunately, the statistical convergence and consisten


h practical performance and computational cost (Hastie et al., 2009)</ref>. Moreover, boosting theory has been used to analyze the success of ResNets in computer vision (Huang et al., 2018)</ref> and AdaGAN (Tolstikhin et al., 2017)</ref> has already successfully incorporated boosting algorithm into the training of GAN
crucial to design deep graph models such that high-order information can be aggregated in an effective way for better predictions.</p><p>There are some works (Xu et al., 2018b;</ref>Liao et al., 2019;</ref>Klicpera et al., 2018;</ref>Li et al., 2019)</ref> that tried to address this issue

ighbors based on GCN, we are faced with stacking l layers' parameter matrix W (i) , i = 0, ..., l -1, which is definitely costly in computation. Besides, Multi-Scale Deep Graph Convolutional Networks (Luan et al., 2019)</ref> also theoretically demonstrated that the output can only contain the stationary information of graph structure and loses all the local informat








ra-ML (Bojchevski &amp; G?nnemann, 2018;</ref>McCallum et al., 2000)</ref>, PubMed (Sen et al., 2008)</ref>, MS-Academic (Shchur et al., 2018)</ref> and Reddit. Dateset statistics are summarized in Table 1</ref>. Recent graph neural networks suffer from ov
boosting theory, AdaBoost (Freund et al., 1999)</ref> is extremely easy to implement and keeps competitive in terms of both practical performance and computational cost (Hastie et al., 2009)</ref>. Moreover, boosting theory has been used to analyze the success of ResNets in computer vision (Huang et al., 2 l-th base classifier as the l-th layers in AdaGCN. As for the realization of Multi-class AdaBoost, we apply SAMME (Stagewise Additive Modeling using a Multi-class Exponential loss function) algorithm (Hastie et al., 2009)</ref>, a natural and clean multi-class extension of the two-class AdaBoost adaptively combining weak classifiers.</p><p>As illustrated in Figure <r e and c i represents the category of current i-th node. To attain a positive ? (l) , we only need (1 -err (l) ) &gt; 1/K, i.e., the accuracy of each weak classifier should be better than random guess (Hastie et al., 2009)</ref>. This can be met easily to guarantee the weights to be updated in the right direction. Then we adjust nodes' weights by increasing weights on d="formula_10">(l)</formula><p>? among all layers, enjoying stronger expressive power.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>In practice, we employ SAMME.R (Hastie et al., 2009)</ref>, the soft version of SAMME, in AdaGCN. SAMME.R (R for Real) algorithm (Hastie et al., 2009)</ref> leverages re /ns/1.0"><head n="3">ALGORITHM</head><p>In practice, we employ SAMME.R (Hastie et al., 2009)</ref>, the soft version of SAMME, in AdaGCN. SAMME.R (R for Real) algorithm (Hastie et al., 2009)</ref> leverages real-valued confidence-rated predictions, i.e., weighted probability estimates, rather than predicted hard labels in SAMME, in the www.tei-c.org/ns/1.0"><head n="4.2">PREDICTION PERFORMANCE</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSIONS AND CONCLUSION</head><p>One potential concern is that AdaBoost (Hastie et al., 2009;</ref>Freund et al., 1999</ref>) is established on i.i.d. hypothesis while graphs have inherent data-dependent proper

remarkable ability on node classification (Kipf &amp; Welling, 2017)</ref>, link prediction (Zhu et al., 2016)</ref> and clustering tasks (Fortunato, 2010)</ref>. Despite their enormous success, almost all of these models have shallow model architectures with only two or three layers. The shallow design of
ncy of boosting (Lugosi &amp; Vayatis, 2001;</ref>Mannor et al., 2003)</ref> can still be preserved when the samples are weakly dependent (Lozano et al., 2013)</ref>. More discussion can refer to Appendix A.5. In this paper, we propose a novel RNN-like deep graph neural network architecture called AdaGCNs.
uired for the OoO core. FSC replaces the complex OoO logic with simple FIFO queues.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Comparison Against CESP</head><p>Palacharla et al. [13]</ref> propose the complexity-effective superscalar processor (CESP) architecture which steers chains of dependent instructions into generic in-order queues. Figure or work has contributed to making processors more complexity-effective and power-efficient. We now point out the most closely related work.</p><p>Complexity-Effective Architectures. Palacharla et al. [13]</ref> propose the complexity-effective superscalar processors (CESP) architecture which steers chains of dependent instructions to in-order queues. Dispatch stalls
verhead upon a stall-on-use in-order core to improve instruction-level parallelism (ILP) as well as memory-hierarchy parallelism (MHP). 1</ref> Load Slice Core (LSC) [5]</ref> was the first work to propose an sOoO core; Freeway [10]</ref> builds upon the LSC proposal and exposes more MHP than LSC by addin ing 56% less power.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND MOTIVATION</head><p>In this section, we briefly cover the background on the two prior sOoO cores -LSC [5]</ref> and Freeway [10]</ref> -and we elaborate on their shortcomings. Figure 1</ref> provides a schem ced profiling information, or binary translation for separating critical instruction slices, unlike FSC.</p><p>Restricted Out-of-Order Microarchitectures. We extensively discussed the Load Slice Core [5]</ref> and Freeway [10]</ref> throughout the paper. Shioya et al. [18]</ref> propose the front-end executi
[6]</ref> also exploit critical instruction slices [24]</ref> for improving performance. More recently, Clairvoyance [20]</ref> and SWOOP [21]</ref> exploit the decoupled nature of access and execute phases for improving energy efficiency. These compiler-based techniques involve new instructions, advanced
s a starting point and reduce complexity by bypassing some of the out-of-order structures. FSC eliminates all out-of-order structures and is therefore more area-and power-efficient. Long-term parking [16]</ref> saves power in an OoO core by allocating back-end resources for critical instructions while buffering non-critical instructions in the front-end. More recentl
execution [23]</ref>, flea-flicker multipass pipelining [3]</ref>, braid processing [22]</ref> and OUTRIDER [6]</ref> also exploit critical instruction slices [24]</ref> for improving performance. More recently, Clairvoyance <ref type="bibr" targe
ion-Level Distributed Processing (ILDP) work, which proposes an ISA with in-order accumulator-based execution units. Our experimental results show that FSC outperforms CESP.</p><p>Salverda and Zilles [15]</ref> analyze the fundamental challenges of fusing small in-order cores on demand into larger cores. They find that fusing small cores is not appealing if those cor
le down-counter. Overall, FSC features a low-cost and effective instruction steering policy that enables out-of-order execution capabilities among in-order queues.</p><p>Decoupled Access-Execute. DAE [19]</ref> is the first work to separate access and execute phases of a program through coordinated queues. Proposals such as speculative-slice execution <ref type="bibr
separate access and execute phases of a program through coordinated queues. Proposals such as speculative-slice execution [23]</ref>, flea-flicker multipass pipelining [3]</ref>, braid processing [22]</ref> and OUTRIDER [6]</ref> also exploit critical instruction slices <ref t
oordinated queues. Proposals such as speculative-slice execution [23]</ref>, flea-flicker multipass pipelining [3]</ref>, braid processing [22]</ref> and OUTRIDER [6]</ref> also exploit critical instruction slices [24]</ref> for improving performa
ocessors (CESP) architecture which steers chains of dependent instructions to in-order queues. Dispatch stalls when an independent instruction cannot be steered to an empty queue. Salverda and Zilles [14]</ref> evaluate CESP in the context of a realistic baseline and point out a large performance gap with a traditional OoO core because of frequent dispatch stalls. A
uate CESP in the context of a realistic baseline and point out a large performance gap with a traditional OoO core because of frequent dispatch stalls. A similar steering policy is used by Kim et al. [9]</ref> in their Instruction-Level Distributed Processing (ILDP) work, which proposes an ISA with in-order accumulator-based execution units. Our experimental results s
m order. The IST is modeled the same way for both LSC and Freeway -we assume a 128-entry 2-way set-associative cache with 2/2 read/write ports. We estimate power consumption and chip area using McPAT [11]</ref> and CACTI v6.5 [12]</ref> assuming a 22 nm technology node. Area and per-access power estimates for the newly added FSC hardwar ared to our baseline OoO core with a chip area of 8.29 mm 2 , FSC occupies 37% less chip area.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Power Consumption</head><p>We use McPAT [11]</ref> to calculate InO and OoO core power consumption. power consumed by the additional FSC hardware structures is modeled using CACTI <ref type="bibr" target="#b11
s-Execute. DAE [19]</ref> is the first work to separate access and execute phases of a program through coordinated queues. Proposals such as speculative-slice execution [23]</ref>, flea-flicker multipass pipelining [3]</ref>, braid processing [22]</ref> and OUTRIDER <ref type=
s a starting point and reduce complexity by bypassing some of the out-of-order structures. FSC eliminates all out-of-order structures and is therefore more area-and power-efficient. Long-term parking [16]</ref> saves power in an OoO core by allocating back-end resources for critical instructions while buffering non-critical instructions in the front-end. More recentl
Freeway -we assume a 128-entry 2-way set-associative cache with 2/2 read/write ports. We estimate power consumption and chip area using McPAT [11]</ref> and CACTI v6.5 [12]</ref> assuming a 22 nm technology node. Area and per-access power estimates for the newly added FSC hardware structures are calculated using CACTI. We compute chip ry instruction  queues (ML, DEL, DLL and HL). We assume a physical register file (PRF) with 32 integer and floating-point registers. The MSHR is extended to support 8 outstanding misses. We use CACTI [12]</ref> to estimate chip area. CACTI accounts for the area of circuit-level structures such as hierarchically repeated wires, arrays, logic and the clock distribution mption</head><p>We use McPAT [11]</ref> to calculate InO and OoO core power consumption. power consumed by the additional FSC hardware structures is modeled using CACTI [12]</ref>. Table 3</ref> reports power consumption for the newly added components.</p><p>Overall, the added hardware structures increa
well as memory-hierarchy parallelism (MHP). 1</ref> Load Slice Core (LSC) [5]</ref> was the first work to propose an sOoO core; Freeway [10]</ref> builds upon the LSC proposal and exposes more MHP than LSC by adding one more in-order queue for uncovering additional independent loads.</p><p>LSC and Freeway is (IBDA). The loads, store-address operations and AGIs execute through a separate bypass queue (B-queue), while all other instructions execute from the main, arithmetic queue (A-queue). Kumar et al. [10]</ref> observe that, in LSC, an independent load may be stuck behind a load that depends on an older long-latency memory load, unnecessarily limiting the exploitable .tei-c.org/ns/1.0"><head n="2">BACKGROUND AND MOTIVATION</head><p>In this section, we briefly cover the background on the two prior sOoO cores -LSC [5]</ref> and Freeway [10]</ref> -and we elaborate on their shortcomings. Figure 1</ref> provides a schematic overview of the two sOoO core microarchitecture B-queue stalls on the dependent load. Therefore, younger independent loads behind the dependent load cannot issue to the memory hierarchy, hindering the opportunity to expose MHP.</p><p>Kumar et al. [10]</ref> propose Freeway, a core microarchitecture that overcomes LSC's MHP bottleneck caused by load-dependent loads. Freeway splits a slice that contains multiple loa >[4]</ref>. The configurations for the InO, FSC and OoO cores are provided in Table 2</ref>. We evaluate LSC and Freeway following the configurations by Kumar et al. [10]</ref>. The size of the A and B queues in LSC is 16-entries each. Freeway has three queues of size 12 entries each. FSC has four lanes with 8 entries each. For fair c separating critical instruction slices, unlike FSC.</p><p>Restricted Out-of-Order Microarchitectures. We extensively discussed the Load Slice Core [5]</ref> and Freeway [10]</ref> throughout the paper. Shioya et al. [18]</ref> propose the front-end execution architecture which executes instructions that hav
m order. The IST is modeled the same way for both LSC and Freeway -we assume a 128-entry 2-way set-associative cache with 2/2 read/write ports. We estimate power consumption and chip area using McPAT [11]</ref> and CACTI v6.5 [12]</ref> assuming a 22 nm technology node. Area and per-access power estimates for the newly added FSC hardwar ared to our baseline OoO core with a chip area of 8.29 mm 2 , FSC occupies 37% less chip area.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Power Consumption</head><p>We use McPAT [11]</ref> to calculate InO and OoO core power consumption. power consumed by the additional FSC hardware structures is modeled using CACTI <ref type="bibr" target="#b11
arget="#b15">[16]</ref> saves power in an OoO core by allocating back-end resources for critical instructions while buffering non-critical instructions in the front-end. More recently, Alipour et al. [1]</ref> leverage instruction criticality and readiness to bypass the out-of-order back-end. Instructions that do not benefit from out-of-order scheduling and instructio
execution [23]</ref>, flea-flicker multipass pipelining [3]</ref>, braid processing [22]</ref> and OUTRIDER [6]</ref> also exploit critical instruction slices [24]</ref> for improving performance. More recently, Clairvoyance <ref type="bibr" targe
power values with the activity factors obtained from the timing model, which are then added to the power consumption numbers provided by McPAT.</p><p>We create representative 1B-instruction SimPoints [17]</ref> for the SPEC CPU2017 benchmarks. We sort the benchmarks by increasing number of last-level cache (LLC) misses per-kilo instructions (MPKI). We notice the maxi
2]</ref> and OUTRIDER [6]</ref> also exploit critical instruction slices [24]</ref> for improving performance. More recently, Clairvoyance [20]</ref> and SWOOP [21]</ref> exploit the decoupled nature of access and execute phases for improving energy efficiency. These compiler-
ion-Level Distributed Processing (ILDP) work, which proposes an ISA with in-order accumulator-based execution units. Our experimental results show that FSC outperforms CESP.</p><p>Salverda and Zilles [15]</ref> analyze the fundamental challenges of fusing small in-order cores on demand into larger cores. They find that fusing small cores is not appealing if those cor
ion could be reduced by many orders of magnitude while increasing the predictive accuracy (Gilmer et al., 2017;</ref>Wu et al., 2018;</ref>Fey et al., 2020)</ref>. Graph neural networks have been proven to be particularly effective in this task (Hu et al., 2020;</ref><ref type="bibr" target= >(Chen et al., 2020;</ref>Nikolentzos et al., 2020;</ref>Abu-El-Haija et al., 2019;</ref>Loukas, 2019;</ref>Fey et al., 2020)</ref>. In the context of molecular property prediction, we highlight the work of Fey et al. (2020)</ref> who proposed to p issue arises from the presence of cycles in the input graph, it was proposed to perform coupled convolution on both the input graph and a coarser version of it from which all cycles have been removed (Fey et al., 2020)</ref>. Despite interesting results, this approach gives more information to the network and considerably changes the architecture.</p><p>In this work, a et al., 2019;</ref>Loukas, 2019;</ref>Fey et al., 2020)</ref>. In the context of molecular property prediction, we highlight the work of Fey et al. (2020)</ref> who proposed to perform message passing between the original graph and a coarser graph containing no cycles. The authors rely on fixed rules simil
a point-wise nonlinearity. The GCN convolution can be seen as a computationally simple first-order approximation of spectral graph convolution (Bruna et al., 2014;</ref>Defferrard et al., 2016)</ref>  1</ref>: Main characteristics of the datasets used in this study. The first column is the total number of compounds in t
feiler Leman kernels (Morris et al., 2019)</ref>, or to increase the receptive field of each convolution (Flam-Shepherd et al., 2020;</ref>Nikolentzos et al., 2020;</ref>Abu-El-Haija et al., 2019)</ref>. However, these approaches make considerable changes to the architecture of on, in particular when dealing with molecular graphs such as found in organic chemistry. This problem has been investigated by many recent works (Chen et al., 2020;</ref>Nikolentzos et al., 2020;</ref>Abu-El-Haija et al., 2019;</ref>Loukas, 2019;</ref><ref type="bibr" target="#
HER IMPROVEMENTS ON GRAPH NEURAL NETWORKS</head><p>Learning features directly on the molecular graph instead of handcrafting them or using other representation is an idea that emerged a few years ago (Duvenaud et al., 2015;</ref>Gilmer et al., 2017;</ref>Kong et al., 2020)</ref>. Many additions and modificat
HER IMPROVEMENTS ON GRAPH NEURAL NETWORKS</head><p>Learning features directly on the molecular graph instead of handcrafting them or using other representation is an idea that emerged a few years ago (Duvenaud et al., 2015;</ref>Gilmer et al., 2017;</ref>Kong et al., 2020)</ref>. Many additions and modificat
et al. (2020)</ref> who proposed to perform message passing between the original graph and a coarser graph containing no cycles. The authors rely on fixed rules similar to the junction tree approach (Jin et al., 2018)</ref> to annotate graph cycles and represent them into specific nodes.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>OTHER IMPROVEMENTS ON
reasoning or semantic segmentation, community detection and social network predictions, recommender systems, traffic predictions, and much more (Zhou et al., 2018;</ref>Wu et al., 2020)</ref>. Among those problems, supervised whole graph property prediction is an important topic, essentially applied to molecular property prediction, whi
HER IMPROVEMENTS ON GRAPH NEURAL NETWORKS</head><p>Learning features directly on the molecular graph instead of handcrafting them or using other representation is an idea that emerged a few years ago (Duvenaud et al., 2015;</ref>Gilmer et al., 2017;</ref>Kong et al., 2020)</ref>. Many additions and modificat
reasoning or semantic segmentation, community detection and social network predictions, recommender systems, traffic predictions, and much more (Zhou et al., 2018;</ref>Wu et al., 2020)</ref>. Among those problems, supervised whole graph property prediction is an important topic, essentially applied to molecular property prediction, whi
l prohibitively large, and they usually do not outperform more traditional methods. Another approach is to extend the current framework, to make it equivalent to higher order Weisfeiler Leman kernels (Morris et al., 2019)</ref>, or to increase the receptive field of each convolution (Flam-Shepherd et al., 2020;</ref><ref type="bibr" targ
reasoning or semantic segmentation, community detection and social network predictions, recommender systems, traffic predictions, and much more (Zhou et al., 2018;</ref>Wu et al., 2020)</ref>. Among those problems, supervised whole graph property prediction is an important topic, essentially applied to molecular property prediction, whi
e="bibr" target="#b4">[4]</ref> in CNNs. By informing a CNN network where to look and what to pay attention to, attention networks achieve a better performance with fewer layers. As an example, SENet [5]</ref> introduces Squeeze-and-Excitation (SE) blocks to study the channel dependencies in a CNN architecture. Although aforementioned CNN architectures achieve better proposed spatial pyramid structure is that it does not introduce any additional parameter. All layers in the spatial pyramid structure are not learnable, which is nearly cost-free. Compared to SENet [5]</ref>, our structure only modifies the first fully-connected layer to tackle the large input size. The small computation overhead contributes to its enhanced performa InceptionV4 contains 3-6 carefully designed paths. All these paths are integrated together using filter concatenation as input to the next block. More recently, attention based networks such as SENet [5]</ref> and CBAM [6]</ref> provide an independent attention path to learn the weight of each channel and achieve state-of-the-art performance.</p><p>At oft-max and Sigmoid, attention mechanism is able to selectively emphasize salient features as well as suppress insignificant features. Thus, visual features could be better captured and exploited. In [5]</ref>, a Squeeze-and-Extraction block was proposed to learn the channel-wise attention for each convolutional layer, which provides an end-to-end training paradigm fo rget="#b23">[23]</ref>, and more.</p><p>We note that existing work on global average pooling used the last feature map which is small in size (7 ? 7 for example). However, attention based CNNs (e.g., [5]</ref>, [6]</ref>, [7]</ref>, etc.) apply global average pooling on each feature map. As presented in <ref type="bibr" t s. However, it cannot be used to learn channel dependency and its non-linear expression affects the effectiveness of the attention mechanism. To address this problem, we leverage the excitation block [5]</ref> to encode v and generate a 1D attention map ?. The excitation block employs two fully-connected layers. Then a sigmoid layer is employed to normalize the output la_5">? = sig (W2? (W1v)) , (<label>6</label></formula><formula xml:id="formula_6">)</formula><p>where ? is a rectified linear unit (ReLU) function and sig denotes the sigmoid function. Like in SENet [5]</ref>, we set r to 16.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Point-wise Convolution</head><p>The attention block in our proposed spatial evaluate the performance of SPANet using CIFAR-100 and a down-sampled ImageNet dataset. Without bells and whistles, SPANet outperforms related stateof-art work [2,</ref>5,</ref>10,</ref>11]</ref>. Experimental results show that structural information in the attention mechanism <p>Most of the existing self-attention based networks follow a path design pattern: they learn an attention map from a feature map and then apply the learned attention map to the original feature map [5,</ref>18]</ref> . However, being confined to aforementioned schema compromises the exploration of attention path connections. For SPANet sion, SPANet refers to SPANet-C unless otherwise specified.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Spatial Pyramid Attention</head><p>Many existing attention based networks [5,</ref>6,</ref>6,</ref>17]</ref> aggregate input feature maps into a 1D vector using global average poo
y alleviates the vanishing gradient problem and improves feature reuse.</p><p>In addition to shortcut connections, there are works studying the internal multi-path connections in convolutional blocks [15]</ref>. The InceptionV4 Network [15]</ref> is one of this kind. Besides a shortcut connection, each inception block in InceptionV4 con use.</p><p>In addition to shortcut connections, there are works studying the internal multi-path connections in convolutional blocks [15]</ref>. The InceptionV4 Network [15]</ref> is one of this kind. Besides a shortcut connection, each inception block in InceptionV4 contains 3-6 carefully designed paths. All these paths are integrated
t dataset. Without bells and whistles, SPANet outperforms related stateof-art work [2,</ref>5,</ref>10,</ref>11]</ref>. Experimental results show that structural information in the attention mechanism, which we focus on, is a crucial factor for model performance. Compared to SE images. We compare ResNet + SPANet with SENet and ResNet. We also apply SPANet and SENet to several other base CNN architectures, including VGG [25]</ref>, MobileNetV2 [11]</ref>, DenseNet [10]</ref>, and ResNext [26]</ref>, to study the generalizability of SPANet.</p></div> .org/ns/1.0"><head n="4.2.">Experimental Results</head><p>We compare the performance of our SPANet with SENet and the base networks. We employ four base networks, i.e., light-weight model MobileNetV2 [11]</ref>, heavy-weight model DenseNet [10]</ref>, ResNeXt [26]</ref>, and VGG16 <ref type="bibr" target="
. We argue that the limitation originating from the global average pooling makes the shallow layers (which output big-size feature maps) unable to fully leverage the advantages of attention mechanism [7]</ref>. Following this argument, we present Spatial Pyramid Attention (SPA), which introduces a spatial pyramid structure to encode the intermediate features instead o global average pooling used the last feature map which is small in size (7 ? 7 for example). However, attention based CNNs (e.g., [5]</ref>, [6]</ref>, [7]</ref>, etc.) apply global average pooling on each feature map. As presented in [20]</ref>, GAP behaves similarly to a structural regula
e effectiveness of SPANet. Note that the four networks represent different network architectures. MobileNetV2 is typically designed for lightweight models like[19,</ref>27,</ref>28]</ref>. DenseNet includes shortcut connections. ResNeXt is the first one that exposes "cardinality" dimension. VGG is a popula
t dataset. Without bells and whistles, SPANet outperforms related stateof-art work [2,</ref>5,</ref>10,</ref>11]</ref>. Experimental results show that structural information in the attention mechanism, which we focus on, is a crucial factor for model performance. Compared to SE images. We compare ResNet + SPANet with SENet and ResNet. We also apply SPANet and SENet to several other base CNN architectures, including VGG [25]</ref>, MobileNetV2 [11]</ref>, DenseNet [10]</ref>, and ResNext [26]</ref>, to study the generalizability of SPANet.</p></div> .org/ns/1.0"><head n="4.2.">Experimental Results</head><p>We compare the performance of our SPANet with SENet and the base networks. We employ four base networks, i.e., light-weight model MobileNetV2 [11]</ref>, heavy-weight model DenseNet [10]</ref>, ResNeXt [26]</ref>, and VGG16 <ref type="bibr" target="
ce the performance of CNNs, recent works add more and more convolutional layers to the CNN architecture. For example, from 8-layer AlexNet [1]</ref> to 1000-layer ResNet [2,</ref>3]</ref>, they aim to improve the accuracy of image recognition. Inevitably, more learnable layers introduce more parameters and pr mas of SPANet.</p><p>We comprehensively evaluate the performance of SPANet using CIFAR-100 and a down-sampled ImageNet dataset. Without bells and whistles, SPANet outperforms related stateof-art work [2,</ref>5,</ref>10,</ref>11]</ref>. Experimental results show that structural from previous layers, which facilities the training of deep networks. Moreover, gating units are employed to regulate the information flow. Subsequently, He et al. proposed Residual Networks (ResNet) [2,</ref>3]</ref>, which learn the residual functions by adding skip-connections. The ResNet shows that an identity mapping shortcut is cruc >[2,</ref>3]</ref>, which learn the residual functions by adding skip-connections. The ResNet shows that an identity mapping shortcut is crucial to ease the optimization [2,</ref>3]</ref>. Hence, ResNet discards the gating units used in Highway Networks and keeps the information passed though shortcuts. The b #b24">[24]</ref> and Downsampled ImageNet [12]</ref> (a downsampled version of the original ImageNet dataset). For training, we adopt a data augmentation scheme used in [2,</ref>3]</ref>. We pad an original image by 4 pixels with value zero on each side and then randomly crop the padded image back to a size get="#b17">[17]</ref> studies attention from both the residual path and the shortcut path. Although Competitive-SENet achieves promising performance, it is tailored particularly for Residual Networks [2]</ref>, which limits its generalization to other models. Without being limited to channel-wise attention, Sanghyun Woo et al. [6]</ref> exploited the n each channel, was introduced in [21]</ref> to replace the conventional fully-connected layers in CNNs. Since then, it has prevailed in computer vision for recognition [2]</ref>, detection [22]</ref>, segmentation [23]</ref>, and more.</p><p>We note that existing work on glob

base CNN architectures, including VGG [25]</ref>, MobileNetV2 [11]</ref>, DenseNet [10]</ref>, and ResNext [26]</ref>, to study the generalizability of SPANet.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment Settings and Datasets</head><p>We imple networks. We employ four base networks, i.e., light-weight model MobileNetV2 [11]</ref>, heavy-weight model DenseNet [10]</ref>, ResNeXt [26]</ref>, and VGG16 [25]</ref>.</p><p>Recognition accuracy.  the base networks in all cases. This is different from our intuition. As af
ype="bibr">6,</ref>6,</ref>17]</ref> aggregate input feature maps into a 1D vector using global average pooling. They achieve structural regularization [20]</ref>, but miss the structural information. In contrast, the spatial pyramid structure in our proposed attention module utilizes average pooling of three different based CNNs (e.g., [5]</ref>, [6]</ref>, [7]</ref>, etc.) apply global average pooling on each feature map. As presented in [20]</ref>, GAP behaves similarly to a structural regularizer and is capable of preventing over-fitting. However, applying GAP to every feature map overemphasizes the ef
odes attention weights. These two parts are light-weight.</p><p>In terms of pooling schema, our spatial pyramid struc-978-1-7281-1331-9/20/$31.00 ?2020 IEEE ture could be considered similar to SPPNet [8]</ref> and Region of Interesting Pooling [9]</ref>. In contrast, our spatial pyramid structure encodes a feature map with more structural and pointwise convolution omitted in Equation ( 2</ref>) are included in the implementation and performance evaluation of the SPA module (Section 4). Following [8]</ref>, we propose 3-level pyramid average pooling: 4 ? 4, 2 ? 2 and 1 ? 1.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Attention Path Connection
arget="#b1">[2]</ref>, [3]</ref>, [5]</ref>, the number of authors (i.e., cluster size) is usually a pre-specified parameter. Current works [6]</ref>, [7]</ref> did not efficiently handle the change of discriminative attributes and inductive paper embedding problem in the heterog ns/1.0"><head>A. Name Disambiguation</head><p>Name disambiguation methods can be divided into supervised [1]</ref>, [8]</ref>, unsupervised [6]</ref>, [9]</ref> and graph-based ones [2]</ref>, [5]</ref>. Graph-based work ve author privacy. Pairwise classification methods are applied to estimate the probability of a pair of author mentions belonging to the same author and are essential in the name disambiguation task. [6]</ref> first learns representation for every name mention in a pairwise or tripletwise way and refines the representation by a graph auto-encoder, but this method negl hor-Paper, Paper-Topic-Paper and Paper-Venue-Paper. We use the author's affiliation as the discriminative attribute to separate papers into small blocks and we use the same trainset and testset as in [6]</ref>.</p><p>In Semantic Scholar, the selected meta-paths of our method consist of Paper-Paper, Paper-Author-Paper, Paper-Topic-Paper, and Paper-Venue-Paper. We use t paper set D into small blocks according discriminative author attributes; 2 Arrange papers in every block as sequence s ∈ S; 3 Construct meta-path based view {G p1</figDesc><table /><note>• Aminer-AND[6]</ref>: This dataset contains 70,285 records of 12,798 unique authors with 100 ambiguous name references.Algorithm 1:</note></figure> <figure xmlns="http://www.tei-c.o
arget="#b2">[3]</ref>, [5]</ref>, the number of authors (i.e., cluster size) is usually a pre-specified parameter. Current works [6]</ref>, [7]</ref> did not efficiently handle the change of discriminative attributes and inductive paper embedding problem in the heterogeneous academic network simultaneously. I resentation for every name mention in a pairwise or tripletwise way and refines the representation by a graph auto-encoder, but this method neglects linkage between paper and author and coauthorship. [7]</ref> addresses the pairwise classification problem by extracting both structure-aware features and global features without considering semantic features. In this pap
adopting an inductive learning setting. DeepGL [13]</ref> aggregates a set of base graph features by relational functions that can generalize across networks. GraphSage [14]</ref> samples a fixed number of neighbors and generate node embeddings by aggregating their features. Both DeepGL and GraphSage are designed for homogeneous graphs. d by a meta-path. It can capture different aspects of structure information through meta-paths and is potential to add new nodes dynamically.</p><p>For each meta-path based view, similar to GraphSage [14]</ref>, node representations are generated by aggregating features of meta-path based neighbors and propagating information across K layers. Node v's representation <p>• Deepwalk [26]</ref>: Deepwalk captures contextual information of neighborhood via uniform random walks for node embedding in homogeneous network.</p><p>• GraphSage [14]</ref>: GraphSage samples node neighborhoods to generate node embeddings for unseen data in an inductive way and is designed for homogeneous network. </p></div> <div
ph Neural Network (GNN) [10]</ref> has attracted rising attention due to effective representation ability. While most GNN works [10]</ref>- [12]</ref> focus on transductive setting, there have been some recent works adopting an inductive learning setting. DeepGL [13]</ref> aggr
g/ns/1.0"><head>B. Graph Embedding</head><p>Graph embedding aims to represent a graph as a low dimensional vector while preserving graph structure and properties. Recently, Graph Neural Network (GNN) [10]</ref> has attracted rising attention due to effective representation ability. While most GNN works [10]</ref>- <ref type="bibr" target= ph structure and properties. Recently, Graph Neural Network (GNN) [10]</ref> has attracted rising attention due to effective representation ability. While most GNN works [10]</ref>- [12]</ref> focus on transductive setting, there have been some recent works adopting an inductive learning setting. DeepGL <ref roposed framework can be trained on a set of example pairs. For each pair of paper sequences, a cosine score function is applied to measure the similarity of the two paper sequence representations as (10)</ref>.</p><p>L sim = sim(h (1) , h (2) ) = h (1) • h (2)  h (1) • h (2) .</p><p>The pairwise similarity loss function encourages node sequences of the same author to

ed by impacts of their publications in the research community. Therefore, it is important to keep publication data in digital libraries accurate, consistent, and up to date.</p><p>Name disambiguation [2]</ref>, [3]</ref>, which aims to identify unique persons with the same name, has been studied for decades but remains largely unsolved. M ons of new papers efficiently. (3) Uncertain number of authors. It is challenging to determine the number of authors with the same name.</p><p>In existing clustering based name disambiguation methods [2]</ref>, [3]</ref>, [5]</ref>, the number of authors (i.e., cluster size) is usually a pre-specified paramet ed [1]</ref>, [8]</ref>, unsupervised [6]</ref>, [9]</ref> and graph-based ones [2]</ref>, [5]</ref>. Graph-based works exploit graph topological features in the academic network to enhance the representation of papers. get="#b1">[2]</ref>, [5]</ref>. Graph-based works exploit graph topological features in the academic network to enhance the representation of papers. For instance, GHOST [2]</ref> constructs document graph based on co-authorship. [5]</ref> leverages only relational data in the form of anonymized graphs to pre ng et al. [5]: This method learns paper embedding by sampling triplets from three graphs constructed by relations of authors and papers and cluster them by hierarchical agglomerative algorithm.• GHOST[2]</ref>: GHOST use affinity propagation algorithm for clustering on a co-authors graph where the node distance is measured based on the number of valid paths. • Louppe
"bibr" target="#b18">[19]</ref> have been studied in recent years. Meta-path is designed to preserve diverse semantic information of node type and edge type [20]</ref>- [22]</ref>. GTN [23]</ref> converts heterogeneous graph to new graph structures which involve identifying task-specific meta-paths and mul
type="bibr" target="#b13">[14]</ref> samples a fixed number of neighbors and generate node embeddings by aggregating their features. Both DeepGL and GraphSage are designed for homogeneous graphs. LAN [15]</ref> aggregates neighbors with both rule-based and network-based attention weights for knowledge graphs.</p><p>Heterogeneous information networks <ref type="bibr"

eous graphs. LAN [15]</ref> aggregates neighbors with both rule-based and network-based attention weights for knowledge graphs.</p><p>Heterogeneous information networks [16]</ref>- [19]</ref> have been studied in recent years. Meta-path is designed to preserve diverse semantic information of node type and
ed in recent years. Meta-path is designed to preserve diverse semantic information of node type and edge type [20]</ref>- [22]</ref>. GTN [23]</ref> converts heterogeneous graph to new graph structures which involve identifying task-specific meta-paths and multi-hop connections. HAN <ref type="bibr" target
y of New York at Buffalo. His papers from 2005 to 2020 are associated with jpei@cs.sfu.ca and Simon Fraser University. The change of discriminative attributes may lead to the paper separation problem [4]</ref>, i.e., papers of an author are regarded as belonging to different authors, which commonly occurs in digital libraries. To address this issue, name disambiguatio
adopting an inductive learning setting. DeepGL [13]</ref> aggregates a set of base graph features by relational functions that can generalize across networks. GraphSage [14]</ref> samples a fixed number of neighbors and generate node embeddings by aggregating their features. Both DeepGL and GraphSage are designed for homogeneous graphs. d by a meta-path. It can capture different aspects of structure information through meta-paths and is potential to add new nodes dynamically.</p><p>For each meta-path based view, similar to GraphSage [14]</ref>, node representations are generated by aggregating features of meta-path based neighbors and propagating information across K layers. Node v's representation <p>• Deepwalk [26]</ref>: Deepwalk captures contextual information of neighborhood via uniform random walks for node embedding in homogeneous network.</p><p>• GraphSage [14]</ref>: GraphSage samples node neighborhoods to generate node embeddings for unseen data in an inductive way and is designed for homogeneous network. </p></div> <div
type="bibr" target="#b13">[14]</ref> samples a fixed number of neighbors and generate node embeddings by aggregating their features. Both DeepGL and GraphSage are designed for homogeneous graphs. LAN [15]</ref> aggregates neighbors with both rule-based and network-based attention weights for knowledge graphs.</p><p>Heterogeneous information networks <ref type="bibr"
"bibr" target="#b15">[16]</ref>- [19]</ref> have been studied in recent years. Meta-path is designed to preserve diverse semantic information of node type and edge type [20]</ref>- [22]</ref>. GTN [23]</ref> converts heterogeneous graph to new graph structures which involve i

fferent research areas.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Namesake problem [1]</ref> poses a huge challenge on many applications, e.g., information retrieval, bibliographic data analysis. When searching for academic publications by author name, disambiguation methods and graph embedding methods.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Name Disambiguation</head><p>Name disambiguation methods can be divided into supervised [1]</ref>, [8]</ref>, unsupervised [6]</ref>, [9]</ref> and graph-based ones <re
to determine the number of authors with the same name.</p><p>In existing clustering based name disambiguation methods [2]</ref>, [3]</ref>, [5]</ref>, the number of authors (i.e., cluster size) is usually a pre-specified parameter. Current works [6]</ref>, <ref type="bibr" target >, [8]</ref>, unsupervised [6]</ref>, [9]</ref> and graph-based ones [2]</ref>, [5]</ref>. Graph-based works exploit graph topological features in the academic network to enhance the representation of papers. For instance, GHOST <ref type="bibr" targ aph topological features in the academic network to enhance the representation of papers. For instance, GHOST [2]</ref> constructs document graph based on co-authorship. [5]</ref> leverages only relational data in the form of anonymized graphs to preserve author privacy. Pairwise classification methods are applied to estimate the probabil
ph Neural Network (GNN) [10]</ref> has attracted rising attention due to effective representation ability. While most GNN works [10]</ref>- [12]</ref> focus on transductive setting, there have been some recent works adopting an inductive learning setting. DeepGL [13]</ref> aggr
b14">[15]</ref> aggregates neighbors with both rule-based and network-based attention weights for knowledge graphs.</p><p>Heterogeneous information networks [16]</ref>- [19]</ref> have been studied in recent years. Meta-path is designed to preserve diverse semantic information of node type and edge type [2
b14">[15]</ref> aggregates neighbors with both rule-based and network-based attention weights for knowledge graphs.</p><p>Heterogeneous information networks [16]</ref>- [19]</ref> have been studied in recent years. Meta-path is designed to preserve diverse semantic information of node type and edge type [2
ecent work shows that personalized PageRank [28]</ref> can be used to directly incorporate multi-hop neighborhood information of a node without explicit message-passing [33]</ref>. Intuitively, propagation based on personalized PageRank corresponds to infinitely many neighborhood aggregation layers where the node influence decays expone tion based on personalized PageRank corresponds to infinitely many neighborhood aggregation layers where the node influence decays exponentially with each layer. However, as proposed, Klicpera et al. [33]</ref>'s approach does not easily scale to large graphs since it performs an expensive variant of power iteration during training.</p><p>In this work, we present PPR pe="bibr" target="#b51">52]</ref> that naively stacking multiple layers may suffer from over-smoothing that can reduce predictive performance.</p><p>To tackle both of these challenges Klicpera et al. [33]</ref> suggest decoupling the feature transformation from the propagation. In their PPNP model, predictions are first generated (e.g. with a neural network) for each 1 is inefficient, the authors propose a variant of power iteration to compute the final predictions instead. Unfortunately, even a moderate number of power iteration evaluations (e.g. Klicpera et al. [33]</ref> used K = 10 to achieve a good approximation) is prohibitively expensive for large graphs since they need to be computed during each gradient-update step. More pically sparse, the obtained diffused features become denser, which significantly reduces the efficiency of the subsequent learning step. Both of these approaches are a special case of the PPNP model [33]</ref> which experimentally shows higher classification performance [18,</ref>33]</ref>.</p><p>Approxim -as well as our newly introduced MAG-Scholar-C dataset (10.5M nodes, 133M edges, 2.8M node features). In addition to the two scalable baselines, we also evaluate how PPRGo compares to the APPNP model [33]</ref> which we build upon. The results are summarized in Table 2</ref>. We can see that the performance of most models is comparab f these approaches are a special case of the PPNP model [33]</ref> which experimentally shows higher classification performance [18,</ref>33]</ref>.</p><p>Approximating PageRank. Recent approaches combine basic techniques to create algorithms with enhanced guarantees [35,</re
Π ppr i,:</formula><p>is equal to the personalized (seeded) PageRank vector of node i. PageRank and its many variants [28,</ref>38,</ref>47]</ref> have been extensively studied in the literature. Here we are interested in efficient and scalable algorithms for computing (an approximation) of personalized P
c datasets has generated significant interest in scaling these methods to larger graphs for use in real-world problems [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref> ations of a given node. While several approaches have been proposed to improve the efficiency of graph neural networks [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref> 26">27,</ref>41,</ref>54]</ref>. Unfortunately, there are few large graph baseline datasets available; apart from a handful of exceptions [16,</ref>54]</ref>, the scalability of most GNN methods has been demonstrated on graphs with fewer than 250K nodes. Moreover, the majorit web-scale) graphs is still under-studied. As we discussed in § 1 the most prevalent approach to scalability is to sample a subset of the graph, e.g. based on different importance scores for the nodes [16,</ref>21,</ref>25,</ref>41,</ref>54]</ref rical activations of the nodes as a control variate. Huang et al. [27]</ref> propose an adaptive sampling strategy with a trainable sampler per layer, and Chiang et al. [16]</ref> sample a block of nodes corresponding to a dense subgraph identified by the clustering algorithm METIS [30]</ref>. Because thes h (233K nodes, 11.6M edges, 602 node features) [25]</ref> typically being the largest graph used for evaluation. 4</ref> Chiang et al. [16]</ref> recently introduced the Amazon2M graph (2.5M nodes, 61M edges, 100 node features) which is large in terms of number of nodes, but tiny in terms of node featur ry on a Single Machine</head><p>Setup. To highlight the benefits of PPRGo we compare the runtime, memory, and predictive performance with SGC [49]</ref> and Cluster-GCN [16]</ref>, two strong baselines that represent the current state-ofthe-art scalable GNNs. Since SGC and Cluster-GCN report significant speedup over FastGCN <ref type="b
c datasets has generated significant interest in scaling these methods to larger graphs for use in real-world problems [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref> ations of a given node. While several approaches have been proposed to improve the efficiency of graph neural networks [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref> 26">27,</ref>41,</ref>54]</ref>. Unfortunately, there are few large graph baseline datasets available; apart from a handful of exceptions [16,</ref>54]</ref>, the scalability of most GNN methods has been demonstrated on graphs with fewer than 250K nodes. Moreover, the majorit web-scale) graphs is still under-studied. As we discussed in § 1 the most prevalent approach to scalability is to sample a subset of the graph, e.g. based on different importance scores for the nodes [16,</ref>21,</ref>25,</ref>41,</ref>54]</ref rical activations of the nodes as a control variate. Huang et al. [27]</ref> propose an adaptive sampling strategy with a trainable sampler per layer, and Chiang et al. [16]</ref> sample a block of nodes corresponding to a dense subgraph identified by the clustering algorithm METIS [30]</ref>. Because thes h (233K nodes, 11.6M edges, 602 node features) [25]</ref> typically being the largest graph used for evaluation. 4</ref> Chiang et al. [16]</ref> recently introduced the Amazon2M graph (2.5M nodes, 61M edges, 100 node features) which is large in terms of number of nodes, but tiny in terms of node featur ry on a Single Machine</head><p>Setup. To highlight the benefits of PPRGo we compare the runtime, memory, and predictive performance with SGC [49]</ref> and Cluster-GCN [16]</ref>, two strong baselines that represent the current state-ofthe-art scalable GNNs. Since SGC and Cluster-GCN report significant speedup over FastGCN <ref type="b
20,</ref>23,</ref>35,</ref>45,</ref>46,</ref>48]</ref>.</p><p>Random walk sampling [19]</ref> is one such approximation technique. While simple to implement, in order to guarantee at hniques to create algorithms with enhanced guarantees [35,</ref>45,</ref>46]</ref>. For example Wei et al. [48]</ref> propose the TopPPR algorithm combining the strengths of random walks and forward/backward search simultaneously. They can compute the top k entries of a perso
ttp://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph Neural Networks (GNNs) excel on a wide variety of network mining tasks from semi-supervised node classification and link prediction [25,</ref>32,</ref>44,</ref>55]</ref> to community detection and graph class erhead. A common strategy for scaling GNNs is to sample the graph structure during training, e.g. sample a fixed number of nodes from the k-hop neighborhood of a given node to generate its prediction [25,</ref>54]</ref>. The key differences between many scalable techniques lies in the design of the sampling scheme. For example, Chen et it on internal graphs with billions of nodes and edges.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Distributed Training</head><p>In contrast to most previously proposed methods [25,</ref>49,</ref>54]</ref> we utilize distributed computing techniques which significantly reduce the ove graphs for use in real-world problems [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref>54]</ref>. Unfortunately, there are few large gra he efficiency of graph neural networks [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref>49,</ref>54]</ref> nt approach to scalability is to sample a subset of the graph, e.g. based on different importance scores for the nodes [16,</ref>21,</ref>25,</ref>41,</ref>54]</ref>. 3</ref> Beyond sampling, Gao et al. <ref typ of publicly available benchmark datasets [2,</ref>13,</ref>14,</ref>21,</ref>25,</ref>27,</ref>41,</ref>49]</ref>. The size of these datasets is relative ef>41,</ref>49]</ref>. The size of these datasets is relatively small, with the Reddit graph (233K nodes, 11.6M edges, 602 node features) [25]</ref> typically being the largest graph used for evaluation. 4</ref> Chiang et al. [16]</ref> recen
ttp://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph Neural Networks (GNNs) excel on a wide variety of network mining tasks from semi-supervised node classification and link prediction [25,</ref>32,</ref>44,</ref>55]</ref> to community detection and graph class erhead. A common strategy for scaling GNNs is to sample the graph structure during training, e.g. sample a fixed number of nodes from the k-hop neighborhood of a given node to generate its prediction [25,</ref>54]</ref>. The key differences between many scalable techniques lies in the design of the sampling scheme. For example, Chen et it on internal graphs with billions of nodes and edges.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Distributed Training</head><p>In contrast to most previously proposed methods [25,</ref>49,</ref>54]</ref> we utilize distributed computing techniques which significantly reduce the ove graphs for use in real-world problems [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref>54]</ref>. Unfortunately, there are few large gra he efficiency of graph neural networks [13,</ref>14,</ref>16,</ref>21,</ref>25,</ref>27,</ref>41,</ref>49,</ref>54]</ref> nt approach to scalability is to sample a subset of the graph, e.g. based on different importance scores for the nodes [16,</ref>21,</ref>25,</ref>41,</ref>54]</ref>. 3</ref> Beyond sampling, Gao et al. <ref typ of publicly available benchmark datasets [2,</ref>13,</ref>14,</ref>21,</ref>25,</ref>27,</ref>41,</ref>49]</ref>. The size of these datasets is relative ef>41,</ref>49]</ref>. The size of these datasets is relatively small, with the Reddit graph (233K nodes, 11.6M edges, 602 node features) [25]</ref> typically being the largest graph used for evaluation. 4</ref> Chiang et al. [16]</ref> recen
on problems that can be addressed via semi-supervised learning.</p><p>Their applications occur across all media types and power many different Google products [29,</ref>39,</ref>40]</ref>. In web-scale datasets, the node sets are large, the graphs commonly have power-law degrees, the datasets change freque
e="bibr" target="#b54">55]</ref> to community detection and graph classification [3,</ref>15,</ref>22,</ref>37]</ref>. The success of GNNs on academic datasets has generated significant interest in scaling these methods to larger graphs for use in real-world problems <ref type
ibr" target="#b35">36]</ref> of personalized PageRank vectors for real-world graphs. These vectors can be readily approximated with sparse vectors and efficiently pre-computed in a distributed manner [5]</ref>. Using the sparse pre-computed approximations we can maintain the influence of relevant nodes located multiple hops away without prohibitive message-passing or ing method. Given a starting configuration, the PageRank scores are updated by traversing the out-links (respect., in-links) of the nodes.</p><p>For this work we adapt the approach by Andersen et al. [5]</ref> since it offers a good balance of scalability, approximation guarantees, and ease of distributed implementation. They show that π (i) can be weakly approximated (ϵ ) H , H i,: = f θ (x i )<label>(2)</label></formula><p>where Π (ϵ ) is a sparse approximation of Π ppr . To obtain each row of Π (ϵ ) we adapt the push-flow algorithm described in Andersen et al. [5]</ref>. We additionally truncate Π (ϵ ) to contain only the top k largest entries for each row. That is, for each node i we only  consider the set of nodes with top k ctively controls the norm of the residual. We show the pseudo-code for computing π (ϵ ) in Algorithm 1. For further details see § A.4.</p><p>Algorithm 1 Approximate personalized PageRank (G, α, t, ϵ) [5]</ref> Inputs: Graph G, teleport prob. α, target node t, max. residual ϵ 1: Initialize the (sparse) estimate-vector π (ϵ ) = 0 and the (sparse) residual-vector r = α • ></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Further Implementational Details</head><p>The pseudo code in Algorithm 1 shows how we compute the approximate personalized PageRank based on [5]</ref>. For single-machine experiments we implement the algorithm as described in Python using Numba for acceleration (not parallelized). In the distributed setting in d in each iteration. Additionally, we truncate nodes with a very large degree (≥ 10000) by randomly sampling their neighbors. The above modifications proved to be just as effective as Andersen et al. [5]</ref>'s method while being significantly faster in terms of runtime.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Applicability and Limitations</head> gorithms for computing (an approximation) of personalized PageRank. Luckily, given the broad applicability of PageRank, many such algorithms have been developed [4,</ref>5,</ref>19,</ref>20,</ref>23,</ref>35,</ref><r 9]</ref> is one such approximation technique. While simple to implement, in order to guarantee at most ϵ absolute error with probability of 1 − 1/n we need O( log n ϵ 2 ) random walks. Forward search [5,</ref>23]</ref> and backward search [4]</ref> can be viewed as deterministic variants of the random walk s rtheless, we can obtain a good approximation by truncating small elements to zero since most of the probability mass in the personalized PageRank vectors π (i) is localized on a small number of nodes [5,</ref>23,</ref>36]</ref>. Thus, we can approximate π (i) with a sparse vector and in turn approximate Π p node in parallel our implementation easily scales to graphs with billions of nodes. Moreover, we can a priori determine the number of iterations we need for achieving a desired approximation accuracy [5,</ref>23]</ref> which in turn means we can reliably estimate the runtime beforehand.</p><p>We implement PPRGo in Tensorflow and optimize
power iteration is very fast to compute, the neural network f θ quickly becomes the limiting factor for inference time, especially if it is computationally expensive (e.g. a deep ResNet architecture [26]</ref> or recurrent neural network (RNN)). With PPRGo, we can leverage the graph's homophily to reduce the number of nodes that need to be analyzed. Since nearby nod
/term> 				</keywords> 			</textClass> 			<abstract> <div xmlns="http://www.tei-c.org/ns/1.0"><p>We examined neural network models to perform video-based stress recognition using ANUStressDB data set [6]</ref>. Recent works on video-based stress recognition [6,</ref>11]</ref> requires feature engineering pro d in this experiment, and also the evaluation method used to measure the model performance.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Set</head><p>The ANUStressDB data set [6]</ref> consists of video samples from 24 subjects. Each video has a duration of 32 min 17 s, divided into 58110 samples (30 samples for 1 s). Each sample has 34 statis FNN model with feature selection technique, which has much less parameters with the expense of around 6-7% accuracy loss</p><p>The methods described in this paper are neural-based model. The paper in [6]</ref> used Support Vector Machine (SVM) based model to perform the task and obtain reported accuracy of 89%. The SVM model requires feature engineering to perform pre /1.0"><p>We examined neural network models to perform video-based stress recognition using ANUStressDB data set [6]</ref>. Recent works on video-based stress recognition [6,</ref>11]</ref> requires feature engineering process, which is time consuming and expensive. The neural network (NN) model aims to reduc (FFNN) and recurrent neural network with Long Short-Term Memory (LSTM). Recent researches on video-based stress recognition system incorporates feature engineering process before making a prediction [6,</ref>11]</ref>. However, this process is expensive and timeconsuming. In our work, we compared methods to improve neural network models
ring process. We set the feed-forward neural network (FFNN) as our baseline model. We extended this model with feature selection techniques to enhance the performance. The magnitude measure technique [3]</ref> uses the absolute value of weights from a fully trained network to measure the contribution of input features towards output values. The -1 norm regularisation enhance the performance of feed-forward neural network by reducing the number of input features. We presented two techniques to reduce the number of features, namely filter method (magnitude measure) [3]</ref> and embedded method ( -1 norm regularisation) [1,</ref>8]</ref>.</p><p>Magnitude Measure Technique. re Technique. The magnitude measure technique takes into account contribution of absolute weight values that connects a hidden neuron j in the hidden layer into an output neuron k in the output layer [3]</ref>. The following equation measures the contribution from an input feature neuron i to a hidden neuron j with input vector dimension din = 34.</p><formula xml:id=" ula><p>We computed the Q-values for all input features in fully-trained neural network based for the data set described in Sect. 2.1, and removed two features with the lowest Q-values as suggested by [3]</ref> to produce more consistent results. The network was re-trained using reduced features. We trained the reduced model over 5000 epochs.</p><p>-1 Norm Regularisati
els to perform video-based stress recognition using ANUStressDB data set [6]</ref>. Recent works on video-based stress recognition [6,</ref>11]</ref> requires feature engineering process, which is time consuming and expensive. The neural network (NN) model aims to reduce this process. In this work, we set a th Long Short-Term Memory (LSTM). Recent researches on video-based stress recognition system incorporates feature engineering process before making a prediction [6,</ref>11]</ref>. However, this process is expensive and timeconsuming. In our work, we compared methods to improve neural network models for video-based stress recognition tas
els to perform video-based stress recognition using ANUStressDB data set [6]</ref>. Recent works on video-based stress recognition [6,</ref>11]</ref> requires feature engineering process, which is time consuming and expensive. The neural network (NN) model aims to reduce this process. In this work, we set a th Long Short-Term Memory (LSTM). Recent researches on video-based stress recognition system incorporates feature engineering process before making a prediction [6,</ref>11]</ref>. However, this process is expensive and timeconsuming. In our work, we compared methods to improve neural network models for video-based stress recognition tas
this process. In this work, we set a baseline Feed-Forward Neural Network (FFNN) and extended the model using Feature Selection Technique, namely magnitude measure technique [3] and -1 regularisation [9]</ref>. Subsequently, we performed extensive evaluation between those models with the Long Short-Term Memory (LSTM) [5] model, which are designed to store state inform arget="#b0">[1,</ref>8]</ref> is an embedded feature selection technique used to bring weight of irrelevant inputs to 0, hence remove them from the model during training [9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM [5]</ref> to perform video-based stress r nction by penalizing parameters with a big value, hence discouraging the model from over-fitting regularisation using -1 norm discourages parameters with high sum of absolute values of the parameters [9]</ref>, thus creating a sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes this technique a good candidate for feature selection. [9]</ref>. We applied -1 penalty term using following equation.</p><formula xml:id="formula_5">error 1 = ? dhid i=0 din j=0 ||w i,j || 1<label>(6)</label></formula><p>The
this process. In this work, we set a baseline Feed-Forward Neural Network (FFNN) and extended the model using Feature Selection Technique, namely magnitude measure technique [3] and -1 regularisation [9]</ref>. Subsequently, we performed extensive evaluation between those models with the Long Short-Term Memory (LSTM) [5] model, which are designed to store state inform arget="#b0">[1,</ref>8]</ref> is an embedded feature selection technique used to bring weight of irrelevant inputs to 0, hence remove them from the model during training [9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM [5]</ref> to perform video-based stress r nction by penalizing parameters with a big value, hence discouraging the model from over-fitting regularisation using -1 norm discourages parameters with high sum of absolute values of the parameters [9]</ref>, thus creating a sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes this technique a good candidate for feature selection. [9]</ref>. We applied -1 penalty term using following equation.</p><formula xml:id="formula_5">error 1 = ? dhid i=0 din j=0 ||w i,j || 1<label>(6)</label></formula><p>The
els to perform video-based stress recognition using ANUStressDB data set [6]</ref>. Recent works on video-based stress recognition [6,</ref>11]</ref> requires feature engineering process, which is time consuming and expensive. The neural network (NN) model aims to reduce this process. In this work, we set a th Long Short-Term Memory (LSTM). Recent researches on video-based stress recognition system incorporates feature engineering process before making a prediction [6,</ref>11]</ref>. However, this process is expensive and timeconsuming. In our work, we compared methods to improve neural network models for video-based stress recognition tas
els to perform video-based stress recognition using ANUStressDB data set [6]</ref>. Recent works on video-based stress recognition [6,</ref>11]</ref> requires feature engineering process, which is time consuming and expensive. The neural network (NN) model aims to reduce this process. In this work, we set a th Long Short-Term Memory (LSTM). Recent researches on video-based stress recognition system incorporates feature engineering process before making a prediction [6,</ref>11]</ref>. However, this process is expensive and timeconsuming. In our work, we compared methods to improve neural network models for video-based stress recognition tas
this process. In this work, we set a baseline Feed-Forward Neural Network (FFNN) and extended the model using Feature Selection Technique, namely magnitude measure technique [3] and -1 regularisation [9]</ref>. Subsequently, we performed extensive evaluation between those models with the Long Short-Term Memory (LSTM) [5] model, which are designed to store state inform arget="#b0">[1,</ref>8]</ref> is an embedded feature selection technique used to bring weight of irrelevant inputs to 0, hence remove them from the model during training [9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM [5]</ref> to perform video-based stress r nction by penalizing parameters with a big value, hence discouraging the model from over-fitting regularisation using -1 norm discourages parameters with high sum of absolute values of the parameters [9]</ref>, thus creating a sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes this technique a good candidate for feature selection. [9]</ref>. We applied -1 penalty term using following equation.</p><formula xml:id="formula_5">error 1 = ? dhid i=0 din j=0 ||w i,j || 1<label>(6)</label></formula><p>The
LeakyReLU [7]</ref> with negative slope 0.1 to avoid dying ReLU problem due to zero gradient during back-propagation. To address overfitting on the model, dropout layers [12]</ref> are used in the LSTM layer (p = 0.1) and both hidden layers (p = 0.2).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Result and Discussion</h
e model is cross-entropy error function. The model was trained using error back-propagation [2]</ref> and optimised using Stochastic Gradient Descent (SGD) with momentum [10]</ref> with learning rate 0.1, and momentum term 0.9. The model hyper-parameters were cross-validated on the training set. We trained the baseline model over 5000 epo
els to perform video-based stress recognition using ANUStressDB data set [6]</ref>. Recent works on video-based stress recognition [6,</ref>11]</ref> requires feature engineering process, which is time consuming and expensive. The neural network (NN) model aims to reduce this process. In this work, we set a th Long Short-Term Memory (LSTM). Recent researches on video-based stress recognition system incorporates feature engineering process before making a prediction [6,</ref>11]</ref>. However, this process is expensive and timeconsuming. In our work, we compared methods to improve neural network models for video-based stress recognition tas
relevant inputs to 0, hence remove them from the model during training [9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM [5]</ref> to perform video-based stress recognition task. The LSTM model worked well with time-series data set with additional parameters to store information from the pr
relevant inputs to 0, hence remove them from the model during training [9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM [5]</ref> to perform video-based stress recognition task. The LSTM model worked well with time-series data set with additional parameters to store information from the pr
e model is cross-entropy error function. The model was trained using error back-propagation [2]</ref> and optimised using Stochastic Gradient Descent (SGD) with momentum [10]</ref> with learning rate 0.1, and momentum term 0.9. The model hyper-parameters were cross-validated on the training set. We trained the baseline model over 5000 epo
><formula xml:id="formula_1">Y = softmax(W ho h)<label>(2)</label></formula><p>The error function used in the model is cross-entropy error function. The model was trained using error back-propagation [2]</ref> and optimised using Stochastic Gradient Descent (SGD) with momentum [10]</ref> with learning rate 0.1, and momentum term 0.9. The
this process. In this work, we set a baseline Feed-Forward Neural Network (FFNN) and extended the model using Feature Selection Technique, namely magnitude measure technique [3] and -1 regularisation [9]</ref>. Subsequently, we performed extensive evaluation between those models with the Long Short-Term Memory (LSTM) [5] model, which are designed to store state inform arget="#b0">[1,</ref>8]</ref> is an embedded feature selection technique used to bring weight of irrelevant inputs to 0, hence remove them from the model during training [9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM [5]</ref> to perform video-based stress r nction by penalizing parameters with a big value, hence discouraging the model from over-fitting regularisation using -1 norm discourages parameters with high sum of absolute values of the parameters [9]</ref>, thus creating a sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes this technique a good candidate for feature selection. [9]</ref>. We applied -1 penalty term using following equation.</p><formula xml:id="formula_5">error 1 = ? dhid i=0 din j=0 ||w i,j || 1<label>(6)</label></formula><p>The
LeakyReLU [7]</ref> with negative slope 0.1 to avoid dying ReLU problem due to zero gradient during back-propagation. To address overfitting on the model, dropout layers [12]</ref> are used in the LSTM layer (p = 0.1) and both hidden layers (p = 0.2).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Result and Discussion</h
e model is cross-entropy error function. The model was trained using error back-propagation [2]</ref> and optimised using Stochastic Gradient Descent (SGD) with momentum [10]</ref> with learning rate 0.1, and momentum term 0.9. The model hyper-parameters were cross-validated on the training set. We trained the baseline model over 5000 epo
LeakyReLU [7]</ref> with negative slope 0.1 to avoid dying ReLU problem due to zero gradient during back-propagation. To address overfitting on the model, dropout layers [12]</ref> are used in the LSTM layer (p = 0.1) and both hidden layers (p = 0.2).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Result and Discussion</h
this process. In this work, we set a baseline Feed-Forward Neural Network (FFNN) and extended the model using Feature Selection Technique, namely magnitude measure technique [3] and -1 regularisation [9]</ref>. Subsequently, we performed extensive evaluation between those models with the Long Short-Term Memory (LSTM) [5] model, which are designed to store state inform arget="#b0">[1,</ref>8]</ref> is an embedded feature selection technique used to bring weight of irrelevant inputs to 0, hence remove them from the model during training [9]</ref>. Finally, we compared improved NN models with a recurrent neural network model with LSTM [5]</ref> to perform video-based stress r nction by penalizing parameters with a big value, hence discouraging the model from over-fitting regularisation using -1 norm discourages parameters with high sum of absolute values of the parameters [9]</ref>, thus creating a sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes sparse weight (parameter) matrix solution. The capabilities of -1 norm to create this sparse solution hence bring some parameters to zero makes this technique a good candidate for feature selection. [9]</ref>. We applied -1 penalty term using following equation.</p><formula xml:id="formula_5">error 1 = ? dhid i=0 din j=0 ||w i,j || 1<label>(6)</label></formula><p>The
absolute value of weights from a fully trained network to measure the contribution of input features towards output values. The -1 norm regularisation technique [1,</ref>8]</ref> is an embedded feature selection technique used to bring weight of irrelevant inputs to 0, hence remove them from the model during training <ref type="bibr" targ to reduce the number of features, namely filter method (magnitude measure) [3]</ref> and embedded method ( -1 norm regularisation) [1,</ref>8]</ref>.</p><p>Magnitude Measure Technique. The magnitude measure technique takes into account contribution of absolute weight values that connects a hidden neuron j in
er, we seek to answer the question: can Transformer models be improved to be computation, memory, and architecture efficient, as well as maintain higher prediction capacity?</p><p>Vanilla Transformer (Vaswani et al. 2017</ref>) has three significant limitations when solving LSTF:</p><p>1. The quadratic computation of self-attention. The atom operation of self-attenti </p><p>(2) for an overview and the following sections for details.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Efficient Self-attention Mechanism</head><p>The canonical self-attention in (Vaswani et al. 2017</ref>) is defined on receiving the tuple input (query, key, value) and performs the scaled dot-product as</p><formula xml:id="formula_0">A(Q, K, V) all the stacks' outputs and have the final hidden representation of encoder.</p><p>Decoder: Generating long sequential outputs through one forward procedure</p><p>We use a standard decoder structure (Vaswani et al. 2017)</ref> in Fig.</p><p>(2), and it is composed of a stack of two identical multihead attention layers. However, the generative inference is employed t
∈ R L V ×d</formula><p>and d is the input dimension. To further discuss the self-attention mechanism, let q i , k i , v i stand for the i-th row in Q, K, V respectively. Following the formulation in (Tsai et al. 2019)</ref>, the i-th query's attention is defined as a kernel smoother in a probability form:</p><formula xml:id="formula_1">A(q i , K, V) = j k(q i , k j

" target="#b19">(Papadimitriou and Yu 2006)</ref>, energy and smart grid management, economics and finance (Zhu and Shasha 2002)</ref>, and disease propagation analysis (Matsubara et al. 2014)</ref>. In these scenarios, we can leverage a substantial amount of time-series data on past behavior to make a forecast in the long run, namely l Some significant real-world applications are sensor network monitoring (Papadimitriou and Yu 2006)</ref>, energy and smart grid management, disease propagation analysis (Matsubara et al. 2014)</ref>, economics and finance forecasting (Zhu and Shasha 2002), evolution of agriecosystems, climate change forecasting, and variations in air po
/p><p>Baselines: The details of network components are given in Appendix E.1. We have selected 5 time-series forecasting methods as comparison, including ARIMA (Ariyo, Adewumi, and Ayo 2014), Prophet (Taylor and Letham 2018)</ref>, LSTMa (Bahdanau, Cho, and Bengio 2015)</ref> and LSTnet (Lai et al. 2018</re
put's time dimension sharply, seeing the n-heads weights matrix (overlapping red squares) of Attention blocks in Fig. (3</ref>). Inspired by the dilated convolution (Yu, Koltun, and Funkhouser 2017;</ref>Gupta and Rush 2017)</ref>, our "distilling" procedure forwards from j-th layer into (j + 1)-th lay

ding ARIMA (Ariyo, Adewumi, and Ayo 2014), Prophet (Taylor and Letham 2018)</ref>, LSTMa (Bahdanau, Cho, and Bengio 2015)</ref> and LSTnet (Lai et al. 2018</ref>) and DeepAR (Flunkert, Salinas, and Gasthaus 2017)</ref>. To better explore the ProbSparse selfattention's performa
liable workhorse for time-series forecasting (Box et al. 2015;</ref>Ray 1990;</ref>Seeger et al. 2017;</ref>Seeger, Salinas, and Flunkert 2016)</ref>, and deep learning techniques mainly develop an encoder-decoder prediction paradigm by using RNN and their variants <ref type="

/p><p>Baselines: The details of network components are given in Appendix E.1. We have selected 5 time-series forecasting methods as comparison, including ARIMA (Ariyo, Adewumi, and Ayo 2014), Prophet (Taylor and Letham 2018)</ref>, LSTMa (Bahdanau, Cho, and Bengio 2015)</ref> and LSTnet (Lai et al. 2018</re
/p><p>Baselines: The details of network components are given in Appendix E.1. We have selected 5 time-series forecasting methods as comparison, including ARIMA (Ariyo, Adewumi, and Ayo 2014), Prophet (Taylor and Letham 2018)</ref>, LSTMa (Bahdanau, Cho, and Bengio 2015)</ref> and LSTnet (Lai et al. 2018</re
put's time dimension sharply, seeing the n-heads weights matrix (overlapping red squares) of Attention blocks in Fig. (3</ref>). Inspired by the dilated convolution (Yu, Koltun, and Funkhouser 2017;</ref>Gupta and Rush 2017)</ref>, our "distilling" procedure forwards from j-th layer into (j + 1)-th lay

" target="#b19">(Papadimitriou and Yu 2006)</ref>, energy and smart grid management, economics and finance (Zhu and Shasha 2002)</ref>, and disease propagation analysis (Matsubara et al. 2014)</ref>. In these scenarios, we can leverage a substantial amount of time-series data on past behavior to make a forecast in the long run, namely l Some significant real-world applications are sensor network monitoring (Papadimitriou and Yu 2006)</ref>, energy and smart grid management, disease propagation analysis (Matsubara et al. 2014)</ref>, economics and finance forecasting (Zhu and Shasha 2002), evolution of agriecosystems, climate change forecasting, and variations in air po
a critical ingredient across many domains, such as sensor network monitoring (Papadimitriou and Yu 2006)</ref>, energy and smart grid management, economics and finance (Zhu and Shasha 2002)</ref>, and disease propagation analysis (Matsubara et al. 2014)</ref>. In these scenarios, we can leverage a substan
ding ARIMA (Ariyo, Adewumi, and Ayo 2014), Prophet (Taylor and Letham 2018)</ref>, LSTMa (Bahdanau, Cho, and Bengio 2015)</ref> and LSTnet (Lai et al. 2018</ref>) and DeepAR (Flunkert, Salinas, and Gasthaus 2017)</ref>. To better explore the ProbSparse selfattention's performa
havior to make a forecast in the long run, namely long sequence time-series forecasting (LSTF). However, existing methods are designed under limited problem setting, like predicting 48 points or less (Hochreiter and Schmidhuber 1997;</ref>Li et al. 2018;</ref>Yu et al. 2017;</ref>Liu et al 2017;</ref>Seeger, Salinas, and Flunkert 2016)</ref>, and deep learning techniques mainly develop an encoder-decoder prediction paradigm by using RNN and their variants (Hochreiter and Schmidhuber 1997;</ref>Li et al. 2018;</ref>Yu et al. 2017)</ref>. Our proposed Informer holds the encode
havior to make a forecast in the long run, namely long sequence time-series forecasting (LSTF). However, existing methods are designed under limited problem setting, like predicting 48 points or less (Hochreiter and Schmidhuber 1997;</ref>Li et al. 2018;</ref>Yu et al. 2017;</ref>Liu et al 2017;</ref>Seeger, Salinas, and Flunkert 2016)</ref>, and deep learning techniques mainly develop an encoder-decoder prediction paradigm by using RNN and their variants (Hochreiter and Schmidhuber 1997;</ref>Li et al. 2018;</ref>Yu et al. 2017)</ref>. Our proposed Informer holds the encode
a critical ingredient across many domains, such as sensor network monitoring (Papadimitriou and Yu 2006)</ref>, energy and smart grid management, economics and finance (Zhu and Shasha 2002)</ref>, and disease propagation analysis (Matsubara et al. 2014)</ref>. In these scenarios, we can leverage a substan
" target="#b19">(Papadimitriou and Yu 2006)</ref>, energy and smart grid management, economics and finance (Zhu and Shasha 2002)</ref>, and disease propagation analysis (Matsubara et al. 2014)</ref>. In these scenarios, we can leverage a substantial amount of time-series data on past behavior to make a forecast in the long run, namely l Some significant real-world applications are sensor network monitoring (Papadimitriou and Yu 2006)</ref>, energy and smart grid management, disease propagation analysis (Matsubara et al. 2014)</ref>, economics and finance forecasting (Zhu and Shasha 2002), evolution of agriecosystems, climate change forecasting, and variations in air po

lly applied to BERT [35,</ref>4]</ref>.</p><p>The maximum length limit in BERT naturally reminds us the limited capacity of Working Memory [2]</ref>, a human cognitive system storing information for logical reasoning and decision-making. Experiments [27,</ref><ref type="bibr" t is responsible for coordinating (multi-modal) information", and "functions like a limited-capacity attentional system capable of selecting and operating control processes and strategies", as Baddeley [2]</ref> pointed out in his 1992 classic. Later research detailed that the contents in the working memory decay over time [5]</ref>, unless
12 tokens away from each other. They never appear in the same BERT input window in the sliding window method, hence we fail to answer the question.</p><p>Pretrained language models, pioneered by BERT [12]</ref>, have emerged as silver bullets for many NLP tasks, such as question answering [38]</ref> and text classification <ref type="bi /www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Challenge of long texts. The direct and superficial obstacle for long texts is that the pretrained max position embedding is usually 512 in BERT [12]</ref>. However, even if the embeddings for larger positions are provided, the memory consumption is unaffordable because all the activations are stored for back-pro
they are proved not relevant enough (with low scores) by more information from new blocks in z + , which is neglected by previous multi-step reasoning methods [13,</ref>1,</ref>10]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>The diversity of downstreaming tasks p
tations by interventions to train judge.</p><p>Our experiments demonstrate that CogLTX outperforms or achieves comparable performance with the state-of-the-art results on four tasks, including NewsQA [44]</ref>, HotpotQA [53]</ref>, 20NewsGroups [22]</ref> and Alibaba, with constant memory consumption rega n="4.1">Reading comprehension</head><p>Dataset and settings. Given a question and a paragraph, the task is to predict the answer span in the paragraph. We evaluate the performance of CogLTX on NewsQA [44]</ref>, which contains 119,633 human-generated questions posed on 12,744 long news articles. 3</ref> Since previous SOTA <ref type=
"#b1">[2]</ref> pointed out in his 1992 classic. Later research detailed that the contents in the working memory decay over time [5]</ref>, unless are kept via rehearsal [3]</ref>, i.e. paying attention to and refreshing the information in the mind. Then the overlooked information is constantly updated with relevant items from long-term m × 10 −5 and 10 −4 respectively. The learning rates warmup over the first 10% steps, and then linearly decay to 1/10 of the max learning rates. The common hyperparameters are batch size = 32, strides= [3,</ref>5]</ref>, t up = 0.2 and t down = −0.05.</p><p>In this section, we separately introduce each task with related results, analysis an
ing memory. The motivation of fine scores is that the relative sizes of coarse scores are not accurate enough without interaction and comparison between blocks, similar to the motivation of reranking [7]</ref>.</p><p>MemRecall in nature enables multi-step reasoning by repeating the procedure with new z + . The importance of iterative retrieval is highlighted by CogQA blocks) rather than Bayesian rules. The judge fits an inductive discriminative model to help infer z.  In the first epoch, the judge is nearly untrained and selects some blocks at random. Among them, (7)</ref> contributes most to the correct classification, thus is marked "relevant". In the second epoch, trained judge finds (1) with strong evidence "prayers" and ( <re "relevant". In the second epoch, trained judge finds (1) with strong evidence "prayers" and ( 1</ref>) is marked as "relevant" at once. Then in the next epoch, (7)</ref> becomes not essential for classification and is marked as "irrelevant".</p><p>4 Experiments In all experiments, the judge and reasoner are finetuned by Adam <re blocks are initialized as "irrelevant" by BM25 (no common words with the label soc.religion.christian).In the first epoch, the judge is nearly untrained and selects some blocks at random. Among them,(7)</ref> contributes most to the correct classification, thus is marked "relevant". In the second epoch, trained judge finds (1) with strong evidence "prayers" and (1) i t to the correct classification, thus is marked "relevant". In the second epoch, trained judge finds (1) with strong evidence "prayers" and (1) is marked as "relevant" at once. Then in the next epoch,(7)</ref> becomes not essential for classification and is marked as "irrelevant".</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figu
tations by interventions to train judge.</p><p>Our experiments demonstrate that CogLTX outperforms or achieves comparable performance with the state-of-the-art results on four tasks, including NewsQA [44]</ref>, HotpotQA [53]</ref>, 20NewsGroups [22]</ref> and Alibaba, with constant memory consumption rega n="4.1">Reading comprehension</head><p>Dataset and settings. Given a question and a paragraph, the task is to predict the answer span in the paragraph. We evaluate the performance of CogLTX on NewsQA [44]</ref>, which contains 119,633 human-generated questions posed on 12,744 long news articles. 3</ref> Since previous SOTA <ref type=
o find some texts longer than the length limit of BERT (usually 512 tokens). This situation may be rare for normalized benchmarks, for example SQuAD [38]</ref> and GLUE [47]</ref>, but very common for more complex tasks [53]</ref> or real-world textual data.</p><p>A straightforward solution for long texts
ast increase with the text length L.</p><p>Related works. As mentioned in Figure 1</ref>, the sliding window method suffers from the lack of long-distance attention. Previous works [49,</ref>33]</ref> tried to aggregate results from each window by mean-pooling, max-pooling, or an additional MLP or LSTM over them; but
es the bottleneck for BERT to show its efficacy in complex tasks (for example Figure 1</ref>). Since the problem roots in the high O(L 2 ) time and space complexity in transformers [46]</ref> (L is the length of the text), another line of research attempts to simplify the structure of transformers [20,</ref><ref type=
ered by BERT [12]</ref>, have emerged as silver bullets for many NLP tasks, such as question answering [38]</ref> and text classification [22]</ref>. Researchers and engineers breezily build state-of-the-art applications following the standard finetuning paradigm, while might end up in disappointment to fi es comparable performance with the state-of-the-art results on four tasks, including NewsQA [44]</ref>, HotpotQA [53]</ref>, 20NewsGroups [22]</ref> and Alibaba, with constant memory consumption regardless of the length of text.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</hea ead><p>Dataset and settings. As one of the most general tasks in NLP, text classification is essential to analyze the topic, sentiment, intent, etc. We conduct experiments on the classic 20NewsGroups [22]</ref>, which contains 18,846 documents from 20 classes. We finetune RoBERTa for 6 epochs in CogLTX.  [16]</ref> 79.4 MS-CNN <ref type
wsGroups [22]</ref>, which contains 18,846 documents from 20 classes. We finetune RoBERTa for 6 epochs in CogLTX.  [16]</ref> 79.4 MS-CNN [32]</ref> 86.1 Text GCN [54]</ref> 86.3 MLP over BERT [33]</ref> 85.5 LSTM over BERT <ref type="bibr" targ
situation may be rare for normalized benchmarks, for example SQuAD [38]</ref> and GLUE [47]</ref>, but very common for more complex tasks [53]</ref> or real-world textual data.</p><p>A straightforward solution for long texts is sliding window [50]</ref>, processing continuous xperiments demonstrate that CogLTX outperforms or achieves comparable performance with the state-of-the-art results on four tasks, including NewsQA [44]</ref>, HotpotQA [53]</ref>, 20NewsGroups [22]</ref> and Alibaba, with constant memory consumption regardless of the length of text.</p></div> <div xmlns=" >Supervised training for judge. The span extraction tasks (Figure 2</ref>(a)) in nature suggest the answer block as relevant. Even multi-hop datasets, e.g. HotpotQA [53]</ref>, usually annotate supporting sentences. In these cases, the judge is naturally trained in a supervised way:</p><formula xml:id="formula_3">loss judge (z) = Cr ef type="bibr" target="#b35">36]</ref>. However, if we can handle long texts with CogLTX, the problem can be elegantly solved by concatenating all the paragraphs as the input of BERTs.</p><p>HotpotQA [53]</ref> is a multi-hop QA dataset of 112,779 questions, whose distractor setting provides 2 necessary paragraphs and 8 distractor paragraphs for each question. Both a
xt), another line of research attempts to simplify the structure of transformers [20,</ref>37,</ref>8,</ref>42]</ref>, but currently few of them have been successfully applied to BERT [35,</ref>4]</ref>.</p><p>The ma
tations by interventions to train judge.</p><p>Our experiments demonstrate that CogLTX outperforms or achieves comparable performance with the state-of-the-art results on four tasks, including NewsQA [44]</ref>, HotpotQA [53]</ref>, 20NewsGroups [22]</ref> and Alibaba, with constant memory consumption rega n="4.1">Reading comprehension</head><p>Dataset and settings. Given a question and a paragraph, the task is to predict the answer span in the paragraph. We evaluate the performance of CogLTX on NewsQA [44]</ref>, which contains 119,633 human-generated questions posed on 12,744 long news articles. 3</ref> Since previous SOTA <ref type=
get="#b1">[2]</ref>, a human cognitive system storing information for logical reasoning and decision-making. Experiments [27,</ref>9,</ref>31]</ref> already showed that the working memory could only hold 5∼9 items/words during reading, so how do humans actually understand long texts?</p><p>"The central exec
h contains 18,846 documents from 20 classes. We finetune RoBERTa for 6 epochs in CogLTX.  [16]</ref> 79.4 MS-CNN [32]</ref> 86.1 Text GCN [54]</ref> 86.3 MLP over BERT [33]</ref> 85.5 LSTM over BERT [33]</ref> 84.7</p><p>CogLTX (Glove init) 87.0
t="#b5">[6]</ref> and ORQA [23]</ref>, and there are also previous works to extract important sentences in unsupervised ways, e.g. based on the metadata about structure [24]</ref>. Experiments on 4 different large datasets show its competitive performance. CogLTX is expected to become a general and strong baseline in many complex NLP ta
[7]</ref>.</p><p>MemRecall in nature enables multi-step reasoning by repeating the procedure with new z + . The importance of iterative retrieval is highlighted by CogQA [13]</ref>, as the answer sentence fails to be directly retrieved by the question in multi-hop reading comprehension. It is worth noting that blocks reserved from last s served from last step can also decay, if they are proved not relevant enough (with low scores) by more information from new blocks in z + , which is neglected by previous multi-step reasoning methods [13,</ref>1,</ref>10]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head> ering</head><p>Dataset and settings. In complex scenarios, the answer is based on multiple paragraphs. Previous methods usually leverage the graph structure between key entities across the paragraphs [13,</ref>36]</ref>. However, if we can handle long texts with CogLTX, the problem can be elegantly solved by concatenating all the paragr
t="#b5">[6]</ref> and ORQA [23]</ref>, and there are also previous works to extract important sentences in unsupervised ways, e.g. based on the metadata about structure [24]</ref>. Experiments on 4 different large datasets show its competitive performance. CogLTX is expected to become a general and strong baseline in many complex NLP ta
ast increase with the text length L.</p><p>Related works. As mentioned in Figure 1</ref>, the sliding window method suffers from the lack of long-distance attention. Previous works [49,</ref>33]</ref> tried to aggregate results from each window by mean-pooling, max-pooling, or an additional MLP or LSTM over them; but
TX only needs fixed memory during training and enables attentions between faraway sentences. Similar ideas were investigated on document-level in DrQA [6]</ref> and ORQA [23]</ref>, and there are also previous works to extract important sentences in unsupervised ways, e.g. based on the metadata about structure <ref type="bibr" target="#b


ery large batches for SGD (Goyal et al., 2017;</ref>Gotmare et al., 2019;</ref>Bernstein et al., 2018;</ref>Xiao et al., 2017)</ref>. We notice that r t has a similar form to the heuristic linear warmup, which can be viewed as setting the rectification term as min(t,Tw)</p></d
(i.e., One Billion Word (Chelba et al., 2013)</ref>) and image classification (i.e., CIFAR10 (Krizhevsky et al., 2009)</ref> and ImageNet (Deng et al., 2009)</ref>) are presented in Figure 4</ref>, 5. The results show that RAdam outperforms Adam in all three datasets. As s
<head>B.3 NEURAL MACHINE TRANSLATION</head><p>Our experiments are based on the default Transformers (Vaswani et al., 2017)</ref> implementation from the fairseq package (Ott et al., 2019)</ref>. Specifically, we use word embedding with 512 dimensions and 6-layer encoder / decoder with 4 head and 1024 hidden dimensions on the IWSLT14' da
set to 128. All models are trained on one NVIDIA Tesla V100 GPU.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 IMAGEINE CLASSIFICATION</head><p>We use the default ResNet architectures (He et al., 2016)</ref> in a public pytorch re-implementation4</ref> . Specifically, we use 20-layer ResNet (9 Basic Blocks) for CIFAR-
ns, and has a big impact on the model behavior.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Comparison.</head><p>The performances on language modeling (i.e., One Billion Word (Chelba et al., 2013)</ref>) and image classification (i.e., CIFAR10 (Krizhevsky et al., 2009)</ref> and ImageNet <ref type="bibr" target="
set to 128. All models are trained on one NVIDIA Tesla V100 GPU.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 IMAGEINE CLASSIFICATION</head><p>We use the default ResNet architectures (He et al., 2016)</ref> in a public pytorch re-implementation4</ref> . Specifically, we use 20-layer ResNet (9 Basic Blocks) for CIFAR-
s of Adam that reducing the variance of the adaptive learning rate: Adam-2k and Adam-eps. We compare them to vanilla Adam with and without warmup on the IWSLT'14 German to English translation dataset (Cettolo et al., 2014)</ref>.</p><p>In order to reduce the variance of the adaptive learning rate (ψ(.)), Adam-2k only updates ψ(.) in the first two thousand iterations,
; use word embedding with 512 dimension and 6-layer encoder / decoder with 8 heads and 2048 hidden dimensions. Label smoothed cross entropy is used as the objective function with an uncertainty = 0.1 (Szegedy et al., 2016)</ref>. We use linear learning rate decay starting from 3e −4 , and the checkpoints of the last 20 epoches are averaged before evaluation. As to th
set to 128. All models are trained on one NVIDIA Tesla V100 GPU.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 IMAGEINE CLASSIFICATION</head><p>We use the default ResNet architectures (He et al., 2016)</ref> in a public pytorch re-implementation4</ref> . Specifically, we use 20-layer ResNet (9 Basic Blocks) for CIFAR-
<head>B.3 NEURAL MACHINE TRANSLATION</head><p>Our experiments are based on the default Transformers (Vaswani et al., 2017)</ref> implementation from the fairseq package (Ott et al., 2019)</ref>. Specifically, we use word embedding with 512 dimensions and 6-layer encoder / decoder with 4 head and 1024 hidden dimensions on the IWSLT14' da
ess in many fields of science and engineering despite its simplicity. Recently, many efforts have been made to accelerate optimization by applying adaptive learning rate.</p><p>In particular, Adagrad (Duchi et al., 2010)</ref> and its variants, e.g., RMSprop (Hinton et al., 2012)</ref>, Adam (Kingma &amp;
am-eps</head><p>Adam-2k Adam-vanilla RAdam Adam-warmup Fast and stable optimization algorithms are what generations of researchers have been pursuing (Gauss, 1823;</ref>Cauchy, 1847)</ref>. Remarkably, stochastic gradient-based optimization, such as stochastic gradient descent (SGD), has witnessed tremendous success in many fields of sci
; use word embedding with 512 dimension and 6-layer encoder / decoder with 8 heads and 2048 hidden dimensions. Label smoothed cross entropy is used as the objective function with an uncertainty = 0.1 (Szegedy et al., 2016)</ref>. We use linear learning rate decay starting from 3e −4 , and the checkpoints of the last 20 epoches are averaged before evaluation. As to th
<head>B.3 NEURAL MACHINE TRANSLATION</head><p>Our experiments are based on the default Transformers (Vaswani et al., 2017)</ref> implementation from the fairseq package (Ott et al., 2019)</ref>. Specifically, we use word embedding with 512 dimensions and 6-layer encoder / decoder with 4 head and 1024 hidden dimensions on the IWSLT14' da
am-eps</head><p>Adam-2k Adam-vanilla RAdam Adam-warmup Fast and stable optimization algorithms are what generations of researchers have been pursuing (Gauss, 1823;</ref>Cauchy, 1847)</ref>. Remarkably, stochastic gradient-based optimization, such as stochastic gradient descent (SGD), has witnessed tremendous success in many fields of sci
ess in many fields of science and engineering despite its simplicity. Recently, many efforts have been made to accelerate optimization by applying adaptive learning rate.</p><p>In particular, Adagrad (Duchi et al., 2010)</ref> and its variants, e.g., RMSprop (Hinton et al., 2012)</ref>, Adam (Kingma &amp;
<head>B.3 NEURAL MACHINE TRANSLATION</head><p>Our experiments are based on the default Transformers (Vaswani et al., 2017)</ref> implementation from the fairseq package (Ott et al., 2019)</ref>. Specifically, we use word embedding with 512 dimensions and 6-layer encoder / decoder with 4 head and 1024 hidden dimensions on the IWSLT14' da
; use word embedding with 512 dimension and 6-layer encoder / decoder with 8 heads and 2048 hidden dimensions. Label smoothed cross entropy is used as the objective function with an uncertainty = 0.1 (Szegedy et al., 2016)</ref>. We use linear learning rate decay starting from 3e −4 , and the checkpoints of the last 20 epoches are averaged before evaluation. As to th
om 3 to around 10, as shown in Figure 1</ref>. Similar phenomena are observed in other scenarios like BERT (a bidirectional transformer language model) pre-training (Devlin et al., 2019)</ref>.</p><p>Duo to the lack of the theoretical underpinnings, there is neither guarantee that warmup would bring consistent improvements for variou
RIES AND MOTIVATIONS</head><p>Generic adaptive methods. Algorithm 1 is a generic framework (all operations are element-wise).</p><p>It describes various popular stochastic gradient descent algorithms (Reddi et al., 2018)</ref>. Specifically, different optimization algorithms can be specified by different choices of φ(.) and ψ(.), where φ(.) specifies how the momentum

ey have a component of similar use as the attention weights ? in our encoder, but it is treated as a free parameter.</p><p>Another way of dealing with multiple link types is well-represented by SHINE [38]</ref>, who treats the heterogeneous types of links as separated homogeneous links, and combines embeddings from all relations in the end. SHINE did not make good us 40]</ref> are way too different from our approach at a very fundamental level, thus are not considered as baselines. Some other methods such as GEM [22]</ref> and SHINE [38]</ref> should be capable of handling the dataset at this scale, but they are not releasing their code to the public, and we can not easily guarantee reproduction.</p
more relaxed than in an offline interview, and behave naturally. Social networks, in return, has shaped people's habits, giving rise to opinion leaders, encouraging youngsters' political involvement [25]</ref>.</p><p>Most existing approaches of ideology detection on social networks focus on text [5,</ref>8,
tection on social networks focus on text [5,</ref>8,</ref>[15]</ref>[16]</ref>[17]</ref>. Most of their methodologies based on probabilistic models, following the long-lasting tradition started by social scientists. Some others <ref type="bibr" ta from text data to do ideology-detection [5,</ref>8,</ref>[15]</ref>[16]</ref>[17]</ref>, only a few paid attention to links [9,</ref>13]</ref>. Our work differs from them all, since: (1) unlike prob hodologies based on probabilistic models, following the long-lasting tradition started by social scientists. Some others [2,</ref>13,</ref>17,</ref>29]</ref> noticed the advantages of neural networks, but seldom do they focus on links. We will show that the social-network link ef>, and directly collected such as from news articles [2]</ref> or from social networks [13,</ref>15,</ref>17]</ref>. Some studies take advantages from both sides, asking self-reported responses from a group of users selected from social networks <ref type="bibr" target="#b29
ehaviors of the politicians. But seldom did they study the mass population's opinions, for the survey-based study is extremely labor-intensive and hard-to-scale [1,</ref>27]</ref>. The booming development of social networks in the recent years shed light on detecting ordinary people's ideology. In social networks, people are more relaxed
ted on ordinary citizens could also be categorized into two types according to the source of data being used: intentionally collected via strategies like survey [1,</ref>20]</ref>, and directly collected such as from news articles [2]</ref> or from social networks [13,</ref><re
tection on social networks focus on text [5,</ref>8,</ref>[15]</ref>[16]</ref>[17]</ref>. Most of their methodologies based on probabilistic models, following the long-lasting tradition started by social scientists. Some others <ref type="bibr" ta from text data to do ideology-detection [5,</ref>8,</ref>[15]</ref>[16]</ref>[17]</ref>, only a few paid attention to links [9,</ref>13]</ref>. Our work differs from them all, since: (1) unlike prob hodologies based on probabilistic models, following the long-lasting tradition started by social scientists. Some others [2,</ref>13,</ref>17,</ref>29]</ref> noticed the advantages of neural networks, but seldom do they focus on links. We will show that the social-network link ef>, and directly collected such as from news articles [2]</ref> or from social networks [13,</ref>15,</ref>17]</ref>. Some studies take advantages from both sides, asking self-reported responses from a group of users selected from social networks <ref type="bibr" target="#b29
n="2.2.1">Graph Convolutional Networks (GCN).</head><p>Inspired by the great success of convolutional neural networks (CNN), researchers have been seeking for its extension onto information networks [11,</ref>19]</ref> to learn the entities' embeddings. The Graph Convolutional Networks (GCN) [19]</ref> co
ted on ordinary citizens could also be categorized into two types according to the source of data being used: intentionally collected via strategies like survey [1,</ref>20]</ref>, and directly collected such as from news articles [2]</ref> or from social networks [13,</ref><re
e link-prediction losses, calculated by binary crossentropy loss between link-labels and the predicted link scores' logits. To keep the links asymmetric, we used Neural Tensor Network (NTN) structure [33]</ref>, with simplification inspired by DistMult [41]</ref>. We set the number of slices be k = 1 for W r ? R d ?d ?k , omitting  the
ted on ordinary citizens could also be categorized into two types according to the source of data being used: intentionally collected via strategies like survey [1,</ref>20]</ref>, and directly collected such as from news articles [2]</ref> or from social networks [13,</ref><re
uch as the speaker's intention, identity, and emotion. This makes automatic speech recognition with the goal of humancomputer interaction popular, and it has been a research hotspot in recent decades [1]</ref>. Automatic Speech Recognition (ASR) refers to the task of an automatic conversion from speech to text by computer. In real life, speech recognition can provide
. . . class(k)(SOL), . . . , class(K )(SOL)]</formula><p>= [0.0015, . . . , 0.0034, 0.934, 0.0019, . . . , 0.003] (6)</p><p>Feature-space Maximum Likelihood Linear Regression (FMLLR) was explored in [32]</ref>, [33]</ref> for speaker adaptive training and it is a feature space transform where we transform acoustic features for better f
nly divided into two types, one is the Neural Network Hidden Markov Models (NN-HMMs), and the other is the End-toend models, such as Encoder-decoder structure [2]</ref>- [4]</ref> and Neural Network structure with Connectionist temporal classification (CTC) loss [5]</ref>, [6]</r

nly divided into two types, one is the Neural Network Hidden Markov Models (NN-HMMs), and the other is the End-toend models, such as Encoder-decoder structure [2]</ref>- [4]</ref> and Neural Network structure with Connectionist temporal classification (CTC) loss [5]</ref>, [6]</r
</ref> is a technique to discourage the complexity of the model. It does this by penalizing the loss function and the regularization term is the sum of the square of all feature weights like Formula. 19</ref>.</p><formula xml:id="formula_18">loss_function = loss + φ * w 2<label>(19)</label></formula><p>where φ denotes regularization parameter. This helps to prevent t
, such as Encoder-decoder structure [2]</ref>- [4]</ref> and Neural Network structure with Connectionist temporal classification (CTC) loss [5]</ref>, [6]</ref>. The hybrid hidden Markov model (HMM) -neural network (NN) approach on phoneme level always need to take time to train fusion as Formula. 5. The language model can linguistically correct the phoneme sequences generated by the acoustic model, and finally get better results. y * = arg max y log p(y|x) + λ log P LM (y) (5)</ref> where P LM (y) is provided by the LM, y * denotes the final score, λ denotes the proportion of language score in the final score, x denotes the training example

f type="bibr" target="#b8">[9]</ref>. It can make full use of the data in the non-target domain to train a better initial model. It has shown promising results in many tasks such as image recognition [10]</ref>, speech recognition [11]</ref>, etc. Unsupervised pre-training also uses additional data to train a better initial model, but un
ependencies between parameters and get a good initial marginal distribution. It has shown promising results in several areas, including Computer Vision (CV) [12]</ref>, [41]</ref>- [44]</ref>, Natural Language Processing (NLP) [13]</ref>, [14]</
n research point. Acoustic models are mainly divided into two types, one is the Neural Network Hidden Markov Models (NN-HMMs), and the other is the End-toend models, such as Encoder-decoder structure [2]</ref>- [4]</ref> and Neural Network structure with Connectionist temporal classification (CTC) loss [5]</r
nly divided into two types, one is the Neural Network Hidden Markov Models (NN-HMMs), and the other is the End-toend models, such as Encoder-decoder structure [2]</ref>- [4]</ref> and Neural Network structure with Connectionist temporal classification (CTC) loss [5]</ref>, [6]</r
ata scenarios. An average relative improvement of 4.3% was observed across the 4 tasks. As far, the method of changing speed has the lowest implementation cost and achieve stateof-the-art performance [23]</ref>. In [24]</ref>, A new method called SpecAugment is proposed and it consists of warping the features, masking blocks of frequenc
ing signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better [30]</ref>. We set up a second task to make both context-dependent (CD) and context-independent (CI) targets the learning goals of the network. Besides, we also investig e modeling units and very little training data can easily lead to overfitting of the neural network.</p><p>To solve these problems, we investigated a new network structure based on multitask learning [30]</ref>. Our proposed structure is not only trained to optimize a triphone crossentropy (CE) based loss and we give the network a second optimization task, which is t
tion (VTLP) to expand training data. When this technique is applied to TIMIT using Deep Neural Networks of different depths, the Phone Error Rate (PER) improved by an average of 0.65% on the test set [22]</ref>. Ko et al. proposed a method that changing the speed of the audio signal, producing 3 versions of the original signal with speed factors of 0.9, 1.0 and 1.1.
</ref> is a technique to discourage the complexity of the model. It does this by penalizing the loss function and the regularization term is the sum of the square of all feature weights like Formula. 19</ref>.</p><formula xml:id="formula_18">loss_function = loss + φ * w 2<label>(19)</label></formula><p>where φ denotes regularization parameter. This helps to prevent t
ctory in a low-resource environment. Therefore, improving the ASR under the condition of low resource has become a research hotspot because the acquisition of labeled speech data is usually difficult [8]</ref>. A common problem in lowresource environments is that the lack of training data often leads to overfitting of the neural network, which makes the model's perfor
STATE-OF-ART</head><p>Since our proposal (MAT + SOL) resembles a regularization method, our experiment compares the results with L2 regularization, which is the-state-of-art method. L2 regularization [35]</ref> is a technique to discourage the complexity of the model. It does this by penalizing the loss function and the regularization term is the sum of the square of
ps networks to and capture more intricate dependencies between parameters and get a good initial marginal distribution. It has shown promising results in several areas, including Computer Vision (CV) [12]</ref>, [41]</ref>- [44]</ref>, Natural Language Processing (NLP) [13]</

ctory in a low-resource environment. Therefore, improving the ASR under the condition of low resource has become a research hotspot because the acquisition of labeled speech data is usually difficult [8]</ref>. A common problem in lowresource environments is that the lack of training data often leads to overfitting of the neural network, which makes the model's perfor
)]</formula><p>= [0.0015, . . . , 0.0034, 0.934, 0.0019, . . . , 0.003] (6)</p><p>Feature-space Maximum Likelihood Linear Regression (FMLLR) was explored in [32]</ref>, [33]</ref> for speaker adaptive training and it is a feature space transform where we transform acoustic features for better fit to a speaker-independent (SI) model. We re details of the them will be shown.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENT A. BASELINE NN-HMM SYSTEM</head><p>All experiments are conducted on Pytorch-Kaldi platform [33]</ref>. We use a single Nvidia TITAN Xp GPU to do single running. Most of the acoustic models are trained with 40-dimensional high resolution MFCC, 40-dimensional Fb 0.9. it turn out to be baselines when the weight is 0.0.</p><p>sequence-discriminative training and the objective function we used in the training is LF-MMI (Lattice-Free Maximum Mutual Information) [33]</ref>, [34]</ref>, which aims to maximize the probability of the target sequence, while minimizing the probability of all other seque
state-of-theart results (Hadsell et al., 2006;</ref>Dosovitskiy et al., 2014;</ref>Oord et al., 2018;</ref>Bachman et al., 2019)</ref>.</p><p>In this work, we introduce a simple framework for contrastive learning of visual representations, which we call SimCLR. Not only does S has been widely used in both supervised and unsupervised representation learning (Krizhevsky et al., 2012;</ref>Hénaff et al., 2019;</ref>Bachman et al., 2019)</ref>, it has not been considered as a systematic way to define the contrastive prediction task. Many existing approaches define contrastive predict between latent representations (Oord et al., 2018;</ref>Hénaff et al., 2019;</ref>Hjelm et al., 2018;</ref>Bachman et al., 2019)</ref>. However, it is not clear if the success of contrastive approaches is determined by the mutual information, or by the specific form of the con p>Here we provide an in-depth comparison of our method to the recently proposed contrastive representation learning methods:</p><p>• DIM/AMDIM (Hjelm et al., 2018;</ref>Bachman et al., 2019)</ref> achieve global-to-local/local-to-neighbor prediction by predicting the middle layer of ConvNet. The ConvNet is a ResNet that has bewen modifie entations, which we call SimCLR. Not only does SimCLR outperform previous work (Figure 1</ref>), but it is also simpler, requiring neither specialized architectures (Bachman et al., 2019;</ref>Hénaff et al., 2019)</ref> nor a memory bank (Wu et al., 2018;</ref><ref type="b luate the learned representations, we follow the widely used linear evaluation protocol (Zhang et al., 2016;</ref>Oord et al., 2018;</ref>Bachman et al., 2019;</ref>Kolesnikov et al., 2019)</ref>, where a linear classifier is trained on top of the frozen base network, and test ata augmentation than supervised learning. Although previous work has reported that data augmentation is useful for self-supervised learning (Doersch et al., 2015;</ref>Bachman et al., 2019;</ref>Hénaff et al., 2019;</ref>Asano et al., 2019)</ref>, we show that data augmentatio used by several previous approaches (Wu et al., 2018)</ref>; and (3) the default nonlinear projection with one additional hidden layer (and ReLU activation), similar to Bachman et al. (2019)</ref>. We observe that a nonlinear projection is better than a linear projection (+3%), and much better than no projection (&gt;10%). When a project accuracy of 94.0%, compared to 95.1% from the supervised baseline using the same architecture and batch size. The best self-supervised model that reports linear evaluation result on CIFAR-10 is AMDIM (Bachman et al., 2019)</ref>, which achieves 91.2% with a model 25× larger than ours. We note that our model can be improved by incorporating extra data augmentations as
splits; we report results only for the first split. Caltech-101 defines no train/test split, so we randomly chose 30 images per class and test on the remainder, for fair comparison with previous work (Donahue et al., 2014;</ref>Simonyan &amp; Zisserman, 2014)</ref>.</p><p>We used the validation sets specified by the dataset creators to
d limit the generality of the learned representations. Discriminative approaches based on contrastive learning in the latent space have recently shown great promise, achieving state-of-theart results (Hadsell et al., 2006;</ref>Dosovitskiy et al., 2014;</ref>Oord et al., 2018;</ref><ref type="bibr" target= v et al., 2019)</ref>, these pretext tasks rely on somewhat ad-hoc heuristics, which limits the generality of learned representations.</p><p>Contrastive visual representation learning. Dating back to Hadsell et al. (2006)</ref>, these approaches learn representations by contrasting positive pairs against negative pairs. Along these lines, <ref type="bibr" target="#b1
type of augmentation involves appearance transformation, such as color distortion (including color dropping, brightness, contrast, saturation, hue) (Howard, 2013;</ref>Szegedy et al., 2015)</ref>, Gaussian blur, and Sobel filtering. Figure 4</ref> visualizes the augmentations that we study in this wor n applying   augmentations individually or in pairs. Since ImageNet images are of different sizes, we always apply crop and resize images (Krizhevsky et al., 2012;</ref>Szegedy et al., 2015)</ref>, which makes it difficult to study other augmentations in the absence of cropping. To eliminate this confound, we consider an asymmetric data ls of these three augmentations are provided below.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Random crop and resize to 224x224</head><p>We use standard Inception-style random cropping (Szegedy et al., 2015)</ref>. The crop of random size (uniform from 0.08 to 1.0 in area) of the original size and a random aspect ratio (default: of 3/4 to 4/3) of the o

ternatives</p><p>We compare the NT-Xent loss against other commonly used contrastive loss functions, such as logistic loss (Mikolov et al., 2013)</ref>, and margin loss (Schroff et al., 2015)</ref>. Table 2</ref> shows the objective function as well as the gradient to the input of the loss function. Loo he model learn from hard negatives; and 2) unlike cross-entropy, other objective functions do not weigh the negatives by their relative hardness. As a result, one must apply semi-hard negative mining (Schroff et al., 2015)</ref> for these loss functions: instead of computing the gradient over all loss terms, one can compute the gradient using semi-hard negative terms
d limit the generality of the learned representations. Discriminative approaches based on contrastive learning in the latent space have recently shown great promise, achieving state-of-theart results (Hadsell et al., 2006;</ref>Dosovitskiy et al., 2014;</ref>Oord et al., 2018;</ref><ref type="bibr" target= v et al., 2019)</ref>, these pretext tasks rely on somewhat ad-hoc heuristics, which limits the generality of learned representations.</p><p>Contrastive visual representation learning. Dating back to Hadsell et al. (2006)</ref>, these approaches learn representations by contrasting positive pairs against negative pairs. Along these lines, <ref type="bibr" target="#b1
as shown in Table 1</ref>. Stronger color augmentation substantially improves the linear evaluation of the learned unsupervised models. In this context, AutoAugment (Cubuk et al., 2019)</ref>, a sophisticated augmentation policy found using supervised learning, does not work better than simple cropping + (stronger) color distortion.
ref type="bibr" target="#b36">(Maji et al., 2013)</ref>, the PASCAL VOC 2007 classification task (Everingham et al., 2010)</ref>, the Describable Textures Dataset (DTD) (Cimpoi et al., 2014)</ref>, Oxford-IIIT Pets (Parkhi et al., 2012)</ref>, Caltech-101 (Fei-Fei et al., 2004)</ref>, and O
., 2014)</ref>, CIFAR-10 and CIFAR-100 (Krizhevsky &amp; Hinton, 2009)</ref>, Birdsnap (Berg et al., 2014)</ref>, the SUN397 scene dataset (Xiao et al., 2010)</ref>, Stanford Cars (Krause et al., 2013)</ref>, FGVC Aircraft (Maji et al., 2013)</re
res the use of in-batch samples for negative sampling instead of a memory bank (Doersch &amp; Zisserman, 2017;</ref>Ye et al., 2019;</ref>Ji et al., 2019)</ref>.</p><p>Recent literature has attempted to relate the success of their methods to maximization of mutual information between latent representations



es" from different nodes. Therefore, after such aggregation, we cannot know which node contributes what to the final aggregated output.</p><p>Without modeling such structural information, as shown in (Kondor et al., 2018)</ref> and (Xu et al., 2019)</ref>, the existing MPNNs cannot discriminate between certain non-isomorphic graphs. In ., 2018)</ref> and GG-NN (Li et al., 2016</ref>) learn weights on "messages" from different neighbors by using attention mechanisms and node and/or edge attributes. CCN (Kondor et al., 2018)</ref> utilizes a covariance architecture to learn structure-aware representations. The major difference between these works and ours is that we off cies by skipping connections during feature aggregations.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">CASE STUDY ON DISTINGUISHING NON-ISOMORPHIC GRAPHS</head><p>In literature, Kondor et al. (2018)</ref> and Xu et al. (2019)</ref> construct several non-isomorphic example graphs that cannot be distinguished by the

n a hierarchical graph. One can design a more sophisticated operator τ , such as borrowing the structure of descriptors in manifold geometry (Kokkinos et al., 2012;</ref>Monti et al., 2017)</ref>, thereby preserving more and richer structural information in neighborhood. </p><formula xml:id="formula_7">τ (z v , z u ) z v [0] &gt; z u [0]
ous space (Bronstein et al., 2017)</ref>; ii) The notion of network geometry bridges the gap between continuous space and graph (Hoff et al., 2002;</ref>Muscoloni et al., 2017)</ref>. Network geometry aims to understand networks by revealing the latent continuous space underlying them, which assumes that nodes are sample
ork, we will explore techniques for choosing a right embedding method-depending not only on input graphs but also on target applications, such as epidemic dynamic prediction on social contact network (Yang et al., 2017;</ref>Pei et al., 2018)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</he
e="bibr" target="#b2">(Chen et al., 2019)</ref>) where node homophily holds (i.e., similar nodes are more likely to be proximal, and vice versa), but may be inappropriate to the disassortative graphs (Newman, 2002)</ref> where node homophily does not hold. For example, Ribeiro et al. (2017)</ref> shows disassortative graphs where nodes
Table 2</ref>. Citation networks. Cora, Citeseer, and Pubmed are standard citation network benchmark datasets (Sen et al., 2008;</ref>Namata et al., 2012)</ref>. In these networks, nodes represent papers, and edges denote citations of one paper by another. Node features are the bag-of-words representat
more likely to be proximal, and vice versa), but may be inappropriate to the disassortative graphs (Newman, 2002)</ref> where node homophily does not hold. For example, Ribeiro et al. (2017)</ref> shows disassortative graphs where nodes of the same class exhibit high structural similarity but are far apart from each other. In such cases employ three embedding methods, Isomap (Tenenbaum et al., 2000)</ref>, Poincare embedding (Nickel &amp; Kiela, 2017)</ref>, and struc2vec (Ribeiro et al., 2017)</ref>, which result in three Geom-GCN variants: Geom-GCN-I, Geom-GCN-P, and Geom-GCN-S. Isomap is a widely used isometry embedding method, by whic
node-wise sampling methods (Hamilton et al., 2017)</ref>, the layer-wise approach (Chen et al., 2018)</ref> and its layer-dependent variant (Huang et al., 2018)</ref>. Specifically, GAT (Velickovic et al., 2018)</ref> has discussed applying dropout on edge attentions. While it o the kind of node sampling based methods, including GraphSAGE (Hamilton et al., 2017)</ref>, FastGCN (Chen et al., 2018)</ref>, and AS-GCN (Huang et al., 2018)</ref>. We name this category of approaches as DropNode. For its original motivation, DropNode samples sub-graphs for mini-batch training, and it can st them with existing State of the Arts (SOTA), including GCN, FastGCN, AS-GCN and GraphSAGE in Table 2</ref>; for the SOTA methods, we reuse the results reported in Huang et al. (2018)</ref>.</p><p>We have these findings: (1) Clearly, our DropEdge obtains significant enhancement against SOTAs; particularly on Reddit, the best accura erlying all node features are accessible during training, while the task in Reddit is inductive meaning the testing nodes are unseen for training. We apply the full-supervised training fashion used inHuang et al. (2018)</ref> andChen et al. (2018)</ref> on all datasets in our experiments. The statics of all datasets are listed in the sup
&amp; Welling (2017); Defferrard et al. (2016)</ref>; Henaff et al. (2015)</ref>; Li et al. (2018b)</ref>; Levie et al. (2017)</ref> apply improvements, extensions, and approximations on spectralbased GCNs. To address the scalability issue of spectral-based GCNs on large grap
prominent research on GCNs is presented in Bruna et al. (2013)</ref>, which develops graph convolution based on spectral graph theory. Later, Kipf &amp; Welling (2017); Defferrard et al. (2016)</ref>; Henaff et al. (2015)</ref>; Li et al. (2018b)</ref>; <ref type="bibr" target
of deep CNNs on image classification, several attempts have been proposed to explore how to build deep GCNs towards node classification (Kipf &amp; Welling, 2017;</ref>Li et al., 2018a;</ref>Xu et al., 2018a;</ref>Li et al., 2019)</ref>; nevertheless, none of them delivers s a deep GCN on small graphs (see 4-layer GCN on Cora in Figure 1</ref>). Over-smoothing, towards the other extreme, makes training a very deep GCN difficult. As first introduced by Li et al. (2018a)</ref> and further explained in Wu et al. (2019)</ref>; Xu et al. (2018a)</ref>; <ref type Kipf &amp; Welling, 2017)</ref>, where the residual mechanism is applied; unexpectedly, as shown in their experiments, residual GCNs still perform worse when the depth is 3 and beyond. The authors in Li et al. (2018a)</ref> first point out the main difficulty in constructing deep networks lying in over-smoothing, but unfortunately, they never propose any method to ad pe="bibr" target="#b24">Oono &amp; Suzuki (2019)</ref> theoretically prove that the node features of deep GCNs will converge to a subspace and incur information loss. It generalizes the conclusion in Li et al. (2018a)</ref> by further considering the ReLu function and convolution filters. Our interpretations on why DropEdge can impede over-smoothing is based on the c the discussion on layer-wise DropEdge for future exploration.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">TOWARDS PREVENTING OVER-SMOOTHING</head><p>By its original definition in Li et al. (2018a)</ref>, the over-smoothing phenomenon implies that the node features will converge to a fixed point as the network depth increases. This unwanted conver ent to the input node features, which as a matter of course incurs detriment of the expressive power of GCNs. Oono &amp; Suzuki (2019)</ref> has generalized the idea in Li et al. (2018a)</ref> by taking both the non-linearity (i.e. the ReLu function) and the convolution filters into account; they explain over-smoothing as convergence to
ice, we focus on four benchmark datasets varying in graph size and feature type:   Figure 2</ref> Implementations We consider five backbones: GCN (Kipf &amp; Welling, 2017), ResGCN (He et al., 2016;</ref>Li et al., 2019)</ref>, JKNet (Xu et al., 2018a)</ref>, IncepGCN<ref type="foot" targ bones Other than the multi-layer GCN, we replace the CNN layer with graph convolution layer to implement three popular backbones recasted from image classification. They are residual network (ResGCN) (He et al., 2016;</ref>Li et al., 2019)</ref>, inception network (IncepGCN) (Szegedy et al., 2016)</ref> and
huge success of CNNs in computer vision, a large number of methods come redefining the notion of convolution on graphs under the umbrella of GCNs. The first prominent research on GCNs is presented in Bruna et al. (2013)</ref>, which develops graph convolution based on spectral graph theory. Later, Kipf &amp; Welling (2017); Defferrard et
huge success of CNNs in computer vision, a large number of methods come redefining the notion of convolution on graphs under the umbrella of GCNs. The first prominent research on GCNs is presented in Bruna et al. (2013)</ref>, which develops graph convolution based on spectral graph theory. Later, Kipf &amp; Welling (2017); Defferrard et
of deep CNNs on image classification, several attempts have been proposed to explore how to build deep GCNs towards node classification (Kipf &amp; Welling, 2017;</ref>Li et al., 2018a;</ref>Xu et al., 2018a;</ref>Li et al., 2019)</ref>; nevertheless, none of them delivers s a deep GCN on small graphs (see 4-layer GCN on Cora in Figure 1</ref>). Over-smoothing, towards the other extreme, makes training a very deep GCN difficult. As first introduced by Li et al. (2018a)</ref> and further explained in Wu et al. (2019)</ref>; Xu et al. (2018a)</ref>; <ref type Kipf &amp; Welling, 2017)</ref>, where the residual mechanism is applied; unexpectedly, as shown in their experiments, residual GCNs still perform worse when the depth is 3 and beyond. The authors in Li et al. (2018a)</ref> first point out the main difficulty in constructing deep networks lying in over-smoothing, but unfortunately, they never propose any method to ad pe="bibr" target="#b24">Oono &amp; Suzuki (2019)</ref> theoretically prove that the node features of deep GCNs will converge to a subspace and incur information loss. It generalizes the conclusion in Li et al. (2018a)</ref> by further considering the ReLu function and convolution filters. Our interpretations on why DropEdge can impede over-smoothing is based on the c the discussion on layer-wise DropEdge for future exploration.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">TOWARDS PREVENTING OVER-SMOOTHING</head><p>By its original definition in Li et al. (2018a)</ref>, the over-smoothing phenomenon implies that the node features will converge to a fixed point as the network depth increases. This unwanted conver ent to the input node features, which as a matter of course incurs detriment of the expressive power of GCNs. Oono &amp; Suzuki (2019)</ref> has generalized the idea in Li et al. (2018a)</ref> by taking both the non-linearity (i.e. the ReLu function) and the convolution filters into account; they explain over-smoothing as convergence to
convolution based on spectral graph theory. Later, Kipf &amp; Welling (2017); Defferrard et al. (2016)</ref>; Henaff et al. (2015)</ref>; Li et al. (2018b)</ref>; Levie et al. (2017)</ref> apply improvements, extensions, and approximations on spectralbased GCNs. To address th
="#b9">(He et al., 2016;</ref>Li et al., 2019)</ref>, inception network (IncepGCN) (Szegedy et al., 2016)</ref> and dense network (JKNet) (Huang et al., 2017;</ref>Xu et al., 2018b)</ref>. Figure 5</ref> shows the detailed architectures of f
hborhood aggregation function to extract high-level features from a node as well as its neighborhoods, have boosted the state-of-the-arts for a variety of tasks on graphs, such as node classification (Bhagat et al., 2011;</ref>Zhang et al., 2018)</ref>, social recommendation (Freeman, 2000;</ref><ref type="b
evertheless, it is shown that success of these models cannot only be attributed to the properties of MI alone, and the choice of encoder and MI estimators have a significant impact on the performance (Tschannen et al., 2020)</ref>.</p><p>Figure 1</ref>. The proposed model for contrastive multi-view representation learning on both node and graph lev

s require specialized encoders to learn graph or node level representations.</p><p>Recent advances in multi-view visual representation learning (Tian et al., 2019;</ref>Bachman et al., 2019;</ref>Chen et al., 2020)</ref>, in which composition of data augmentations is used to generate multiple views of a same a single summary feature, i.e., global feature, with all local features. Contrastive multiview coding (CMC) (Tian et al., 2019)</ref>, augmented multi-scale DIM (AMDIM) (Bachman et al., 2019)</ref>, and SimCLR (Chen et al., 2020)</ref> extend the InfoMax principle to multiple views and maximize the MI across r graphs, contrasting node and graph encodings achieves better performance for both node and graph classification tasks, and (2) contrasting multi-scale encodings helps visual representation learning (Bachman et al., 2019)</ref> but has a negative effect on graph representation learning.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3.">EFFECT OF VIE visual representation learning suggest that contrasting congruent and incongruent views of images allows encoders to learn rich representations (Tian et al., 2019;</ref>Bachman et al., 2019)</ref>. Unlike images in which views are generated by standard augmentations, e.g., cropping, rotating, distorting colors, etc., defining views on gr

raphgraph or multi-scale encodings, (3) a simple graph readout layer achieves better performance on both tasks compared to hierarchical graph pooling methods such as differentiable pooling (DiffPool) (Ying et al., 2018)</ref>, and (4) applying regularization (except early-stopping) or normalization layers has a negative effect on the performance.</p><p>Using these fi the network parameters, and σ is a PReLU non-linearity. In section 4.4, we show that this pooling function achieves better results compared to more complicated graph pooling methods such as DiffPool (Ying et al., 2018)</ref>. Applying the readout function to node representations results in two graph representations, each associated with one of the views. The represe
d to data with arbitrary topology such as point clouds (Hassani &amp; Haley, 2019)</ref>, meshes (Wang et al., 2018)</ref>, robot designs (Wang et al., 2019)</ref>, physical processes (Sanchez-Gonzalez et al., 2018)</ref>, social net-Proceedings of the 37 th International Con
similarity measures between substructures. Graph autoencoders (GAE) (Kipf &amp; Welling, 2016;</ref>Garcia Duran &amp; Niepert, 2017;</ref>Wang et al., 2017;</ref>Pan et al., 2018;</ref>Park et al., 2019)</ref> train encoders that impose the topo models reported in (Park et al., 2019)</ref> including: variational GAE (VGAE) (Kipf &amp; Welling, 2016)</ref>, marginalized GAE (MGAE) (Wang et al., 2017)</ref>, adversarially regularized GAE (ARGA) and VGAE (ARVGA) (Pan et al., 2018)</ref>, and GALA <ref type="bibr" targe
(Veličković et al., 2019;</ref>Ribeiro et al., 2017)</ref>. Also, they are limited to transductive settings and cannot use node features (You et al., 2019)</ref>. Graph kernels (Borgwardt &amp; Kriegel, 2005;</ref>Shervashidze et al., 2009;</ref
xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Unsupervised Representation Learning on Graphs</head><p>Random walks (Perozzi et al., 2014;</ref>Tang et al., 2015;</ref>Grover &amp; Leskovec, 2016;</ref><ref type="bibr" targ /1.0"><head n="4.3.">Comparison with State-of-the-Art</head><p>To evaluate node classification under the linear evaluation protocol, we compare our results with unsupervised models including DeepWalk (Perozzi et al., 2014)</ref> and DGI. We also train a GAE (Kipf &amp; Welling, 2016)</ref>, a variant of DGI with a GDC encoder, and a var
t="#b54">Veličković et al., 2018;</ref>2019;</ref>Sun et al., 2020)</ref>. For node classification, we use Citeseer, Cora, and Pubmed citation networks (Sen et al., 2008)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation Protocol</head><p>For both node and graph classification benchmar
ication algorithm (ICA) (Lu &amp; Getoor, 2003)</ref>, label propagation (LP) (Zhu et al., 2003)</ref>, manifold regularization (ManiReg) (Belkin et al., 2006)</ref>, semi-supervised embedding (SemiEmb) (Weston et al., 2012)</ref>, Planetoid (Yan
em at a time, RRD formulates this as a ranking matching problem between the recommendation list of the teacher and that of the student. To this end, RRD adopts the list-wise learning-to-rank approach [29]</ref> and learns to ensure the student to preserve the ranking orders predicted by the teacher. However, directly applying the list-wise approach can have adverse e ulates this as a ranking matching problem between the recommendation list of the teacher model and that of the student model. To this end, RRD adopts the classical list-wise learning-to-rank approach [29]</ref>. Its core idea is to define a probability of a permutation (i.e., a ranking order) based on the ranking score predicted by a model, and train the model to max rder) based on the ranking score predicted by a model, and train the model to maximize the likelihood of the ground-truth ranking order. For more details about the list-wise approach, please refer to [29]</ref>.</p><p>However, merely adopting the list-wise loss can have adverse effects on the ranking performance. Because a user is interested in only a few items among ly sampled interesting items.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.2</head><p>Relaxed permutation probability. Then, RRD defines a relaxed permutation probability motivated by [29]</ref>. For user 𝑢, 𝝅 𝒖 denotes a ranked list of all the sampled items (𝐾 + 𝐿) sorted by the original order in the teacher's recommendation list. r 𝑢 denotes ranking
ever, a growing scale of users (and items) and sophisticated model architecture to capture complex patterns make the size of the model continuously increasing [13,</ref>25,</ref>28,</ref>30]</ref>. A large model with numerous parameters has a high capacity, and thus usually h ize of the recommender model is continuously increasing, and the computational time and memory cost required for the inference are also increasing accordingly [13,</ref>25,</ref>28,</ref>30]</ref>. Due to the high latency, it becomes difficult to apply such large recommender ply such large model to real-time platform.</p><p>Motivated by the significant success of knowledge distillation (KD) in the computer vision field, a few work [13,</ref>25]</ref> have employed KD for RS to reduce the size of models while maintaining the performance. KD is a model-agnostic strategy to accelerate the learning of a new com ailable binary labels. The student model trained with KD has comparable performance to that of the teacher, and also has a lower latency due to its small size [13,</ref>25]</ref>.</p><p>The core idea behind this process is that the soft labels predicted by the teacher model reveal hidden relations among entities (i.e., users and items) items only labeled as '0' [13]</ref>. By using the additional supervisions from the teacher model, the state-of-the-art methods [13,</ref>25]</ref> have achieved comparable or even better performance to the teacher models with faster inference time.</p><p>However, there are still limitations in existing me chieved comparable or even better performance to the teacher models with faster inference time.</p><p>However, there are still limitations in existing methods [13,</ref>25]</ref>. First, the learning of the student is only guided by the teacher's prediction results, which is not sufficient to fully take advantage of the knowledge stored wledge in the teacher, which is used to make such predictions, contains more detailed information that Figure 1</ref>: The existing methods [13,</ref>25]</ref> distill the knowledge only based on the teacher's predictions (b). The proposed framework directly distills the latent knowledge stored in the teacher (a) alon ew method-RRD-that transfers the knowledge from the teacher's predictions with direct consideration of ranking orders among items. Unlike the existing methods [13,</ref>25]</ref> that distill the knowledge of an item at a time, RRD formulates this as a ranking matching problem between the recommendation list of the teacher and that of t ng the uninteresting items that the user would not be interested in. RRD achieves superior recommendation performance compared to the state-of-the-art methods [13,</ref>25]</ref>. An unified framework. We propose a novel framework-DE-RRD-which enables the student model to learn both from the teacher's predictions and from the latent kno r" target="#b4">[5]</ref>. Knowledge Distillation in Recommender System. Recently, inspired by the huge success of KD in the computer vision field, a few work [13,</ref>25]</ref> have adopted KD to RS. A pioneer work is Ranking Distillation (RD) [25]</ref> which applies KD for the ranking problem; Providin reas the uninteresting items should be sampled from the wide range of the rest. To sample the interesting items, we adopt a ranking position importance scheme [20,</ref>25]</ref> that places more emphasis on the higher positions in the ranking list. In the scheme, the probability of the 𝑘-th ranked item to be sampled is defined as: 𝑝 𝑘 the number of parameters based on the size of the last hidden layer. The limiting ratios (𝜙) are {0.1, 0.5, 1.0}. Following the notation of the previous work [13,</ref>25]</ref>, we call the student model trained without the help of the teacher model (i.e., no distillation) as "Student" in this experiment sections.</p><p>Comparison Met improve the learning of the student model. Specifically, the items ranked near the top of a user's recommendation list would have strong correlations to the items that the user has interacted before [25]</ref>. Also, the soft labels provide guidance for distinguishing the items that each user would like and the items that each user would not be interested in among n ess of KD in the computer vision field, a few work [13,</ref>25]</ref> have adopted KD to RS. A pioneer work is Ranking Distillation (RD) [25]</ref> which applies KD for the ranking problem; Providing recommendations of top-𝑁 unobserved items that have not interacted with a user. RD jointly optimizes a bas ist are matter. Also, such high-ranked items reveal hidden patterns among entities (i.e., users and items); the high-ranked items in the recommendation list would have strong correlations to the user [25]</ref>. By using such additional supervisions from the teacher, they have achieved the comparable performance to the teacher with faster inference time.</p><p>Howeve cher model (i.e., no distillation) as "Student" in this experiment sections.</p><p>Comparison Methods. The proposed framework is compared with the following methods:</p><p>• Ranking Distillation (RD) [25]</ref>: A KD method for recommender system that uses items with the highest ranking from the teacher's predictions for distilling the knowledge. • Collaborative Dist
to capture complex patterns make the size of the model continuously increasing [13,</ref>25,</ref>28,</ref>30]</ref>. A large model with numerous parameters has a high capacity, and thus usually has better recommendation performance. On the other hand, it requires a large com ime and memory cost required for the inference are also increasing accordingly [13,</ref>25,</ref>28,</ref>30]</ref>. Due to the high latency, it becomes difficult to apply such large recommender to the real-time large-scale platform. In this section, we review several approa ency. Several methods have adopted hash techniques to reduce the inference cost [10,</ref>15,</ref>16,</ref>30]</ref>. They first learn binary representations of users and items, then construct the hash table. Although exploiting the binary representation can significantly red
several approaches to alleviate this problem. Balancing Effectiveness and Efficiency. Several methods have adopted hash techniques to reduce the inference cost [10,</ref>15,</ref>16,</ref>30]</ref>. They first learn binary representations of users and items, then construct the
he teacher. However, directly applying the list-wise approach can have adverse effects on the recommendation performance. Since a user is interested in only a few items among the numerous total items [10]</ref>, learning the detailed ranking orders of all items is not only daunting but also ineffective. To tackle this challenge, RRD reformulates the daunting task to a b28">[29]</ref>.</p><p>However, merely adopting the list-wise loss can have adverse effects on the ranking performance. Because a user is interested in only a few items among the numerous total items [10]</ref>, learning the detailed ranking orders of all the unobserved items is not only daunting but also ineffective. The recommendation list from the teacher model con le platform. In this section, we review several approaches to alleviate this problem. Balancing Effectiveness and Efficiency. Several methods have adopted hash techniques to reduce the inference cost [10,</ref>15,</ref>16,</ref>30]</ref>. They first learn binary representation ndation task based on implicit feedback, we evaluate the performance of each method with widely used three ranking metrics [6,</ref>9,</ref>10]</ref>: hit ratio (H@𝑁 ), normalized discounted cumulative gain (N@𝑁 ), and mean reciprocal rank (M@𝑁 ). H@𝑁 measures whether the test item is present in the top-𝑁 lis
imited compared to models that use real-values representations. In addition, several work has focused on accelerating the inference of the existing recommenders [1,</ref>14,</ref>26]</ref>. Specifically, tree-based data structures [2]</ref>, data compression techniques <ref typ
to capture complex patterns make the size of the model continuously increasing [13,</ref>25,</ref>28,</ref>30]</ref>. A large model with numerous parameters has a high capacity, and thus usually has better recommendation performance. On the other hand, it requires a large com ime and memory cost required for the inference are also increasing accordingly [13,</ref>25,</ref>28,</ref>30]</ref>. Due to the high latency, it becomes difficult to apply such large recommender to the real-time large-scale platform. In this section, we review several approa ency. Several methods have adopted hash techniques to reduce the inference cost [10,</ref>15,</ref>16,</ref>30]</ref>. They first learn binary representations of users and items, then construct the hash table. Although exploiting the binary representation can significantly red
s) and sophisticated model architecture to capture complex patterns make the size of the model continuously increasing [13,</ref>25,</ref>28,</ref>30]</ref>. A large model with numerous parameters has a high capacity, and thus usually has better recommendation performance. On usly increasing, and the computational time and memory cost required for the inference are also increasing accordingly [13,</ref>25,</ref>28,</ref>30]</ref>. Due to the high latency, it becomes difficult to apply such large recommender to the real-time large-scale platform. I
he teacher. However, directly applying the list-wise approach can have adverse effects on the recommendation performance. Since a user is interested in only a few items among the numerous total items [10]</ref>, learning the detailed ranking orders of all items is not only daunting but also ineffective. To tackle this challenge, RRD reformulates the daunting task to a b28">[29]</ref>.</p><p>However, merely adopting the list-wise loss can have adverse effects on the ranking performance. Because a user is interested in only a few items among the numerous total items [10]</ref>, learning the detailed ranking orders of all the unobserved items is not only daunting but also ineffective. The recommendation list from the teacher model con le platform. In this section, we review several approaches to alleviate this problem. Balancing Effectiveness and Efficiency. Several methods have adopted hash techniques to reduce the inference cost [10,</ref>15,</ref>16,</ref>30]</ref>. They first learn binary representation ndation task based on implicit feedback, we evaluate the performance of each method with widely used three ranking metrics [6,</ref>9,</ref>10]</ref>: hit ratio (H@𝑁 ), normalized discounted cumulative gain (N@𝑁 ), and mean reciprocal rank (M@𝑁 ). H@𝑁 measures whether the test item is present in the top-𝑁 lis
imited compared to models that use real-values representations. In addition, several work has focused on accelerating the inference of the existing recommenders [1,</ref>14,</ref>26]</ref>. Specifically, tree-based data structures [2]</ref>, data compression techniques <ref typ
arrow range near the top of the list, whereas the uninteresting items should be sampled from the wide range of the rest. To sample the interesting items, we adopt a ranking position importance scheme [20,</ref>25]</ref> that places more emphasis on the higher positions in the ranking list. In the scheme, the probability of the 𝑘-th rank
nference of the existing recommenders [1,</ref>14,</ref>26]</ref>. Specifically, tree-based data structures [2]</ref>, data compression techniques [26]</ref>, and approximated nearest neighbor search techniques [4,</r
relaxed ranking orders among items.</p><p>Evaluation Protocol. We follow the widely used leave-one-out evaluation protocol [6,</ref>9,</ref>19]</ref>. For each user, we leave out a single interacted item for testing, and use the rest for training. In our experiments, we leave out an additional interacted ite
parameters of the student model, 𝜆 is a hyperparameter that controls the effects of RD. The base recommender can be any existing RS model such as BPR [21]</ref>, NeuMF [6]</ref>, and L 𝐵𝑎𝑠𝑒 is its loss function (e.g., binary cross-entropy). The distillation loss of RD for user 𝑢 is defined as follows:</p><formula xml:id="formula_1">L 𝑅𝐷 (∈ R 𝑑 𝑠 ). The output of the mapping function can be a separate representation of a user, an item (e.g., BPR [21]</ref>) or their combined representation (e.g., NeuMF [6]</ref>) based on the base model's structure and the type of selected layer. Here, we use user 𝑢 as an example for convenience. An expert 𝐸 is trained to reconstruct ℎ used in the inference phase.</p><p>The loss function of DE can be flexibly defined based on the base model's structure and the types of hidden layer chosen for the distillation. Concretely, for NeuMF [6]</ref>, which is a state-ofthe-art deep recommender, the loss function can be defined to 1) separately distill knowledge of users and items in a mini-batch (i.e., 𝑢 ∈𝐵 nk model for implicit feedback. It assumes that observed items are more preferred than unobserved items and optimizes Matrix Factorization (MF) with the pair-wise ranking loss function.</p><p>• NeuMF [6]</ref>: The state-of-the-art deep model for implicit feedback. NeuMF combines MF and Multi-Layer Perceptron (MLP) to learn the user-item interaction, and optimizes it "bibr" target="#b26">[27]</ref>, Foursquare [17]</ref>. We remove users and items having fewer than five ratings for CiteULike, twenty ratings for Foursquare as done in [6,</ref>9,</ref>21]</ref>. Data statistics are summarized in Table 1</ref> the knowledge revealed from the teacher's predictions with consideration of relaxed ranking orders among items.</p><p>Evaluation Protocol. We follow the widely used leave-one-out evaluation protocol [6,</ref>9,</ref>19]</ref>. For each user, we leave out a single interacted item for testing, and use the res times and report the average results.</p><p>As we focus on the top-𝑁 recommendation task based on implicit feedback, we evaluate the performance of each method with widely used three ranking metrics [6,</ref>9,</ref>10]</ref>: hit ratio (H@𝑁 ), normalized discounted cumulative gain (N@𝑁 ), and mean reciproca
+ 𝑖 ∈𝐵 L (𝑖)) or 2) distill the combined knowledge (i.e., (𝑢,𝑖) ∈𝐵 L (𝑢, 𝑖)). Also, we adopt a simple temperature annealing schedule, which gradually decays the temperature from 𝜏 0 to 𝜏 𝑃 as done in [11]</ref>: 𝜏 (𝑝) = 𝜏 0 (𝜏 𝑃 /𝜏 0 ) 𝑝/𝑃 where 𝜏 (𝑝) is the temperature at epoch 𝑝, and 𝑃 is the total training epochs.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"
nference of the existing recommenders [1,</ref>14,</ref>26]</ref>. Specifically, tree-based data structures [2]</ref>, data compression techniques [26]</ref>, and approximated nearest neighbor search techniques [4,</r
(1)</label></formula><p>where 𝜃 𝑠 is the learning parameters of the student model, 𝜆 is a hyperparameter that controls the effects of RD. The base recommender can be any existing RS model such as BPR [21]</ref>, NeuMF [6]</ref>, and L 𝐵𝑎𝑠𝑒 is its loss function (e.g., binary cross-entropy). The distillation loss of RD for user 𝑢 is define ). Similarly, let ℎ 𝑠 (•) denote a mapping function to the student's representation space (∈ R 𝑑 𝑠 ). The output of the mapping function can be a separate representation of a user, an item (e.g., BPR [21]</ref>) or their combined representation (e.g., NeuMF [6]</ref>) based on the base model's structure and the type of selected layer. He have different architectures and optimization strategies. We choose a latent factor model and a deep learning model that are broadly used for top-𝑁 recommendation with implicit feedback.</p><p>• BPR [21]</ref>: A learning-to-rank model for implicit feedback. It assumes that observed items are more preferred than unobserved items and optimizes Matrix Factorization (M 7]</ref>. We remove users and items having fewer than five ratings for CiteULike, twenty ratings for Foursquare as done in [6,</ref>9,</ref>21]</ref>. Data statistics are summarized in Table 1</ref>. Base Models. We validate the proposed framework on base models that have di
uare [17]</ref>. We remove users and items having fewer than five ratings for CiteULike, twenty ratings for Foursquare as done in [6,</ref>9,</ref>21]</ref>. Data statistics are summarized in Table 1</ref>. Base Models. We validate the proposed r's predictions with consideration of relaxed ranking orders among items.</p><p>Evaluation Protocol. We follow the widely used leave-one-out evaluation protocol [6,</ref>9,</ref>19]</ref>. For each user, we leave out a single interacted item for testing, and use the rest for training. In our experiments, we /p><p>As we focus on the top-𝑁 recommendation task based on implicit feedback, we evaluate the performance of each method with widely used three ranking metrics [6,</ref>9,</ref>10]</ref>: hit ratio (H@𝑁 ), normalized discounted cumulative gain (N@𝑁 ), and mean reciprocal rank (M@𝑁 ). H@𝑁 measures whether the
+ 𝑖 ∈𝐵 L (𝑖)) or 2) distill the combined knowledge (i.e., (𝑢,𝑖) ∈𝐵 L (𝑢, 𝑖)). Also, we adopt a simple temperature annealing schedule, which gradually decays the temperature from 𝜏 0 to 𝜏 𝑃 as done in [11]</ref>: 𝜏 (𝑝) = 𝜏 0 (𝜏 𝑃 /𝜏 0 ) 𝑝/𝑃 where 𝜏 (𝑝) is the temperature at epoch 𝑝, and 𝑃 is the total training epochs.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"
s) and sophisticated model architecture to capture complex patterns make the size of the model continuously increasing [13,</ref>25,</ref>28,</ref>30]</ref>. A large model with numerous parameters has a high capacity, and thus usually has better recommendation performance. On usly increasing, and the computational time and memory cost required for the inference are also increasing accordingly [13,</ref>25,</ref>28,</ref>30]</ref>. Due to the high latency, it becomes difficult to apply such large recommender to the real-time large-scale platform. I
nference of the existing recommenders [1,</ref>14,</ref>26]</ref>. Specifically, tree-based data structures [2]</ref>, data compression techniques [26]</ref>, and approximated nearest neighbor search techniques [4,</r
(1)</label></formula><p>where 𝜃 𝑠 is the learning parameters of the student model, 𝜆 is a hyperparameter that controls the effects of RD. The base recommender can be any existing RS model such as BPR [21]</ref>, NeuMF [6]</ref>, and L 𝐵𝑎𝑠𝑒 is its loss function (e.g., binary cross-entropy). The distillation loss of RD for user 𝑢 is define ). Similarly, let ℎ 𝑠 (•) denote a mapping function to the student's representation space (∈ R 𝑑 𝑠 ). The output of the mapping function can be a separate representation of a user, an item (e.g., BPR [21]</ref>) or their combined representation (e.g., NeuMF [6]</ref>) based on the base model's structure and the type of selected layer. He have different architectures and optimization strategies. We choose a latent factor model and a deep learning model that are broadly used for top-𝑁 recommendation with implicit feedback.</p><p>• BPR [21]</ref>: A learning-to-rank model for implicit feedback. It assumes that observed items are more preferred than unobserved items and optimizes Matrix Factorization (M 7]</ref>. We remove users and items having fewer than five ratings for CiteULike, twenty ratings for Foursquare as done in [6,</ref>9,</ref>21]</ref>. Data statistics are summarized in Table 1</ref>. Base Models. We validate the proposed framework on base models that have di
omains including computer vision and recommendation system, it has been an active research topic in information retrieval community and search engine industry as the next generation search technology [13]</ref>.</p><p>In general, a search engine comprises a recall layer targeting to retrieve a set of relevant documents in low latency and computational cost, usually c s issuing the query and the context where the searcher is. Because of this, embedding-based retrieval in Facebook search is not a text embedding problem, as is actively researched in the IR community [13]</ref>. Instead it is a more complex problem that requires understanding of text, user, and the context altogether.</p><p>To deploy embedding-based retrieval in Face
age understanding [10]</ref>. Among them embedding, which is also called representation learning, has been proven to be successful techniques contributing to the success [2]</ref>. In essence, embedding is a way to represent a sparse vector of ids as a dense feature vector, which is also called semantic embedding in that it can often lear
parameters we need to tune:</p><p>• Coarse quantization. There are different algorithms for coarse quantization. It is useful to compare between IMI [11]</ref> and IVF [15]</ref> algorithms. And it is important to tune number of coarse clusters num_cluster, which will affect both perf and recall. • Product quantization. There are multi
del focuses on recall and the second stage model specializes at differentiating more similar results returned by the first stage model. We shared the same spirit as the cascaded embedding training in [18]</ref>, which ensembled a set of models trained with different level of hardness in a cascaded manner. We explored different forms of ensemble embeddings, including
del focuses on recall and the second stage model specializes at differentiating more similar results returned by the first stage model. We shared the same spirit as the cascaded embedding training in [18]</ref>, which ensembled a set of models trained with different level of hardness in a cascaded manner. We explored different forms of ensemble embeddings, including
parameters we need to tune:</p><p>• Coarse quantization. There are different algorithms for coarse quantization. It is useful to compare between IMI [11]</ref> and IVF [15]</ref> algorithms. And it is important to tune number of coarse clusters num_cluster, which will affect both perf and recall. • Product quantization. There are multi
onents for the embedding quantization, one is the coarse quantization which quantizes embedding vectors into coarse clusters typically through K-means algorithm, and the other is product quantization [8]</ref> which does a fine-grained quantization to enable efficient calculation of embedding distances. There are several important parameters we need to tune:</p><p>• C
del focuses on recall and the second stage model specializes at differentiating more similar results returned by the first stage model. We shared the same spirit as the cascaded embedding training in [18]</ref>, which ensembled a set of models trained with different level of hardness in a cascaded manner. We explored different forms of ensemble embeddings, including
onents for the embedding quantization, one is the coarse quantization which quantizes embedding vectors into coarse clusters typically through K-means algorithm, and the other is product quantization [8]</ref> which does a fine-grained quantization to enable efficient calculation of embedding distances. There are several important parameters we need to tune:</p><p>• C
of the query text but can satisfy users' search intent.</p><p>In the last years, deep learning has made significant progress in speech recognition, computer vision, and natural language understanding [10]</ref>. Among them embedding, which is also called representation learning, has been proven to be successful techniques contributing to the success <ref type="bibr" t
een a query and documents. The query and documents are encoded with a neural network model into dense vectors, on which we use cosine similarity as the distance metric. We propose to use triplet loss [14]</ref> to approximate the recall objective to learn the neural network encoder, which is also called embedding model.</p><p>While semantic embedding is commonly form irection as well as an active research area for embedding learning. However, most of the research are from computer vision field and for the classification task [6,</ref>14,</ref>16,</ref>17]</ref>, while search retrieval does not have concept of "classes" and therefore is a u
/www.tei-c.org/ns/1.0"><head n="4.2">System Implementation</head><p>In order to integrate embedding-based retrieval into our serving stack, we implemented first-class support for NN search in Unicorn [3]</ref>, a retrieval engine powering most search products at Facebook. Unicorn represents each document as a bag of terms, which are arbitrary strings that express bina s, instead of writing a separate system, we inherited all the features of the existing system, such as realtime updates, efficient query planning and execution, and support for multi-hop queries (see [3]</ref>).</p><p>The latter allows us to support top-K NN queries, where instead of matching by radius we select only the K documents closest to the query, and then eval
parameters we need to tune:</p><p>• Coarse quantization. There are different algorithms for coarse quantization. It is useful to compare between IMI [11]</ref> and IVF [15]</ref> algorithms. And it is important to tune number of coarse clusters num_cluster, which will affect both perf and recall. • Product quantization. There are multi
vial change of the model training task, e.g., add more hard negatives. • Always try OPQ. It is often useful to transform data prior to applying the quantization. We experimented with both PCA and OPQ [5]</ref> to transform the data, and observed that OPQ is generally more effective, as shown in Table 3</ref> and Figure <ref type="figu
parameters we need to tune:</p><p>• Coarse quantization. There are different algorithms for coarse quantization. It is useful to compare between IMI [11]</ref> and IVF [15]</ref> algorithms. And it is important to tune number of coarse clusters num_cluster, which will affect both perf and recall. • Product quantization. There are multi
f embedding distances. There are several important parameters we need to tune:</p><p>• Coarse quantization. There are different algorithms for coarse quantization. It is useful to compare between IMI [11]</ref> and IVF [15]</ref> algorithms. And it is important to tune number of coarse clusters num_cluster, which will affect both perf a
/www.tei-c.org/ns/1.0"><head n="4.2">System Implementation</head><p>In order to integrate embedding-based retrieval into our serving stack, we implemented first-class support for NN search in Unicorn [3]</ref>, a retrieval engine powering most search products at Facebook. Unicorn represents each document as a bag of terms, which are arbitrary strings that express bina s, instead of writing a separate system, we inherited all the features of the existing system, such as realtime updates, efficient query planning and execution, and support for multi-hop queries (see [3]</ref>).</p><p>The latter allows us to support top-K NN queries, where instead of matching by radius we select only the K documents closest to the query, and then eval
of the query text but can satisfy users' search intent.</p><p>In the last years, deep learning has made significant progress in speech recognition, computer vision, and natural language understanding [10]</ref>. Among them embedding, which is also called representation learning, has been proven to be successful techniques contributing to the success <ref type="bibr" t
del focuses on recall and the second stage model specializes at differentiating more similar results returned by the first stage model. We shared the same spirit as the cascaded embedding training in [18]</ref>, which ensembled a set of models trained with different level of hardness in a cascaded manner. We explored different forms of ensemble embeddings, including
f embedding distances. There are several important parameters we need to tune:</p><p>• Coarse quantization. There are different algorithms for coarse quantization. It is useful to compare between IMI [11]</ref> and IVF [15]</ref> algorithms. And it is important to tune number of coarse clusters num_cluster, which will affect both perf a
een a query and documents. The query and documents are encoded with a neural network model into dense vectors, on which we use cosine similarity as the distance metric. We propose to use triplet loss [14]</ref> to approximate the recall objective to learn the neural network encoder, which is also called embedding model.</p><p>While semantic embedding is commonly form irection as well as an active research area for embedding learning. However, most of the research are from computer vision field and for the classification task [6,</ref>14,</ref>16,</ref>17]</ref>, while search retrieval does not have concept of "classes" and therefore is a u
parameters we need to tune:</p><p>• Coarse quantization. There are different algorithms for coarse quantization. It is useful to compare between IMI [11]</ref> and IVF [15]</ref> algorithms. And it is important to tune number of coarse clusters num_cluster, which will affect both perf and recall. • Product quantization. There are multi
ct incorrectly labeled sequences into training data and harm model performance.</p><p>We propose SeqMix, a data augmentation method for generating sub-sequences along with their labels based on mixup (Zhang et al., 2018)</ref>. Under the active sequence labeling framework, Se-qMix is capable of generating plausible pseudo labeled sequences for the queried samples in umber of iterations are reached. We summarize the above procedure in Algorithm 1.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sequence Mixup in the Embedding Space</head><p>Mixup (Zhang et al., 2018)</ref> is a data augmentation method that implements linear interpolation in the input space. Given two input samples x i , x j along </p><formula xm ive learning approach but do not study data augmentation for active sequence labeling.</p><p>Interpolation-based Regularizations Mixup implements interpolation in the input space to regularize models (Zhang et al., 2018)</ref>. Recently, the Mixup variants (Verma et al., 2019;</ref>Summers and Dinneen, 201 onsideration to the generation speed and the augment rate setting, we finally choose 500 as the upper limit rather than a too narrow score range setting.</p><p>For the mixing coefficient λ, we follow (Zhang et al., 2018)</ref> to sample it from Beta(α, α) and explore α ranging from [0.5, 16]</ref>. We present this parameter study in Section 4.4. The
h for specifying the policy, where the unlabeled data can be sampled by the disagreement of the base models. The disagreement can be defined in several ways, here we take the vote entropy proposed by (Dagan and Engelson, 1995)</ref>. Given a committee consist of C models, the vote entropy for input x is:</p><formula xml:id="formula_5">γ VE (x) = − 1 T T t=1 M m=1 V m ="bibr" target="#b31">(Scheffer et al., 2001;</ref>Culotta and McCallum, 2005;</ref>Kim et al., 2006)</ref> and committee-based approaches (Dagan and Engelson, 1995)</ref>   2017</ref>) further improve the aforementioned active learning approaches to improve the sampling diversity as well
2016)</ref> are inapplicable because they can only generate word sequences without labels. It is also infeasible to apply heuristic data augmentation methods such as context-based words substitution (Kobayashi, 2018)</ref>, synonym replacement, random insertion, swap, and deletion (Wei and Zou, 2019)</ref>, paraphrasing <ref type="bibr fic task, Hu et al. (2017)</ref> propose to augment text data in an encoder-decoder manner. Very recently, (Anaby-Tavor et al., 2020;</ref>Kobayashi, 2018)</ref> harness the power of pre-trained language models and augmenting the text data based on contextual patterns. Although these methods can augment the
/1.0"><head n="4.1">Experiment Setup</head><p>Datasets. We conduct experiments on three sequence labeling datasets for the named entity recognition (NER) and event detection tasks.</p><p>(1) CoNLL-03 (Tjong Kim Sang and De Meulder, 2003)</ref> is a corpus for NER task. It provides four named entity types: persons, locations, organizations, and miscellaneous. 2  (2) A
ods (Clark et al., 2018;</ref>Chen et al., 2020b)</ref>, external weak supervision (Lison et al., 2020;</ref>Liang et al., 2020;</ref>Ren et al., 2020;</ref>Zhang et al., 2019;</ref>Yu
p><p>Interpolation-based Regularizations Mixup implements interpolation in the input space to regularize models (Zhang et al., 2018)</ref>. Recently, the Mixup variants (Verma et al., 2019;</ref>Summers and Dinneen, 2019;</ref>Guo et al., 2019b)</ref> turn to perform interpol
r to score the perplexity of the sequences. The final generated sequences will consist of only the sequences that pass the sequence quality screening. For screening, we utilize a language model GPT-2 (Radford et al., 2019)</ref> to score sequence x by computing its perplexity:</p><formula xml:id="formula_17">Perplexity(x) = 2 − 1 T T i=1 log p(w i ) , (<label>9</labe
2016)</ref> are inapplicable because they can only generate word sequences without labels. It is also infeasible to apply heuristic data augmentation methods such as context-based words substitution (Kobayashi, 2018)</ref>, synonym replacement, random insertion, swap, and deletion (Wei and Zou, 2019)</ref>, paraphrasing <ref type="bibr fic task, Hu et al. (2017)</ref> propose to augment text data in an encoder-decoder manner. Very recently, (Anaby-Tavor et al., 2020;</ref>Kobayashi, 2018)</ref> harness the power of pre-trained language models and augmenting the text data based on contextual patterns. Although these methods can augment the
p><p>Interpolation-based Regularizations Mixup implements interpolation in the input space to regularize models (Zhang et al., 2018)</ref>. Recently, the Mixup variants (Verma et al., 2019;</ref>Summers and Dinneen, 2019;</ref>Guo et al., 2019b)</ref> turn to perform interpol
et="#b34">(Shen et al., 2017;</ref>Hazra et al., 2019;</ref>Liu et al., 2018;</ref>Fang et al., 2017;</ref>Gao et al., 2019)</ref>. In this study, we mainly focus on active learning approaches which select samples based on the query policy design. So far, various uncertainty-
ods (Clark et al., 2018;</ref>Chen et al., 2020b)</ref>, external weak supervision (Lison et al., 2020;</ref>Liang et al., 2020;</ref>Ren et al., 2020;</ref>Zhang et al., 2019;</ref>Yu
f>5]</ref>, as the raw signal is in a continuous, high-dimensional space and is not structured for human communication (e.g., unlike words).</p><p>Several recent studies [61,</ref>46,</ref>36,</ref>66,</ref>35,</ref tency.</p><p>MoCo is a mechanism for building dynamic dictionaries for contrastive learning, and can be used with various pretext tasks. In this paper, we follow a simple instance discrimination task [61,</ref>63,</ref>2]</ref>: a query matches a key if they are encoded views (e.g., different crops) of the an be defined in terms of the data representation computed by a network [29]</ref>. Contrastive learning is at the core of several recent works on unsupervised learning [61,</ref>46,</ref>36,</ref>66,</ref>35,</ref solely on the three mechanisms.</p><p>The results are in Figure 3</ref>. Overall, all three mechanisms benefit from a larger K. A similar trend has been observed in [61,</ref>56]</ref> under the memory bank mechanism, while here we show that this trend is more general and can be seen in all mechanisms. 4]</ref>.</p><p>Contrastive learning vs. pretext tasks. Various pretext tasks can be based on some form of contrastive loss functions. The instance discrimination method [61]</ref> is related to the exemplar-based task [17]</ref> and NCE [28]</ref>. The pretext task in contras et="#b45">[46]</ref>, is considered in this paper:</p><formula xml:id="formula_0">Lq = − log exp(q•k+/τ ) K i=0 exp(q•ki/τ )<label>(1)</label></formula><p>where τ is a temperature hyper-parameter per [61]</ref>. The sum is over one positive and K negative samples. Intuitively, this loss is the log loss of a (K+1)-way softmax-based classifier that tries to classify q receptive field size [2]</ref>, which may complicate the transfer of these networks to downstream tasks.</p><p>Another mechanism is the memory bank approach proposed by [61]</ref> (Figure 2b</ref>). A memory bank consists of the representations of all samples in the dataset. The dictionary for each mini-batch is rando last seen, so the sampled keys are essentially about the encoders at multiple different steps all over the past epoch and thus are less consistent. A momentum update is adopted on the memory bank in [61]</ref>. Its momentum update is on the representations of the same sample, not the encoder. This momentum update is irrelevant to our method, because MoCo does not ke >Contrastive learning can drive a variety of pretext tasks. As the focus of this paper is not on designing a new pretext task, we use a simple one mainly following the instance discrimination task in [61]</ref>, to which some recent works [63,</ref>2]</ref> are related.</p><p>Following <ref type="bibr" targ scrimination task in [61]</ref>, to which some recent works [63,</ref>2]</ref> are related.</p><p>Following [61]</ref>, we consider a query and a key as a positive pair if they originate from the same image, and otherwise as a negative sample pair. Following <ref type="bibr" t <p>Technical details. We adopt a ResNet [33]</ref> as the encoder, whose last fully-connected layer (after global average pooling) has a fixed-dimensional output (128-D [61]</ref>). This output vector is normalized by its L2-norm [61]</ref>. This is the representation of the query or key. The temperature τ oder, whose last fully-connected layer (after global average pooling) has a fixed-dimensional output (128-D [61]</ref>). This output vector is normalized by its L2-norm [61]</ref>. This is the representation of the query or key. The temperature τ in Eqn.( 1</ref>) is set as 0.07 <ref type="bibr" t ed by its L2-norm [61]</ref>. This is the representation of the query or key. The temperature τ in Eqn.( 1</ref>) is set as 0.07 [61]</ref>. The data augmentation setting follows [61]</ref>: a 224×224-pixel crop is taken from a randomly resized image, and then underg tation of the query or key. The temperature τ in Eqn.( 1</ref>) is set as 0.07 [61]</ref>. The data augmentation setting follows [61]</ref>: a 224×224-pixel crop is taken from a randomly resized image, and then undergoes random color jittering, random horizontal flip, and random grayscale conversi . For IN-1M, we use a mini-batch size of 256 (N in Algorithm 1) in 8 GPUs, and an initial learning rate of 0.03. We train for 200 epochs with the learning rate multiplied by 0.1 at 120 and 160 epochs [61]</ref>, taking ∼53 hours training ResNet-50. For IG-1B, we use a mini-batch size of 1024 in 64 GPUs, and a learning rate of 0.12 which is exponentially decayed by 0. f>). The number of negatives is K in memory bank and MoCo, and is K−1 in end-to-end (offset by one because the positive key is in the same mini-batch). The network is ResNet-50.</p><p>The memory bank [61]</ref> mechanism can support a larger dictionary size. But it is 2.6% worse than MoCo. This is inline with our hypothesis: the keys in the memory bank are from very y noticeable but relatively small, suggesting that the larger-scale data may not be fully exploited. We hope an advanced pretext task will improve this. Beyond the simple instance discrimination task [61]</ref>, it is possible to adopt MoCo for pretext tasks like masked auto-encoding, e.g., in language [12]</ref> and in vision <ref type otated labels".</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Here 58.0% is with InfoNCE and K=65536. We reproduce 54.3% when using NCE and K=4096 (the same as[61]</ref>), close to 54.0% in[61]</ref>.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Parameter s/1.0" place="foot" n="2" xml:id="foot_1">Here 58.0% is with InfoNCE and K=65536. We reproduce 54.3% when using NCE and K=4096 (the same as[61]</ref>), close to 54.0% in[61]</ref>.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Parameters are of the feature extractor: e.g., we do not count the par softmax-based classifier that tries to classify q as k + . Contrastive loss functions can also be based on other forms [29,</ref>59,</ref>61,</ref>36]</ref>, such as margin-based losses and variants of NCE losses. The contrastive loss serves as an unsupervised objective funct er network and x q is a query sample (likewise, k = f k (x k )). Their instantiations depend on the specific pretext task. The input x q and x k can be images [29,</ref>61,</ref>63]</ref>, patches [46]</ref>, or context consisting a set of patches <ref type="bibr" target="#b4 P 75 .</p><p>Interestingly, the transferring accuracy depends on the detector structure. For the C4 backbone, by default used in existing ResNet-based results [14,</ref>61,</ref>26,</ref>66]</ref>, the advantage of unsupervised pre-training is larger. The relation between pre
ding dynamic dictionaries for contrastive learning, and can be used with various pretext tasks. In this paper, we follow a simple instance discrimination task [61,</ref>63,</ref>2]</ref>: a query matches a key if they are encoded views (e.g., different crops) of the same image. Using this pretext task, MoCo </p><p>The end-to-end update by back-propagation is a natural mechanism (e.g., [29,</ref>46,</ref>36,</ref>63,</ref>2,</ref>35]</ref>, Figure 2a</ref>). It uses samples in the current mini-batch a kewise, k = f k (x k )). Their instantiations depend on the specific pretext task. The input x q and x k can be images [29,</ref>61,</ref>63]</ref>, patches [46]</ref>, or context consisting a set of patches [46]</ref>. The networks f q and f k ntext consisting a set of patches [46]</ref>. The networks f q and f k can be identical [29,</ref>59,</ref>63]</ref>, partially shared [46,</ref>36,</ref>2]</ref>, or different <ref ty us of this paper is not on designing a new pretext task, we use a simple one mainly following the instance discrimination task in [61]</ref>, to which some recent works [63,</ref>2]</ref> are related.</p><p>Following [61]</ref>, we consider a query and a key as a positive pair .</p><p>Following [61]</ref>, we consider a query and a key as a positive pair if they originate from the same image, and otherwise as a negative sample pair. Following [63,</ref>2]</ref>, we take two random "views" of the same image under random data augmentation to form a positive pair. The queries and ke
and weight decay 0.0001. Learning rate is 0.003 on VOC and is 0.01 on Cityscapes (multiplied by 0.1 at 70th and 90-th percentile of training). For VOC, we train on the train aug2012 set (augmented by [30]</ref>, 10582 images) for 30k iterations, and evaluate on val2012. For Cityscapes, we train on the train fine set (2975 images) for 90k iterations, and evaluate on t
lor jittering, random horizontal flip, and random grayscale conversion, all available in PyTorch's torchvision package.</p><p>Shuffling BN. Our encoders f q and f k both have Batch Normalization (BN) [37]</ref> as in the standard ResNet [33]</ref>. In experiments, we found that using BN prevents the model from learning good representati
e same image under random data augmentation to form a positive pair. The queries and keys are respectively encoded by their encoders, f q and f k . The encoder can be any convolutional neural network [39]</ref>.</p><p>Algorithm 1 provides the pseudo-code of MoCo for this pretext task. For the current mini-batch, we encode the queries and their corresponding keys, whi
type="bibr" target="#b27">[28]</ref>.</p><p>Pretext tasks. A wide range of pretext tasks have been proposed. Examples include recovering the input under some corruption, e.g., denoising auto-encoders [58]</ref>, context autoencoders [48]</ref>, or cross-channel auto-encoders (colorization) [64,</ref><ref t
pervised pre-training is most influential when serving as the initialization for finetuning in downstream tasks (e.g., [21,</ref>20,</ref>43,</ref>52]</ref>). Next we compare MoCo with ImageNet supervised pre-training, transferred to various tasks including PASCAL VOC <ref ty new dataset and model designs on it are to be explored. The following </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5. Implementation: Semantic segmentation</head><p>We use an FCN-based [43]</ref> structure. The backbone consists of the convolutional layers in R50, and the 3×3 convolutions in conv 5 blocks have dilation 2 and stride 1. This is followed have dilation 2 and stride 1. This is followed by two extra 3×3 convolutions of 256 channels, with BN and ReLU, and then a 1×1 convolution for perpixel classification. The total stride is 16 (FCN-16s [43]</ref>). We set dilation = 6 in the two extra 3×3 convolutions, following the large field-of-view design in [6]</ref>.</p><p>Training i
ts, etc.) for building tokenized dictionaries, on which unsupervised learning can be based. Computer vision, in contrast, further concerns dictionary building [54,</ref>9,</ref>5]</ref>, as the raw signal is in a continuous, high-dimensional space and is not structured for human communication (e.g., unlike w
across GPUs [49]</ref>), instead of freezing it by an affine layer [33]</ref>. We also use BN in the newly initialized layers (e.g., FPN [41]</ref>), which helps calibrate magnitudes.</p><p>We perform normalization when fine-tuning supervised and unsupervised pre-training models. MoCo uses the same hyper- p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">COCO Object Detection and Segmentation</head><p>Setup. The model is Mask R-CNN [32]</ref> with the FPN [41]</ref> or C4 backbone, with BN tuned, implemented in [60]</ref>. The image scale is in [640, 800] pixels during training and is 800 at
13,</ref>45]</ref>, tracking [59]</ref> or segmenting objects [47]</ref> in videos, or clustering features [3,</ref>4]</ref>.</p><p>Contrastive learning vs. pretext tasks. Various pretext tasks can be based on some form of contrastive loss functio
es are not exploited by unsupervised learning). This dataset is well-balanced in its class distribution, and its images generally contain iconic view of objects.</p><p>Instagram-1B (IG-1B): Following [44]</ref>, this is a dataset of ∼1 billion (940M) public images from Instagram. The images are from ∼1500 hashtags [44]</ref> that are re ew of objects.</p><p>Instagram-1B (IG-1B): Following [44]</ref>, this is a dataset of ∼1 billion (940M) public images from Instagram. The images are from ∼1500 hashtags [44]</ref> that are related to the ImageNet categories. This dataset is relatively uncurated comparing to IN-1M, and has a long-tailed, unbalanced distribution of real-w

upervised representation learning is highly successful in natural language processing, e.g., as shown by GPT [50,</ref>51]</ref> and BERT [12]</ref>. But supervised pre-training is still dominant in computer vision, where unsupervised methods generally lag behind. The reason may stem from differences in th ill improve this. Beyond the simple instance discrimination task [61]</ref>, it is possible to adopt MoCo for pretext tasks like masked auto-encoding, e.g., in language [12]</ref> and in vision [46]</ref>. We hope MoCo will be useful with other pretext tasks that involve contrastive learning. </p></div><fi
otably, we achieve competitive results using a standard ResNet-50 and require no specific architecture designs, e.g.,  Notations: R101 * /R170 * is ResNet-101/170 with the last residual stage removed [14,</ref>46,</ref>35]</ref>, and R170 is made wider [35]</ref>; Rv50 is a r t: up to +0.9 AP 50 , +3.7 AP, and +4.9 AP 75 .</p><p>Interestingly, the transferring accuracy depends on the detector structure. For the C4 backbone, by default used in existing ResNet-based results [14,</ref>61,</ref>26,</ref>66]</ref>, the advantage of unsupervised pre-tra erpart on COCO [31]</ref>. Our goal is to investigate transferabil-AP 50</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>AP</head><p>AP 75 pre-train RelPos, by [14]</ref> Multi-task [14]</ref> Jigsaw, by [26]</ref>  Table 4</ref>. Comparison with pr ef>. Our goal is to investigate transferabil-AP 50</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>AP</head><p>AP 75 pre-train RelPos, by [14]</ref> Multi-task [14]</ref> Jigsaw, by [26]</ref>  Table 4</ref>. Comparison with previous methods on object detection fine-tuned on PASC erparts are from the respective papers, and are reported as having the same structure as the respective unsupervised pre-training counterparts. All entries are based on the C4 backbone. The models in [14]</ref> are R101 v2 [34]</ref>, and others are R50. The RelPos (relative position) [13]</ref> result is v2 [34]</ref>, and others are R50. The RelPos (relative position) [13]</ref> result is the best single-task case in the Multi-task paper [14]</ref>. The Jigsaw [45]</ref> result is from the ResNet-based implementation in [26]</ref>. Our results
" target="#b16">[17]</ref>, patch orderings [13,</ref>45]</ref>, tracking [59]</ref> or segmenting objects [47]</ref> in videos, or clustering features [3,</ref>4]</ref>.</p><p>Contrastive learning vs. pretext tasks.
target="#b34">[35]</ref>; Rv50 is a reversible net [23]</ref>, RX50 is ResNeXt-50-32×8d [62]</ref>. † : Pre-training uses FastAutoAugment [40]</ref> that is supervised by ImageNet labels.</p><p>patchified inputs [46,</ref>35]</ref>, carefully ta
://www.tei-c.org/ns/1.0"><head n="4.2.1">PASCAL VOC Object Detection</head><p>Setup. The detector is Faster R-CNN [52]</ref> with a backbone of R50-dilated-C5 or R50-C4 [32]</ref> (details in appendix), with BN tuned, implemented in [60]</ref>. We fine-tune all layers end-to-end. The image scale is [480, 8 2 (Table 2b</ref>).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">COCO Object Detection and Segmentation</head><p>Setup. The model is Mask R-CNN [32]</ref> with the FPN [41]</ref> or C4 backbone, with BN tuned, implemented in [60]</ref>. The image scal O longer fine-tuning</head><p>In Table 5</ref> we reported results of the 1× (∼12 epochs) and 2× schedules on COCO. These schedules were inherited from the original Mask R-CNN paper [32]</ref>, which could be suboptimal given later advance in the field. In Table A</ref>.1, we supplement the results of a 6× schedule (∼72 epochs) <re
., learning rates) selected for supervised pre-training. To relieve this problem, we adopt feature normalization during fine-tuning: we fine-tune with BN that is trained (and synchronized across GPUs [49]</ref>), instead of freezing it by an affine layer [33]</ref>. We also use BN in the newly initialized layers (e.g., FPN <ref type="bi
e same image under random data augmentation to form a positive pair. The queries and keys are respectively encoded by their encoders, f q and f k . The encoder can be any convolutional neural network [39]</ref>.</p><p>Algorithm 1 provides the pseudo-code of MoCo for this pretext task. For the current mini-batch, we encode the queries and their corresponding keys, whi
></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>AP</head><p>AP 75 pre-train RelPos, by [14]</ref> Multi-task [14]</ref> Jigsaw, by [26]</ref>  Table 4</ref>. Comparison with previous methods on object detection fine-tuned on PASCAL VOC trainval2007. Evaluation is on test2007. The I is the best single-task case in the Multi-task paper [14]</ref>. The Jigsaw [45]</ref> result is from the ResNet-based implementation in [26]</ref>. Our results are with 9k-iteration fine-tuning, averaged over 5 trials. In the brackets are the gaps to the ImageNet supervised pre-training counterpart. In g ring accuracy depends on the detector structure. For the C4 backbone, by default used in existing ResNet-based results [14,</ref>61,</ref>26,</ref>66]</ref>, the advantage of unsupervised pre-training is larger. The relation between pre-training vs. detector structures has be
ts, etc.) for building tokenized dictionaries, on which unsupervised learning can be based. Computer vision, in contrast, further concerns dictionary building [54,</ref>9,</ref>5]</ref>, as the raw signal is in a continuous, high-dimensional space and is not structured for human communication (e.g., unlike w
ferred to various tasks including PASCAL VOC [18]</ref>, COCO [42]</ref>, etc. As prerequisites, we discuss two important issues involved [31]</ref>: normalization and schedules.</p><p>Normalization. As noted in Sec. 4.1, features produced by unsupervised pre-training can have different distributions compa nterpart.</p><p>Schedules. If the fine-tuning schedule is long enough, training detectors from random initialization can be strong baselines, and can match the ImageNet supervised counterpart on COCO [31]</ref>. Our goal is to investigate transferabil-AP 50</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>AP</head><p>AP 75 pre-train RelPos, by <ref type="bibr 0.5 point.</p><p>ity of features, so our experiments are on controlled schedules, e.g., the 1× (∼12 epochs) or 2× schedules [22]</ref> for COCO, in contrast to 6×∼9× in [31]</ref>. On smaller datasets like VOC, training longer may not catch up [31]</ref>. Nonetheless, in our fine-tuning, MoCo uses the same ) or 2× schedules [22]</ref> for COCO, in contrast to 6×∼9× in [31]</ref>. On smaller datasets like VOC, training longer may not catch up [31]</ref>. Nonetheless, in our fine-tuning, MoCo uses the same schedule as the ImageNet supervised counterpart, and random initialization results are provided as refere er [32]</ref>, which could be suboptimal given later advance in the field. In Table A</ref>.1, we supplement the results of a 6× schedule (∼72 epochs) [31]</ref> and compare with those of the 2× schedule.</p><p>We observe: (i) fine-tuning with ImageNet-supervised pre-training still has improvements (41.9 AP bb ); (ii)
iv xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">CROSS-LAYER PARAMETER SHARING</head><p>The idea of sharing parameters across layers has been previously explored with the Transformer architecture (Vaswani et al., 2017)</ref>, but this prior work has focused on training for standard encoderdecoder tasks rather than the pretraining/finetuning setting. Different fro .</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MODEL ARCHITECTURE CHOICES</head><p>The backbone of the ALBERT architecture is similar to BERT in that it uses a transformer encoder (Vaswani et al., 2017)</ref> with GELU nonlinearities (Hendrycks &amp; Gimpel, 2016)</ref>. We follow the BERT notation conventions and de




ions.</p><p>Evidence from these improvements reveals that a large network is of crucial importance for achieving state-of-the-art performance (Devlin et al., 2019;</ref>Radford et al., 2019)</ref>. It has become common practice to pre-train large models and distill them down to smaller ones (Sun et al., 20
ions.</p><p>Evidence from these improvements reveals that a large network is of crucial importance for achieving state-of-the-art performance (Devlin et al., 2019;</ref>Radford et al., 2019)</ref>. It has become common practice to pre-train large models and distill them down to smaller ones (Sun et al., 20
ibuted training, as the communication overhead is directly proportional to the number of parameters in the model.</p><p>Existing solutions to the aforementioned problems include model parallelization (Shazeer et al., 2018;</ref>Shoeybi et al., 2019)</ref> and clever memory management (Chen et al., 2016;</re
ref>Halliday &amp; Hasan, 1976;</ref>Grosz et al., 1995)</ref>. Most objectives found effective in practice are quite simple. Skipthought (Kiros et al., 2015)</ref> and FastSent (Hill et al., 2016)</ref> sentence embeddings are learned by using an encoding of a sentence to pr

p://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Full network pre-training (Dai &amp; Le, 2015;</ref>Radford et al., 2018;</ref>Devlin et al., 2019;</ref>Howard &amp; Ruder, 2018)</ref> has led to a series of breakthroughs in language representation learning. Many n to build high-performance pretrained language representations.</p><p>Evidence from these improvements reveals that a large network is of crucial importance for achieving state-of-the-art performance (Devlin et al., 2019;</ref>Radford et al., 2019)</ref>. It has become common practice to pre-train large models and distill them down to s eving a GLUE score of 89.4, a SQuAD 2.0 test F1 score of 92.2, and a RACE test accuracy of 89.4. The latter appears to be a particularly strong improvement, a jump of +17.4% absolute points over BERT (Devlin et al., 2019;</ref>Clark et al., 2019)</ref>, +7.6% over XLNet (Yang et al., 2019)</ref>, +6.2% over nce embeddings are learned in order to determine the ordering of two consecutive sentences. Unlike most of the above work, however, our loss is defined on textual segments rather than sentences. BERT (Devlin et al., 2019)</ref> uses a loss based on predicting whether the second segment in a pair has been swapped with a segment from another document. We compare to thi ">THE ELEMENTS OF ALBERT</head><p>In this section, we present the design decisions for ALBERT and provide quantified comparisons against corresponding configurations of the original BERT architecture (Devlin et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MODEL ARCHITECTURE CHOICES</head><p>The backbone of the ALBERT architecture y DQE.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Similar strategies have been explored by</head><p>Inter-sentence coherence loss. In addition to the masked language modeling (MLM) loss (Devlin et al., 2019)</ref>, BERT uses an additional loss called next-sentence prediction (NSP). NSP is a binary classification loss for predicting whether two segments "><head n="4">EXPERIMENTAL RESULTS</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">EXPERIMENTAL SETUP</head><p>To keep the comparison as meaningful as possible, we follow the BERT (Devlin et al., 2019)</ref> setup in using the BOOKCORPUS (Zhu et al., 2015)</ref> and English Wikipedia (D as possible, we follow the BERT (Devlin et al., 2019)</ref> setup in using the BOOKCORPUS (Zhu et al., 2015)</ref> and English Wikipedia (Devlin et al., 2019)</ref> for pretraining baseline models. These two corpora consist of around 16GB of uncompressed text. We format our inputs as "</p><formula xml:id= div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">ADDITIONAL TRAINING DATA AND DROPOUT EFFECTS</head><p>The experiments done up to this point use only the Wikipedia and BOOKCORPUS datasets, as in (Devlin et al., 2019)</ref>. In this section, we report measurements on the impact of the additional data used by both XLNet (Yang et al., 22">(Hendrycks &amp; Gimpel, 2016)</ref>. We follow the BERT notation conventions and denote the vocabulary embedding size as E, the number of encoder layers as L, and the hidden size as H. Following Devlin et al. (2019)</ref>, we set the feed-forward/filter size to be 4H and the number of attention heads to be H/64.</p><p>There are three main contributions that ALBE igDesc>The effect of removing dropout, measured for an ALBERT-xxlarge configuration.4.9 CURRENT STATE-OF-THE-ART ON NLU TASKSThe results we report in this section make use of the training data used byDevlin et al. (2019)</ref>, as well as the additional data used byLiu et al. (2019)</ref> andYang et al. (2 ><p>A.4 HYPERPARAMETERS Hyperparameters for downstream tasks are shown in Table 14</ref>. We adapt these hyperparameters from Liu et al. (2019)</ref>, Devlin et al. (2019), and</ref>Yang et al. (2019)</ref>. </p></div>			</div> 			<div type="references">  				<listBibl>  <biblStruct xml:i
v> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of Grounded video description (GVD) [Zhou et al., 2019]</ref> aims to generate more grounded and accurate descriptions by linking the generated words with the regions in video frames. Compared to convention relationships among the region proposals; and ii) attending them for text generation. On one hand, existing works either encode region proposals independently or using selfattention-based mechanisms [Zhou et al., 2019]</ref>. Therefore, it either fails to consider implicit structural information among the region proposals or needs to handle noisy or fake relationship f>Liu et al., 2018;</ref>Li et al., 2019a]</ref>, many works model the video in both global video features and regional object features. In [Zhou et al., 2019]</ref>, they encode the objects with transformer [Vaswani et al., 2017]</ref> and then link the words of generated descriptions with t ">1 c</ref>).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Video Global Encoder</head><p>We model the video's global level feature by a Bi-directional LSTM network like most works [Zhou et al., 2019]</ref> given by: h = BiLST M (v) = {h 1 , h 2 , ..., h m } where v ∈ R n×d is the global feature extracted by a pre-trained 3D-ConvNet <ref type="bibr" /www.tei-c.org/ns/1.0"><head n="3.2">Graph with Refinement Encoder</head><p>In this section, we propose a novel visual representation method from the perspective of regions. First of all, inspired by [Zhou et al., 2019]</ref>, we enhance the proposal features by adding the position and class features. As for proposal modeling, we propose a novel spatial-temporal seque tial topology can be obtained with or without prior knowledge considering the generality.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Enhancement</head><p>In this part, we follow [Zhou et al., 2019]</ref>'s work, which fusing the spatial-temporal and class features with the original features to enrich them.</p><p>(1) For each proposal, we define i ] denotes row-wise concatenation and W p ∈ R l×(d+k+dsp) is the embedding weight. Then we will apply feature aggregation on the enhanced feature R.</p><p>We adopt the same classification loss just as [Zhou et al., 2019]</ref> do denoted as L cls .</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial-temporal Sequence-Graph Data Structure</head><p>Here we w ds while absorbing the visual clues given by: h t = LST M (h1</ref> t , h f rame + h attention ). h t is used to generate descriptions. We adopt the same MLE loss as [Zhou et al., 2019]</ref> which denoted by L sent .</p><p>Finally, the overall loss function consists of four parts:</p><formula xml:id="formula_17">L = L sent + λ a L a s<label>(10)</label></formula><p>4 Experiment</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We conduct our experiments on the Grounded ActivityNet-Entities Dataset [Zhou et al., 2019]</ref> for evaluation. It contains 15k video with 158k spatially annotated bounding boxes from 52k video segments.</p></div> <div xmlns="http://www.tei mentation Details</head><p>In this section, we introduce some implementation details of our HAST-Graph2Seq method. Data processing. For a fair comparison, the data processing procedure is the same to [Zhou et al., 2019]</ref>. For each video segment in the dataset, we uniformly sample 10 frames. And for each frame, we use a Faster R-CNN [ Graph2Seq with the SOTA models, i.e., Masked Transformer [Zhou et al., 2018]</ref>, BiM-STM+TempoAtnn [Zhou et al., 2018]</ref> and ZhouGVD [Zhou et al., 2019]</ref> on Grounded ActivityNet Captions Dataset to verify the effectiveness of our method. Moreover, since the initial graph of the HAST-Graph2Seq can 0 as the initial graph individually.</p><p>(3) w/o. hierarchical attention (abbr: -hie. attn.). We remove the hierarchical attention and replace it with the coarsegrain proposal attention proposed by [Zhou et al., 2019]</ref>.</p><p>Table 3</ref> gives all ablation results on the validation set. As shown in Table <ref type="table" tar
iption</head><p>With the rapid development of deep learning in CV and NLP, video description begins to generate the description of a video using the attention-based encoder-decoder like architectures [Venugopalan et al., 2015;</ref>Xu et al., 2018b;</ref>Liu et al., 2016]</ref>. These methods are effective bu CV and NLP, video description begins to generate the description of a video using the attention-based encoder-decoder like architectures [Venugopalan et al., 2015;</ref>Xu et al., 2018b;</ref>Liu et al., 2016]</ref>. These methods are effective but they overlook the fine-grained object clues that separated i ain goal for graph-tosequence learning is to generate sequential content from graph structured data, which learns a mapping between graph inputs to sequence outputs through attention-based mechanisms [Xu et al., 2018a;</ref>Chen et al., 2020;</ref>Gao et al., 2019]</ref>. However, since there is no explicit g
ave much to do with others, the methods like self-attention may confuse the model. Therefore, graph-based methods which model the regions with abundant semantic relations are introduced to this area. [Yao et al., 2018]</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph-to-sequence Learning</head><p>Graph-to-sequence learning has been surge
ave much to do with others, the methods like self-attention may confuse the model. Therefore, graph-based methods which model the regions with abundant semantic relations are introduced to this area. [Yao et al., 2018]</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph-to-sequence Learning</head><p>Graph-to-sequence learning has been surge
nd then focus on the objects in these frames.</p><p>More recently, the graph-based method for video understanding started attracting more attentions in some close related fields such as image caption [Li et al., 2019b]</ref>. However, due to the complexity of video understanding, there still remains significant challenges to adapt these graph-based approaches into the ion Graph. Since the region features are extracted by a pre-trained model trained on VG [Krishna et al., 2017]</ref> dataset, we can train a semantic relation classifier [Li et al., 2019b]</ref> on it. We adopt almost the same operation except replacing the KNN step by the classifier to find the related nodes set R p .</p></div> <div xmln description of a video using the attention-based encoder-decoder like architectures [Venugopalan et al., 2015;</ref>Xu et al., 2018b;</ref>Liu et al., 2016]</ref>. These methods are effective but they overlook the fine-grained object clues that separated in frames.</p><p>Borrowing the ideas of spatial-attent they overlook the fine-grained object clues that separated in frames.</p><p>Borrowing the ideas of spatial-attention in image caption domain [Anderson et al., 2018;</ref>Liu et al., 2018;</ref>Li et al., 2019a]</ref>, many works model the video in both global video features and regional object features. In <r like most works [Zhou et al., 2019]</ref> given by: h = BiLST M (v) = {h 1 , h 2 , ..., h m } where v ∈ R n×d is the global feature extracted by a pre-trained 3D-ConvNet [Tran et al., 2015]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph with Refinement Encoder</head><p>In this section, we propose a novel vis ssing procedure is the same to [Zhou et al., 2019]</ref>. For each video segment in the dataset, we uniformly sample 10 frames. And for each frame, we use a Faster R-CNN [Ren et al., 2015]</ref> detector with ResNeXt-101 backbone to detect 100 region proposals and extract the feature. The detector is pre-trained on Visual Genome <ref type
urate descriptions by linking the generated words with the regions in video frames. Compared to conventional video description task that generates a human-like sentence to describe the video contents [Zhou et al., 2018]</ref>, GVD has advantages of modelling the video by objects and associating the generated text with them to describe the video in a high-quality and g easure all of these scores. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Comparisons</head><p>We compare HAST-Graph2Seq with the SOTA models, i.e., Masked Transformer [Zhou et al., 2018]</ref>, BiM-STM+TempoAtnn [Zhou et al., 2018]</ref> and ZhouGVD [Zhou et al., 2019]</ref> o 1.0"><head n="4.4">Performance Comparisons</head><p>We compare HAST-Graph2Seq with the SOTA models, i.e., Masked Transformer [Zhou et al., 2018]</ref>, BiM-STM+TempoAtnn [Zhou et al., 2018]</ref> and ZhouGVD [Zhou et al., 2019]</ref> on Grounded ActivityNet Captions Dataset to verify the effectiveness of our
nd then focus on the objects in these frames.</p><p>More recently, the graph-based method for video understanding started attracting more attentions in some close related fields such as image caption [Li et al., 2019b]</ref>. However, due to the complexity of video understanding, there still remains significant challenges to adapt these graph-based approaches into the ion Graph. Since the region features are extracted by a pre-trained model trained on VG [Krishna et al., 2017]</ref> dataset, we can train a semantic relation classifier [Li et al., 2019b]</ref> on it. We adopt almost the same operation except replacing the KNN step by the classifier to find the related nodes set R p .</p></div> <div xmln description of a video using the attention-based encoder-decoder like architectures [Venugopalan et al., 2015;</ref>Xu et al., 2018b;</ref>Liu et al., 2016]</ref>. These methods are effective but they overlook the fine-grained object clues that separated in frames.</p><p>Borrowing the ideas of spatial-attent they overlook the fine-grained object clues that separated in frames.</p><p>Borrowing the ideas of spatial-attention in image caption domain [Anderson et al., 2018;</ref>Liu et al., 2018;</ref>Li et al., 2019a]</ref>, many works model the video in both global video features and regional object features. In <r like most works [Zhou et al., 2019]</ref> given by: h = BiLST M (v) = {h 1 , h 2 , ..., h m } where v ∈ R n×d is the global feature extracted by a pre-trained 3D-ConvNet [Tran et al., 2015]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph with Refinement Encoder</head><p>In this section, we propose a novel vis ssing procedure is the same to [Zhou et al., 2019]</ref>. For each video segment in the dataset, we uniformly sample 10 frames. And for each frame, we use a Faster R-CNN [Ren et al., 2015]</ref> detector with ResNeXt-101 backbone to detect 100 region proposals and extract the feature. The detector is pre-trained on Visual Genome <ref type
urate descriptions by linking the generated words with the regions in video frames. Compared to conventional video description task that generates a human-like sentence to describe the video contents [Zhou et al., 2018]</ref>, GVD has advantages of modelling the video by objects and associating the generated text with them to describe the video in a high-quality and g easure all of these scores. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Comparisons</head><p>We compare HAST-Graph2Seq with the SOTA models, i.e., Masked Transformer [Zhou et al., 2018]</ref>, BiM-STM+TempoAtnn [Zhou et al., 2018]</ref> and ZhouGVD [Zhou et al., 2019]</ref> o 1.0"><head n="4.4">Performance Comparisons</head><p>We compare HAST-Graph2Seq with the SOTA models, i.e., Masked Transformer [Zhou et al., 2018]</ref>, BiM-STM+TempoAtnn [Zhou et al., 2018]</ref> and ZhouGVD [Zhou et al., 2019]</ref> on Grounded ActivityNet Captions Dataset to verify the effectiveness of our
">Liu et al., 2016]</ref>. These methods are effective but they overlook the fine-grained object clues that separated in frames.</p><p>Borrowing the ideas of spatial-attention in image caption domain [Anderson et al., 2018;</ref>Liu et al., 2018;</ref>Li et al., 2019a]</ref>, many works model the video in bot
nd then focus on the objects in these frames.</p><p>More recently, the graph-based method for video understanding started attracting more attentions in some close related fields such as image caption [Li et al., 2019b]</ref>. However, due to the complexity of video understanding, there still remains significant challenges to adapt these graph-based approaches into the ion Graph. Since the region features are extracted by a pre-trained model trained on VG [Krishna et al., 2017]</ref> dataset, we can train a semantic relation classifier [Li et al., 2019b]</ref> on it. We adopt almost the same operation except replacing the KNN step by the classifier to find the related nodes set R p .</p></div> <div xmln description of a video using the attention-based encoder-decoder like architectures [Venugopalan et al., 2015;</ref>Xu et al., 2018b;</ref>Liu et al., 2016]</ref>. These methods are effective but they overlook the fine-grained object clues that separated in frames.</p><p>Borrowing the ideas of spatial-attent they overlook the fine-grained object clues that separated in frames.</p><p>Borrowing the ideas of spatial-attention in image caption domain [Anderson et al., 2018;</ref>Liu et al., 2018;</ref>Li et al., 2019a]</ref>, many works model the video in both global video features and regional object features. In <r like most works [Zhou et al., 2019]</ref> given by: h = BiLST M (v) = {h 1 , h 2 , ..., h m } where v ∈ R n×d is the global feature extracted by a pre-trained 3D-ConvNet [Tran et al., 2015]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph with Refinement Encoder</head><p>In this section, we propose a novel vis ssing procedure is the same to [Zhou et al., 2019]</ref>. For each video segment in the dataset, we uniformly sample 10 frames. And for each frame, we use a Faster R-CNN [Ren et al., 2015]</ref> detector with ResNeXt-101 backbone to detect 100 region proposals and extract the feature. The detector is pre-trained on Visual Genome <ref type
sequential content from graph structured data, which learns a mapping between graph inputs to sequence outputs through attention-based mechanisms [Xu et al., 2018a;</ref>Chen et al., 2020;</ref>Gao et al., 2019]</ref>. However, since there is no explicit graph structure for video, it is hard to adapt these me earns a mapping between graph inputs to sequence outputs through attention-based mechanisms [Xu et al., 2018a;</ref>Chen et al., 2020;</ref>Gao et al., 2019]</ref>. However, since there is no explicit graph structure for video, it is hard to adapt these methods directly. Unlike these previous methods, we prop by KNN</formula><p>Algorithm and add edges between r i and R p .</p><p>(2) With external knowledge method: Relation Graph. Since the region features are extracted by a pre-trained model trained on VG [Krishna et al., 2017]</ref> dataset, we can train a semantic relation classifier [Li et al., 2019b]</ref> on it. We adopt almost the same o er R-CNN [Ren et al., 2015]</ref> detector with ResNeXt-101 backbone to detect 100 region proposals and extract the feature. The detector is pre-trained on Visual Genome [Krishna et al., 2017]</ref>. Finally, for the video feature, the temporal feature map is a stack of frame-wise appearance and motion features. Hyperparameter settings. W ( A dir + A T dir )/2 Feature Aggregation We adapt the classic spectral graph convolutional network to aggregate the features of the nodes modeled by topology A.</p><p>Inspired by resnet architecture [He et al., 2016]</ref>, we propose the basic module of our architecture as follows (the layer normalization and dropout operations are omitted):</p><formula xml:id="form
ical 6D pose estimation algorithms, which have been designed for rigid objects [31,</ref>25,</ref>24,</ref>28]</ref>. Algorithms that do consider object articulations [13,</ref>14,</ref><ref type="bibr" target="#b1 D models for particular object instances.</p><p>Category-level pose estimation aims to infer an object's pose and scale relative to a category-specific canonical representation. Recently, Wang et al. [28]</ref> extended the object coordinate based approach to perform categorylevel pose estimation. The key idea behind the intracategory generalization is to regress the is to regress the coordinates within a Normalized Object Coordinate Space (NOCS), where the sizes are normalized and the orientations are aligned for objects in a given category. Whereas the work by [28]</ref> focuses on pose and size estimation for rigid objects, the work presented here extends the NOCS concept to accommodate articulated objects at both part and ob p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">ANCSH Representation</head><p>Our ANCSH representation is inspired by and closely related to Normalized Object Coordinate Space (NOCS) [28]</ref>, which we briefly review here. NOCS is defined as a 3D space contained within a unit cube and was introduced in [28]</ref> to e to Normalized Object Coordinate Space (NOCS) [28]</ref>, which we briefly review here. NOCS is defined as a 3D space contained within a unit cube and was introduced in [28]</ref> to estimate the category-level 6D pose and size of rigid objects. For a given category, the objects are consistently aligned by their orientations in the NOCS nts in the eyeglasses category to be in right angles; we define the rest states of all drawers to be closed. In addition to normalizing the articulations, NAOCS applies the same normalization used in [28]</ref> to the objects, including zero-centering, aligning orientations, and uniformly scaling.</p><p>As a canonical object representation, NAOCS has the following ad ing each individual joint in NAOCS.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>NPCS.</head><p>For each part, NPCS further zero-centers its position and uniformly scales it as is done in [28]</ref>, while at the same time keeps its orientation unchanged as in NAOCS. In this respect, NPCS is defined similarly to NOCS [28]</r and uniformly scales it as is done in [28]</ref>, while at the same time keeps its orientation unchanged as in NAOCS. In this respect, NPCS is defined similarly to NOCS [28]</ref> but for individual parts instead of whole objects. NPCS provides a part reference frame and we can define the part pose and scale as the transformation from N sizes {R (j) , t (j) , s (j) } for each part S (j) .</p><p>Considering a part S (j) , for the points {p i ∈ S (j) }, we have their corresponding NPCS predictions {c i |p i ∈ S (j) }. We could follow [28]</ref> to perform pose fitting, where the Umeyama algorithm [26]</ref> is adopted within a RANSAC [10]</ s. Then we fix {s (j) } and adopt a non-linear least-squares solver to further optimize {R (j) , t (j) }, as is commonly done for bundle adjustment [2]</ref>. Similar to [28]</ref>, we also use RANSAC for outlier removal.</p><p>Finally, for each part S (j) , we use the fitted R (j) , t (j) , s (j) and the NPCS {c i |p i ∈ S (j) } to comp we also use RANSAC for outlier removal.</p><p>Finally, for each part S (j) , we use the fitted R (j) , t (j) , s (j) and the NPCS {c i |p i ∈ S (j) } to compute an amodal bounding box, the same as in [28]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Camera-Space Joint Parameters and Joint States Estimation</head><p>Knowing {R (j) , t (j) ,
c i |p i ∈ S (j) }. We could follow [28]</ref> to perform pose fitting, where the Umeyama algorithm [26]</ref> is adopted within a RANSAC [10]</ref> framework to robustly estimate the 6D pose and size of a single rigid object. However, without leveraging joint constraints, naively applying this approach to
ibr" target="#b30">[31,</ref>25,</ref>24,</ref>28]</ref>. Algorithms that do consider object articulations [13,</ref>14,</ref>12,</ref>16]</ref> often require the exact object CAD mod ied geometry predictions like length, width are for the whole object with scale variation only.</p><p>Another line of work relies on active manipulation of an object to infer its articulation pattern [13,</ref>14,</ref>12,</ref>16,</ref>32]</ref
ibr" target="#b23">24,</ref>28]</ref>. Algorithms that do consider object articulations [13,</ref>14,</ref>12,</ref>16]</ref> often require the exact object CAD model and the associated joint parameters at test time, preventing them from general ariation only.</p><p>Another line of work relies on active manipulation of an object to infer its articulation pattern [13,</ref>14,</ref>12,</ref>16,</ref>32]</ref>. For example, Katz et al. [14]</ref>, uses a rob
the human body and the human hand. For human pose estimation, approaches have been developed using end-to-end networks to predict 3D joint locations directly [17,</ref>23,</ref>19]</ref>, using dense correspondence maps between 2D images and 3D surface models [3]</ref>, or es
dense correspondence maps between 2D images and 3D surface models [3]</ref>, or estimating full 3D shape through 2D supervision [15,</ref>20]</ref>. Similarly, techniques for hand pose estimation (e.g., [27,</ref>11]</ref>) leverages dense coord
del with an observed 3D point cloud. Another family of approaches aim to regress the object coordinates onto its CAD model for each observed object pixel, and then use voting to solve for object pose [6,</ref>7]</ref>. These approaches are limited by the need to have exact CAD models for particular object instances.</p><p>Category-level p
ype="bibr" target="#b18">19]</ref>, using dense correspondence maps between 2D images and 3D surface models [3]</ref>, or estimating full 3D shape through 2D supervision [15,</ref>20]</ref>. Similarly, techniques for hand pose estimation (e.g., [27,</ref><ref type="bibr" targe
c i |p i ∈ S (j) }. We could follow [28]</ref> to perform pose fitting, where the Umeyama algorithm [26]</ref> is adopted within a RANSAC [10]</ref> framework to robustly estimate the 6D pose and size of a single rigid object. However, without leveraging joint constraints, naively applying this approach to
ibr" target="#b23">24,</ref>28]</ref>. Algorithms that do consider object articulations [13,</ref>14,</ref>12,</ref>16]</ref> often require the exact object CAD model and the associated joint parameters at test time, preventing them from general ariation only.</p><p>Another line of work relies on active manipulation of an object to infer its articulation pattern [13,</ref>14,</ref>12,</ref>16,</ref>32]</ref>. For example, Katz et al. [14]</ref>, uses a rob
on, dense coordinate predictions in each NPCS, transformations from each NPCS to NAOCS, and joint parameters in NAOCS, correspondingly. The network is based on two modules adapted from the PointNet++ [21]</ref> segmentation architecture. The part segmentation head predicts a per-point probability distribution among the M rigid parts. The NPCS head predicts M coordina
ref>. Augmenting text-based retrieval with external structured information, such as knowledge graph and Wikipedia hyperlinks, has also been explored recently (Min et al., 2019b;</ref>Asai et al., 2020)</ref>. The use of dense vector representations for retrieval has a long history since Latent Semantic Analysis (Deerweste
eb. WebQuestions (WQ) (Berant et al., 2013</ref>) consists of questions selected using Google Suggest API, where the answers are entities in Freebase. CuratedTREC (TREC) (Baudi? and ?ediv?, 2015)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Selection of positive passages</head><p>Because only pairs of questions and ans
(e.g., Chen et al., 2017;</ref>Yang et al., 2019a,b;</ref>Nie et al., 2019;</ref>Min et al., 2019a;</ref>Wolfson et al., 2020)</ref>. Augmenting text-based retrieval with external structured information, such as knowledge graph and Wikipedia hyperlinks, has also been explor
erwester et al., 1990)</ref>. Using labeled pairs of queries and documents, discriminatively trained dense encoders have become popular recently (Yih et al., 2011;</ref>Huang et al., 2013;</ref>Gillick et al., 2019)</ref>, with applications to cross-lingual document retrieval, ad relevance prediction, Web
negative otherwise. This creates B training instances in each batch, where there are B -1 negative passages for each question. The trick of in-batch negatives has been used in the full batch setting (Yih et al., 2011)</ref> and more recently for mini-batch (Henderson et al., 2017;</ref>Gillick et al., 201 ent Semantic Analysis (Deerwester et al., 1990)</ref>. Using labeled pairs of queries and documents, discriminatively trained dense encoders have become popular recently (Yih et al., 2011;</ref>Huang et al., 2013;</ref>Gillick et al., 2019)</ref>, with applications to cross-li
r" target="#b39">(Voorhees, 1999)</ref> is a task that answers factoid questions using a large collection of documents. While early QA systems are often complicated and consist of multiple components (Ferrucci (2012)</ref>; Moldovan et al. (2003)</ref>, inter alia), the advances of reading comprehension models suggest a much simplified t
negatives has been used in the full batch setting (Yih et al., 2011)</ref> and more recently for mini-batch (Henderson et al., 2017;</ref>Gillick et al., 2019)</ref>. It has been shown to be an effective strategy for learning a dual-encoder model that boosts the number of training examples.</p></div> <div ries and documents, discriminatively trained dense encoders have become popular recently (Yih et al., 2011;</ref>Huang et al., 2013;</ref>Gillick et al., 2019)</ref>, with applications to cross-lingual document retrieval, ad relevance prediction, Web search and entity retrieval. Such approaches complement
f type="bibr" target="#b6">Das et al. (2019)</ref>, who propose to retrieve relevant passages iteratively using reformulated question vectors. As an alternative approach that skips passage retrieval, Seo et al. (2019)</ref> propose to encode candidate answer phrases as vectors and directly retrieve the answers to the input questions efficiently. Using additional pret A accuracy, as observed byWang et al. (2019)</ref>.</p></note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>  4  Exceptions include(Seo et al., 2019)</ref> and(Roberts et al., 2020)</ref>, which retrieves and generates the answers, respectively.</p></note> 			<note xml
(e.g., Chen et al., 2017;</ref>Yang et al., 2019a,b;</ref>Nie et al., 2019;</ref>Min et al., 2019a;</ref>Wolfson et al., 2020)</ref>. Augmenting text-based retrieval with external structured information, such as knowledge graph and Wikipedia hyperlinks, has also been explor
erwester et al., 1990)</ref>. Using labeled pairs of queries and documents, discriminatively trained dense encoders have become popular recently (Yih et al., 2011;</ref>Huang et al., 2013;</ref>Gillick et al., 2019)</ref>, with applications to cross-lingual document retrieval, ad relevance prediction, Web
Eq. ( 1</ref>). Applying it to selecting the passage from a small number of retrieved candidates has been shown to work well (Wang et al., 2019</ref>(Wang et al., , 2018;;</ref>Lin et al., 2018)</ref>.</p><p>Specifically, let P i ? R L?h (1 ? i ? k) be a BERT (base, uncased in our exper
r" target="#b39">(Voorhees, 1999)</ref> is a task that answers factoid questions using a large collection of documents. While early QA systems are often complicated and consist of multiple components (Ferrucci (2012)</ref>; Moldovan et al. (2003)</ref>, inter alia), the advances of reading comprehension models suggest a much simplified t
lity to have a task-specific representation. With special in-memory data structures and indexing schemes, retrieval can be done efficiently using maximum inner product search (MIPS) algorithms (e.g., Shrivastava and Li (2014)</ref>; Guo et al. (2016)</ref>).</p><p>However, it is generally believed that learning a good dense vector repre
negative otherwise. This creates B training instances in each batch, where there are B -1 negative passages for each question. The trick of in-batch negatives has been used in the full batch setting (Yih et al., 2011)</ref> and more recently for mini-batch (Henderson et al., 2017;</ref>Gillick et al., 201 ent Semantic Analysis (Deerwester et al., 1990)</ref>. Using labeled pairs of queries and documents, discriminatively trained dense encoders have become popular recently (Yih et al., 2011;</ref>Huang et al., 2013;</ref>Gillick et al., 2019)</ref>, with applications to cross-li
wn effective in passage or dialogue re-ranking tasks (Nogueira and Cho, 2019;</ref>Humeau et al., 2020)</ref>. Finally, a concurrent work (Khattab and Zaharia, 2020)</ref> demonstrates the feasibility of full dense retrieval in IR tasks. Instead of employing the dual-encoder framework, they introduced a la
transformed space. Inner product search has been widely used and studied, as well as its connection to cosine similarity and L2 distance (Mussmann and Ermon, 2016;</ref>Ram and Gray, 2012)</ref>. As our ablation study finds other similarity functions perform comparably (Section 5.2; Appendix B), we thus choose the simpler inner product
ior to cosine. Similarly, in addition to negative loglikelihood, a popular option for ranking is triplet loss, which compares a positive passage and a negative one directly with respect to a question (Burges et al., 2005)</ref>. Our experiments show that using triplet loss does not affect the results much. More details can be found in Appendix B.</p><p>Cross-dataset g
.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-domain question answering (QA) (Voorhees, 1999)</ref> is a task that answers factoid questions using a large collection of documents. While early QA systems are often complicated and consist of multip arginal loss in exact match accuracy (40.8 vs. 41.5 EM on NQ), which should be roughly comparable to ORQA's 5-passage setup.</p><p>Passage retrieval has been an important component for open-domain QA (Voorhees, 1999)</ref>. It not only effectively reduces the search space for answer extraction, but also identifies the support context for users to verify the answer. S
ory data structures and indexing schemes, retrieval can be done efficiently using maximum inner product search (MIPS) algorithms (e.g., Shrivastava and Li (2014)</ref>; Guo et al. (2016)</ref>).</p><p>However, it is generally believed that learning a good dense vector representation needs a large number of labeled pairs of question and
erwester et al., 1990)</ref>. Using labeled pairs of queries and documents, discriminatively trained dense encoders have become popular recently (Yih et al., 2011;</ref>Huang et al., 2013;</ref>Gillick et al., 2019)</ref>, with applications to cross-lingual document retrieval, ad relevance prediction, Web
ory data structures and indexing schemes, retrieval can be done efficiently using maximum inner product search (MIPS) algorithms (e.g., Shrivastava and Li (2014)</ref>; Guo et al. (2016)</ref>).</p><p>However, it is generally believed that learning a good dense vector representation needs a large number of labeled pairs of question and
d passages (or answers), without additional pretraining? By leveraging the now standard BERT pretrained model (Devlin et al., 2019)</ref> and a dual-encoder architecture (Bromley et al., 1994)</ref>, we focus on developing the right training scheme using a relatively small number of question and passage pairs. Through a series of careful
ifying the inner working mechanisms, GNNs cannot be fully trusted, which prevents their use in critical applications pertaining to fairness, privacy, and safety [7,</ref>40]</ref>. For example, we can train a GNN model to predict the effects of drugs where we treat each drug as a molecular graph. Without exploring the working mechanisms, ingly important but is still less explored. To the best of our knowledge, there is no existing study on interpreting GNNs at the model-level. The existing study [4,</ref>40]</ref> only provides example-level explanations for graph models. As a radical departure from existing work, we propose a novel interpretation technique, known as XGN ">Graph Model Interpretations</head><p>To the best of our knowledge, there are only a few existing studies focusing on the interpretability of deep graph models [4,</ref>40]</ref>. The recent GNN interpretation tool GNN Explainer [40]</ref> proposes to explain deep graph models at the example-level by learn b_4">1</ref>. Since there is no existing work investigating model-level interpretations of GNNs, we have no baseline to compare with. Note that existing studies [4,</ref>40]</ref> only focus on interpreting GNNs at example-level while ignoring the model-level explanations. Comparing with them is not expected since these example-level and xisting studies focusing on the interpretability of deep graph models [4,</ref>40]</ref>. The recent GNN interpretation tool GNN Explainer [40]</ref> proposes to explain deep graph models at the example-level by learning soft masks. For a given example, it applies soft masks to graph edges and node features
techniques have been proposed to explain deep learning models on image and text data. Depending on what kind of interpretations are provided, existing techniques can be categorized into example-level [5,</ref>9,</ref>29,</ref>31,</ref>32,</ref><re ef>43]</ref>, visualizations of intermediate feature maps [29,</ref>48]</ref>, and occlusion-based methods [5,</ref>9,</ref>45]</ref>. Instead of providing input-dependent explanations, model-level interpretations ai
46]</ref>. In addition, extensive efforts have been made towards different graph operations, such as graph convolution [13,</ref>16,</ref>19]</ref>, graph pooling [20,</ref>44]</ref>, and graph attention [10,</ref>< imension vector to represent its features. Graph neural networks learn node features based on these matrices. Even though there are several variants of GNNs, such as graph convolution networks (GCNs) [19]</ref>, graph attention networks (GATs) [37]</ref>, and graph isomorphism networks (GINs) [39]</ref>, t
ass score of class c i and be valid to graph rules. Since such guidance is not differentiable, we employ policy gradient [35]</ref> to train the generator. According to [21,</ref>42]</ref>, the loss function for the action a t at step t can be mathematically written as</p><formula xml:id="formula_7">L д =
f>9,</ref>29,</ref>31,</ref>32,</ref>43,</ref>45,</ref>48]</ref> or model-level [8,</ref>24,</ref><ref type="bibr" target=" eature maps [29,</ref>48]</ref>, and occlusion-based methods [5,</ref>9,</ref>45]</ref>. Instead of providing input-dependent explanations, model-level interpretations aim to explain the general behavior of the model by investigating what input pa
ass score of class c i and be valid to graph rules. Since such guidance is not differentiable, we employ policy gradient [35]</ref> to train the generator. According to [21,</ref>42]</ref>, the loss function for the action a t at step t can be mathematically written as</p><formula xml:id="formula_7">L д =
prediction, without respect to any specific input example. Input optimization [8,</ref>[24]</ref>[25]</ref>[26]</ref> is the most popular model-level interpretation method. These two categories of interpretation methods aim at explaining deep models in different views. Since es for deep learning models on image data, known as input optimization methods [8,</ref>[24]</ref>[25]</ref>[26]</ref>. These methods generally generate optimized input that can maximize a certain behavior of deep models. They randomly initialize the input and iteratively upda ed input for interpreting image and text models is known as input optimization [8,</ref>[24]</ref>[25]</ref>[26]</ref>43]</ref>. However, as discussed in Section 2.2, such optimization method cannot be applied to interpret graph models because of
ass score of class c i and be valid to graph rules. Since such guidance is not differentiable, we employ policy gradient [35]</ref> to train the generator. According to [21,</ref>42]</ref>, the loss function for the action a t at step t can be mathematically written as</p><formula xml:id="formula_7">L д =
" target="#b31">32,</ref>43,</ref>45,</ref>48]</ref> or model-level [8,</ref>24,</ref>25]</ref> methods. Example-level interpretations explain the prediction for a given input example, by determining important featu l behavior of the model by investigating what input patterns can lead to a certain prediction, without respect to any specific input example. Input optimization [8,</ref>[24]</ref>[25]</ref>[26]</ref> is the most popular model-level interpretation method. These two categories ions</head><p>Next, we briefly discuss popular model-level interpretation techniques for deep learning models on image data, known as input optimization methods [8,</ref>[24]</ref>[25]</ref>[26]</ref>. These methods generally generate optimized input that can maximize a certai ere G * is the optimized input graph we need. A popular way to obtain such optimized input for interpreting image and text models is known as input optimization [8,</ref>[24]</ref>[25]</ref>[26]</ref>43]</ref>. However, as discussed in Section 2.
models, such as sensitivity analysis (SA) [12]</ref>, guided backpropagation (GBP) [33]</ref>, and layer-wise relevance propagation (LRP) [3]</ref>. The SA and GBP methods are based on the gradients while the LRP method computes the saliency maps by decomposing the output While input-dependent explanations
obtained the state-of-the-art performance on different graph tasks, such as node classification [11,</ref>37]</ref>, graph classification [39,</ref>47]</ref>, and link prediction [46]</ref>. In addition, extensive efforts have been made towards , such as graph convolution networks (GCNs) [19]</ref>, graph attention networks (GATs) [37]</ref>, and graph isomorphism networks (GINs) [39]</ref>, they share a similar feature learning strategy. For each node, GNNs update its node features by aggregating the features from its neighbors and combining the
systems. With this, it outperforms the accuracy of an RNN-based system (similar to Hellendoorn et al. 2017b) by 37.0%, the Deep3 system (Raychev et al., 2016a) by 29.7%, and an adaptation of Code2Seq (Alon et al., 2019a)</ref> for code prediction by 30.0%. These are significant margins.</p><p>We present in the paper several ways of communicating the code structure to kschmidt et al., 2019</ref>, Hellendoorn et al., 2020</ref>, Yang and Xiang, 2019)</ref>. We include an adaptation of path-based Code2Seq (Alon et al., 2019a)</ref> in our evaluations and show that our models significantly outperforms Code2Seq .</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1. models as well as models from previous work (SeqRNN (Hellendoorn and Devanbu, 2017b)</ref>, Deep3 (Raychev et al., 2016a)</ref>, Code2Seq (Alon et al., 2019a)</ref>).</p><p>Fig 3 puts these models in perspective. Along the x-axis is an indication whether the model considers only source code tokens as text, • from 43.9% to 73.6% when comparing a non-neural tree based model (Deep3 (Raychev et al., 2016a</ref>)) vs. TravTrans+ ; • from 43.6% to 73.6% when comparing Code2Seq (Alon et al., 2019a)</ref>  Thus, we argue that our proposal of using Transformer+ with tree inputs for code prediction is both practical and surpasses previous work by a , 2020</ref>, Raychev et al., 2014</ref>, Svyatkovskiy et al., 2019)</ref>; this model works on token sequences. We also include Code2Seq (Alon et al., 2019a)</ref> to compare our efforts against a popular code embedding technique that works on ASTs, albeit one that is not meant for next token prediction; i nerate target method summarization.</p><p>The original task of Code2Seq was method summarization: given a method body, how well can Code2Seq generate the correct method name? The training proposed in (Alon et al., 2019a)</ref> is not well suited for next token prediction. In code summarization, a set of leaf-to-leaf paths needs to be created one time for a method. By e="bibr" target="#b21">(Hellendoorn and Devanbu, 2017a</ref>, Karampatsis et al., 2020</ref>, Li et al., 2018)</ref>), to paths in an AST (Alon et al., 2019a</ref>(Alon et al., ,b, 2020))</ref>, and sometimes even ways to convey static analysis information to the neural network <ref type="b ">1</ref>, makes it an interesting comparison. We explore this similarity further in Sec 6.2.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Code2Seq</head><p>Code2Seq is a model by Alon et al. 2019a</ref> that embeds code snippets by embedding AST paths in a neural network.</p><p>At a high-level, given an AST, Code2Seq creates path representations f
</p><p>Transformers. Researchers in the natural language processing (NLP) community have recently developed Transformers, a new neural architecture for even more effective natural language processing (Vaswani et al., 2017)</ref>. Transformers overcome a major drawback of RNNs' ineffectiveness in capturing long-term dependencies by solely relying on attention mechanis ment to pass along more context information, as explained in (Dai et al., 2019)</ref>.</p><p>A.3 Why not Positional Encoding? Some Transformers uses positional encoding (Vaswani et al., 2017)</ref> or positional embedding (Radford et al., 2019)</ref> to provide model extra positional information over eleme is the dimension of key vectors. An operational example of self-attention for our SeqTrans model is presented in Sec 2.3.1. For other details (especially on the multi-head attention), please refer to Vaswani et al. (2017)</ref> and in particular, GPT-2 (Radford et al., 2019)</ref>, for a more thorough description.</p><p>The next sections discuss vari
hidden states.</p><p>A limitation of RNNs is the difficulty they have in tracking long-range dependence, even with various proposals to mitigate the problem (e.g. long-short-term-memory (LSTM) cells (Hochreiter and Schmidhuber, 1997)</ref>, which we do use in our implementation, attention on top of RNNs (Iyer et al., 2016)</ref>, and s
e="bibr" target="#b27">(Karampatsis et al., 2020)</ref>. Indeed, several papers in the literature, including work done in industrial contexts (Aye and Kaiser, 2020</ref>, Raychev et al., 2014</ref>, Svyatkovskiy et al., 2019)</ref> has used RNNs. Attempts has been made on feeding RNNs (LSTMs) with serializ epresentative of recent RNN-based methods used in recent papers for code prediction (Aye and Kaiser, 2020, Hellendoorn and Devanbu, 2017b, Karampatsis et al., 2020</ref>, Raychev et al., 2014</ref>, Svyatkovskiy et al., 2019)</ref>; this model works on token sequences. We also include Code2Seq <ref type="b e predicting location is available (Allamanis et al., 2018b</ref>, Alon et al., 2020</ref>, Brockschmidt et al., 2019</ref>, Raychev et al., 2014)</ref> or where the granularity of prediction is smaller (e.g. characters (Bielik et al., 2016b)</ref> or subtokens rg/ns/1.0"><head n="3.1">SeqRNN</head><p>For next token prediction, a popular method is to feed the source sequence tokens into an RNN (or LSTM) (Aye and Kaiser, 2020, Hellendoorn and Devanbu, 2017b, Raychev et al., 2014</ref>, Svyatkovskiy et al., 2019)</ref>. In this way, we create a language model that computes the probability of the

e="bibr" target="#b27">(Karampatsis et al., 2020)</ref>. Indeed, several papers in the literature, including work done in industrial contexts (Aye and Kaiser, 2020</ref>, Raychev et al., 2014</ref>, Svyatkovskiy et al., 2019)</ref> has used RNNs. Attempts has been made on feeding RNNs (LSTMs) with serializ epresentative of recent RNN-based methods used in recent papers for code prediction (Aye and Kaiser, 2020, Hellendoorn and Devanbu, 2017b, Karampatsis et al., 2020</ref>, Raychev et al., 2014</ref>, Svyatkovskiy et al., 2019)</ref>; this model works on token sequences. We also include Code2Seq <ref type="b e predicting location is available (Allamanis et al., 2018b</ref>, Alon et al., 2020</ref>, Brockschmidt et al., 2019</ref>, Raychev et al., 2014)</ref> or where the granularity of prediction is smaller (e.g. characters (Bielik et al., 2016b)</ref> or subtokens rg/ns/1.0"><head n="3.1">SeqRNN</head><p>For next token prediction, a popular method is to feed the source sequence tokens into an RNN (or LSTM) (Aye and Kaiser, 2020, Hellendoorn and Devanbu, 2017b, Raychev et al., 2014</ref>, Svyatkovskiy et al., 2019)</ref>. In this way, we create a language model that computes the probability of the
>.</p><p>Traditional ML-based techniques for Code Completion. Some of the early ML models for code prediction relied on n-gram language models (Hindle et al., 2016</ref>, Nguyen et al., 2013</ref>). An n-gram language model computes the probability of the next token given previous n tokens (n-grams) as context. Specifically, the model e
ues to developer productivity tools (Allamanis et al., 2018a)</ref>, and in particular, to code prediction (Brockschmidt et al., 2019</ref>, Hindle et al., 2016</ref>, Li et al., 2018</ref>, Raychev et al., 2016a)</ref>. The idea of code prediction in general f type="bibr" target="#b5">(Allamanis et al., 2018a)</ref>.</p><p>Traditional ML-based techniques for Code Completion. Some of the early ML models for code prediction relied on n-gram language models (Hindle et al., 2016</ref>, Nguyen et al., 2013</ref>). An n-gram language model computes the probability of the next token given previous
this body of work is in the different ways in which they represent a program as an input to a neural architecture. These representations have ranged from linear token sequence (as for code prediction (Hellendoorn and Devanbu, 2017a</ref>, Karampatsis et al., 2020</ref>, Li et al., 2018)</ref>), to paths in
e entailment.</p><p>There has been a surge of interest since 2019 in extending Transformer models to handle beyond sequential structures for NLP (Ahmed et al., 2019</ref>, Nguyen et al., 2020</ref>, Wang et al., 2019)</ref>. In the realm of learning over source code using transformers, it has been shown that taking tree
ore challenging when predicting identifiers, such as method names, variable names, and so on, as developers can come up with arbitrary identifier names. Possible mitigation includes copying mechanism (Allamanis et al., 2016</ref>, Brockschmidt et al., 2019</ref>, Fernandes et al., 2019)</ref> and open-vocabulary models <

ues to developer productivity tools (Allamanis et al., 2018a)</ref>, and in particular, to code prediction (Brockschmidt et al., 2019</ref>, Hindle et al., 2016</ref>, Li et al., 2018</ref>, Raychev et al., 2016a)</ref>. The idea of code prediction in general f type="bibr" target="#b5">(Allamanis et al., 2018a)</ref>.</p><p>Traditional ML-based techniques for Code Completion. Some of the early ML models for code prediction relied on n-gram language models (Hindle et al., 2016</ref>, Nguyen et al., 2013</ref>). An n-gram language model computes the probability of the next token given previous
in our datasets, it doubled the number). An improvement to this sliding window technique would be to maintain the hidden states at each segment to pass along more context information, as explained in (Dai et al., 2019)</ref>.</p><p>A.3 Why not Positional Encoding? Some Transformers uses positional encoding (Vaswani et al., 2017)</ref> o
e of code, as opposed to seeing code as text. These include probabilistic contextfree grammars (Allamanis and Sutton, 2014)</ref> and probabilistic higher-order grammars (Bielik et al., 2016a</ref>, Raychev et al., 2016a,b)</ref>. This class of models considers code artifacts as abstract syntax trees, and make their pred
ore challenging when predicting identifiers, such as method names, variable names, and so on, as developers can come up with arbitrary identifier names. Possible mitigation includes copying mechanism (Allamanis et al., 2016</ref>, Brockschmidt et al., 2019</ref>, Fernandes et al., 2019)</ref> and open-vocabulary models <
e of code, as opposed to seeing code as text. These include probabilistic contextfree grammars (Allamanis and Sutton, 2014)</ref> and probabilistic higher-order grammars (Bielik et al., 2016a</ref>, Raychev et al., 2016a,b)</ref>. This class of models considers code artifacts as abstract syntax trees, and make their pred
with serialized ASTs (Liu et al., 2016)</ref>; accuracy is further improved by using more AST guided architectures (Li et al., 2018</ref>, Liu et al., 2020)</ref>. We include a variation of an RNN (LSTM)-based model in our evaluation.</p><p>Among other flavors of code completion, such as where program aft

learning techniques over Code, beyond Code</head><p>Completion. There are many other uses of deep learning techniques for code, beyond code completion. These include techniques for code summarization (Alon et al., 2019b)</ref>, bug finding (Allamanis et al., 2018b)</ref>, repair (Vasic et al., 2019)</ref> an br" target="#b35">Raychev et al. (Raychev et al., 2016a)</ref> had found that-for the code prediction problem-a non-neural but tree aware engine could outperform RNNs. In the same spirit, Alon et al. (Alon et al., 2019b)</ref> had found-for code summarization problem (though not for code prediction in their paper)-that embedding the AST structure of code even in limit
hidden states.</p><p>A limitation of RNNs is the difficulty they have in tracking long-range dependence, even with various proposals to mitigate the problem (e.g. long-short-term-memory (LSTM) cells (Hochreiter and Schmidhuber, 1997)</ref>, which we do use in our implementation, attention on top of RNNs (Iyer et al., 2016)</ref>, and s
ne of work carries out code prediction based on statistics (in the training corpus) on syntactic structure of code, as opposed to seeing code as text. These include probabilistic contextfree grammars (Allamanis and Sutton, 2014)</ref> and probabilistic higher-order grammars (Bielik et al., 2016a</ref>, Raychev et al., 20
r classifiers to build prediction models. Shi et al. (2016)</ref> proposed a local classification-based method based on structure similarity and side effect similarity. Ferdousi et al. (2017)</ref> predicted DDIs based on drug functional similarities. Kastrin et al. (2018)</ref> proposed a statistical learn
and integrated multiple similarities for better solutions. Park et al. (2015)</ref> applied the random walk with restart on the protein-protein network to predict DDIs. Sridhar et al. (2016)</ref> proposed a probabilistic approach to infer DDIs from the network, which was constructed based on multiple drug-drug similarities and known in
www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The prevalence of polypharmacy is increasing over recent years, especially among the elders who suffer from multiple diseases. The recent study (Kantor et al., 2015;</ref>Qato et al., 2016)</ref> showed that 67% of elderly Americans took five or more medications in 2010-2011, includ
prediction after a softmax layer. Between layers, we add batch normalization layers (Ioffe and Szegedy, 2015)</ref> to accelerate the convergence, and add dropout layers (Srivastava et al., 2014)</ref> to avoid over-fitting and enhance generalization ability.</p><p>The combination of different sub-models is important for DDIMDL. Here, th
to reduce time and cost (Wishart et al., 2008</ref>(Wishart et al., , 2006;;</ref>Wang et al., 2009;</ref>Kanehisa et al., 2010;</ref>Kuhn et al., 2010;</ref>Li et al., 2010;</ref>Kno
ormances than individual models. Deepika and Geetha (2018) adopted a semi-supervised learning framework with network representation learning and meta-learning from four drug datasets to predict DDIs. Zhang et al. (2017)</ref> applied ensemble methods with chemical, biological, phenotypic and network data to predict potential DDIs. Zhang
u et al. (2018)</ref> classified the biological events collected from DrugBank into 86 types and built the deep learning-based model based on drug chemical substructures to predict DDI events. Later, Lee et al. (2019)</ref> directly merged three features as input of a DNN to build a prediction model.</p><p>Although the above works have made crucial efforts on the eve oreover, we implement a deep neural network (DNN) which has the same structure as DDIMDL's sub-models, but the DNN  concatenates all features straightly as its input. The same structure is adopted by (Lee et al., 2019)</ref>. We compare DDIMDL with it to demonstrate the usefulness of multimodal deep learning. Thus, the models based on RF, KNN, LR and DNN are used as t prediction, and our multimodal deep learning framework outperforms the traditional classifiers and deep network structures in previous studies (Ryu et al., 2018;</ref>Lee et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Case study</head><p>In this section, we conduct case studies to validate the us
r understanding of DDIs. However, DDIs can lead to different biological consequences or events. Predicting DDI-associated events is a meaningful and challenging task, and has received some attention. Herrero-Zazo et al. (2013)</ref> built a manually annotated corpus for DDIs in biomedical texts. They collected DDIs from DrugBank and MedLine, and annotated the DDI rela
and integrated multiple similarities for better solutions. Park et al. (2015)</ref> applied the random walk with restart on the protein-protein network to predict DDIs. Sridhar et al. (2016)</ref> proposed a probabilistic approach to infer DDIs from the network, which was constructed based on multiple drug-drug similarities and known in
he prevalence of polypharmacy is increasing over recent years, especially among the elders who suffer from multiple diseases. The recent study (Kantor et al., 2015;</ref>Qato et al., 2016)</ref> showed that 67% of elderly Americans took five or more medications in 2010-2011, including prescription drugs, over-the-counter drugs and dietar
ation, the therapeutic efficacy and so on. The "action" represents the increase or decrease after lemmatization. Since descriptions about DDIs in DrugBank have fixed syntax, we apply StanfordNLP tool (Qi et al., 2018)</ref> to obtain the dependency relationship. By using the tool, we can obtain a tuple for each word. We selected index (index of the word in the senten
mized ranking function automatically [10]</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ref>. To generate diversified results, these methods either explicitly model subtopic coverage of the results [6]</ref><ref type="bib pervised explicit approaches are proposed e.g. xQuAD [7]</ref>, PM2 [8]</ref>, HxQuAD/HPM2 [9]</ref> and DSSA [14]</ref>.</p><p>Those existing approaches used greedy document sequential selection. They compare every single candidate document with the selected document sequence, ranking list. Since the information utilities of the candidate documents are not independent, this strategy may not lead to global optimal rankings. Based on the reinforced learning approach MDP-DIV [14]</ref>, Feng [15]</ref> proposed the M2DIV model with the Monte-Caro Tree Search (MCTS) to search a larger ranking space and minimize opic relevance features 𝒙 𝑞 𝑖 :</p><formula xml:id="formula_4">𝑠 𝑞 𝑖 = 𝒙 𝑇 𝑞 𝑖 𝒘 𝑟 (𝑖 ∈ [1, 𝑘]).</formula><p>Here 𝒘 𝑟 is a learnable parameter. We use the same relevance features as the previous work [14]</ref> for 𝒙 𝑞 and 𝒙 𝑞 𝑖 , including BM25, TF-IDF, language model scores, Page Rank, the numbers of incoming links and outgoing links, et al. More details about thes 13">[14]</ref> for 𝒙 𝑞 and 𝒙 𝑞 𝑖 , including BM25, TF-IDF, language model scores, Page Rank, the numbers of incoming links and outgoing links, et al. More details about these features can be found in [14]</ref> and we omit the details due to space limitation. In the future, we plan to explore more neural-based features.</p><p>(5) The Final Ranking. The summarized doc , and return the encoded representation of the subtopics. This is because the subtopic embeddings we used are actually the document embeddings. We use the subtopic embeddings released by Jiang et al. [14]</ref> based on doc2vec. The subtopic embeddings is produced from the pseudo documents of those corresponding subqueries: retrieve top Z documents with traditional I .<label>(12)</label></formula><p>3.5.1 The list-pairwise sampling. Since the dataset of search result diversification task is limited, we inherit the list-pairwise sampling approach from Jiang et al. [14]</ref> in order to get enough training samples. We are using pairs of training samples (𝐶, 𝑑 1 , 𝑑 1 ) with common context 𝐶, appending document pair 𝑑 1 and 𝑑 2 to l those subtopics with uniform weights.</p><p>For a fair comparison, we are using the document relevance features and embeddings exactly the same as the DSSA, which have been released by Jiang et al. [14]</ref> in the repository on GitHub2</ref> . Those training data includes 18 relevance features for each query and subquery produced ">[31]</ref> (denoted as S-rec). Inheriting the spirit of the previous works [11]</ref>[12]</ref>[13]</ref>[14]</ref>, all those metrics are computed on top 20 results of a document ranking list. Two-tailed paired t-test are used to conduct significance testing with p-value&l iversification.</p><p>R-LTR [11]</ref>, PAMM [12]</ref> and PAMM-NTN [13]</ref>. Inspired by previous work [14]</ref>, we use the metric of 𝛼 − 𝑛DCG@20 to tune the parameters. The neural tensor network(NTN) is used with both R-LTR and PAMM, denoted as R-LTR-NTN and PAMM-NTN. ranking 𝜏 − are tuned per query for the PAMM. The distributed representations of documents here are 100-dimensional vectors generated by the LDA [32]</ref>.</p><p>DSSA [14]</ref>. We train the DSSA model with the code and data released by Jiang et al. on GitHub5</ref> , and use the following optimized reported in the work, instead we use the doc2vec embedding released for a fair comparison. The result is denoted as DSSA (doc2vec).</p><p>Since the deep reinforced learning based models e.g. MDP-DIV [14]</ref> and M2DIV [15]</ref> are taking too much time to train, we do not take those models as baseline.</p></div> <div xmlns="http://w itly model subtopic coverage of the results [6]</ref>[7]</ref>[8]</ref>[9]</ref>14]</ref> (i.e., explicit approaches), or directly reduce result redundancy by comparing document-document similarity regardless the use of subtopics <ref type="bibr" ta
ism modeling each position in a sequence and compute the representation for each hidden state of the sequence. Recently, the models fully based on self-attention mechanism (denoted as self-attention  [16]</ref> in the Neural Machine Translation (NMT) task, have achieved great successes on many NLP tasks. Researchers have used self-attention networks, e.g. GPT <ref ty
="#b8">[9]</ref>. While in recent years, more and more researchers tried to use machine learning methods in search result diversification in order to learn an optimized ranking function automatically [10]</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ get="#b13">14]</ref> (i.e., explicit approaches), or directly reduce result redundancy by comparing document-document similarity regardless the use of subtopics [5,</ref>[10]</ref>[11]</ref>[12]</ref>[13]</ref> (i.e., implicit approaches).</p><p>T core of the candidate document is the linear combination of the relevance score and the novelty score. Inheriting the spirit of MMR, researchers have also proposed supervised methods, such as SVM-DIV [10]</ref>, R-LTR [11]</ref>), PAMM [12]</ref>, and PAMM-NTN [13]</ref>), for the relevance and diversity linearly. HxQuAD and HPM2 requires extra parameter 𝛼 to control the weights of the hierarchical subtopic layers. The parameters are tuned with cross validation and ListMLE [10]</ref> is used to learn a prior relevance function with no diversification.</p><p>R-LTR [11]</ref>, PAMM <ref type="bibr" target="#b11"
ct> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Research shows that most queries issued by users are short [1]</ref>[2]</ref>[3]</ref>[4]</ref>, and these queries could be ambiguous or va
="bibr" target="#b17">[18]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1.2</head><p>The evaluation metrics. The official diversity evaluation metrics of Web Track include ERR-IA [28]</ref>, 𝛼-nDCG [29]</ref> and NRBP [30]</ref>, which are used in our experiments. Besides the metrics a
Process with Self-Attention</head><p>As we described above, research shows that the diversity ranking is NP-hard and for most of the previous models, greedy sequential selection is a common solution [25]</ref>. Those models will compare every candidate document with the selected sequence and select the best candidate document one-by-one appending it into the selecte
achieved great successes on many NLP tasks. Researchers have used self-attention networks, e.g. GPT [17]</ref>, BERT [18]</ref> and ERNIE [19]</ref>, as alternatives to RNNs and CNNs in many NLP tasks. However, to the best of our knowledge, only a few researchers [20,</ref><r
="bibr" target="#b17">[18]</ref> and ERNIE [19]</ref>, as alternatives to RNNs and CNNs in many NLP tasks. However, to the best of our knowledge, only a few researchers [20,</ref>21]</ref> have tried to use the self-attention network in the information retrieval tasks. There are no self-attention based mod S 𝐷 . Recall that different from those greedy sequential selection based models, DESA doesn't depend on the sequential selection process. This is similar to some ad-hoc ranking models such as SetRank [20]</ref>.</p><p>This process is formulated as the following equations:</p><formula xml:id="formula_5">𝒗 𝑑 𝑡 ,𝑞,𝑞 𝑖 = [𝒙 𝑞 ; 𝒉 enc 𝑡 ; 𝒉 dec 𝒕 ; 𝑠 𝑞 1 , . . . , 𝑠 𝑞 𝑘 ] and the query matrix can be defined as 𝒒 = 𝑫.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.2</head><p>The Multi-Head Attention Component. Following by some previous work e.g. SetRank [20]</ref>, we use the multi-head strategy in order to learn multiple aspects of different documents. The multihead attention strategy denoted as MultiHead will first pr >where 𝒂 𝑖 is defined by:</p><formula xml:id="formula_11">𝒂 𝑖 = Attn(𝒒𝑾 𝑄 𝑖 , 𝑲𝑾 𝐾 𝑖 , 𝑽𝑾 𝑉 𝑖 ), 𝑖 ∈ [1, ℎ].<label>(6)</label></formula><p>Here all those 𝑾 parameters are learnable. Previous research [20]</ref> has shown that using the multi-head strategy may help the selfattention network to learn better document similarity distribution at multi aspects. For the sel diversified initial ranking sequence as input, and jointly return the diversified ranking scores of all those documents. Similar as some other selfattention based ad-hoc ranking approach e.g. SetRank [20]</ref>, the model can return the ranking list with sorting all the candidate documents with their ranking scores. Different from the greedy document sequential selec levance scores of subtopics.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Discussion</head><p>DESA is inspired by several existing models in IR based on selfattention e.g. SetRank [20]</ref>. And the implicit implementation of DESA with no subtopics can be seen as an adaption of SetRank for search result diversification task. While the properties
="bibr" target="#b17">[18]</ref> and ERNIE [19]</ref>, as alternatives to RNNs and CNNs in many NLP tasks. However, to the best of our knowledge, only a few researchers [20,</ref>21]</ref> have tried to use the self-attention network in the information retrieval tasks. There are no self-attention based mod S 𝐷 . Recall that different from those greedy sequential selection based models, DESA doesn't depend on the sequential selection process. This is similar to some ad-hoc ranking models such as SetRank [20]</ref>.</p><p>This process is formulated as the following equations:</p><formula xml:id="formula_5">𝒗 𝑑 𝑡 ,𝑞,𝑞 𝑖 = [𝒙 𝑞 ; 𝒉 enc 𝑡 ; 𝒉 dec 𝒕 ; 𝑠 𝑞 1 , . . . , 𝑠 𝑞 𝑘 ] and the query matrix can be defined as 𝒒 = 𝑫.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.2</head><p>The Multi-Head Attention Component. Following by some previous work e.g. SetRank [20]</ref>, we use the multi-head strategy in order to learn multiple aspects of different documents. The multihead attention strategy denoted as MultiHead will first pr >where 𝒂 𝑖 is defined by:</p><formula xml:id="formula_11">𝒂 𝑖 = Attn(𝒒𝑾 𝑄 𝑖 , 𝑲𝑾 𝐾 𝑖 , 𝑽𝑾 𝑉 𝑖 ), 𝑖 ∈ [1, ℎ].<label>(6)</label></formula><p>Here all those 𝑾 parameters are learnable. Previous research [20]</ref> has shown that using the multi-head strategy may help the selfattention network to learn better document similarity distribution at multi aspects. For the sel diversified initial ranking sequence as input, and jointly return the diversified ranking scores of all those documents. Similar as some other selfattention based ad-hoc ranking approach e.g. SetRank [20]</ref>, the model can return the ranking list with sorting all the candidate documents with their ranking scores. Different from the greedy document sequential selec levance scores of subtopics.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Discussion</head><p>DESA is inspired by several existing models in IR based on selfattention e.g. SetRank [20]</ref>. And the implicit implementation of DESA with no subtopics can be seen as an adaption of SetRank for search result diversification task. While the properties
embeddings are generated by doc2vec with window size 5. In the future work we will try to import several deeplearning based technologies for feature extraction and document representation e.g. K-NRM [27]</ref> or BERT [18]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1.2</head><p>The evaluation metrics. The officia
mlns="http://www.tei-c.org/ns/1.0"><head>4.1.2</head><p>The evaluation metrics. The official diversity evaluation metrics of Web Track include ERR-IA [28]</ref>, 𝛼-nDCG [29]</ref> and NRBP [30]</ref>, which are used in our experiments. Besides the metrics above, we also include the metrics of Precision-IA
Process with Self-Attention</head><p>As we described above, research shows that the diversity ranking is NP-hard and for most of the previous models, greedy sequential selection is a common solution [25]</ref>. Those models will compare every candidate document with the selected sequence and select the best candidate document one-by-one appending it into the selecte
achieved great successes on many NLP tasks. Researchers have used self-attention networks, e.g. GPT [17]</ref>, BERT [18]</ref> and ERNIE [19]</ref>, as alternatives to RNNs and CNNs in many NLP tasks. However, to the best of our knowledge, only a few researchers [20,</ref><r
proaches are used. Most of the traditional approaches to search result diversification are unsupervised and they are based on handcrafted features and functions [5]</ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref>. While in recent years, more and more resea ">[12]</ref>[13]</ref>[14]</ref>. To generate diversified results, these methods either explicitly model subtopic coverage of the results [6]</ref>[7]</ref>[8]</ref>[9]</ref>14]</ref> (i. [29]</ref> and NRBP [30]</ref>, which are used in our experiments. Besides the metrics above, we also include the metrics of Precision-IA [6]</ref> (denoted as Pre-IA) and Subtopic Recall [31]</ref> (denoted as S-rec). Inheriting the spirit of the previous works <ref type="bib
achine learning methods in search result diversification in order to learn an optimized ranking function automatically [10]</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ref>. To generate diversified results, these methods either explicitly model subt dancy by comparing document-document similarity regardless the use of subtopics [5,</ref>[10]</ref>[11]</ref>[12]</ref>[13]</ref> (i.e., implicit approaches).</p><p>To simplify the problem and accelerate the online ranking, existing methods usuall core. Inheriting the spirit of MMR, researchers have also proposed supervised methods, such as SVM-DIV [10]</ref>, R-LTR [11]</ref>), PAMM [12]</ref>, and PAMM-NTN [13]</ref>), for learning a better document similarity function automatically. The explicit approaches model the 5">[6]</ref> (denoted as Pre-IA) and Subtopic Recall [31]</ref> (denoted as S-rec). Inheriting the spirit of the previous works [11]</ref>[12]</ref>[13]</ref>[14]</ref>, all those metrics are computed on top 20 results of a document ranking list cross validation and ListMLE [10]</ref> is used to learn a prior relevance function with no diversification.</p><p>R-LTR [11]</ref>, PAMM [12]</ref> and PAMM-NTN [13]</ref>. Inspired by previous work [14]</ref>, we use the metric of 𝛼 − 𝑛DCG@20
fication are unsupervised and they are based on handcrafted features and functions [5]</ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref>. While in recent years, more and more researchers tried to use machine learning methods in search result diversification #b13">[14]</ref>. To generate diversified results, these methods either explicitly model subtopic coverage of the results [6]</ref>[7]</ref>[8]</ref>[9]</ref>14]</ref> (i.e., explicit approaches), or directly reduce result redundancy by comparing do ery which has not been covered by the selected document as possible. Nowadays both unsupervised and supervised explicit approaches are proposed e.g. xQuAD [7]</ref>, PM2 [8]</ref>, HxQuAD/HPM2 [9]</ref> and DSSA [14]</ref>.</p><p>Those existing approaches used greedy document se #foot_3">4</ref> . All those diversification approaches in our experiments are using the search results of Lemur as initial ranking sequences.</p><p>xQuAD [7]</ref>, PM2 [8]</ref>, HxQuAD and HPM2 [9]</ref>. These are the unsupervised explicit baseline approaches for comparison. All the unsupervised methods u
proaches are used. Most of the traditional approaches to search result diversification are unsupervised and they are based on handcrafted features and functions [5]</ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref>. While in recent years, more and more resea ">[12]</ref>[13]</ref>[14]</ref>. To generate diversified results, these methods either explicitly model subtopic coverage of the results [6]</ref>[7]</ref>[8]</ref>[9]</ref>14]</ref> (i. [29]</ref> and NRBP [30]</ref>, which are used in our experiments. Besides the metrics above, we also include the metrics of Precision-IA [6]</ref> (denoted as Pre-IA) and Subtopic Recall [31]</ref> (denoted as S-rec). Inheriting the spirit of the previous works <ref type="bib
Process with Self-Attention</head><p>As we described above, research shows that the diversity ranking is NP-hard and for most of the previous models, greedy sequential selection is a common solution [25]</ref>. Those models will compare every candidate document with the selected sequence and select the best candidate document one-by-one appending it into the selecte
="#b8">[9]</ref>. While in recent years, more and more researchers tried to use machine learning methods in search result diversification in order to learn an optimized ranking function automatically [10]</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ get="#b13">14]</ref> (i.e., explicit approaches), or directly reduce result redundancy by comparing document-document similarity regardless the use of subtopics [5,</ref>[10]</ref>[11]</ref>[12]</ref>[13]</ref> (i.e., implicit approaches).</p><p>T core of the candidate document is the linear combination of the relevance score and the novelty score. Inheriting the spirit of MMR, researchers have also proposed supervised methods, such as SVM-DIV [10]</ref>, R-LTR [11]</ref>), PAMM [12]</ref>, and PAMM-NTN [13]</ref>), for the relevance and diversity linearly. HxQuAD and HPM2 requires extra parameter 𝛼 to control the weights of the hierarchical subtopic layers. The parameters are tuned with cross validation and ListMLE [10]</ref> is used to learn a prior relevance function with no diversification.</p><p>R-LTR [11]</ref>, PAMM <ref type="bibr" target="#b11"
="#b8">[9]</ref>. While in recent years, more and more researchers tried to use machine learning methods in search result diversification in order to learn an optimized ranking function automatically [10]</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ get="#b13">14]</ref> (i.e., explicit approaches), or directly reduce result redundancy by comparing document-document similarity regardless the use of subtopics [5,</ref>[10]</ref>[11]</ref>[12]</ref>[13]</ref> (i.e., implicit approaches).</p><p>T core of the candidate document is the linear combination of the relevance score and the novelty score. Inheriting the spirit of MMR, researchers have also proposed supervised methods, such as SVM-DIV [10]</ref>, R-LTR [11]</ref>), PAMM [12]</ref>, and PAMM-NTN [13]</ref>), for the relevance and diversity linearly. HxQuAD and HPM2 requires extra parameter 𝛼 to control the weights of the hierarchical subtopic layers. The parameters are tuned with cross validation and ListMLE [10]</ref> is used to learn a prior relevance function with no diversification.</p><p>R-LTR [11]</ref>, PAMM <ref type="bibr" target="#b11"
fication are unsupervised and they are based on handcrafted features and functions [5]</ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref>. While in recent years, more and more researchers tried to use machine learning methods in search result diversification #b13">[14]</ref>. To generate diversified results, these methods either explicitly model subtopic coverage of the results [6]</ref>[7]</ref>[8]</ref>[9]</ref>14]</ref> (i.e., explicit approaches), or directly reduce result redundancy by comparing do ery which has not been covered by the selected document as possible. Nowadays both unsupervised and supervised explicit approaches are proposed e.g. xQuAD [7]</ref>, PM2 [8]</ref>, HxQuAD/HPM2 [9]</ref> and DSSA [14]</ref>.</p><p>Those existing approaches used greedy document se #foot_3">4</ref> . All those diversification approaches in our experiments are using the search results of Lemur as initial ranking sequences.</p><p>xQuAD [7]</ref>, PM2 [8]</ref>, HxQuAD and HPM2 [9]</ref>. These are the unsupervised explicit baseline approaches for comparison. All the unsupervised methods u
based on handcrafted features and functions [5]</ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref>. While in recent years, more and more researchers tried to use machine learning methods in search result diversification in order to learn an optimized ranking ed results, these methods either explicitly model subtopic coverage of the results [6]</ref>[7]</ref>[8]</ref>[9]</ref>14]</ref> (i.e., explicit approaches), or directly reduce result redundancy by comparing document-document similarity regardless t nt as possible. Nowadays both unsupervised and supervised explicit approaches are proposed e.g. xQuAD [7]</ref>, PM2 [8]</ref>, HxQuAD/HPM2 [9]</ref> and DSSA [14]</ref>.</p><p>Those existing approaches used greedy document sequential selection. They compare every single candida nd we only use the first level of the subtopics with no hierarchical subtopics. The max subtopic number of the queries is 10, and the average subtopic number is about 9.48. As those previous works do [9]</ref> we treat all those subtopics with uniform weights.</p><p>For a fair comparison, we are using the document relevance features and embeddings exactly the same as use the search results produced by language model and retrieved by the Lemur service 3</ref> as the non-diversified baseline. These results are released by Hu et at. [9]</ref> and can be found on the website 4</ref> . All those diversification approaches in our experiments are using the search results n our experiments are using the search results of Lemur as initial ranking sequences.</p><p>xQuAD [7]</ref>, PM2 [8]</ref>, HxQuAD and HPM2 [9]</ref>. These are the unsupervised explicit baseline approaches for comparison. All the unsupervised methods use the parameter 𝜆 to combine the relevance and diversity
ermitt2/grobid"/> 				</application> 			</appInfo> 		</encodingDesc> 		<profileDesc> 			<abstract> <div xmlns="http://www.tei-c.org/ns/1.0"><p>We generalize deep self-attention distillation in MINILM (Wang et al., 2020)</ref> by only using self-attention relation distillation for taskagnostic compression of pretrained Transformers. In particular, we define multi-head tudent models using inverted-bottleneck and bottleneck structures to keep their layer number and hidden size the same, layer-wisely transferring hidden states and self-attention distributions. MINILM (Wang et al., 2020)</ref> proposes deep self-attention distillation, which uses self-attention distributions and value relations to help the student to deeply mimic teac leads to a restriction that the number of attention heads of student model has to be the same as its teacher.</p><p>In this work, we generalize and simplify deep self-attention distillation of MINILM (Wang et al., 2020)</ref> by using self-attention relation distillation. We introduce multi-head self-attention relations computed by scaled dot-product of pairs of quer her and student layers. MobileBERT (Sun et al., 2019b)</ref> assumes the student has the same number of layers as its teacher to perform layer-wise distillation. MINILM (Wang et al., 2020)</ref> transfers selfattention knowledge of teacher's last layer to the student last Transformer layer. Different from previous work, our method uses et="#b30">(Sanh et al., 2019;</ref>Tsai et al., 2019;</ref>Jiao et al., 2019;</ref>Sun et al., 2019b;</ref>Wang et al., 2020)</ref>. The student models are distilled from large pretrained Transformers using large-scale text corpora. The distilled task-agnostic model can be di d SQuAD 2.0. (1) Previous methods (Sanh et al., 2019;</ref>Jiao et al., 2019;</ref>Sun et al., 2019a;</ref>Wang et al., 2020)</ref>  MobileBERT compresses a specially designed teacher model (in the BERT LARGE size) with inverted bottleneck modules into a 24-layer student usin ults of DistilBERT are taken fromSanh et al. (2019)</ref>. The rest results of Distil-BERT, TinyBERT 2 , BERT SMALL , Truncated BERT BASE and 6×768 MINILM are taken fromWang et al. (2020)</ref>. BERT SMALL</figDesc><table><row><cell>Model</cell><cell>Teacher</cell><cell cols="9">#Param Speedup SQuAD2 MNLI-m QNLI QQP RTE SST MRPC CoLA Av
lize task-specific distillation (Sun et al., 2019a;</ref>Turc et al., 2019;</ref>Aguilar et al., 2019;</ref>Mukherjee and Awadallah, 2020;</ref>Xu et al., 2020;</ref>Hou et al., 2020;</ref><ref type="bibr" target="#
(Cer et al., 2017)</ref> and QQP), and four inference tasks (MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et al., 2016)</ref>, RTE (Dagan et al., 2006;</ref>Bar-Haim et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivo

gan et al., 2006;</ref>Bar-Haim et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivogli et al., 2009)</ref> and WNLI (Levesque et al., 2012)</ref>). Following BERT (Devlin et al., 2018)</ref> Following MobileBERT (Sun et al.,

gan et al., 2006;</ref>Bar-Haim et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivogli et al., 2009)</ref> and WNLI (Levesque et al., 2012)</ref>). Following BERT (Devlin et al., 2018)</ref> Following MobileBERT (Sun et al.,
tp://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pretrained Transformers (Radford et al., 2018;</ref>Devlin et al., 2018;</ref>Dong et al., 2019;</ref>Yang et al., 2019;</ref>Joshi et al., 2019;</ref>Liu e ead><p>Pretrained Transformers (Radford et al., 2018;</ref>Devlin et al., 2018;</ref>Dong et al., 2019;</ref>Yang et al., 2019;</ref>Joshi et al., 2019;</ref>Liu et al., 2019;</ref>Bao et to adapt to specific tasks. BERT (Devlin et al., 2018)</ref> proposes to pretrain a deep bidirectional Transformer using masked language modeling (MLM) objective. UNILM (Dong et al., 2019)</ref> is jointly pretrained on three types language modeling objectives to adapt to both understanding and generation tasks. XL-Net (
gan et al., 2006;</ref>Bar-Haim et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivogli et al., 2009)</ref> and WNLI (Levesque et al., 2012)</ref>). Following BERT (Devlin et al., 2018)</ref> Following MobileBERT (Sun et al.,
oLA and accuracy for the rest.</p><p>representation.</p><p>Extractive Question Answering The task aims to predict a continuous sub-span of the passage to answer the question. We evaluate on SQuAD 2.0 (Rajpurkar et al., 2018)</ref>, which has been served as a major question answering benchmark. We pack the question and passage tokens together with special tokens to fo esented in Table 6</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B SQuAD 2.0</head><p>We present the dataset statistics and metrics of SQuAD 2.0 5 (Rajpurkar et al., 2018)</ref> in Table 7</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>C Hyper-parameters for Fine-
oLA and accuracy for the rest.</p><p>representation.</p><p>Extractive Question Answering The task aims to predict a continuous sub-span of the passage to answer the question. We evaluate on SQuAD 2.0 (Rajpurkar et al., 2018)</ref>, which has been served as a major question answering benchmark. We pack the question and passage tokens together with special tokens to fo esented in Table 6</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B SQuAD 2.0</head><p>We present the dataset statistics and metrics of SQuAD 2.0 5 (Rajpurkar et al., 2018)</ref> in Table 7</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>C Hyper-parameters for Fine-
p><p>And the Oscar L creates new single-model SoTAs on VQA and NLVR2.  VQA One major vision-and-language understanding tasks for the existing VLP models is VQA. The SoTA result for VQA is from UNITER [6]</ref> large model. Table 6</ref> summarized the evaluation results with the recent VLP work on VQA task, we can see that Oscar B is _3">6</ref> summarized the evaluation results with the recent VLP work on VQA task, we can see that Oscar B is the best among the models with equivalent size, even slightly better (0.04%) than UNITER [6]</ref> large. And the Oscar L improves the SoTA overall accuracy with 0.42% on the test-std split.</p><p>NLVR2 Another major task for the existing VLP models is NLVR2. And the Oscar L improves the SoTA overall accuracy with 0.42% on the test-std split.</p><p>NLVR2 Another major task for the existing VLP models is NLVR2. Similarly, the SoTA model on NLVR2 is UNITER [6]</ref> large. As reported in Table 7</ref>, with the equivalent model sizes, Oscar outperforms UNITER by 0.31% and 0.46% absolutely o 5">5,</ref>47,</ref>36,</ref>19,</ref>10]</ref> employ BERT-like objectives [6]</ref> to learn crossmodal representations from a concatenated-sequence of visual region features and language token embeddings. They heavily rely on the self-attentio
ilar ideas are employed for image captioning [14]</ref> and text-based image retrieval [30]</ref>. In particular, the seminal work DeViSE [8]</ref> proposes to identify visual objects using semantic information gleaned from un-annotated text. This semantic information is exploited to make predictions of ima
the pre-training corpus based on the existing V+L datasets, including COCO [21]</ref>, Conceptual Captions (CC) [32]</ref>, SBU captions [27]</ref>, flicker30k [45]</ref>, GQA [13]</ref> etc. As shown in Table 
-text pairs, and that fine-tuning VLP models on task-specific data achieves state-of-the-art (SoTA) results on well-established V+L tasks.</p><p>These VLP models are based on multi-layer Transformers [40]</ref>. To pre-train such models, existing methods simply concatenate image region features and text features as input and resort to the self-attention mechanism to
n</head><p>Learning cross-modal representations is fundamental to a wide range of visionlanguage (V+L) tasks, such as visual question answering, image-text retrieval, image captioning. Recent studies [23,</ref>39,</ref>5,</ref>36,</ref>20,</ref>< beddings. They heavily rely on the self-attention mechanism of Transformers to learn joint representations that are appropriately contextualized in both modalities. For example, early efforts such as [23,</ref>39]</ref> propose a two-stream and three-stream Transformer-based framework with co-attention to fuse the two modalities, respec problems, such as visual questionanswering (VQA), image-text retrieval and image captioning etc. The existing methods [38,</ref>39,</ref>23,</ref>5,</ref>47,</ref>36,</ref>19,</ref><r
the pre-training corpus based on the existing V+L datasets, including COCO [21]</ref>, Conceptual Captions (CC) [32]</ref>, SBU captions [27]</ref>, flicker30k [45]</ref>, GQA [13]</ref> etc. As shown in Table 
n</head><p>Learning cross-modal representations is fundamental to a wide range of visionlanguage (V+L) tasks, such as visual question answering, image-text retrieval, image captioning. Recent studies [23,</ref>39,</ref>5,</ref>36,</ref>20,</ref>< beddings. They heavily rely on the self-attention mechanism of Transformers to learn joint representations that are appropriately contextualized in both modalities. For example, early efforts such as [23,</ref>39]</ref> propose a two-stream and three-stream Transformer-based framework with co-attention to fuse the two modalities, respec problems, such as visual questionanswering (VQA), image-text retrieval and image captioning etc. The existing methods [38,</ref>39,</ref>23,</ref>5,</ref>47,</ref>36,</ref>19,</ref><r
the pre-training corpus based on the existing V+L datasets, including COCO [21]</ref>, Conceptual Captions (CC) [32]</ref>, SBU captions [27]</ref>, flicker30k [45]</ref>, GQA [13]</ref> etc. As shown in Table 
the pre-training corpus based on the existing V+L datasets, including COCO [21]</ref>, Conceptual Captions (CC) [32]</ref>, SBU captions [27]</ref>, flicker30k [45]</ref>, GQA [13]</ref> etc. As shown in Table 
-text pairs, and that fine-tuning VLP models on task-specific data achieves state-of-the-art (SoTA) results on well-established V+L tasks.</p><p>These VLP models are based on multi-layer Transformers [40]</ref>. To pre-train such models, existing methods simply concatenate image region features and text features as input and resort to the self-attention mechanism to
asets, including COCO [21]</ref>, Conceptual Captions (CC) [32]</ref>, SBU captions [27]</ref>, flicker30k [45]</ref>, GQA [13]</ref> etc. As shown in Table 1</ref>, the number of unique images is 4.1 million. I
pe="bibr" target="#b19">19,</ref>20]</ref> are used. However, the roofline model lack fine-grained estimation and customized models are not general as desired. Timeloop [21]</ref> and Eyeriss [22]</ref> use for and parallel-for to describe the temporal and spatial mapping of DNN accelerators. Specifically,
of experiments, we compare our Predictor's predicted performance with Eyeriss's chip measurement results using their Fig. 3</ref>: The # of (L) DRAM and (R) GB accesses in Eyeriss [29]</ref> and our Predictor for AlexNet's CONV layers. normalized unit energy [14]</ref>. First, Table  gure">4</ref> compares the latency of executing AlexNet's five CONV layers, and shows that the predicted ones and Eye-Fig. 4</ref>: Comparison on the inference latency from Eyeriss [29]</ref> and our Predictor when running AlexNet. Validation against FPGA Implementation. We compare our Predictor's predicted latency with FPGA measured ones under the ,625.23,240.94,81.96" type="bitmap" /></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The energy breakdown from Eyeriss[29]</ref> and our Predictor, for the CONV1 and CONV5 of AlexNet[30]</ref>.</figDesc><table><row><cell>Layer</cell><cell>comp.</cell><cell
"><head n="1.">INTRODUCTION</head><p>Deep Neural Networks (DNNs) have achieved record-breaking performance in various applications, such as image classification [1,</ref>2]</ref> and natural language processing [3]</ref>. However, their powerful performance often comes with a prohibitive complexity <ref type= #b15">[15]</ref>, developing DNN accelerators presents significant challenges, because: (1)</ref> mainstream DNNs have millions of parameters and billions of operations; (2)</ref> the design space of DNN accelerator is large due to numerous design choices of architectures, hardware IPs, DNN-to-accelerator-mappings, etc.; and (3) there is
e="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The energy breakdown from Eyeriss[29]</ref> and our Predictor, for the CONV1 and CONV5 of AlexNet[30]</ref>.</figDesc><table><row><cell>Layer</cell><cell>comp.</cell><cell>RF</cell><cell>NoC</cell><cell>GB</cell></row><row><cell></cell><cell cols="4">Meas. Pred. Mea
>2]</ref> and natural language processing [3]</ref>. However, their powerful performance often comes with a prohibitive complexity [4,</ref>5,</ref>6,</ref>7,</ref>8]</ref>. Moreover, DNN-based applications often require
y [9,</ref>10,</ref>11,</ref>12,</ref>13,</ref>14]</ref>.</p><p>While DNN accelerators can be 1000× more efficient than general purpose computing platforms [15]</ref>, developing DNN ac he DianNao series [13,</ref>17]</ref> is an early effort on synthesis based ASIC accelerators; Eyeriss proposes a row-stationary dataflow [14]</ref> to reduce expensive DRAM accesses; and Google TPUs [11,</ref>12]</ref> use a systolic array to a mption. Accelergy [23]</ref> proposes a configuration language to describe hardware architectures and depends on plug-ins, e.g., Timeloop, to calculate the energy as in [14]</ref>. The work in [24]</ref> adopts Halide [25]</ref>, a domain-specific language for image processin ="#b24">[24]</ref> adopts Halide [25]</ref>, a domain-specific language for image processing applications, and proposes a modeling framework which is similar to that of [14]</ref>. MAESTRO [26]</ref> is the very first to adopt a data-centric approach.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><hea n is how to describe the whole design space, i.e., cover all possible design choices, in a way that is easy to follow? For ease of use and better visualization, we adopt a nested for-loop description [14]</ref> to describe the design space as shown in Fig. 1</ref>. Specifically, we employ (1) the primitive, for, to describe the temporal operations <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENT RESULTS</head><p>We validate our proposed DNN-Chip Predictor by comparing its predicted performance with actual chip measured ones in [14]</ref>, FPGA implementation results in [28]</ref>, and synthesis results based on a commercial CMOS technology, under the same experim g their Fig. 3</ref>: The # of (L) DRAM and (R) GB accesses in Eyeriss [29]</ref> and our Predictor for AlexNet's CONV layers. normalized unit energy [14]</ref>. First, Table 1</ref> compares the energy breakdown of AlexNet's first and fifth CONV layers (denoted as CONV1 and CONV5, re
y [9,</ref>10,</ref>11,</ref>12,</ref>13,</ref>14]</ref>.</p><p>While DNN accelerators can be 1000× more efficient than general purpose computing platforms [15]</ref>, developing DNN ac he DianNao series [13,</ref>17]</ref> is an early effort on synthesis based ASIC accelerators; Eyeriss proposes a row-stationary dataflow [14]</ref> to reduce expensive DRAM accesses; and Google TPUs [11,</ref>12]</ref> use a systolic array to a mption. Accelergy [23]</ref> proposes a configuration language to describe hardware architectures and depends on plug-ins, e.g., Timeloop, to calculate the energy as in [14]</ref>. The work in [24]</ref> adopts Halide [25]</ref>, a domain-specific language for image processin ="#b24">[24]</ref> adopts Halide [25]</ref>, a domain-specific language for image processing applications, and proposes a modeling framework which is similar to that of [14]</ref>. MAESTRO [26]</ref> is the very first to adopt a data-centric approach.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><hea n is how to describe the whole design space, i.e., cover all possible design choices, in a way that is easy to follow? For ease of use and better visualization, we adopt a nested for-loop description [14]</ref> to describe the design space as shown in Fig. 1</ref>. Specifically, we employ (1) the primitive, for, to describe the temporal operations <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENT RESULTS</head><p>We validate our proposed DNN-Chip Predictor by comparing its predicted performance with actual chip measured ones in [14]</ref>, FPGA implementation results in [28]</ref>, and synthesis results based on a commercial CMOS technology, under the same experim g their Fig. 3</ref>: The # of (L) DRAM and (R) GB accesses in Eyeriss [29]</ref> and our Predictor for AlexNet's CONV layers. normalized unit energy [14]</ref>. First, Table 1</ref> compares the energy breakdown of AlexNet's first and fifth CONV layers (denoted as CONV1 and CONV5, re
y [9,</ref>10,</ref>11,</ref>12,</ref>13,</ref>14]</ref>.</p><p>While DNN accelerators can be 1000× more efficient than general purpose computing platforms [15]</ref>, developing DNN ac he DianNao series [13,</ref>17]</ref> is an early effort on synthesis based ASIC accelerators; Eyeriss proposes a row-stationary dataflow [14]</ref> to reduce expensive DRAM accesses; and Google TPUs [11,</ref>12]</ref> use a systolic array to a mption. Accelergy [23]</ref> proposes a configuration language to describe hardware architectures and depends on plug-ins, e.g., Timeloop, to calculate the energy as in [14]</ref>. The work in [24]</ref> adopts Halide [25]</ref>, a domain-specific language for image processin ="#b24">[24]</ref> adopts Halide [25]</ref>, a domain-specific language for image processing applications, and proposes a modeling framework which is similar to that of [14]</ref>. MAESTRO [26]</ref> is the very first to adopt a data-centric approach.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><hea n is how to describe the whole design space, i.e., cover all possible design choices, in a way that is easy to follow? For ease of use and better visualization, we adopt a nested for-loop description [14]</ref> to describe the design space as shown in Fig. 1</ref>. Specifically, we employ (1) the primitive, for, to describe the temporal operations <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENT RESULTS</head><p>We validate our proposed DNN-Chip Predictor by comparing its predicted performance with actual chip measured ones in [14]</ref>, FPGA implementation results in [28]</ref>, and synthesis results based on a commercial CMOS technology, under the same experim g their Fig. 3</ref>: The # of (L) DRAM and (R) GB accesses in Eyeriss [29]</ref> and our Predictor for AlexNet's CONV layers. normalized unit energy [14]</ref>. First, Table 1</ref> compares the energy breakdown of AlexNet's first and fifth CONV layers (denoted as CONV1 and CONV5, re
/ref>. However, their powerful performance often comes with a prohibitive complexity [4,</ref>5,</ref>6,</ref>7,</ref>8]</ref>. Moreover, DNN-based applications often require not only high accuracy, but also aggressive hardware performance, including
/ref>. However, their powerful performance often comes with a prohibitive complexity [4,</ref>5,</ref>6,</ref>7,</ref>8]</ref>. Moreover, DNN-based applications often require not only high accuracy, but also aggressive hardware performance, including
e="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The energy breakdown from Eyeriss[29]</ref> and our Predictor, for the CONV1 and CONV5 of AlexNet[30]</ref>.</figDesc><table><row><cell>Layer</cell><cell>comp.</cell><cell>RF</cell><cell>NoC</cell><cell>GB</cell></row><row><cell></cell><cell cols="4">Meas. Pred. Mea
In contrast, an end-to-end (E2E) SLU system [1]</ref>[2]</ref>[3]</ref>[4]</ref>[5]</ref>[6]</ref>[7]</ref> processes speech input directly into intent without going through an intermediate [6]</ref>[7]</ref> processes speech input directly into intent without going through an intermediate text transcript. There are many advantages of end-to-end SLU systems [5]</ref>, the most significant of which is that E2E systems can directly optimize the end goal of intent recognition, without having to perform intermediate tasks like A ddress this problem using a curriculum and transfer learning approach whereby the model is gradually trained on increasingly relevant data until it is fine-tuned on the actual domain data. Similarly, [5,</ref>12]</ref> advocate pre-training an ASR model on a large amount of transcribed speech data to initialize a speech-to-intent model t
a large amount of appropriate training data. To train an end-to-end speech-to-intent model, we need intent-labeled speech data, and such data is usually scarce. [7,</ref>11]</ref> address this problem using a curriculum and transfer learning approach whereby the model is gradually trained on increasingly relevant data until it is fine-tu
text followed by a natural language understanding (NLU) system that interprets the meaning, or intent, of the text. In contrast, an end-to-end (E2E) SLU system [1]</ref>[2]</ref>[3]</ref>[4]</ref>[5]</ref>[6]</ref><ref
v> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Leveraging pre-trained text embedding</head><p>Leveraging text embedding (TE) from models pre-trained on large amounts of data, such as BERT [14]</ref> and GPT-2 [15]</ref>, has recently improved performance in a number of NLU tasks. In this paper, we use BERT-based text embeddi [18]</ref>[19]</ref>. We employ the following steps to train the final model. (A) T2I model pre-training: As in the standard process outlined in the original BERT paper [14]</ref>, we first fine-tune BERT on the available text-to-intent data using a masked language model (LM) task as the intermediate task. The model is further fine-tune pout probability of 0.5 on the LSTM output at each layer.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">BERT based T2I model</head><p>We start with pre-trained BERTbase model of [14]</ref>. Using the implementation introduced in [24]</ref>, we first pre-train using a masked LM target with learning rate 3e-5 for 10
s the meaning, or intent, of the text. In contrast, an end-to-end (E2E) SLU system [1]</ref>[2]</ref>[3]</ref>[4]</ref>[5]</ref>[6]</ref>[7]</ref> processes speech input directly into intent
nerated reference transcripts.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">TTS system</head><p>The TTS system architecture is similar to the single speaker system described in [25]</ref>. It is a modular system based on three neural-net models: one to infer prosody, one to infer acoustic features, and an LPCNet [
n this step; hence, we can use ASR speech data instead of specific in-domain intent data, which is usually limited.</p><p>In our work, we use a phone-based connectionist temporal classification (CTC) [13]</ref> acoustic model (AM) trained on general speech data as the base ASR system. First, we initialize the S2I model with this model and adapted it to the in-domain
ems, cascaded systems are modular and each component can be optimized separately or jointly (also with end-to-end criteria [6,</ref>8,</ref>9]</ref>). One key advantage of modular components is that each component can be trained on data that may be more abundant. For example, there is a lot of transcribed spe
by 20 epochs of soft forgetting training [20]</ref>, followed by 20 epochs of guided training [21]</ref>. We use sequence noise injection [22]</ref> and SpecAugment [23]</ref> throughout the training to provide on-the-fly data augmentation, and we also use a dropout probabili
and transfer learning approach whereby the model is gradually trained on increasingly relevant data until it is fine-tuned on the actual domain data. Similarly, [5,</ref>12]</ref> advocate pre-training an ASR model on a large amount of transcribed speech data to initialize a speech-to-intent model that is then trained on a much smaller t
tent system. The text embeddings are used to "guide" acoustic embeddings which are trained with a limited amount of S2I data, in the same spirit as learning a shared representation between modalities [16]</ref>[17]</ref>[18]</ref>[19]</ref>. We employ the following steps to t
n this step; hence, we can use ASR speech data instead of specific in-domain intent data, which is usually limited.</p><p>In our work, we use a phone-based connectionist temporal classification (CTC) [13]</ref> acoustic model (AM) trained on general speech data as the base ASR system. First, we initialize the S2I model with this model and adapted it to the in-domain
to "guide" acoustic embeddings which are trained with a limited amount of S2I data, in the same spirit as learning a shared representation between modalities [16]</ref>[17]</ref>[18]</ref>[19]</ref>. We employ the following steps to train the final model. (A) T2I model pre-t
derstanding (NLU) system that interprets the meaning, or intent, of the text. In contrast, an end-to-end (E2E) SLU system [1]</ref>[2]</ref>[3]</ref>[4]</ref>[5]</ref>[6]</ref>[7]</ref> proc
We first perform speed and tempo perturbation (0.9x and 1.1x) resulting in a 1500-hour audio data set. We train the AM for 20 epochs using CTC loss, followed by 20 epochs of soft forgetting training [20]</ref>, followed by 20 epochs of guided training [21]</ref>. We use sequence noise injection [22]</ref>
to "guide" acoustic embeddings which are trained with a limited amount of S2I data, in the same spirit as learning a shared representation between modalities [16]</ref>[17]</ref>[18]</ref>[19]</ref>. We employ the following steps to train the final model. (A) T2I model pre-t
ems, cascaded systems are modular and each component can be optimized separately or jointly (also with end-to-end criteria [6,</ref>8,</ref>9]</ref>). One key advantage of modular components is that each component can be trained on data that may be more abundant. For example, there is a lot of transcribed spe
trained with a limited amount of S2I data, in the same spirit as learning a shared representation between modalities [16]</ref>[17]</ref>[18]</ref>[19]</ref>. We employ the following steps to train the final model. (A) T2I model pre-training: As in the standard process outli
stem [1]</ref>[2]</ref>[3]</ref>[4]</ref>[5]</ref>[6]</ref>[7]</ref> processes speech input directly into intent without going through an intermediate text transcript. There are many advanta to perform intermediate tasks like ASR.</p><p>Compared to end-to-end SLU systems, cascaded systems are modular and each component can be optimized separately or jointly (also with end-to-end criteria [6,</ref>8,</ref>9]</ref>). One key advantage of modular components is that each component can be trained on d
ion (ASR) system converting speech into text followed by a natural language understanding (NLU) system that interprets the meaning, or intent, of the text. In contrast, an end-to-end (E2E) SLU system [1]</ref>[2]</ref>[3]</ref>[4]</ref>[5]</ref><ref
nerated reference transcripts.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">TTS system</head><p>The TTS system architecture is similar to the single speaker system described in [25]</ref>. It is a modular system based on three neural-net models: one to infer prosody, one to infer acoustic features, and an LPCNet [
/ref>[2]</ref>[3]</ref>[4]</ref>[5]</ref>[6]</ref>[7]</ref> processes speech input directly into intent without going through an intermediate text transcript. There are many advantages of end-to-end SLU systems <ref type foreign language translation, etc.</p><p>While end-to-end SLU is an active area of research, currently the most promising results under-perform or just barely outperform traditional cascaded systems [7,</ref>10]</ref>. One reason is that deep learning models require a large amount of appropriate training data. To train an end-to-end spee n is that deep learning models require a large amount of appropriate training data. To train an end-to-end speech-to-intent model, we need intent-labeled speech data, and such data is usually scarce. [7,</ref>11]</ref> address this problem using a curriculum and transfer learning approach whereby the model is gradually trained on increas
s probability in traditional left-to-right LMs using Bayes' theorem is not tractable. 4 Words along the dependency path between the entities might be even more indicative of the relation, as noted by Toutanova et al. (2015)</ref>. It is quite possible that using these techniques may further improve results, but we did not test these at this time due to the increased
es so that the language generation process is explicitly conditioned on symbolic knowledge (Ahn et al., 2016;</ref>Yang et al., 2017;</ref>IV et al., 2019;</ref>Hayashi et al., 2020)</ref>. Similar extensions have been applied to large-scale pre-trained LMs like BERT, where co

es so that the language generation process is explicitly conditioned on symbolic knowledge (Ahn et al., 2016;</ref>Yang et al., 2017;</ref>IV et al., 2019;</ref>Hayashi et al., 2020)</ref>. Similar extensions have been applied to large-scale pre-trained LMs like BERT, where co
tly conditioned on symbolic knowledge (Ahn et al., 2016;</ref>Yang et al., 2017;</ref>IV et al., 2019;</ref>Hayashi et al., 2020)</ref>. Similar extensions have been applied to large-scale pre-trained LMs like BERT, where contextualized word representations are enhanced with e
re extractors,  where the hidden vectors learned through a language modeling objective are then used in downstream language understanding systems (Dai and Le, 2015;</ref>Melamud et al., 2016;</ref>Peters et al., 2018;</ref>Devlin et al., 2019)</ref>.</p><p>Interestingly, it is
text of end-to-end sequence generation (Hoang et al., 2017)</ref>, and in the context of making small changes to an existing input in the context of adversarial attacks (Ebrahimi et al., 2018;</ref>Wallace et al., 2019)</ref>. However, we found that directly optimizing prompts guided by gradients was unstab
open information extraction systems (Banko et al., 2007)</ref>, manually defined patterns are often leveraged to filter out noisy relational phrases. For example, ReVerb (Fader et al., 2011)</ref> incorporates three syntactic constraints listed in Table 7</ref> to improve the coherence and informativeness
ns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent years have seen the primary role of language models (LM) transition from generating or evaluating the fluency of natural text (Mikolov and Zweig, 2012;</ref>Merity et al., 2018;</ref>Melis et al., 2018;</ref><ref type="bibr" target="
has a common border with y" and "x adjoins y". This is conceptually similar to query expansion techniques used in information retrieval that reformulate a given query to improve retrieval performance (Carpineto and Romano, 2012)</ref>.</p><p>While many methods could be used for paraphrasing, we follow the simple method of using back-translation <ref type="bibr" target
language understanding systems (Dai and Le, 2015;</ref>Melamud et al., 2016;</ref>Peters et al., 2018;</ref>Devlin et al., 2019)</ref>.</p><p>Interestingly, it is also becoming apparent that LMs1</ref> themselves can be used as a tool for text ties ( § 5). We first demonstrate that improved prompts significantly improve accuracy on this task, with the one-best prompt extracted by our method raising accuracy from 31.1% to 34.1% on BERT-base (Devlin et al., 2019)</ref>, with similar gains being obtained with BERT-large as well. We further demonstrate that using a diversity of prompts through ensembling furthe act prediction performance,  1</ref>.</p><formula xml:id="formula_5">Properties T-REx T-REx-train #subject-</formula><p>Models As the models to probe, we use BERTbase and BERT-large (Devlin et al., 2019)</ref>.</p><p>Evaluation Metrics We use two metrics to evaluate the success of prompts in probing LMs. The first evaluation metric, micro-averaged ac
ment datasets, FLAG works purely in the node feature space by adding gradient-based adversarial perturbations to the input node features with graph structures unchanged. FLAG leverages "free" methods (Shafahi et al., 2019)</ref> to conduct efficient adversarial training so that it is highly scalable to large-scale datasets. We verify the effectiveness of FLAG on the Note that our method differs from other augmentations for graphs in that it happens in the input node feature space.</p><p>Augmentation for "free". We leverage the "free" adversarial training method (Shafahi et al., 2019)</ref> to craft adversarial data augmentations. PGD is a strong but inefficient way to solve the inner maximization of (6). While computing the gra
ph structure (or edge features) and node features. In the limited cases where data augmentation can be done on graphs, it generally focuses exclusively on the graph structure by adding/removing edges (Rong et al., 2019)</ref>. To date, there is no study on how to manipulate graphs in node feature space for enhanced performance.</p><p>In the meantime, adversarial data lidates our conjecture.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>Existing graph regularizers mainly focus on augmenting graph structures by modifying edges (Rong et al., 2019;</ref>Hamilton et al., 2017;</ref>Chen et al., 2018)</ref>. We propose to effectively aug
#b10">(Garcia &amp; Bruna, 2017)</ref>, social analysis (Qiu et al., 2018;</ref>Li &amp; Goldwasser, 2019)</ref>, and recommender systems (Ying et al., 2018)</ref>. However, the training of GNNs on large-scale datasets usually suffers from overfitting, and realistic graph datasets often involve a high volu
">Jiang et al., 2019)</ref>, and visual question answering (Gan et al., 2020)</ref>. Despite the rich literature about adversarial training of GNNs for security purposes (Zügner et al., 2018;</ref>Dai et al., 2018;</ref>Bojchevski &amp; Günnemann, 2019;</ref><ref type="bibr" tar
n et al. (2020)</ref> showed that VQA model accuracy was further improved by adversarial augmentation. To clarify, FLAG is intrinsically different from the previous graph adversarial training methods (Feng et al., 2019;</ref>Deng et al., 2019;</ref>Jin &amp; Zhang, 2019)</ref>.  adversarial training methods (Feng et al., 2019;</ref>Deng et al., 2019;</ref>Jin &amp; Zhang, 2019)</ref>. Feng et al. (2019)</ref> proposed to reinforce local smoothness to make embeddings within communities similar. All three methods assigned pseudo-labels to test nodes duri

target="#b0">Balaji et al., 2019)</ref>, recently a growing amount of attention has been paid to using adversarial perturbations to augment datasets and ultimately alleviate overfitting. For example, Volpi et al. (2018)</ref> showed adversarial data augmentation is a data-dependent regularization that could help generalize to out-of-distribution samples, and its effe or language word embeddings do not have such straightforward semantic meanings, which makes the selection of highly heuristic. In light of the positive effect of large perturbations on generalization (Volpi et al., 2018)</ref>, and also to simplify hyperparameter search, FLAG drops the projection step when performing the inner maximization. Note that, although the pe

diction tasks. We conduct extensive experiments across OGB datasets by applying FLAG to prestigious GNN models, which are GCN, GraphSAGE, GAT, and GIN (Kipf &amp; Welling, 2016;</ref>Hamilton et al., 2017;</ref>Veličković et al., 2017;</ref>Xu et al., 2019)</ref> and show that FLAG brings .tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>Existing graph regularizers mainly focus on augmenting graph structures by modifying edges (Rong et al., 2019;</ref>Hamilton et al., 2017;</ref>Chen et al., 2018)</ref>. We propose to effectively augment graph data using adversarial perturbations. On larg results of node classification in Table 1</ref>. On ogbn-products, GraphSAGE, GAT, and DeeperGCN all receive promising results with FLAG. We adopt neighbor sampling (Hamilton et al., 2017)</ref> as the mini-batch algorithm for GraphSAGE and GAT to make the experiments scalable. For DeeperGCN, we follow the original setup by <ref typ hms are critical to training GNNs on large-scale datasets. We test how different algorithms will work with adversarial data augmentation with GraphSAGE as the backbone. From the left part of sampling (Hamilton et al., 2017)</ref> and GraphSAINT (Zeng et al., 2019</ref>) can all work with FLAG to further boost performance, while Cluster
diction tasks. We conduct extensive experiments across OGB datasets by applying FLAG to prestigious GNN models, which are GCN, GraphSAGE, GAT, and GIN (Kipf &amp; Welling, 2016;</ref>Hamilton et al., 2017;</ref>Veličković et al., 2017;</ref>Xu et al., 2019)</ref> and show that FLAG brings .tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>Existing graph regularizers mainly focus on augmenting graph structures by modifying edges (Rong et al., 2019;</ref>Hamilton et al., 2017;</ref>Chen et al., 2018)</ref>. We propose to effectively augment graph data using adversarial perturbations. On larg results of node classification in Table 1</ref>. On ogbn-products, GraphSAGE, GAT, and DeeperGCN all receive promising results with FLAG. We adopt neighbor sampling (Hamilton et al., 2017)</ref> as the mini-batch algorithm for GraphSAGE and GAT to make the experiments scalable. For DeeperGCN, we follow the original setup by <ref typ hms are critical to training GNNs on large-scale datasets. We test how different algorithms will work with adversarial data augmentation with GraphSAGE as the backbone. From the left part of sampling (Hamilton et al., 2017)</ref> and GraphSAINT (Zeng et al., 2019</ref>) can all work with FLAG to further boost performance, while Cluster
ry features in ogbn-products. We believe that adversarial augmentation on discrete vs. continuous input features will lead to different effects. To illustrate, we provide a simple example on the Cora (Getoor, 2005)</ref> dataset. We choose FGSM to craft adversarial augmentation for a GCN. By adding Gaussian noise with standard deviation σ, we simulate node features d
ody> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Speech synthesis (text to speech, TTS) [28,</ref>30,</ref>35,</ref>41]</ref> and speech recognition (automatic speech recognition, ASR) [6,</ref><ref type="bibr" targ urce and unsupervised settings.</p><p>• In the rich-resource setting, both TTS [22,</ref>28,</ref>30,</ref>35]</ref> and ASR [6,</ref>10,</ref>11]</ref> require a large amount of paired is paper 11</ref> .</p><p>Data Proprocessing. For the speech data, we re-sample it to 16kHZ and convert the raw waveform into mel-spectrograms following Shen et al. [35]</ref> with 50ms frame size, 12.5ms hop size. For the text, we use text normalization rules to convert the irregular word into the normalized type which is easier to
p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Speech synthesis (text to speech, TTS) [28,</ref>30,</ref>35,</ref>41]</ref> and speech recognition (automatic spee e corresponding related works in rich-resource, low-resource, extremely low-resource and unsupervised settings.</p><p>• In the rich-resource setting, both TTS [22,</ref>28,</ref>30,</ref>35]</ref> and ASR [6,</ref>10
t methods such as unifying the character spaces between rich-resource and lowresource languages, or learning the mapping between the character embeddings of rich-and low-resource languages as used in [9]</ref>. However, we find these methods result in similar accuracy for both TTS and ASR. • Speaker Module To design the speaker module, we explore several ways includin
es a pronunciation lexicon to convert the character sequence into phoneme sequence as the model input (e.g., "speech" is converted into "s p iy ch"), which is called as grapheme-to-phoneme conversion [36]</ref>. Additionally, TTS models use text normalization rules to convert the irregular word into the normalized type that is easier to pronounce (e.g., "Sep 7th" is
single-speaker high-quality paired data are reduced to dozens of minutes in TTS [2,</ref>12,</ref>23,</ref>31]</ref> while the multi-speaker low-quality paired data is reduced to dozens of hours in ASR [16,</ref>32 other. Next, we introduce some specific designs in dual transformation to support multi-speaker TTS and ASR.</p><p>Multi-Speaker TTS Synthesis. Different from [23,</ref>31]</ref> that only support a single speaker in both TTS and ASR model, we support multi-speaker TTS and ASR in the dual transformation stage. Specifically, we randomly unciation similarity between human languages [42]</ref>. • Dual transformation. Considering the dual nature between TTS and ASR, we further leverage dual transformation [31]</ref> to boost the accuracy of each other with unpaired speech and text data. • Knowledge distillation. To further improve the accuracy of TTS and ASR and facilitat </head><p>TTS and ASR are two dual tasks and their dual nature can be explored to boost the accuracy of each other, especially in the lowresource scenarios. Therefore, we leverage dual transformation [31]</ref> between TTS and ASR to improve the ability to transform between text and speech. Dual transformation shares similar ideas with backtranslation <ref type="bibr tructure [40]</ref>. One difference from the original Transformer model is that we replace the feed-forward network with a one-dimensional convolution network following [31]</ref>, in order to better capture the dependencies in a long speech sequence.</p><p>Input/Output Module. To enable the Transformer model to support ASR and TTS, we r capture the dependencies in a long speech sequence.</p><p>Input/Output Module. To enable the Transformer model to support ASR and TTS, we need different input and output modules for speech and text [31]</ref>. For the TTS model: 1) The input module of the encoder is a character/phoneme embedding lookup table, which converts character/phoneme ID into embedding; 2) T ting the high quality of the synthesized speech. • There are also some related works focusing on low-resource TTS and ASR, such as Speech Chain [39]</ref>, Almost Unsup [31]</ref>, and SeqRQ-AE [23]</ref>. However, these methods require much data resource to build systems and thus cannot achieve reasonable ype="bibr" target="#b22">[23]</ref>. However, these methods require much data resource to build systems and thus cannot achieve reasonable accuracy in the extremely low-resource setting. For example, [31]</ref> requires a pronunciation lexicon to convert the character sequence into phoneme sequence, and dozens of hours of single-speaker high-quality unpaired speech d oneme sequence, and dozens of hours of single-speaker high-quality unpaired speech data to improve the accuracy, which are costly and not available in the extremely low-resource setting. As a result, [31]</ref> cannot synthesize reasonable speech in TTS and achieves high WER according to our preliminary experiments.</p><p>As a summary, LRSpeech achieves an IR score o
h and text data. • Knowledge distillation. To further improve the accuracy of TTS and ASR and facilitate online deployment, we leverage knowledge distillation [18,</ref>37]</ref> to synthesize paired data to train better TTS and ASR models.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Formulation of TTS and ASR</head have word skipping and repeating issues; 3) The accuracy of the ASR model needs to be further improved. Therefore, we further leverage knowledge distillation [18,</ref>37]</ref>, which generates target sequences given source sequences as input to construct a pseudo corpus, to customize the TTS and ASR models for better accuracy.</p><p>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Data Cost and Accuracy</head><p>Next, we introduce the extremely low data cost while promising accuracy achieved by LRSpeech.</p><p>According to [4,</ref>14,</ref>15,</ref>38,</ref>43]</ref>,
/1.0"><head n="1">INTRODUCTION</head><p>Speech synthesis (text to speech, TTS) [28,</ref>30,</ref>35,</ref>41]</ref> and speech recognition (automatic speech recognition, ASR) [6,</ref>10,</ref><ref type="bibr" targe > <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Formulation of TTS and ASR</head><p>TTS and ASR are usually formulated as sequence to sequence problems [6,</ref>41]</ref>. Denote the text and speech sequence pair (x, y) ∈ D, where D is the paired text and speech corpus. Each element in the text sequence x represents a phoneme or high attention weights from target speech frames, and thus is less likely to cause word skipping. Attention Diagonal Ratio. As demonstrated by previous works [30,</ref>41]</ref>, the attention alignments between text and speech are monotonic and diagonal. When the synthesized speech has word skipping and repeating issues, or is totally _6">6</ref> dataset to synthesize speech for evaluation. We randomly select 200 sentences for IR test and 20 sentences for MOS test, following the practice in [30,</ref>41]</ref>  7</ref> . Each speech is listened by at least 5 testers for IR test and 20 testers for MOS test, who are all native English
es a pronunciation lexicon to convert the character sequence into phoneme sequence as the model input (e.g., "speech" is converted into "s p iy ch"), which is called as grapheme-to-phoneme conversion [36]</ref>. Additionally, TTS models use text normalization rules to convert the irregular word into the normalized type that is easier to pronounce (e.g., "Sep 7th" is
) the alignment capability between speech and text in rich-resource languages can benefit the alignment learning in low-resource languages, due to the pronunciation similarity between human languages [42]</ref>. • Dual transformation. Considering the dual nature between TTS and ASR, we further leverage dual transformation [31]</ref> to uages share similar vocal organs and thus similar pronunciations, the ability of alignment learning in one language can help the alignment in another language [19,</ref>42]</ref>. This motivates us to transfer the TTS and ASR models that trained in rich-resource languages into low-resource languages, considering there are plenty of pair
) the alignment capability between speech and text in rich-resource languages can benefit the alignment learning in low-resource languages, due to the pronunciation similarity between human languages [42]</ref>. • Dual transformation. Considering the dual nature between TTS and ASR, we further leverage dual transformation [31]</ref> to uages share similar vocal organs and thus similar pronunciations, the ability of alignment learning in one language can help the alignment in another language [19,</ref>42]</ref>. This motivates us to transfer the TTS and ASR models that trained in rich-resource languages into low-resource languages, considering there are plenty of pair
ich we broadly refer to as learning from structure, have recently developed into an exciting and promising application area for deep learning (Graves et al., 2020;</ref>Ingraham et al., 2019;</ref>Pereira et al., 2016;</ref>Townshend et al., 2019;</ref><ref type="bibr" target scribed as a connectivity pattern rather than a rigid shape. Recent state-of-the-art GNNs include GraphQA (Baldassarre et al., 2020)</ref> on MQA, Structured Transformer (Ingraham et al., 2019)</ref> on CPD, and ProteinSolver (Strokach et al., 2020)</ref> on CPD and mutation stability prediction. These meth F.</p><p>Protein design GVP-GNN achieves state-of-the-art performance on CATH 4.2, representing a substantial improvement both in terms of perplexity and sequence recovery over Structured Transformer (Ingraham et al., 2019)</ref>, a GNN method which was trained using the same training and validation sets (Table 3</ref>). Following <r utput the network's prediction.</p><p>In computational protein design, the network learns a generative model over the space of protein sequences conditioned on the given backbone structure. Following Ingraham et al. (2019)</ref>, we frame this as an autoregressive task and use a masked encoder-decoder architecture to capture the joint distribution over all positions: r (Ingraham et al., 2019)</ref>, a GNN method which was trained using the same training and validation sets (Table 3</ref>). Following Ingraham et al. (2019)</ref>, we report evaluation on short (100 or fewer amino acid residues) and single-chain subsets of the CATH 4.2 test set, containing 94 and 103 p ts and structures in each set can be found in Table 6</ref>.</p><p>Protein design As described in the main text, we use the CATH 4.2 dataset and splits as curated by Ingraham et al. (2019)</ref> and the TS50 test set as curated by Li et al. (2014)</ref>. To evaluate on TS50, we remove sequences with mor ximate real-world applications that may require design of novel structures, the heldout evaluation set should bear minimal similarity to the training structures. We use the CATH 4.2 dataset curated byIngraham et al. (2019)</ref> in which all available structures with 40% nonredudancy are partitioned by their CATH (class, architecture, topology/fold, homologous superf

ns collectively projected to local coordinates (Karasikov et al., 2019)</ref>, physicsinspired energy terms (O'Connell et al., 2018;</ref>Uziela et al., 2017)</ref>, or context-free grammars of protein topology (Greener et al., 2018)</ref>. The structure is then viewed as a s ds that use sequential representations-VoroMQA (Olechnovič &amp; Venclovas, 2017)</ref>, SBROD (Karasikov et al., 2019)</ref>, and ProQ3D (Uziela et al., 2017)</ref>. All of these methods learn solely from protein structure,6</ref> with the exception of ProQ3D, which in ad hich in addition uses sequence profiles based on alignments, which are not always available. We include ProQ3D because it is an improved version of the best single-model method in CASP 11 and CASP 12 (Uziela et al., 2017)</ref>. GVP-GNN outperforms all other structural methods in both global and per-target correlation, and even performs better than ProQ3D on all but s a linear model over secondary structure and contact-based features(Cheng et al., 2019)</ref>. FaeNNz 7(Studer et al., 2020)</ref>, ProQ3D(Uziela et al., 2017)</ref>, and VoroMQA</figDesc><table /><note>8(Olechnovič &amp; Venclovas, 2017</ref>) learn a multi-layer perceptron
ble /><note>8(Olechnovič &amp; Venclovas, 2017</ref>) learn a multi-layer perceptron or statistical potential on top of such structural features. Finally, MULTICOM-NOVEL(Hou et al., 2019)</ref> and ProQ4(Hurtado et al., 2018)</ref> employ one-dimensional deep convolutional networks on top of sequential rep
t the GDT-TS score of a candidate structure compared to the experimentally solved structure for that target. GDT-TS is a scalar measure of how similar two protein backbones are after global alignment (Zemla et al., 2001)</ref>.</p><p>In addition to accurately predicting the absolute quality of a candidate structure, a good MQA method should also be able to accurately
Ns include GraphQA (Baldassarre et al., 2020)</ref> on MQA, Structured Transformer (Ingraham et al., 2019)</ref> on CPD, and ProteinSolver (Strokach et al., 2020)</ref> on CPD and mutation stability prediction. These methods vary in their representation of geometry: while some, such as GraphQA and ProteinSo ="#b4">(Chen et al., 2019)</ref> 39.2 SPIN2 (O'Connell et al., 2018)</ref> 33.6 Wang's model (Wang et al., 2018)</ref> 33.0 ProteinSolver (Strokach et al., 2020)</ref> 30.8 SPIN (Li et al., 2014)</ref> 30.3 Rosetta 30.0</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head
ves et al., 2020;</ref>Ingraham et al., 2019;</ref>Pereira et al., 2016;</ref>Townshend et al., 2019;</ref>Won et al., 2019)</ref>. Successful applications of deep learning are often driven by techniques that leverage the problem structure of the domain-for example, convoluti
ural features and three also using sequence profiles. SASHAN learns a linear model over secondary structure and contact-based features(Cheng et al., 2019)</ref>. FaeNNz 7(Studer et al., 2020)</ref>, ProQ3D(Uziela et al., 2017)</ref>, and VoroMQA</figDesc><table /><note>8(Olech
tive sequence recovery-splitting the set of all known native structures in the PDB and attempting to design the sequences corresponding to held-out structuresis typically used to benchmark CPD models (Li et al., 2014;</ref>O'Connell et al., 2018;</ref>Wang et al., 2018)</ref>. Drawing an analogy between se g structure-only method for each metric is in bold, as is the top performing-method overall (if different We also report results on TS50, an older test set of 50 native structures first introduced by Li et al. (2014)</ref>. The smaller size of this benchmark also allows a comparison to the computationally expensive physics-based calculations of the fixbb protocol in p><p>Protein design As described in the main text, we use the CATH 4.2 dataset and splits as curated by Ingraham et al. (2019)</ref> and the TS50 test set as curated by Li et al. (2014)</ref>. To evaluate on TS50, we remove sequences with more than 30% similarity as computed by PSIBLAST to any protein in TS50 from CATH 4.2.</p></div> <d 21">(O'Connell et al., 2018)</ref> 33.6 Wang's model (Wang et al., 2018)</ref> 33.0 ProteinSolver (Strokach et al., 2020)</ref> 30.8 SPIN (Li et al., 2014)</ref> 30.3 Rosetta 30.0</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F VISUALIZATION AND INTERPRETATION OF LEARNED FEATURES</head><p>The ge
tive sequence recovery-splitting the set of all known native structures in the PDB and attempting to design the sequences corresponding to held-out structuresis typically used to benchmark CPD models (Li et al., 2014;</ref>O'Connell et al., 2018;</ref>Wang et al., 2018)</ref>. Drawing an analogy between se g structure-only method for each metric is in bold, as is the top performing-method overall (if different We also report results on TS50, an older test set of 50 native structures first introduced by Li et al. (2014)</ref>. The smaller size of this benchmark also allows a comparison to the computationally expensive physics-based calculations of the fixbb protocol in p><p>Protein design As described in the main text, we use the CATH 4.2 dataset and splits as curated by Ingraham et al. (2019)</ref> and the TS50 test set as curated by Li et al. (2014)</ref>. To evaluate on TS50, we remove sequences with more than 30% similarity as computed by PSIBLAST to any protein in TS50 from CATH 4.2.</p></div> <d 21">(O'Connell et al., 2018)</ref> 33.6 Wang's model (Wang et al., 2018)</ref> 33.0 ProteinSolver (Strokach et al., 2020)</ref> 30.8 SPIN (Li et al., 2014)</ref> 30.3 Rosetta 30.0</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F VISUALIZATION AND INTERPRETATION OF LEARNED FEATURES</head><p>The ge
n area for deep learning (Graves et al., 2020;</ref>Ingraham et al., 2019;</ref>Pereira et al., 2016;</ref>Townshend et al., 2019;</ref>Won et al., 2019)</ref>. Successful applications of deep learning are often driven by techniques that leverag
during the inference phase.</p><p>Our primary goal is to develop a recommender model that achieves a balance between effectiveness and efficiency. In this paper, we employ knowledge distillation (KD) [10]</ref> which is a network compression technique by transferring the distilled knowledge of a large model (a.k.a., a teacher model) to a small model (a.k.a., a student 0"><head>II. PRELIMINARIES</head><p>In this section, we first introduce the basic notations and formulate the top-N recommendation problem. Then, we explain the concept of knowledge distillation (KD) [10]</ref> and present rank distillation (RD) [11]</ref> that applies knowledge distillation to recommender models. Problem statement. For ponential sampling, we can also modify uniform sampling (line 4). This sampling method is used in our proposed training strategies.</p><p>Temperature in the KD loss. One key factor of the original KD [10]</ref> is to find a proper balance between the soft targets and hard labels. To tackle this issue, [10]</ref> introduces the notion of a p><p>Temperature in the KD loss. One key factor of the original KD [10]</ref> is to find a proper balance between the soft targets and hard labels. To tackle this issue, [10]</ref> introduces the notion of a temperature T . Although the soft target is a useful resource for educating the student model, its distribution is often too sharp.

ack, implying a mixture of unlabeled positive/negative preferences. Such ambiguity has been explicitly discussed in one-class collaborative filtering (OCCF) [12]</ref>- [19]</ref>. Given user u, I + u = {i ∈ I|r ui = 1} is the set of items with known positive feedback, and I − u = I\I + u is the set of items with missing feedback.</p><p user-item similarity, and Zheng et al. [18]</ref> employed multiple similarity matrices between users and items to predict drug-target interaction. Moreover, Yao et al. [19]</ref> proposed dual regularization by combining the weighted-and imputation-based methods.</p><p>The proposed model is similar to the imputation method because the
known feedback. (3) Because a few topranked items are of interest to top-N recommendation, we should consider the degrees of importance of items based on their rankings.</p><p>Recently, Tang and Wang [11]</ref> proposed a KD model to address the ranking problem, called rank distillation (RD). RD uses only a few items with the highest rankings in the label distributio basic notations and formulate the top-N recommendation problem. Then, we explain the concept of knowledge distillation (KD) [10]</ref> and present rank distillation (RD) [11]</ref> that applies knowledge distillation to recommender models. Problem statement. For a set of users U = {u 1 , . . . , u m } and a set of items I = {i 1 , . . . developed in the context of the classification problem. They no longer remain valid in the top-N recommendation problem because Fig. 1</ref>. Illustration of rank distillation (RD) [11]</ref>. The teacher model transfers manipulated top-k items as the distilled knowledge to the student model. of two reasons. First, many recommender models focus on ing for informative correlations between items. Consequently, the student model using the soft target may have worse performance than the original student model. Rank distillation (RD). Tang and Wang [11]</ref> proposed ranking distillation (RD) that applies KD for ranking models. As depicted in Fig. 1</ref>, RD minimizes two losses: a ranking loss ets. As preprocessing, we filtered out the users who had less than 10 ratings and the items that were rated by less than 5 users. Table I reports the detailed statistics of these datasets.</p><p>• RD [11]</ref>: To define the KD loss in equation ( 4</ref>), this utilizes only the top-K items of the soft target by quantizing the rs were equal to their default values in public implementation. Note that there is a difference between λ that appears in RD and CD. Specifically, we used the following parameter settings.</p><p>• RD [11]</ref> and RD-Rank: We set ρ to be 0.5. For CDAE, the number of items in the soft target was 15. For Caser, the number of items in the soft target was 10. • CD-Base, ented our model and baseline models using TensorFlow 1.9.0 (CDAE) and PyTorch 1.0.0 (Caser). For Caser, we used the public PyTorch implementation 6</ref> provided in [11]</ref>. All experiments were conducted on a desktop with 128 GB memory and 2 Intel Xeon Processor E5-2630 v4 (2.20 GHz, 25M cache), and all models were trained using models. Teacher and student models indicate the baseline CF model with different parameters without KD. Also, the gain indicates how additional accuracy achieved by the proposed model over that of RD [11]</ref>.</p><p>Based on this evaluation, we found several interesting observations. Firstly, both CD-TG and CD-SG significantly outperform RD over all datasets. Note uation, we found several interesting observations. Firstly, both CD-TG and CD-SG significantly outperform RD over all datasets. Note that the improvement gap for RD is somewhat different from that in [11]</ref>. It is because we used leave-one-out evaluation while [11]</ref> used cross-validation evaluation. Our models are consistently utperform RD over all datasets. Note that the improvement gap for RD is somewhat different from that in [11]</ref>. It is because we used leave-one-out evaluation while [11]</ref> used cross-validation evaluation. Our models are consistently better than RD by 2.7-33.2% and 2.7-29.1% in HR and NDCG, respectively. Also, CD-Base achieves b student model. Fig. 4</ref> depicts the relationship between model size and efficiency. The model size is proportional to the accuracy of our model, as observed in [11]</ref> as well. The same tendency consistently holds in different CF models. In both CF models, ones of the small size perform comparably to the teacher model, where ps://github.com/hexiangnan/sigir16-eals</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">http://dawenl.github.io/data/gowalla pro.zip Competitive models. Since RD[11]</ref> is the state-of-the-art KD model for top-N recommendation, we compare the proposed model with the original RD. Besides, we evaluated two baseline models, RD-R
sing teacher-guided model training.</p><p>• CD-SG: This is our proposed model using student-guided model training. To validate the proposed model, we chose two state-ofthe-art recommender models-CDAE [8]</ref> and Caser [7]</ref>. (This paper focuses on top-N recommender models with point-wise preferences. We leave the evaluation for othe ned and shared among all KD models. We randomly initialized model parameters using Gaussian distribution N (0, 1). Specifically, each baseline CF model had the following hyperparameters.</p><p>• CDAE [8]</ref>: The latent dimensions for the teacher and the student model were 100 and 10, respectively. We set the number of negative sampling items to be 0.5*|I u | and th
ice of loss functions for KD. [27]</ref> observed that the distance-based loss is inappropriate for transferring activation boundaries, and thus suggested a hinge loss. [22]</ref> and [23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN [21]</ref> b
student model, respectively. Note that this setting is consistent with existing KD studies.</p><p>Evaluation protocol. We adopted the leave-one-out evaluation [4]</ref>- [6]</ref>. Specifically, we held-out the last timestamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training stamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training data. Unlike sampling-based evaluation [4]</ref>- [6]</ref> that randomly chose 100 items from the set of unrated items, we chose all unrated items as the candidate items. We believe that this evaluation protocol is time We measured the accuracy of top-N recommendation for two metrics, hit rate (HR) and normalized discounted cumulative gain (NDCG), as done in existing studies [4]</ref>- [6]</ref>. The size N of the ranked list was chosen to be 50 for HR@N and NDCG@N, respectively. HR@N examines whether or not the test item is present in the top-N list, a
student model, respectively. Note that this setting is consistent with existing KD studies.</p><p>Evaluation protocol. We adopted the leave-one-out evaluation [4]</ref>- [6]</ref>. Specifically, we held-out the last timestamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training stamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training data. Unlike sampling-based evaluation [4]</ref>- [6]</ref> that randomly chose 100 items from the set of unrated items, we chose all unrated items as the candidate items. We believe that this evaluation protocol is time We measured the accuracy of top-N recommendation for two metrics, hit rate (HR) and normalized discounted cumulative gain (NDCG), as done in existing studies [4]</ref>- [6]</ref>. The size N of the ranked list was chosen to be 50 for HR@N and NDCG@N, respectively. HR@N examines whether or not the test item is present in the top-N list, a
the graph. Lastly, Sindhwani et al. [13]</ref> regarded unobserved feedback as optimization variables and imputed missing feedback via optimization. Besides, Li et al. [17]</ref> leveraged side information to construct user-item similarity, and Zheng et al. [18]</ref> employed multiple similarity matrices
tized model parameters incur the loss of accuracy, it can reduce the memory size and enhance efficiency. Second, the pruning and sharing method presented in [32]</ref>, [33]</ref> removes or binds model parameters which are redundant or have minimal impacts in loss functions. In principle, these research directions focus on designing an
This is our proposed model using student-guided model training. To validate the proposed model, we chose two state-ofthe-art recommender models-CDAE [8]</ref> and Caser [7]</ref>. (This paper focuses on top-N recommender models with point-wise preferences. We leave the evaluation for other models with pair-wise preferences, e.g., NPR <re et the number of negative sampling items to be 0.5*|I u | and the denoising ratio as 0.1. We used the Adagrad optimizer with learning rate = 0.2, l2-regularizer = 0.001, and batch size = 256. • Caser [7]</ref>: The latent dimensions for the teacher and the student model were 50 and 5, respectively. We set sequence length L to be 5, target length T to be 1, and the num
on variables and imputed missing feedback via optimization. Besides, Li et al. [17]</ref> leveraged side information to construct user-item similarity, and Zheng et al. [18]</ref> employed multiple similarity matrices between users and items to predict drug-target interaction. Moreover, Yao et al. [19]</re
hod by matching the gradients (i.e., Jacobians) of output activations for the input.</p><p>Along an alternative direction, several algorithms focused on analyzing the choice of loss functions for KD. [27]</ref> observed that the distance-based loss is inappropriate for transferring activation boundaries, and thus suggested a hinge loss. <ref type="bibr" target="#b21"
tion task, it is non-trivial to incorporate it into recommender models. More concretely, applying KD to recommender models involves several challenges: (1) Implicit user feedback is extremely sparse. (2)</ref> As users only provide positive feedback in implicit datasets, there is inherent ambiguity regarding unknown (or missing) feedback. That is, unknown feedback can
tion task, it is non-trivial to incorporate it into recommender models. More concretely, applying KD to recommender models involves several challenges: (1) Implicit user feedback is extremely sparse. (2)</ref> As users only provide positive feedback in implicit datasets, there is inherent ambiguity regarding unknown (or missing) feedback. That is, unknown feedback can

student model, respectively. Note that this setting is consistent with existing KD studies.</p><p>Evaluation protocol. We adopted the leave-one-out evaluation [4]</ref>- [6]</ref>. Specifically, we held-out the last timestamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training stamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training data. Unlike sampling-based evaluation [4]</ref>- [6]</ref> that randomly chose 100 items from the set of unrated items, we chose all unrated items as the candidate items. We believe that this evaluation protocol is time We measured the accuracy of top-N recommendation for two metrics, hit rate (HR) and normalized discounted cumulative gain (NDCG), as done in existing studies [4]</ref>- [6]</ref>. The size N of the ranked list was chosen to be 50 for HR@N and NDCG@N, respectively. HR@N examines whether or not the test item is present in the top-N list, a
Second, Paquet and Koenigstein [15]</ref> proposed a sampling-based method by considering the degree distributions of users/items in the graph. Lastly, Sindhwani et al. [13]</ref> regarded unobserved feedback as optimization variables and imputed missing feedback via optimization. Besides, Li et al. [17]</
ice of loss functions for KD. [27]</ref> observed that the distance-based loss is inappropriate for transferring activation boundaries, and thus suggested a hinge loss. [22]</ref> and [23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN [21]</ref> b
Second, Paquet and Koenigstein [15]</ref> proposed a sampling-based method by considering the degree distributions of users/items in the graph. Lastly, Sindhwani et al. [13]</ref> regarded unobserved feedback as optimization variables and imputed missing feedback via optimization. Besides, Li et al. [17]</
student training. FitNet [25]</ref> first pointed out such limitation and suggested using the output of intermediate layers as additional matching criteria. Similarly, [26]</ref> utilized the gram matrix of the channel responses from the teacher model as additional information to educate the student model. Net2Net <ref type="bibr" targ
into smaller ones. In general, existing work falls into three categories: (1) binarization and discretion, (2) pruning and sharing model parameters, and (3) knowledge distillation (KD).</p><p>First, [30]</ref>, [31]</ref> proposed the binary encoding of model parameters. Under this method, real-valued model parameters are discretized v
undaries, and thus suggested a hinge loss. [22]</ref> and [23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN [21]</ref> bypassed the convergence step of adversarial learning by employing a triple-player game [28]</ref>. In this study, we develop a

criteria. Similarly, [26]</ref> utilized the gram matrix of the channel responses from the teacher model as additional information to educate the student model. Net2Net [34]</ref> employed model parameters of the teacher model directly to initialize those of the student model. Recently, [20]</ref> used the
the graph. Lastly, Sindhwani et al. [13]</ref> regarded unobserved feedback as optimization variables and imputed missing feedback via optimization. Besides, Li et al. [17]</ref> leveraged side information to construct user-item similarity, and Zheng et al. [18]</ref> employed multiple similarity matrices
xity were chosen for the teacher and the student model, respectively. Note that this setting is consistent with existing KD studies.</p><p>Evaluation protocol. We adopted the leave-one-out evaluation [4]</ref>- [6]</ref>. Specifically, we held-out the last timestamp useritem interaction as the test data for each user, and the rest of user . Specifically, we held-out the last timestamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training data. Unlike sampling-based evaluation [4]</ref>- [6]</ref> that randomly chose 100 items from the set of unrated items, we chose all unrated items as the candidate items. We beli more thorough.</p><p>Evaluation metrics. We measured the accuracy of top-N recommendation for two metrics, hit rate (HR) and normalized discounted cumulative gain (NDCG), as done in existing studies [4]</ref>- [6]</ref>. The size N of the ranked list was chosen to be 50 for HR@N and NDCG@N, respectively. HR@N examines whether or not the
teacher model.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Neural recommender models [1]</ref>- [9]</ref> have achieved better performance than conventional latent factor models either by capturing non-linear and complex corr
into smaller ones. In general, existing work falls into three categories: (1) binarization and discretion, (2) pruning and sharing model parameters, and (3) knowledge distillation (KD).</p><p>First, [30]</ref>, [31]</ref> proposed the binary encoding of model parameters. Under this method, real-valued model parameters are discretized v
rk falls into three categories: (1) binarization and discretion, (2) pruning and sharing model parameters, and (3) knowledge distillation (KD).</p><p>First, [30]</ref>, [31]</ref> proposed the binary encoding of model parameters. Under this method, real-valued model parameters are discretized via binary representation. Although the disc
tized model parameters incur the loss of accuracy, it can reduce the memory size and enhance efficiency. Second, the pruning and sharing method presented in [32]</ref>, [33]</ref> removes or binds model parameters which are redundant or have minimal impacts in loss functions. In principle, these research directions focus on designing an
ice of loss functions for KD. [27]</ref> observed that the distance-based loss is inappropriate for transferring activation boundaries, and thus suggested a hinge loss. [22]</ref> and [23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN [21]</ref> b
student training. FitNet [25]</ref> first pointed out such limitation and suggested using the output of intermediate layers as additional matching criteria. Similarly, [26]</ref> utilized the gram matrix of the channel responses from the teacher model as additional information to educate the student model. Net2Net <ref type="bibr" targ
student model, respectively. Note that this setting is consistent with existing KD studies.</p><p>Evaluation protocol. We adopted the leave-one-out evaluation [4]</ref>- [6]</ref>. Specifically, we held-out the last timestamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training stamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training data. Unlike sampling-based evaluation [4]</ref>- [6]</ref> that randomly chose 100 items from the set of unrated items, we chose all unrated items as the candidate items. We believe that this evaluation protocol is time We measured the accuracy of top-N recommendation for two metrics, hit rate (HR) and normalized discounted cumulative gain (NDCG), as done in existing studies [4]</ref>- [6]</ref>. The size N of the ranked list was chosen to be 50 for HR@N and NDCG@N, respectively. HR@N examines whether or not the test item is present in the top-N list, a
ice of loss functions for KD. [27]</ref> observed that the distance-based loss is inappropriate for transferring activation boundaries, and thus suggested a hinge loss. [22]</ref> and [23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN [21]</ref> b
into smaller ones. In general, existing work falls into three categories: (1) binarization and discretion, (2) pruning and sharing model parameters, and (3) knowledge distillation (KD).</p><p>First, [30]</ref>, [31]</ref> proposed the binary encoding of model parameters. Under this method, real-valued model parameters are discretized v
o address this challenge, existing studies can be categorized into weight-based, sampling-based, and imputationbased methods. First, the weight-based method [12]</ref>, [16]</ref> regards all missing feedback as negative ones. For instance, Hu et al. [12]</ref> and Pan et al. <ref type="bibr" target="#b15" br" target="#b11">[12]</ref>, [16]</ref> regards all missing feedback as negative ones. For instance, Hu et al. [12]</ref> and Pan et al. [16]</ref> controlled weights as the confidence of negative values with various schemes, such as uniform, user-oriented, and item-oriented methods. Second, Paquet and Ko
sing teacher-guided model training.</p><p>• CD-SG: This is our proposed model using student-guided model training. To validate the proposed model, we chose two state-ofthe-art recommender models-CDAE [8]</ref> and Caser [7]</ref>. (This paper focuses on top-N recommender models with point-wise preferences. We leave the evaluation for othe ned and shared among all KD models. We randomly initialized model parameters using Gaussian distribution N (0, 1). Specifically, each baseline CF model had the following hyperparameters.</p><p>• CDAE [8]</ref>: The latent dimensions for the teacher and the student model were 100 and 10, respectively. We set the number of negative sampling items to be 0.5*|I u | and th
undaries, and thus suggested a hinge loss. [22]</ref> and [23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN [21]</ref> bypassed the convergence step of adversarial learning by employing a triple-player game [28]</ref>. In this study, we develop a
on variables and imputed missing feedback via optimization. Besides, Li et al. [17]</ref> leveraged side information to construct user-item similarity, and Zheng et al. [18]</ref> employed multiple similarity matrices between users and items to predict drug-target interaction. Moreover, Yao et al. [19]</re
tion task, it is non-trivial to incorporate it into recommender models. More concretely, applying KD to recommender models involves several challenges: (1) Implicit user feedback is extremely sparse. (2)</ref> As users only provide positive feedback in implicit datasets, there is inherent ambiguity regarding unknown (or missing) feedback. That is, unknown feedback can
o address this challenge, existing studies can be categorized into weight-based, sampling-based, and imputationbased methods. First, the weight-based method [12]</ref>, [16]</ref> regards all missing feedback as negative ones. For instance, Hu et al. [12]</ref> and Pan et al. <ref type="bibr" target="#b15" br" target="#b11">[12]</ref>, [16]</ref> regards all missing feedback as negative ones. For instance, Hu et al. [12]</ref> and Pan et al. [16]</ref> controlled weights as the confidence of negative values with various schemes, such as uniform, user-oriented, and item-oriented methods. Second, Paquet and Ko
undaries, and thus suggested a hinge loss. [22]</ref> and [23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN [21]</ref> bypassed the convergence step of adversarial learning by employing a triple-player game [28]</ref>. In this study, we develop a
sing teacher-guided model training.</p><p>• CD-SG: This is our proposed model using student-guided model training. To validate the proposed model, we chose two state-ofthe-art recommender models-CDAE [8]</ref> and Caser [7]</ref>. (This paper focuses on top-N recommender models with point-wise preferences. We leave the evaluation for othe ned and shared among all KD models. We randomly initialized model parameters using Gaussian distribution N (0, 1). Specifically, each baseline CF model had the following hyperparameters.</p><p>• CDAE [8]</ref>: The latent dimensions for the teacher and the student model were 100 and 10, respectively. We set the number of negative sampling items to be 0.5*|I u | and th
ence of the solutions was not changed, but locally finding external similar patches. It yields great limitations of deep SISR. SISR performance was boosted right after the non-local attention modules [2,</ref>20,</ref>38]</ref> were proposed. They explored non-local selfsimilarity property and embedded the ng. To further unleash the power of deep CNNs, Lim et al. [19]</ref>   [20]</ref>, RNAN [37]</ref> and SAN [2]</ref>, incorporate non-local operation into their networks in order to make better use of image structural cues, by considering long-range feature correlations. As su gure" target="#fig_2">3</ref>, is a simple identical pathway connecting the convolutional features to the fusion structure. For the IS-NL branch, it contains a non-local attention module adopted from [2]</ref> and a deconvolution layer for upscaling the module outputs. The IS-NL module is region-based in this paper. As in [2]</ref>, we di ins a non-local attention module adopted from [2]</ref> and a deconvolution layer for upscaling the module outputs. The IS-NL module is region-based in this paper. As in [2]</ref>, we divide the feature maps into region grids, where the inter-dependencies are captured independently in each grid. This reduces the computation burden.</p><p> RCAN [37]</ref>, NLRN [20]</ref>, SRFBN [18]</ref>, OISR [12]</ref> and SAN [2]</ref>.</p><p>Quantitative Evaluations In Table 1</ref>, We report the quantitative comparisons for scale factor ×2, ×3 and ×4. Compa 9]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours Urban100 (4×): img 078 HR Bicubic LapSRN [17]</ref> EDSR [19]</ref> DBPN <ref type="bibr" tar 9]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours Urban100 (4×): img 047 HR Bicubic LapSRN [17]</ref> EDSR [19]</ref> DBPN <ref type="bibr" tar 9]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours which only needs 20% parameters of RCAN and SAN, but achieves the second best result. Therefore, our CSNLN obtains better parameter efficiency in compariso
>, RDN [39]</ref>, RCAN [37]</ref>, NLRN [20]</ref>, SRFBN [18]</ref>, OISR [12]</ref> and SAN [2]</ref>.</p><p>Quantitative Evaluations In Table 1</ref>, We report the quantitative the shown examples, our method perceptually out-performs other state-of-the-arts by a large margin. EDSR [19]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours Urban100 (4×): i 1">[2]</ref> Ours Urban100 (4×): img 078 HR Bicubic LapSRN [17]</ref> EDSR [19]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours Urban100 (4×): i 1">[2]</ref> Ours Urban100 (4×): img 047 HR Bicubic LapSRN [17]</ref> EDSR [19]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours which only needs
in the areas of satellite imaging, medical imaging, surveillance monitoring and high-definition display and imaging etc [3,</ref>32,</ref>40,</ref>41,</ref>43]</ref>. The mapping between LR and HR image is not bijective, which yields more possib
ref>8,</ref>9,</ref>13,</ref>23,</ref>26,</ref>31]</ref>. In the pioneering work, Glasner et al. [9]</ref> proposed to jointly exploit repeating patches within and across image scales by ef type="bibr" target="#b6">[7]</ref> effectively assumed that similar patches exist in an extremely localized region and thus can greatly reduce computation time. Following this fashion, Yang et al. [31]</ref> proposed a very fast regression model that focused on only in-place cross-scale similarity. To handle appearance variations in the scene, Huang et al. <ref ty
ref>8,</ref>9,</ref>13,</ref>23,</ref>26,</ref>31]</ref>. In the pioneering work, Glasner et al. [9]</ref> proposed to jointly exploit repeating patches within and across image scales by ef type="bibr" target="#b6">[7]</ref> effectively assumed that similar patches exist in an extremely localized region and thus can greatly reduce computation time. Following this fashion, Yang et al. [31]</ref> proposed a very fast regression model that focused on only in-place cross-scale similarity. To handle appearance variations in the scene, Huang et al. <ref ty
of deep SISR, for several years, efforts [5,</ref>14,</ref>19,</ref>37,</ref>39,</ref>33,</ref>6]</ref> have been made on increasing the depth or width of the networks to increase the r simply adding or concatenating them together, as widely used in previous works [19,</ref>20,</ref>38,</ref>39]</ref>. In this paper, we proposed a mutual-projected fusion to progressively combine features together. The algorithm procedure is illustrated in Figure <ref type="f head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets and Evaluation Metrics</head><p>Following [19,</ref>38,</ref>39]</ref>, we use 800 images from DIV2K [28]</ref> dataset to train our models. For testing, we report the performance on five standard be SRMDNF [36]</ref>, MemNet [27]</ref>, EDSR [19]</ref>, DBPN [11]</ref>, RDN [39]</ref>, RCAN [37]</ref>, NLRN [20]</ref>, SRFBN [18]</ref>, OISR <ref ty ut-performs other state-of-the-arts by a large margin. EDSR [19]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours Urban100 (4×): img 078 HR Bicubic LapSRN <ref type="bibr" targ cubic LapSRN [17]</ref> EDSR [19]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours Urban100 (4×): img 047 HR Bicubic LapSRN <ref type="bibr" targ cubic LapSRN [17]</ref> EDSR [19]</ref> DBPN [11]</ref> OISR [12]</ref> RDN [39]</ref> RCAN [37]</ref> SAN [2]</ref> Ours which only needs 20% parameters of RCAN and SAN, but achieves
eveloped and achieves promising results. Such algorithms utilize the cross-scale information redundancy of a given image as a unique source for reconstruction without relying on any external examples [7,</ref>8,</ref>9,</ref>13,</ref>23,</ref><ref f> proposed to jointly exploit repeating patches within and across image scales by integrating the idea of multiple image SR and examplebased SR into a unified framework. Furthermore, Freedman et al. [7]</ref> effectively assumed that similar patches exist in an extremely localized region and thus can greatly reduce computation time. Following this fashion, Yang et al
image as a unique source for reconstruction without relying on any external examples [7,</ref>8,</ref>9,</ref>13,</ref>23,</ref>26,</ref>31]</ref>. In the pioneering work, Glasner et al. et al. [31]</ref> proposed a very fast regression model that focused on only in-place cross-scale similarity. To handle appearance variations in the scene, Huang et al. [13]</ref> enlarged the internal dictionary by modeling geometric transformations. The idea of internal data repetition has also been applied to solve SR with blur and n erformance on five standard benchmark datasets: Set5 [1]</ref>, Set14 [34]</ref>, B100 [21]</ref>, Urban100 [13]</ref> and Manga109 [22]</ref>. For evaluation, all the SR results are first transformed into YCbCr space and evaluated by PSNR and SS on-local attention and the in-scale one is to allow network to benefit from abundant internal HR hints with different scales. To verify it, we visualize its correlation maps on 6 images from Urban100 [13]</ref>, and compare it with in-scale non-local attention. As shown in Figure 6</ref>, these images contain extensive recurrences o
re correspondence makes us search high-frequency details directly from LR images, leading to more faithful, accurate and high-quality reconstructions.</p><p>Since the first deep learning-based method [4]</ref> was proposed, discriminative learning based methods make it possible to use large-scale external image priors for SISR. Compared with traditional methods, they r and noisy images [23,</ref>26]</ref>.</p><p>Deep CNNs for Image SR The first work that introduced CNN to solve image SR was proposed by [4]</ref>, where they interpret the three consecutive convolution layers as corresponding extraction, non-linear mapping and reconstruction step in sparse coding. Kim et
image as a unique source for reconstruction without relying on any external examples [7,</ref>8,</ref>9,</ref>13,</ref>23,</ref>26,</ref>31]</ref>. In the pioneering work, Glasner et al. et al. [31]</ref> proposed a very fast regression model that focused on only in-place cross-scale similarity. To handle appearance variations in the scene, Huang et al. [13]</ref> enlarged the internal dictionary by modeling geometric transformations. The idea of internal data repetition has also been applied to solve SR with blur and n erformance on five standard benchmark datasets: Set5 [1]</ref>, Set14 [34]</ref>, B100 [21]</ref>, Urban100 [13]</ref> and Manga109 [22]</ref>. For evaluation, all the SR results are first transformed into YCbCr space and evaluated by PSNR and SS on-local attention and the in-scale one is to allow network to benefit from abundant internal HR hints with different scales. To verify it, we visualize its correlation maps on 6 images from Urban100 [13]</ref>, and compare it with in-scale non-local attention. As shown in Figure 6</ref>, these images contain extensive recurrences o
14,</ref>19,</ref>37,</ref>39,</ref>33,</ref>6]</ref> have been made on increasing the depth or width of the networks to increase the receptive field or improve the feature representation. However, the essence of th
h research in NLP-oriented work with EBMs, which tends to use EBM representations inside the training loops of neural networks, blurring different dimensions of the problem. By contrast -similarly to Parshakova et al. (2019a;</ref>b)</ref> in a different context -we clearly decouple the relatively simple problem of determining a "pivot" optimal EBM f i ) , and estimate µ(λ)</p><p>. = E x∼p φ(x) by SNIS (Self Normalized Importance Sampling) (Kim &amp; Bengio, 2016;</ref>Owen, 2013;</ref>Parshakova et al., 2019a</ref>) SNIS consists in computing:</p><formula xml:id="formula_4">μ(λ) = N i=1 w i (λ) φ(x i ) N i=1 w i (λ) ,<label>(6)</label></formula><p>and ng the global sequence (Andor et al., 2016;</ref>Belanger &amp; McCallum, 2016)</ref>. Some current applications to text generation include Parshakova et al. (2019a)</ref> and Deng et al. (2020)</ref>, who augment a standard autoregressive LM with an additional global factor in
onal control, is that of social biases conspicuous in pretrained language models. (Stanovsky et al., 2019;</ref>Prates et al., 2020;</ref>Sheng et al., 2019a;</ref>Brown et al., 2020b)</ref>. However, applying distributional control on pretrained models is still an understudie
in open-domain generation where no gold references are available for fine-tuning, making the pretrained LM itself the yardstick for fluency. Jaques et al. (2017);</ref>Ziegler et al. (2019)</ref> propose a conservative fine-tuning approach moderated by a KL penalty between the trained policy and the original LM, discouraging large devi objective rather than a distributional one; in other words, while GDC tries to get a similar sampling distribution to p, this baseline tries to get sequences of maximal probability p(x). (3) ZIEGLER (Ziegler et al., 2019)</ref>: an approach relying on the RL Proximal Policy Optimization (PPO) algorithm (Schulman et al., 2017)</ref> and periments. This shows the usefulness of our proposed analysis -in addition to the self-BLEU metrics -for distinguishing diversity at the sequence level or at the distribution level. Similarly, ZIEGLER(Ziegler et al., 2019)</ref> often suffers from the same lack of sample diversity (5 out of the 17 experiments); GDC obtains the highest diversity amongst all baselines,
all generations. One problem that is currently causing a lot of concern, and which could much benefit from distributional control, is that of social biases conspicuous in pretrained language models. (Stanovsky et al., 2019;</ref>Prates et al., 2020;</ref>Sheng et al., 2019a;</ref><ref type="bibr" target="
ed stories or dialogues. Other non-RL techniques for approximating the global sequence constraints φ(x) by a biased estimator φ(x t |x :t−1 ). These techniques usually referred to as weighted decodingHoltzman et al. (2018)</ref>;See et al. (2019)</ref> this however still requires a heavy search procedure and this biased estimation of se
mating the global sequence constraints φ(x) by a biased estimator φ(x t |x :t−1 ). These techniques usually referred to as weighted decodingHoltzman et al. (2018)</ref>;See et al. (2019)</ref> this however still requires a heavy search procedure and this biased estimation of sequences that satisfy the global constraint compromises fluen
n (Ranzato et al., 2016;</ref>Bahdanau et al., 2017)</ref>, or hand crafted rewards (Li et al., 2016b;</ref>Tambwekar et al., 2019)</ref> to improve certain a priori desirable features.</p><p>However, such an optimization process is not infallible; <ref type="bibr" target="#b3 between the perplexity-based training of the initial model and the evaluation metrics used at test time. Some others use heuristic rewards as in (Li et al., 2016b;</ref>Tambwekar et al., 2019)</ref> Competing Degeneration in Controlled Text Generation When using such approaches, one needs to take care of not forgetting too much of the o

BLEU and ROUGE for Machine Translation and Summarization (Ranzato et al., 2016;</ref>Bahdanau et al., 2017)</ref>, or hand crafted rewards (Li et al., 2016b;</ref>Tambwekar et al., 2019)</ref> to improve certain a priori desirable features.</p><p>However, such an optimization ROUGE at training time to compensate for the mismatch between the perplexity-based training of the initial model and the evaluation metrics used at test time. Some others use heuristic rewards as in (Li et al., 2016b;</ref>Tambwekar et al., 2019)</ref> Competing Degeneration in Controlled Text Generation When using such approaches, one f>), actor critic for Abstractive Summarization (Bahdanau et al., 2017)</ref>, Image-to-Text Liu et al. (2016b)</ref>, Dialogue Generation Li et al. (2016b)</ref>, and Video Captioning (Pasunuru &amp; Bansal, 2017)</ref>. With respect to rewards, some approaches for Machine Tr
optimization techniques when training generative models for text, has recently been documented in (Caccia et al., 2020)</ref>. So additionally, we report Self-BLEU-3,4,5 (Zhu et al., 2018)</ref> to measure repetitions at a distributional level across the whole set of generated samples, and also provide a token/type frequency analysis (se
on There is a large reinforcement learning inspired literature about steering an autoregressive sequential model towards optimizing some global reward over the generated text. This includes REINFORCE (Williams, 1992a)</ref> for Machine translation (MT) Ranzato et al. ( 2016</ref>), actor critic for Abstractive Summarization <ref type="bibr" target
la xml:id="formula_13">)</formula><p>where d is the dimension of z. Thus, we only need to calculate category loss term. To enable distribution q ϕ c (z|x q c ) differentiable, we follow previous work [2,</ref>3,</ref>19]</ref> to use reparameterization trick to parameterize z. Reparameterization Trick Instea
values for corresponding products I c in the same category c.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MAML</head><p>We give an overview of Model-Agnostic Meta-Learning method [12]</ref> which is a representative algorithm of optimization-based metalearning approaches. First, we use our problem as an example to introduce the general learning s y. Thus, how we take advantage of this set to benefit our framework is a key problem. To tackle this problem, we propose to encode the information from support set into our parameter inspired by MAML [12]</ref> and further we can obtain a category-specific model to accelerate unseen category adaptation. We will introduce how to incorporate information from support se on the unlabeled support data of given task with entropy minimization, and then conduct inference on testing query data.</p><p>•Meta-Learning We select two state-of-the-art meta learning models MAML [12]</ref> and Meta-SGD [21]</ref> as baselines. The model architectures of two baselines are identical with Transformers in fine-tune set l-based and metric-learning based models. Optimization-based methods aim to modify the gradient descent based learning procedure for new task quick adaptation. In the optimization-based methods, MAML [12]</ref> is a recent promising model which learns a set of model parameters that are used to rapidly learn novel task with a small set of labeled data. Following this
e natural language inference (NLI) task, which automatically determines if a hypothesis is true or false based on a text statement. Recently, powerful neural network based models, such as Transformer [24]</ref> and BERT [11]</ref> have shown promising performance towards NLI task. However, their success relies on sufficient high-quality /div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Model Architecture</head><p>Our model mainly includes two components: encoder and decoder.</p><p>Encoder The encoder in use is Transformer [24]</ref>, which is a context-aware model and has been proven powerful in textual classification. The transformer takes a sequence of word tokens as input. In our probl dings.</p><p>•Fine-tune Attribute validation is related to natural language inference (NLI) problem. We select three state-of-the-art models ESIM [10]</ref>, Transformer [24]</ref>, BERT [11]</ref> as baselines. All sublayers of ESIM produce the output with dimension d = 16 except the last output layer. For tiNLI) corpus have promoted the development of many different neural NLI models [10,</ref>11,</ref>14,</ref>24]</ref> that achieve promising performance. However, NLI task usually requires large annotated datasets for training purpose. While pre-training is beneficial, it is n
eriment section 4.6.</p><formula xml:id="formula_11">L c q = −E q ϕc (z |x q c ) [log p θc (y q c |z)] Inference Loss +λ D K L (q ϕc (z |x q c ) | | q ϕc (z |x s c ))</formula><p>Bridging Regularizer (10)</ref> In this paper, we assume q ϕ c (z|x q c ) and q ϕ c (z|x s c ) follow multivariate normal distributions N (µ(x q c ), σ 2 (x q c )I) and N (µ(x s c ), σ 2 (x s cription and the average of attribute value word embeddings.</p><p>•Fine-tune Attribute validation is related to natural language inference (NLI) problem. We select three state-of-the-art models ESIM [10]</ref>, Transformer [24]</ref>, BERT [11]</ref> as baselines. All sublayers of ESIM produce the output w target="#b5">[6]</ref> (SNLI) and Multi-Genre Natural Language Inference [28]</ref> (MultiNLI) corpus have promoted the development of many different neural NLI models [10,</ref>11,</ref>14,</ref>24]</ref> that achieve promising performance. How
unlabeled support set by entropy minimization. Entropy minimization encourages the confidence of predictions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref>22,</ref><ref type="bibr" to output inference results. In the fine-tune setting, the training data include unlabeled support data and labeled query data. We use the entropy minimization to define the loss on unlabeled data as [15]</ref> and use the cross-entropy to define the loss on labeled data. The ratio of labeled loss and unlabeled loss is set as 10:1. In the testing stage, the pre-train
eled, we redefine the loss function on unlabeled support set by entropy minimization. Entropy minimization encourages the confidence of predictions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref><ref type="bibr"
eriment section 4.6.</p><formula xml:id="formula_11">L c q = −E q ϕc (z |x q c ) [log p θc (y q c |z)] Inference Loss +λ D K L (q ϕc (z |x q c ) | | q ϕc (z |x s c ))</formula><p>Bridging Regularizer (10)</ref> In this paper, we assume q ϕ c (z|x q c ) and q ϕ c (z|x s c ) follow multivariate normal distributions N (µ(x q c ), σ 2 (x q c )I) and N (µ(x s c ), σ 2 (x s cription and the average of attribute value word embeddings.</p><p>•Fine-tune Attribute validation is related to natural language inference (NLI) problem. We select three state-of-the-art models ESIM [10]</ref>, Transformer [24]</ref>, BERT [11]</ref> as baselines. All sublayers of ESIM produce the output w target="#b5">[6]</ref> (SNLI) and Multi-Genre Natural Language Inference [28]</ref> (MultiNLI) corpus have promoted the development of many different neural NLI models [10,</ref>11,</ref>14,</ref>24]</ref> that achieve promising performance. How
ine of research is metalearning. Meta-learning has long been proposed as a form of learning that would allow systems to systematically build up and re-use knowledge across different but related tasks [25]</ref>. More specifically, meta-Learning approaches can be broadly classified into three categories: optimization-based, model-based and metric-learning based models
V = {v i : i ∈ I }, we aim to identify X = (P, V ) pair that are incorrect for product I .</p><p>After defining our problem, we introduce our learning setting. Following the few-shot learning setting [26]</ref>, in each category c ∼ C, we have a few unlabeled examples x s c = {x s c,i } N i=1 to constitute the support set D s c and have a small set of labeled example
meter gradient update step is set to 1 and inner learning rate β is set to 0.3 for all fine-tune and meta-learning models. The traditional models (LR, SVM, RF) are implemented by scikit-learn package [23]</ref>. The best parameters are selected based on the validation set.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Comparison</head><
ation. Entropy minimization encourages the confidence of predictions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref>22,</ref>27]</ref>. More concretel
dels have achieved an improvement in the performance of anomaly detection due to their powerful abilities [8]</ref>. The deep learning anomaly detection (DAD) approaches [7,</ref>30]</ref> model the log data as a natural language sequence and apply RNN and CNN to detect anomalies. Different with log anomaly
e natural language inference (NLI) task, which automatically determines if a hypothesis is true or false based on a text statement. Recently, powerful neural network based models, such as Transformer [24]</ref> and BERT [11]</ref> have shown promising performance towards NLI task. However, their success relies on sufficient high-quality /div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Model Architecture</head><p>Our model mainly includes two components: encoder and decoder.</p><p>Encoder The encoder in use is Transformer [24]</ref>, which is a context-aware model and has been proven powerful in textual classification. The transformer takes a sequence of word tokens as input. In our probl dings.</p><p>•Fine-tune Attribute validation is related to natural language inference (NLI) problem. We select three state-of-the-art models ESIM [10]</ref>, Transformer [24]</ref>, BERT [11]</ref> as baselines. All sublayers of ESIM produce the output with dimension d = 16 except the last output layer. For tiNLI) corpus have promoted the development of many different neural NLI models [10,</ref>11,</ref>14,</ref>24]</ref> that achieve promising performance. However, NLI task usually requires large annotated datasets for training purpose. While pre-training is beneficial, it is n
tions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref>22,</ref>27]</ref>. More concretely, the loss function L c s on the support set x s c is defined
ation. Entropy minimization encourages the confidence of predictions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref>22,</ref>27]</ref>. More concretel
eled, we redefine the loss function on unlabeled support set by entropy minimization. Entropy minimization encourages the confidence of predictions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref><ref type="bibr"
="#b3">[4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref>22,</ref>27]</ref>. More concretely, the loss function L c s on the support set x s c is defined by entropy as follows:</p><formula xml:id="formula_6">L c s (θ, ϕ, x s c ) = −E q
meter gradient update step is set to 1 and inner learning rate β is set to 0.3 for all fine-tune and meta-learning models. The traditional models (LR, SVM, RF) are implemented by scikit-learn package [23]</ref>. The best parameters are selected based on the validation set.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Comparison</head><
dels have achieved an improvement in the performance of anomaly detection due to their powerful abilities [8]</ref>. The deep learning anomaly detection (DAD) approaches [7,</ref>30]</ref> model the log data as a natural language sequence and apply RNN and CNN to detect anomalies. Different with log anomaly
="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Attribute validation task is related to anomaly detection which aims to find patterns in data that do not conform to expected behavior [9]</ref>. In the anomaly detection, the most related line of research is log anomaly detection which aims to find text, which can indicate the reasons and the nature of
ation. Entropy minimization encourages the confidence of predictions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref>22,</ref>27]</ref>. More concretel
tions and is commonly used in the semisupervised learning [4,</ref>15,</ref>20]</ref> and domain adaptation [16,</ref>22,</ref>27]</ref>. More concretely, the loss function L c s on the support set x s c is defined
h NLP research now focuses on interpreting the Transformer, e.g., the subspecialty of "BERTology" (Rogers et al., 2020)</ref>, which specifically studies the BERT model (Devlin et al., 2019)</ref>.</p><p>In this work, we adapt and extend this line of interpretability research to protein sequences. We analyze Transformer protein models t t uses attention to accelerate learning (Vaswani et al., 2017)</ref>. In NLP, transformers are the backbone of state-of-the-art pre-trained language models such as BERT (Devlin et al., 2019)</ref>. BERTology focuses on interpreting what the BERT model learns about language using a suite of probes and interventions <ref type="bibr" targe
nd ProtTrans also released several large-scale pretrained protein Transformer models (Elnaggar et al., 2020)</ref>. Riesselman et al. ( 2019</ref>); Madani et al. (2020)</ref> trained autoregressive generative models to predict the functional effect of mutations and generate natural-like proteins.</p><p>From an inter

restricted to specific families or superfamilies of proteins (Kinjo &amp; Nakamura, 2009)</ref>, and binding sites can reveal evolutionary relationships among proteins (Lee et al., 2017)</ref>. Thus binding sites may provide the model with a high-level characterization of the protein that is robust to individual sequence variation. By
to remarkable advances in understanding human health and the development of disease therapies. The decreasing cost of sequencing technology has enabled vast databases of naturally occurring proteins (El-Gebali et al., 2019a)</ref>, which are rich in information for developing powerful machine learning models of protein sequences. For example, sequence models leverag
of amino acid sequences. We primarily focus on the BERT-Base model from TAPE (Rao et al., 2019)</ref>, which was pretrained on Pfam, a dataset of 31M protein sequences (El-Gebali et al., 2019b)</ref>. We refer to this model as TapeBert. We also analyze 4 pre-trained Transformer models from ProtTrans (Elna
the Secondary Structure dataset (Rao et al., 2019;</ref>Berman et al., 2000;</ref>Moult et al., 2018;</ref>Klausen et al., 2019)</ref> from TAPE. We considered a more fine-grained taxonomy of secondary structure with three categories: Helix, Strand, and Turn/Bend, with the la the Secondary Structure dataset (Rao et al., 2019;</ref>Berman et al., 2000;</ref>Moult et al., 2018;</ref>Klausen et al., 2019)</ref>. The former was used for analysis of amino acids and contact maps, and the latter was used for analysis of secondary structure. We additional


, attention may have less or more explanatory power for model predictions (Jain &amp; Wallace, 2019;</ref>Serrano &amp; Smith, 2019;</ref>Pruthi et al., 2020;</ref>Moradi et al., 2019;</ref>Vashishth et al., 2019)</ref>. Visualization techniques
Probing tasks. We also perform probing tasks on the model, which test the knowledge contained in model representations by using the them as inputs to a classifier that predicts a property of interest (Veldhoen et al., 2016;</ref>Conneau et al., 2018;</ref>Adi et al., 2016)</ref>. The performance of the prob ut language using a suite of probes and interventions (Rogers et al., 2020)</ref>. So-called diagnostic classifiers are used to interpret the outputs from BERT's layers (Veldhoen et al., 2016)</ref>. At a high level, mechanisms for interpreting BERT can be placed into three main categories: interpreting the learned embeddings <ref type=


nce modeling (Rosenfeld et al., 2001;</ref>Wang et al., 2015;</ref>2017;</ref>Wang &amp; Ou, 2017;</ref>2018a;</ref>Parshakova et al., 2019)</ref>. In particular, our residual modeling form and the training algorithm is the same as in <ref ty


d to close the gap between the model distribution and the data distribution, rather than relying on surrogate ranking losses. This approach is also related to other sequence level training objectives (Edunov et al., 2018)</ref>, with the major differ-ence that in those works training aims at improving the baseline model, but generation at test time is still greedy.</p
ut in text application we cannot use gradient-based MCMC methods (Teh et al., 2003;</ref>Du &amp; Mordatch, 2019)</ref> and Gibbs sampling (Welling et al., 2005)</ref> is too slow to be practical. Generating negatives by local perturbations of the ground truth would be efficient but hardly useful for genera

d to close the gap between the model distribution and the data distribution, rather than relying on surrogate ranking losses. This approach is also related to other sequence level training objectives (Edunov et al., 2018)</ref>, with the major differ-ence that in those works training aims at improving the baseline model, but generation at test time is still greedy.</p
he partition function is intractable, Maximum Likelihood Estimation (MLE) requires samples from the model distribution, which is usually approximated with Monte Carlo sampling or mean field inference (Hinton, 2012;</ref>LeCun et al., 2006)</ref> for globally normalized models. Unfortunately, both approaches are too expensive for text ap
greedy selection of one token at a time without lookahead.</p><p>Energy-based models (EBMs) (Hinton, 2002;</ref>LeCun et al., 2006;</ref>Ranzato et al., 2007</ref>) are a more general framework which potentially address all these issues, as they do not require any local normalization. They only require th have a long history in machine learning (Hopfield, 1982;</ref>Hinton, 2002;</ref>LeCun et al., 2006;</ref>Ranzato et al., 2007)</ref>. The key challenge of training is mining for good negatives. This can be accomplished explicitly by fantasizing inputs where the energy shoul hallenge of training is mining for good negatives. This can be accomplished explicitly by fantasizing inputs where the energy should be increased or implicitly via global constraints such as sparsity (Ranzato et al., 2007)</ref>. Methods attempting at maximizing the likelihood of the data require to sample from the distribution induced by the model. Unfortunately, gr sample from the distribution induced by the model. Unfortunately, gradient-based MCMC approaches like Hybrid Monte Carlo (Teh et al., 2003)</ref> and Langevyn dynamics (Ranzato et al., 2007;</ref>Du &amp; Mordatch, 2019;</ref>Xie et al., 2016;</ref>2017;</ref
empirically this type of approach can outperform modern state-of-the-art language modeling baselines, both in terms of perplexity, and through human evaluation.</p><p>Generative Adversarial Networks (Goodfellow et al., 2014</ref>) also relate to EBMs, except that in EBMs the generator is implicit and negatives samples are produced by the discriminator itself. In our
s at improving the baseline model, but generation at test time is still greedy.</p><p>Energy Networks have been used for sequence modeling (Rosenfeld et al., 2001;</ref>Wang et al., 2015;</ref>2017;</ref>Wang &amp; Ou, 2017;</ref>2018a;</ref>


">(Ranzato et al., 2007;</ref>Du &amp; Mordatch, 2019;</ref>Xie et al., 2016;</ref>2017;</ref>2019;</ref>2018;</ref>Gao et al., 2018;</ref>Nijkamp et al., 2019)</ref> are not applicable when the input is discrete tion function</p><formula xml:id="formula_5">Z θ = x P LM (x) exp(−E θ (x)) = E x∼P LM exp(−E θ (x))</formula><p>, we derive two estimators for the log-partition function log Z θ based on the work of Nowozin (2018)</ref>.</p><formula xml:id="formula_6">Theorem 2. Denote T n as the empirical estimate of log E x∼P LM exp(−E(x)) with n samples x i ∼ P LM (i = 1, • • • , ant to emphasize that they are true only asymptotically (when n is sufficiently large). We also want to note that to get lower variance estimates we use leave-one-out strategy to estimate T n−1 . See Nowozin (2018)</ref> for implementation details and methods to improve numeric stability.</p><p>Similarly to locally normalized models, we can also factorize the probabi and let T n = log 1 n n i=1 exp(−E(x i )), then ∀ &gt; 0, ∃N &gt; 0 such that ∀n &gt; N we have Z θ − &lt; E[T n ] &lt; Z θ &lt; E[(2n − 1)T n − 2(n − 1)T n−1 ] &lt; Z θ + (7)</formula><p>Proof. From Nowozin (2018)</ref> Eq. 35, we can write E[T n ] as</p><formula xml:id="formula_11">E[T n ] = Z θ − µ 2 2µ 2 1 n + 1 3µ 3 µ 3 n 2 − 1 4µ 4 ( 3 n 2 µ 2 2 + 1 n 3 (µ 4 −


>Baselines We consider as base language model (BASE LM) used to generate negatives for the residual EBM, a transformer language model with 12 layers, h = 16, d model = 1024, d f f = 4096 (we refer to Vaswani et al. (2017)</ref> for notations). This is also our first baseline model.</p><p>The joint model has as many parameters as the sum of the number of parameters in 68, d f f = 6272, and is trained by standard token level cross-entropy loss.</p><p>Residual EBM Architecture We consider two architectures for our residual EBM, both of them are based on transformers (Vaswani et al., 2017;</ref>Devlin et al., 2018)</ref>. The first version uses causal self-attention and is derived from the base LM, a uni
during training, and E θ is the energy function parameterized by θ. The resulting model P θ (x) is globally normalized due to the energy term. Note that the same residual formulation was also used in Rosenfeld et al. (2001)</ref>; Wang &amp; Ou (2018b)</ref>; Parshakova et al. (2019)</ref>.</p><p>This form , with the major differ-ence that in those works training aims at improving the baseline model, but generation at test time is still greedy.</p><p>Energy Networks have been used for sequence modeling (Rosenfeld et al., 2001;</ref>Wang et al., 2015;</ref>2017;</ref>Wang &amp; Ou, 2017;</ref><ref type="bi
and increased at other data points (a.k.a. negative examples). In maximum likelihood training negatives are generated from the model, but in text application we cannot use gradient-based MCMC methods (Teh et al., 2003;</ref>Du &amp; Mordatch, 2019)</ref> and Gibbs sampling (Welling et al., 2005)</ref> is to </ref>. Methods attempting at maximizing the likelihood of the data require to sample from the distribution induced by the model. Unfortunately, gradient-based MCMC approaches like Hybrid Monte Carlo (Teh et al., 2003)</ref> and Langevyn dynamics (Ranzato et al., 2007;</ref>Du &amp; Mordatch, 2019;</ref><re
nce modeling (Rosenfeld et al., 2001;</ref>Wang et al., 2015;</ref>2017;</ref>Wang &amp; Ou, 2017;</ref>2018a;</ref>Parshakova et al., 2019)</ref>. In particular, our residual modeling form and the training algorithm is the same as in <ref ty
shed by Elsevier Ltd.</p><p>gorithms to resist noise and outliers. Prior probability defined on the label field is one of the most effective way to construct the connection between neighboring pixels [5]</ref> . It decreases with the number of pixels having the same label with the central one in the neighborhood system. Thus, it is able to distinguish noise, outliers
image as axes to establish a Cartesian coordinate system and exhibits all the pixels of the detected image as points in it. Pixels representing the same object naturally cluster in the spectral space [4]</ref> . This property provides us an opportunity to segment pixels belonging to different objects according to their positions in the spectral space, automatically. S
pe="bibr" target="#b16">[17]</ref> .</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Riemannian manifold space</head><p>Image representation is very important for image segmentation [18]</ref> . Riemannian manifold space is based on the characteristics that a probability distribution in the Euclidean space can be expressed by a point on a Riemannian
div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Spectral space-based algorithms</head><p>Mean shift is a typical clustering algorithm which shifts the mean of the cluster to its center of mass [6]</ref> . Recently, Yamasaki and Tanaka have studied the properties of it via regarding mean shift-based algorithms as gradient ascent with adaptive step size, which pr
ility to control the scale of clusters in the KL-based constraint [16]</ref> . Kernel function-based FCM defined the dissimilarity between pixels by RBF kernel function [27]</ref> . Riemannian manifold space-based Manifold Projection (MP) algorithm [20]</ref> acts as a baseline for the proposed four geodes
s, and assigns pixels to their nearest cluster when the centers of the clusters are appropriate [8]</ref> . It is widely used in image segmentation due to its simplicity [9]</ref> . However, pixels far away from cluster centers are easily to be wrongly assigned. To suppress the effect of noise, Mirghasemi et al. used an adaptive wavelet s
{ θ k } can be expressed by coordinate system { η k } as</p><formula xml:id="formula_6">θ 1 = − η 1 (η 1 ) 2 − η 2 θ 2 = 1 2(η 1 ) 2 − 2 η 2 (7)</formula><p>According to the Legendre transformations [22]</ref> , potential function</p><formula xml:id="formula_7">under the coordinate system { η k } is ϕ(η) = θ k η k − ψ (θ ) = 1 2 ln (−(η 1 ) 2 + η 2 ) − 1 2 − 1 2 ln
ter centers are easily to be wrongly assigned. To suppress the effect of noise, Mirghasemi et al. used an adaptive wavelet shrinkage to restrain noise and outliers and then segment the image with FCM [10]</ref> . The reason caused poor performance on noise and outliers of the traditional spectral space-based algorithms is that the segmentation model cannot describe va
having the same label with the central pixel. Farag et al. employed the Support Vector Machines (SVM) to define the class conditional probability and combined it with the MRF-based prior distribution [15]</ref> . The proposed segmentation model is solved by maximum a posteriori. Chatzis and Varvarigou used the prior distribution as a cluster-size controller in the in
ense can be used to improve the robustness of segmentation algorithms to noise and outliers. Markov Random Field (MRF) model is an efficient way to construct the connection between neighboring pixels [13,</ref>14]</ref> . It defines the prior probability according to the labels of pixels in the neighborhood system. The prior probability
on-based manifold projection criterion. Detailed descriptions are as follows.</p><p>Radial Basis Function (RBF) is a non-linear function which can map low dimensional data to higher dimensional space [23]</ref> . It is</p><formula xml:id="formula_12">defined as RBF = exp {−γ || v p − v q || 2 }</formula><p>, where v p is the intensity of point p, v q is the intensity
space [11]</ref> . Weighted kernel based FCM combines the advantages of kernel function and the weighted FCM, thus it is able to obtain much better segmentation results [12]</ref> .</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Neighborhood system-based algorithms</head><p>Neighboring pixels have a greater chance to
ility to control the scale of clusters in the KL-based constraint [16]</ref> . Kernel function-based FCM defined the dissimilarity between pixels by RBF kernel function [27]</ref> . Riemannian manifold space-based Manifold Projection (MP) algorithm [20]</ref> acts as a baseline for the proposed four geodes
">[15]</ref> . The proposed segmentation model is solved by maximum a posteriori. Chatzis and Varvarigou used the prior distribution as a cluster-size controller in the introduced KL-based constraint [16]</ref> . Due to the smoothing effect of the prior probability defined on the label field, the proposed algorithm outperforms other spectral space-based ones. Guided [26]</ref> . Kullback-Leibler (KL)-based FCM (KLFCM) employed the posterior probability as the dissimilarity and used the prior probability to control the scale of clusters in the KL-based constraint [16]</ref> . Kernel function-based FCM defined the dissimilarity between pixels by RBF kernel function [27]</ref> . Riemannian manifold sp
on-based manifold projection criterion. Detailed descriptions are as follows.</p><p>Radial Basis Function (RBF) is a non-linear function which can map low dimensional data to higher dimensional space [23]</ref> . It is</p><formula xml:id="formula_12">defined as RBF = exp {−γ || v p − v q || 2 }</formula><p>, where v p is the intensity of point p, v q is the intensity
ant task in remote sensing image processing [1]</ref> . The accuracy of image segmentation has an essential influence on the subsequent image analysis and interpretation [2]</ref> . Convolutional Neural Network (CNN) which can extract contextual information of an image has gain more attention these years [3]<
image analysis and interpretation [2]</ref> . Convolutional Neural Network (CNN) which can extract contextual information of an image has gain more attention these years [3]</ref> . It learns features of the input image by stacking the convolutional and pooling layers. The constructed network is a nonlinear model acting as a transformatio
target="#b18">[19]</ref> . Zhao et al. assumed the feature of a pixel is characterized by a Gaussian pdf established in its neighborhood system, and then map the Gaussian pdf to a Riemannian manifold [20]</ref> . Then, a point on the Riemannian manifold represents a pixel in the image. Since the mapping process takes the interaction between a pixel and its neighborin can represent spectral and spatial features simultaneously. Inspired by this, a Gaussian model is constructed in neighborhood system and its pdf is used to describe the features of the central pixel [20]</ref> . This expression does not only contain the characteristics of the central pixel but also the features of its neighbors. Then, the pdf-expressed image is mapp re constructed to represent the features of the detected image and its corresponding segmentation result. The final segmentation result is obtained by manifold projection between the two submanifolds [20]</ref> . The details are as follows.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Neighbor mapping</head><formula xml:id="formula_0">Let X = { x ernel function-based FCM defined the dissimilarity between pixels by RBF kernel function [27]</ref> . Riemannian manifold space-based Manifold Projection (MP) algorithm [20]</ref> acts as a baseline for the proposed four geodesic-kernel-based image segmentation algorithms, namely MPGK, MPGK_PoP, MPGK_PiP and MPGK_mFS. The corresponding .">Analysis of parameters and computational complexity</head><p>Size of neighborhood systems has a strong impact on the final segmentation results. The impact has been discussed in the former work in [20]</ref> . As MPGK-based algorithms have similar foundation with MP, the influence of size of neighborhood systems are similar. The larger the size of neighborhood sys
pe="bibr" target="#b16">[17]</ref> .</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Riemannian manifold space</head><p>Image representation is very important for image segmentation [18]</ref> . Riemannian manifold space is based on the characteristics that a probability distribution in the Euclidean space can be expressed by a point on a Riemannian
e in the feature space [24]</ref> . FCM_S algorithm introduces a constraint in image domain, that neighboring pixels contribute to the segmentation of the central pixel [25]</ref> . Markov Random Model-based FCM (MRF_FCM) used the MRF model to establish the connection between pixels in the neighborhood system to improve the possibility
Markov Random Model-based FCM (MRF_FCM) used the MRF model to establish the connection between pixels in the neighborhood system to improve the possibility of neighboring pixels having the same label [26]</ref> . Kullback-Leibler (KL)-based FCM (KLFCM) employed the posterior probability as the dissimilarity and used the prior probability to control the scale of clust
e in the feature space [24]</ref> . FCM_S algorithm introduces a constraint in image domain, that neighboring pixels contribute to the segmentation of the central pixel [25]</ref> . Markov Random Model-based FCM (MRF_FCM) used the MRF model to establish the connection between pixels in the neighborhood system to improve the possibility
lications on resource-constrained devices has created an acute need for highly efficient image processing pipeline implementations.</p><p>In recent years, the Halide image processing language [Ragan- Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013</ref>] has proven to be an effective system for authoring high-performance image process acute need for highly efficient image processing pipeline implementations.</p><p>In recent years, the Halide image processing language [Ragan- Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013</ref>] has proven to be an effective system for authoring high-performance image processing code, and it is now used to synthesize production co xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Prior Work</head><p>There have been a number of recent efforts to automatically generate efficient image processing pipelines from high-level programs. Ragan-Kelley et al. [2013]</ref> employed auto-tuning guided by genetic search to automatically generate Halide schedules that were performance competitive with hand-tun section we summarize common global program restructuring decisions made by Halide developers when authoring efficient schedules. We assume familiarity with the Halide system, and refer the reader to [Ragan-Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013]</ref> for a comprehensive description of the language and its features.</p><p>A Table 1</ref>. These benchmarks span a range of computational photography, image processing, and computer vision workloads. Eight of the benchmarks are drawn from public literature [Ragan-Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013;</ref>Ragan-Kelley et al. 2015]</ref> and the Hali ions made by Halide developers when authoring efficient schedules. We assume familiarity with the Halide system, and refer the reader to [Ragan-Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013]</ref> for a comprehensive description of the language and its features.</p><p>A Halide program is a DAG of computation, where each node in the of computational photography, image processing, and computer vision workloads. Eight of the benchmarks are drawn from public literature [Ragan-Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013;</ref>Ragan-Kelley et al. 2015]</ref> and the Halide open source community. We also added six new Halide benchmar
LENSBLUR, NLMEANS, and MAXFILTER) written and manually-scheduled by professional Halide developers.</p><p>? Dense matrix-matrix multiplication (MATMUL). Fast bilateral filter using the bilateral grid [Chen et al. 2007</ref>]. Constructs the grid using a histogram reduction, followed by stencil and sampling operations.   Dense matrix-matrix multiplication written as a

vision workloads. Eight of the benchmarks are drawn from public literature [Ragan-Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013;</ref>Ragan-Kelley et al. 2015]</ref> and the Halide open source community. We also added six new Halide benchmarks:</p><p>? Three computational photography pipelines (LENSBLU


mplex pipelines. OpenTuner output for more complex pipelines such as RAW camera processing, pyramid blending, and multi-scale interpolation is five to ten times slower than hand-tuned implementations [Mullapudi et al. 2015]</ref>.</p><p>While auto-tuning may seem like an attractive strategy for optimizing Halide programs, its use in a production setting is problemati mplementations (e.g., Photoshop's local Laplacian filters).</p><p>Auto-tune. Since prior work showed that stochastic auto-tuning systems struggled to converge quickly (or at all) on complex pipelines [Mullapudi et al. 2015]</ref>, we implemented a simple, bruteforce auto-tuning system that searched the low-dimensional space of auto-scheduler parameters, rather than t g capabilities to multi-resolution operations and dynamic filtering [Hegarty et al. 2016</ref>], but in doing so it sacrifices fully automatic scheduling.</p><p>PolyMage [Mullapudi et al. 2015</ref>] extends polyhedral analysis techniques to schedule image processing pipelines implemented in a Halide-like dataflow language. Although the igurations:</p><p>? PARALLELISM_THRESHOLD={6,12,18,24} This parameter sweep can take hours to days for our more complex benchmarks.</p><p>PolyMage. We approximate the scheduling behavior of Poly-Mage [Mullapudi et al. 2015</ref>] by restricting the auto-scheduler to tile only two spatial dimensions and to consider only a single tile size. Also following PolyMage, we containing five functions, organized into two groups. While Halide allows many possible computation orderings for a group, to make exploration of the optimization space tractable, our system follows Mullapudi et al. [2015]</ref> and only considers a narrower space schedules that tile the loop nest corresponding to the group's output function. The computation of all the group are from the same function), and all other functions in the group will be computed within the loop nest of the output function. The iterative grouping process is similar to that employed by Mullapudi et al. [2015]</ref>. However, while their work makes grouping decisions given a predetermined loop tiling structure, our solution jointly makes grouping and lo
vision workloads. Eight of the benchmarks are drawn from public literature [Ragan-Kelley et al. 2012;</ref>Ragan-Kelley et al. 2013;</ref>Ragan-Kelley et al. 2015]</ref> and the Halide open source community. We also added six new Halide benchmarks:</p><p>? Three computational photography pipelines (LENSBLU
sampling and rate changes. Building upon Darkroom, Rigel employs the synchronous dataflow model to further extend pipeline scheduling capabilities to multi-resolution operations and dynamic filtering [Hegarty et al. 2016</ref>], but in doing so it sacrifices fully automatic scheduling.</p><p>PolyMage [Mullapudi et al. 2015</ref>] extends
k with the modern formulation of the Halide language), and required a day or more to find high-quality schedules. A more general Halide auto-tuner was later implemented within the OpenTuner framework [Ansel et al. 2014]</ref>. This system was able to find efficient schedules for simpler pipelines (e.g., bilateral filtering) in about an hour, but fails to converge to g
mplex pipelines. OpenTuner output for more complex pipelines such as RAW camera processing, pyramid blending, and multi-scale interpolation is five to ten times slower than hand-tuned implementations [Mullapudi et al. 2015]</ref>.</p><p>While auto-tuning may seem like an attractive strategy for optimizing Halide programs, its use in a production setting is problemati mplementations (e.g., Photoshop's local Laplacian filters).</p><p>Auto-tune. Since prior work showed that stochastic auto-tuning systems struggled to converge quickly (or at all) on complex pipelines [Mullapudi et al. 2015]</ref>, we implemented a simple, bruteforce auto-tuning system that searched the low-dimensional space of auto-scheduler parameters, rather than t g capabilities to multi-resolution operations and dynamic filtering [Hegarty et al. 2016</ref>], but in doing so it sacrifices fully automatic scheduling.</p><p>PolyMage [Mullapudi et al. 2015</ref>] extends polyhedral analysis techniques to schedule image processing pipelines implemented in a Halide-like dataflow language. Although the igurations:</p><p>? PARALLELISM_THRESHOLD={6,12,18,24} This parameter sweep can take hours to days for our more complex benchmarks.</p><p>PolyMage. We approximate the scheduling behavior of Poly-Mage [Mullapudi et al. 2015</ref>] by restricting the auto-scheduler to tile only two spatial dimensions and to consider only a single tile size. Also following PolyMage, we containing five functions, organized into two groups. While Halide allows many possible computation orderings for a group, to make exploration of the optimization space tractable, our system follows Mullapudi et al. [2015]</ref> and only considers a narrower space schedules that tile the loop nest corresponding to the group's output function. The computation of all the group are from the same function), and all other functions in the group will be computed within the loop nest of the output function. The iterative grouping process is similar to that employed by Mullapudi et al. [2015]</ref>. However, while their work makes grouping decisions given a predetermined loop tiling structure, our solution jointly makes grouping and lo
rs neural network based re-ranking models matured and a distinct trade-off emerged between a neural re-ranking model's effectiveness and its efficiency. While IR-specific networks are reasonably fast [36,</ref>5,</ref>15]</ref>, large Transformer based models [32]</ref>, such ize query and document sequences independent from each other and distill the interactions between terms in a single interaction match matrix, followed by softhistogram scoring based on kernel-pooling [36]</ref>. This allows us to explain scoring reasons by probing the model at the point of the information bottleneck to analyze contextualized term representations and interactions with the histogram-based DRMM model. However, it suffered from the non-differentability of a hard histogram method and the resulting lack of fine-tuned word representations. Xiong et al. [36]</ref> improve on the idea and propose the kernel-pooling technique as part of the KNRM model. Conceptually, it approximates a histogram with a set of Gaussian kerne with pairwise cosine similarity as interaction extractor:</p><formula xml:id="formula_3">Mi,j = cos( qi, dj)<label>(4)</label></formula><p>Then, we transform each entry in M with a set of RBF-kernels [36]</ref>. Each kernel focuses on a specific similarity range with center µ k . The size of all ranges is set by σ. In contrast to Xiong et al. <ref type="bibr" target= th a set of RBF-kernels [36]</ref>. Each kernel focuses on a specific similarity range with center µ k . The size of all ranges is set by σ. In contrast to Xiong et al. [36]</ref> we do not employ an exact match kernel -as contextualized representations do not produce exact matches. Each kernel results in a matrix K ∈ R q len ×d len :</ d has a continuous stream of interactions in each layer and each attention head, making a focused analysis unfeasible.</p><p>The differences of TK to previous kernel-pooling methods are:</p><p>• KNRM [36]</ref> uses only word embeddings, therefore a match does not have context or positional information. • CONV-KNRM [5]</ref> uses a local R model with additional contextualized similarities (via fixed window neighborhood mean vectors) and improves the robustness of PACRR's pooling strategy with randomization during training.</p><p>KNRM [36]</ref> uses a soft-histogram (differentiable Gaussian kernel functions) on top of the interaction matrix of query and document embeddings -summing the interactions b
While IR-specific networks are reasonably fast [36,</ref>5,</ref>15]</ref>, large Transformer based models [32]</ref>, such as BERT [6]</ref>, show substantially better effectiveness at the cost of orders of magnitude longer inference time <ref t r of lightweight Trans-1 TU Wien, Austria, email: s.hofstaetter@tuwien.ac.at 2 TU Wien, Austria, email: markus.zlabinger@tuwien.ac.at 3 TU Wien, Austria, email: hanbury@ifs.tuwien.ac.at former layers [32]</ref> (we evaluate up to three) can effectively contextualize query and document word embeddings. TK's second contribution is a network structure built for explaina KNRM by adding a CNN layer on top of the word embeddings, enabling word-level n-gram representation learning -a local contextualization, fixed by the n-gram size hyperparameter.</p><p>Vaswani et al. [32]</ref> proposed the Transformer architecture in the context of language translation. Their encoder-decoder is built of Transformer layers, each containing multi-head of the contextualization by the end-toend learned α parameter. This allows the model to decide the intensity of the contextualization. We calculate the context(t1:n) with a set of Transformer layers [32]</ref>. First, the input sequence is fused with a positional encoding to form p1:n, followed by a set of l Transformer layers:</p><formula xml:id="formula_1">Transfo
odels [32]</ref>, such as BERT [6]</ref>, show substantially better effectiveness at the cost of orders of magnitude longer inference time [12,</ref>20,</ref>25]</ref>. Given the same amount of limited time, a faster reranking model can incorpora , so that the best model choice becomes task dependent [31]</ref>.</p><p>Recently, the issue of efficiency gained traction in the neural IR community. Hofstätter et al. [12]</ref> establish efficiency baselines for common neural IR models (including BERT) and propose to incorporate speed metrics in replicability campaigns and public lea
layers is involved, inference can be sped up by removing later layers and scoring the intermediate results instead [20]</ref> or by pruning unnecessary attention-heads [33]</ref>. In this work we speed up Transformer contextualization by using very small and few Transformer blocks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><he
the trade-off between effectiveness and efficiency has been thoroughly studied [34,</ref>35,</ref>37,</ref>4]</ref>. This includes applying a temporal constraint on the number of features that are selected for a re-ranking model [35]</ref>, incor , incorporating an efficiency metric in the training of linear rankers [34]</ref>, and comparing the effectiveness and efficiency of various learning-to-rank algorithms [4]</ref>. In web search the speed of a response is crucial as determined by Kohavi et al. [19]</ref> in a large scale experiment, however,
matured and a distinct trade-off emerged between a neural re-ranking model's effectiveness and its efficiency. While IR-specific networks are reasonably fast [36,</ref>5,</ref>15]</ref>, large Transformer based models [32]</ref>, such as BERT [6] . It averages word vectors with a sliding window and appends their similarities to the noncontextualized similarities of the PACRR [15]</ref> model. The CONV-KNRM model [5]</ref> extends KNRM by adding a CNN layer on top of the word embeddings, enabling word-level n-gram representation learning -a local contextualization, fixed by the n- oding and sequence wide self-attention allows for local and global contextualization at the same time. This makes TK more powerful than previous local-only contextualization methods used in CONV-KNRM [5]</ref> and CO-PACRR [16]</ref>.  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interaction Scoring</head><p>After th o previous kernel-pooling methods are:</p><p>• KNRM [36]</ref> uses only word embeddings, therefore a match does not have context or positional information. • CONV-KNRM [5]</ref> uses a local-contextualization with limited positional information in the form of n-gram learning with CNNs. It cross-matches all n-grams in n 2 match matrices, /ref> uses a soft-histogram (differentiable Gaussian kernel functions) on top of the interaction matrix of query and document embeddings -summing the interactions by their similarity.</p><p>CONV-KNRM [5]</ref> applies a CNN over the query and document word embeddings, resulting in word-level n-gram representations. CONV-KNRM cross-matches n-grams and subsequently scor
tude longer than a simple word embedding.</p><p>In traditional learning-to-rank the trade-off between effectiveness and efficiency has been thoroughly studied [34,</ref>35,</ref>37,</ref>4]</ref>. This includes applying a temporal constraint on the number of features that are 5,</ref>37,</ref>4]</ref>. This includes applying a temporal constraint on the number of features that are selected for a re-ranking model [35]</ref>, incorporating an efficiency metric in the training of linear rankers [34]</ref>, and comparing the effectiveness and efficienc
odels [32]</ref>, such as BERT [6]</ref>, show substantially better effectiveness at the cost of orders of magnitude longer inference time [12,</ref>20,</ref>25]</ref>. Given the same amount of limited time, a faster reranking model can incorpora , so that the best model choice becomes task dependent [31]</ref>.</p><p>Recently, the issue of efficiency gained traction in the neural IR community. Hofstätter et al. [12]</ref> establish efficiency baselines for common neural IR models (including BERT) and propose to incorporate speed metrics in replicability campaigns and public lea
the trade-off between effectiveness and efficiency has been thoroughly studied [34,</ref>35,</ref>37,</ref>4]</ref>. This includes applying a temporal constraint on the number of features that are selected for a re-ranking model [35]</ref>, incor , incorporating an efficiency metric in the training of linear rankers [34]</ref>, and comparing the effectiveness and efficiency of various learning-to-rank algorithms [4]</ref>. In web search the speed of a response is crucial as determined by Kohavi et al. [19]</ref> in a large scale experiment, however,
ithub.com/sebastianhofstaetter/transformer-kernel-ranking. The repository contains all pre-processing and evaluation code, as well as clear and documented neural network implementations using PyTorch [27]</ref> and Al-lenNLP [10]</ref>.</p><p>In summary, the main contributions of this work are as follows:</p><p>• We propose TK: a re-rank compute baselines as well as the initial ranking lists, which we use to generate training and evaluation inputs for the neural models. For our neural re-ranking training and inference we use PyTorch [27]</ref> and AllenNLP [10]</ref>. For BERT support we use the pytorch-transformer library 4</ref> . We
stText [3]</ref> or ELMo [29]</ref> -as it offers many benefits in practice. Word embeddings are easy to pre-train on domain specific data [14]</ref>. They require only one id per term, making the index consume less disk space, once prepared for re-ranking. Most importantly, at query time, their selection i
in the form of n-gram learning with CNNs. It cross-matches all n-grams in n 2 match matrices, reducing the analyzability.</p><p>For the first stage indexing and retrieval we use the Anserini toolkit [38]</ref> to compute baselines as well as the initial ranking lists, which we use to generate training and evaluation inputs for the neural models. For our neural re-ra
faster at query time is to offload computation to the indexing phase, either by assuming query term independence [23]</ref> or by approximating interaction similarities [17]</ref>. When a large number of pre-trained Transformer layers is involved, inference can be sped up by removing later layers and scoring the intermediate results ins
/p><p>We conduct experiments on three large retrieval collections: MSMARCO-Passage [2]</ref>, MSMARCO-Document [2]</ref>, and TREC CAR 2017 [7]</ref>. We evaluate a broad range of traditional and neural ranking models. We introduce time-budget aware evaluation, which varies the re-ranking depth according to t target="#foot_1">5</ref> . If a passage contains the answer to a query (judged by a human annotator) it is deemed relevant in the retrieval task as well as the document containing it.</p><p>TREC CAR [7]</ref> is created as part of the TREC Complex Answer Retrieval (CAR) task in 2017. It is based on Wikipedia sections: the heading is used as the query and the section
</ref>, such as BERT [6]</ref>, show substantially better effectiveness at the cost of orders of magnitude longer inference time [12,</ref>20,</ref>25]</ref>. Given the same amount of limited time, a faster reranking model can incorporate more documents than a less efficient o type="bibr" target="#b23">[24,</ref>25]</ref> first showed the applicability of BERT for re-ranking and the resulting substantial effectiveness gains. MacAvaney et al. [20]</ref> show that it is beneficial to combine BERT's classification label with the output of interactionbased neural IR models. Both note that using BERT comes at a s type="bibr" target="#b16">[17]</ref>. When a large number of pre-trained Transformer layers is involved, inference can be sped up by removing later layers and scoring the intermediate results instead [20]</ref> or by pruning unnecessary attention-heads [33]</ref>. In this work we speed up Transformer contextualization by using very smal
ized interaction models [11]</ref>. The first representation-focused neural IR models unsuccessfully tried to match single vector representations per query and document [21]</ref>. Then, interaction-focused models moved to a more fine-grained modelling of query-document interactions based on a match-matrix. Now, contextualization in var
matured and a distinct trade-off emerged between a neural re-ranking model's effectiveness and its efficiency. While IR-specific networks are reasonably fast [36,</ref>5,</ref>15]</ref>, large Transformer based models [32]</ref>, such as BERT [6] . It averages word vectors with a sliding window and appends their similarities to the noncontextualized similarities of the PACRR [15]</ref> model. The CONV-KNRM model [5]</ref> extends KNRM by adding a CNN layer on top of the word embeddings, enabling word-level n-gram representation learning -a local contextualization, fixed by the n- oding and sequence wide self-attention allows for local and global contextualization at the same time. This makes TK more powerful than previous local-only contextualization methods used in CONV-KNRM [5]</ref> and CO-PACRR [16]</ref>.  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interaction Scoring</head><p>After th o previous kernel-pooling methods are:</p><p>• KNRM [36]</ref> uses only word embeddings, therefore a match does not have context or positional information. • CONV-KNRM [5]</ref> uses a local-contextualization with limited positional information in the form of n-gram learning with CNNs. It cross-matches all n-grams in n 2 match matrices, /ref> uses a soft-histogram (differentiable Gaussian kernel functions) on top of the interaction matrix of query and document embeddings -summing the interactions by their similarity.</p><p>CONV-KNRM [5]</ref> applies a CNN over the query and document word embeddings, resulting in word-level n-gram representations. CONV-KNRM cross-matches n-grams and subsequently scor
the trade-off between effectiveness and efficiency has been thoroughly studied [34,</ref>35,</ref>37,</ref>4]</ref>. This includes applying a temporal constraint on the number of features that are selected for a re-ranking model [35]</ref>, incor , incorporating an efficiency metric in the training of linear rankers [34]</ref>, and comparing the effectiveness and efficiency of various learning-to-rank algorithms [4]</ref>. In web search the speed of a response is crucial as determined by Kohavi et al. [19]</ref> in a large scale experiment, however,
vocabulary [13]</ref>. Various approaches exist to reduce the match-matrix of term similarities to the matching score: using stacked Convolutional Neural Networks (CNN) [26,</ref>22]</ref>, parallel single-layered CNNs for n-gram interaction modelling [15]</ref>, recurrent ne Dirichlet smoothing (LM), and RM3 [1]</ref> as traditional retrieval method baselines. In the following we give an overview over our neural baselines:</p><p>MatchPyramid [26]</ref> applies several stacked CNN layers with max-pooling on top of a term-by-term interaction matrix. The pooling sizes become smaller with each layer -like a pyra
leDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The importance of efficient and fast search engines is well established [19]</ref>. Therefore, the time spent on each part of the Information Retrieval (IR) pipeline has to be managed with time-constraints. Naturally, re-ranking models, whic paring the effectiveness and efficiency of various learning-to-rank algorithms [4]</ref>. In web search the speed of a response is crucial as determined by Kohavi et al. [19]</ref> in a large scale experiment, however, in some expert tasks, users are willing to wait longer for better results, so that the best model choice becomes task de
.</p><p>In traditional learning-to-rank the trade-off between effectiveness and efficiency has been thoroughly studied [34,</ref>35,</ref>37,</ref>4]</ref>. This includes applying a temporal constraint on the number of features that are selected for a re-ranking model <ref typ
odels [32]</ref>, such as BERT [6]</ref>, show substantially better effectiveness at the cost of orders of magnitude longer inference time [12,</ref>20,</ref>25]</ref>. Given the same amount of limited time, a faster reranking model can incorpora , so that the best model choice becomes task dependent [31]</ref>.</p><p>Recently, the issue of efficiency gained traction in the neural IR community. Hofstätter et al. [12]</ref> establish efficiency baselines for common neural IR models (including BERT) and propose to incorporate speed metrics in replicability campaigns and public lea
original graph by simply shuffling node features. Then, an objective based on MI maximization is proposed to maximize the MI between node embeddings and a global summary embedding. Following DGI, GMI [30]</ref> proposes two node-level contrastive objectives to directly measure MI between input and representations of nodes and edges respectively, without explicit data #b50">[51]</ref> proposes to not rely on an explicit graph embedding, but rather focus on maximizing the agreement of node embeddings across two corrupted views of the graph.</p><p>Following DGI, GMI [30]</ref> employs two discriminators to directly measure MI between input and representations of both nodes and edges without data augmentation; MVGRL <ref type="bibr" astic perturbation.</p><p>Summary of comparisons with related graph contrastive learning methods. In summary, we provide a brief comparison between the  [44]</ref>, GMI [30]</ref>, and MVGRL [15]</ref> in Table 1</ref>, where the two columns "Topology" and "Attribute" deno including Graph Autoencoders (GAE, VGAE) [21]</ref>, Deep Graph Infomax (DGI) [44]</ref>, Graphical Mutual Information Maximization (GMI) [30]</ref>, and Multi-View Graph Representation Learning (MVGRL) [15]</ref>. Furthermore, we report the performance obtained using a logis
directly measure MI between input and representations of nodes and edges respectively, without explicit data augmentation. Moreover, to supplement the input graph with more global information, MVGRL [15]</ref> proposes to augment the input graph using graph diffusion. Then, it constructs graph views by uniformly sampling subgraphs and learns to contrast node represe llowing DGI, GMI [30]</ref> employs two discriminators to directly measure MI between input and representations of both nodes and edges without data augmentation; MVGRL [15]</ref> proposes to learn both node-level and graph-level representations by performing node diffusion and contrasting node representations to augmented graph summary related graph contrastive learning methods. In summary, we provide a brief comparison between the  [44]</ref>, GMI [30]</ref>, and MVGRL [15]</ref> in Table 1</ref>, where the two columns "Topology" and "Attribute" denote data augmentation strategies at both levels. It is nfomax (DGI) [44]</ref>, Graphical Mutual Information Maximization (GMI) [30]</ref>, and Multi-View Graph Representation Learning (MVGRL) [15]</ref>. Furthermore, we report the performance obtained using a logistic regression classifier on raw node features and DeepWalk with embeddings concatenated with in
(NCE) [12]</ref>. These random-walk-based methods are proved to be equivalent to factorizing some forms of graph proximity (e.g., transformation of the adjacent matrix) [35]</ref>, which overly emphasize on the structural information encoded in these graph proximities and also face severe scaling problem with large-scale datasets. Also,
ervised counterparts.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A IMPLEMENTATION DETAILS A.1 Computing Infrastructures</head><p>All models are implemented using PyTorch Geometric 1.6.1 [8]</ref>, PyTorch 1.6.0 [29]</ref>, and NetworkX 2.5. All datasets used throughout experiments are available in PyTorch Geometric librarie
ref type="bibr" target="#b48">49]</ref> explores in-batch negative samples. For an image patch as the anchor, these methods usually find a global summary vector [1,</ref>18]</ref> or patches in neighboring views [17,</ref>42]</ref> as the positive sample, and contrast them wit r" target="#b16">[17,</ref>42]</ref> as the positive sample, and contrast them with negative-sampled counterparts, such as patches of other images within the same batch [18]</ref>.</p><p>Theoretical analysis sheds light on the reasons behind their success [33]</ref>. Objectives used in these methods can be
ref type="bibr" target="#b48">49]</ref> explores in-batch negative samples. For an image patch as the anchor, these methods usually find a global summary vector [1,</ref>18]</ref> or patches in neighboring views [17,</ref>42]</ref> as the positive sample, and contrast them wit r" target="#b16">[17,</ref>42]</ref> as the positive sample, and contrast them with negative-sampled counterparts, such as patches of other images within the same batch [18]</ref>.</p><p>Theoretical analysis sheds light on the reasons behind their success [33]</ref>. Objectives used in these methods can be
ative-sampled counterparts, such as patches of other images within the same batch [18]</ref>.</p><p>Theoretical analysis sheds light on the reasons behind their success [33]</ref>. Objectives used in these methods can be seen as maximizing the lower bounds of MI between input features and their representations <ref type="bibr" target="# formula_11">)<label>10</label></formula><p>Proof sketch. We first observe that our objective J is a lower bound of the InfoNCE objective [42]</ref>, which is defined as [33]</ref>. According to van den Oord et al. [42]</ref>, the InfoNCE estimator is a lower bound of the true MI. Therefore, the theorem dir d="formula_18">)<label>14</label></formula><p>Proof. We first show the connection between our objective J and the InfoNCE objective [42]</ref> , which can be defined as [33]</ref> 𝐼 NCE (U; V) ≜ E   </p><p>Thus, we arrive at 2J ≤ 𝐼 (U; V) + 𝐼 (V; U) = 2𝐼 (U; V),</p><p>which leads to the inequality</p><formula xml:id="formula_21">J ≤ 𝐼 ( convenience of notation. 𝜌 𝑟 (𝒗 𝑖 ) and 𝜌 𝑐 (𝒗 𝑖 )</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>( 17 )</head><label>17</label><figDesc>According to Poole et al.[33]</ref>, the InfoNCE estimator is a lower bound of the true MI, i.e.𝐼 NCE (U, V) ≤ 𝐼 (U; V).</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fi tual information maximization between node features and the embeddings in the two views, which has been widely applied in the representation learning literature [1,</ref>33,</ref>39,</ref>41]</ref>. MI quantifies the amount of information obtained about one random variable by
ref type="bibr" target="#b48">49]</ref> explores in-batch negative samples. For an image patch as the anchor, these methods usually find a global summary vector [1,</ref>18]</ref> or patches in neighboring views [17,</ref>42]</ref> as the positive sample, and contrast them wit r" target="#b16">[17,</ref>42]</ref> as the positive sample, and contrast them with negative-sampled counterparts, such as patches of other images within the same batch [18]</ref>.</p><p>Theoretical analysis sheds light on the reasons behind their success [33]</ref>. Objectives used in these methods can be
graph attributive and structural features. However, existing GNN models are mostly established in a supervised manner [19,</ref>22,</ref>43]</ref>, which require abundant labeled nodes for training. Recently, Contrastive Learning (CL), as revitalization of the classical information maximization (InfoMax) ncoders over conventional methods. Among them, considerable literature has grown up around the theme of supervised GNN [19,</ref>22,</ref>43,</ref>45]</ref>, which requires labeled datasets that may not be accessible in real-world applications. Along the other line of develop th supervised counterparts, we also report the performance of two representative models Graph Convolutional Networks (GCN) [22]</ref> and Graph Attention Networks (GAT) [43]</ref>, where they are trained in an endto-end fashion. For all baselines, we report their performance based on their official code.</p></div> <div xmlns="http://www
ion pipeline [1,</ref>3,</ref>7]</ref>, consisting of color jitter, random flip, cropping, resizing, rotation [9]</ref>, color distortion [23]</ref>, etc. Existing work [16,</ref>39,</ref
15]</ref> proposes to learn both node-level and graph-level representations by performing node diffusion and contrasting node representations to augmented graph summary representations. Moreover, GCC [34]</ref> proposes a pretraining framework based on contrastive learning. It proposes to construct multiple graph views by sampling subgraphs based on random walks and
ef>. Objectives used in these methods can be seen as maximizing the lower bounds of MI between input features and their representations [24]</ref>. However, recent work [41]</ref> reveals that downstream performance in evaluating the quality of representations may strongly depend on the bias that is encoded not only in the convolutional e the critic 𝜃 (𝒖, 𝒗) = 𝑠 (𝑔(𝒖), 𝑔(𝒗)), where 𝑠 (•, •) is the cosine similarity and 𝑔(•) is a nonlinear projection to enhance the expression power of the critic [3,</ref>41]</ref>. The projection function 𝑔 in our method is implemented with a two-layer perceptron model. Given a positive pair, we naturally define negative samples as all o o views, which has been widely applied in the representation learning literature [1,</ref>33,</ref>39,</ref>41]</ref>. MI quantifies the amount of information obtained about one random variable by observing the other random variable. Theorem 1. Let X 𝑖 = {𝒙 𝑘 } 𝑘 ∈N (𝑖) be the ork further provides empirical evidence that optimizing a stricter bound of MI may not lead to better downstream performance on visual representation learning [40,</ref>41]</ref>, which further highlights the importance of the design of data augmentation strategies.</p><p>When optimizing 𝐼 (𝑼 ; 𝑽 ), a lower bound of 𝐼 (𝑿 ; 𝑼 , 𝑽 ), we e
learning [1,</ref>16,</ref>39]</ref> and natural language processing [4,</ref>6,</ref>26]</ref>. These CL methods seek to maximize the Mutual Information (MI) between the input (i.e. images) and its representations (i
graph attributive and structural features. However, existing GNN models are mostly established in a supervised manner [19,</ref>22,</ref>43]</ref>, which require abundant labeled nodes for training. Recently, Contrastive Learning (CL), as revitalization of the classical information maximization (InfoMax) ncoders over conventional methods. Among them, considerable literature has grown up around the theme of supervised GNN [19,</ref>22,</ref>43,</ref>45]</ref>, which requires labeled datasets that may not be accessible in real-world applications. Along the other line of develop th supervised counterparts, we also report the performance of two representative models Graph Convolutional Networks (GCN) [22]</ref> and Graph Attention Networks (GAT) [43]</ref>, where they are trained in an endto-end fashion. For all baselines, we report their performance based on their official code.</p></div> <div xmlns="http://www
ode classification. The datasets are collected from real-world networks of different kinds; their detailed statistics is summarized in Table 2</ref>.</p><p>• Wiki-CS [25]</ref> is a reference network constructed from Wikipedia.</p><p>The nodes correspond to articles about computer science and edges are hyperlinks between the articles Wiki-CS has dense numerical features. While the other four datasets only contain sparse one-hot features. For the Wiki-CS dataset, we evaluate the models on the public splits shipped with the dataset [25]</ref>. Regarding the other four co-coauthor and co-purchase datasets, since they have no public splits available, we instead use the random splits where 10%, 10%, a
ny fields, e.g., visual representation learning [1,</ref>16,</ref>39]</ref> and natural language processing [4,</ref>6,</ref>26]</ref>. These CL methods seek to maximize the Mutual Information (MI) between the input (
ormation maximization (InfoMax) principle [24]</ref>, achieves great success in many fields, e.g., visual representation learning [1,</ref>16,</ref>39]</ref> and natural language processing [4,</ref>6,</ref><ref type= 7]</ref>, consisting of color jitter, random flip, cropping, resizing, rotation [9]</ref>, color distortion [23]</ref>, etc. Existing work [16,</ref>39,</ref>47]</ref> employs a memory bank for storing negative samples. Other work <ref type="bibr
ny fields, e.g., visual representation learning [1,</ref>16,</ref>39]</ref> and natural language processing [4,</ref>6,</ref>26]</ref>. These CL methods seek to maximize the Mutual Information (MI) between the input (
, which aims to transform nodes to low-dimensional dense embeddings that preserve graph attributive and structural features. However, existing GNN models are mostly established in a supervised manner [19,</ref>22,</ref>43]</ref>, which require abundant labeled nodes for training. Recently, Contrastive Lear t work on graph neural networks (GNN) employs more powerful graph convolutional encoders over conventional methods. Among them, considerable literature has grown up around the theme of supervised GNN [19,</ref>22,</ref>43,</ref>45]</ref>, which requires labeled datasets that
et="#b38">39,</ref>47]</ref> employs a memory bank for storing negative samples. Other work [1,</ref>3,</ref>49]</ref> explores in-batch negative samples. For an image patch as the anchor, these methods usually find a global summary vector [1,</ref
graph attributive and structural features. However, existing GNN models are mostly established in a supervised manner [19,</ref>22,</ref>43]</ref>, which require abundant labeled nodes for training. Recently, Contrastive Learning (CL), as revitalization of the classical information maximization (InfoMax) ncoders over conventional methods. Among them, considerable literature has grown up around the theme of supervised GNN [19,</ref>22,</ref>43,</ref>45]</ref>, which requires labeled datasets that may not be accessible in real-world applications. Along the other line of develop th supervised counterparts, we also report the performance of two representative models Graph Convolutional Networks (GCN) [22]</ref> and Graph Attention Networks (GAT) [43]</ref>, where they are trained in an endto-end fashion. For all baselines, we report their performance based on their official code.</p></div> <div xmlns="http://www
e input (i.e. images) and its representations (i.e. image embeddings) by contrasting positive pairs with negative-sampled counterparts.</p><p>Inspired by previous CL methods, Deep Graph InfoMax (DGI) [44]</ref> marries the power of GNN into InfoMax-based methods. DGI firstly augments the original graph by simply shuffling node features. Then, an objective based on MI ation schemes used in the aforementioned methods suffer from two drawbacks. At first, simple data augmentation in either the structural domain or the attribute domain, such as feature shifting in DGI [44]</ref>, is not sufficient for generating diverse neighborhoods (i.e. contexts) for nodes, especially when node feature is sparse, leading to difficulty in optimizing velopment, unsupervised GNNs receive little attention. Representative methods include GraphSAGE [14]</ref>, which incorporates DeepWalk-like objectives. Recent work DGI [44]</ref> marries the power of GNN and contrastive learning, which focuses on maximizing MI between global graph embeddings and local node embeddings. Specifically, to ant patterns underneath the graph through stochastic perturbation.</p><p>Summary of comparisons with related graph contrastive learning methods. In summary, we provide a brief comparison between the  [44]</ref>, GMI [30]</ref>, and MVGRL [15]</ref> in Table 1</ref>, where ively.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Evaluation protocol.</head><p>For every experiment, we follow the linear evaluation scheme as introduced in Veličković et al. [44]</ref>, where each model is firstly trained in an unsupervised manner; then, the resulting embeddings are used to train and test a simple ℓ 2 -regularized logistic r /ref> and node2vec [11]</ref> and (2) deep learning methods including Graph Autoencoders (GAE, VGAE) [21]</ref>, Deep Graph Infomax (DGI) [44]</ref>, Graphical Mutual Information Maximization (GMI) [30]</ref>, and Multi-View Graph Representation Learning (MVGRL) <ref type="bi
length limit in BERT. Concretely, we extend ProdLDA (Srivastava and Sutton, 2017)</ref>, a state-of-the-art topic model that implements black-box variational inference (Ranganath et al., 2014)</ref>, to include BERT representations. Our approach leads to consistent significant improvements in topic coherence, and produces competitive r
en et al., 2015;</ref>Petterson et al., 2010)</ref>, use word relationships derived from external knowledge bases (Chen et al., 2013;</ref>Yang et al., 2015)</ref>, or pre-trained word embeddings (Das et al., 2015;</ref>Dieng et al., 2019;</ref><re
Then, we compute the overall average of those values for all the topics (α).</p><p>Eventually, to evaluate how diverse the topics generated by a single model are, we use the rankbiased overlap (RBO) (Webber et al., 2010)</ref>. RBO compares two topics of the same model. The key qualities of this measure are twofold: it allows disjointedness between the lists of topi
2017</ref>) also propose Neural-LDA, which has been found to be scarcely effective in topic modeling by different researchers, though(Srivastava and Sutton, 2017;</ref>Wang et al., 2020)</ref>. Our first results with this model were also inconsistent, so we excluded it from the further experiments.</note> 			<note xmlns="http://www.tei
en et al., 2015;</ref>Petterson et al., 2010)</ref>, use word relationships derived from external knowledge bases (Chen et al., 2013;</ref>Yang et al., 2015)</ref>, or pre-trained word embeddings (Das et al., 2015;</ref>Dieng et al., 2019;</ref><re
foot_5">5</ref> (the model we extended);6</ref> (ii) Neural Variational Document Model (NVDM) (Miao et al., 2016)</ref>; and (iii) LDA (Blei et al., 2003)</ref>.</p><p>Configurations We train all models with the same hyper-parameter configurations to maximize comparability. The inference network for both
knife, lemon, banana, spoon". Coherence can be measured in a variety of ways, from human evaluation via intrusion tests (Chang et al., 2009)</ref> to approximated scores (Lau et al., 2014;</ref>Röder et al., 2015)</ref>.</p><p>Topic models have inspired many extensions that incorporate several types of info
oherent, but are affected by some added noise/mixture of topics.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Several topic models are based on neural networks (Larochelle and Lauly, 2012;</ref>Salakhutdinov and Hinton, 2009)</ref> or neural variational inference (Mi
foot_5">5</ref> (the model we extended);6</ref> (ii) Neural Variational Document Model (NVDM) (Miao et al., 2016)</ref>; and (iii) LDA (Blei et al., 2003)</ref>.</p><p>Configurations We train all models with the same hyper-parameter configurations to maximize comparability. The inference network for both
ilar to that described in Ding et al. (2018)</ref>. First, we compute the average pairwise cosine similarity of the word embeddings of the top-10 words in a topic -using (Mikolov et al., 2013)</ref> embeddings. Then, we compute the overall average of those values for all the topics (α).</p><p>Eventually, to evaluate how diverse the topic
en et al., 2015;</ref>Petterson et al., 2010)</ref>, use word relationships derived from external knowledge bases (Chen et al., 2013;</ref>Yang et al., 2015)</ref>, or pre-trained word embeddings (Das et al., 2015;</ref>Dieng et al., 2019;</ref><re
pplications, such as autonomous driving.</p><p>A growing body of research has been dedicated to answering what causes deep networks to be fragile to adversarial examples and how to improve robustness [47,</ref>13,</ref>36,</ref>35,</ref>21,</ref oves robustness [43,</ref>52]</ref>. It has been theoretically shown that decreasing the input dimensionality of data improves robustness [47]</ref>. Adversarial training [35]</ref> improves robustness by dynamically augmenting the training data using generated adversarial ex ref type="bibr" target="#b49">[51]</ref>, our work improves adversarial robustness while also maintaining performance on natural examples.</p><p>Using the first order vulnerability of neural networks [47]</ref>, we theoretically show that increasing output dimensionality -treating each output dimension as an individual task -improves the robustness of the entire mode zation layers. [41]</ref> decreases the input gradients norm. These methods can improve the model's robustness without compromising clean accuracy. Simon-Gabriel et al. [47]</ref> conducted a theoretical analysis of the vulnerability of neural network classifiers, and connected gradient norm and adversarial robustness. Our method enhanc target="#b31">[33,</ref>31,</ref>27]</ref>. We denote the multitask predictor as F and each individual task predictor as F c . Prior work [47]</ref> showed that the norm of gradients captures the vulnerability of the model. We thus measure the multitask models' vulnerability with the same metric. Since we model should have smaller change of the loss given any perturbation of the input. Given the adversarial noise is imperceptible, i.e., r → 0, we can approximate ∆L with a first-order Taylor expansion [47]</ref>.</p><p>Lemma 1. For a given neural network F that predicts multiple tasks, the adversarial vulnerability is</p><formula xml:id="formula_5">E x [∆L(x, y, r)] ≈ l:id="formula_10">E[ ∂ x L all (x, y) 2 2 ] = E( R 2 2 ) = 1 M E r i 2 = σ 2 M ∝ 1 M<label>(6)</label></formula><p>Remark 1. By increasing the number of output tasks M , the first order vulnerability [47]</ref> of network decreases. In the ideal case, if the model has an infinite number of uncorrelated tasks, then it is impossible to find an adversarial examples that norm of the joint gradient for many tasks, which measures the adversarial vulnerability. Overall, as we add more tasks, the norm of the joint gradient decreases, indicating improvement to robustness [47]</ref>. The only exception is the depth estimation task, which we believe is due to the large range of values (0 to +∞) that its outputs take. Empirically, a larger ></figure> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">We use the same dimension for baselines and ours during comparison because input dimension impacts robustness[47]</ref>.</note> 		</body> 		<back>  			<div type="acknowledgement"> <div xmlns="http://www.tei-c.org/ns/1.0"><p>We evaluate the model robustness with L ∞ bounded adve
n</head><p>Deep networks obtain high performance in many computer vision tasks [19,</ref>58,</ref>32,</ref>18]</ref>, yet they remain brittle to adversarial examples. A large body of work has demonstrated that images with human-imperceptible noise <ref type="bibr" target="#b3
get="#b47">49]</ref>. The investigations center around two factors: the training data and the optimization procedure. For instance, more training data -both labeled and unlabeled -improves robustness [43,</ref>52]</ref>. It has been theoretically shown that decreasing the input dimensionality of data improves robustness <ref type="bibr"
ustness for two classes of attack: both when a single task is attacked or several tasks are simultaneously attacked. We experiment with up to 11 vision tasks on two natural image datasets, Cityscapes [8]</ref> and Taskonomy [60]</ref>. When all tasks are under attack, multitask learning increases segmentation robustness by up to 7 points ments on adversarial training and show that they are complementary (Section 5.5).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>Cityscapes. The Cityscapes dataset [8]</ref> consists of images of urban driving scenes. We study three tasks: semantic segmentation, depth estimation, and image reconstruction. We use the full resolution
,</ref>11,</ref>9,</ref>2,</ref>6,</ref>46,</ref>54,</ref>37]</ref> to fool target models. While attacking single output models [17,</ref><ref type="bibr" t pal curvature (p), reshading (r), and image reconstruction (A). We use the "tiny" version of their dataset splits [1]</ref>. We resize the images to 256 × 256.  We do not use the DAG [54]</ref> attack for segmentation because it is an unrestricted attack without controlling L ∞ bound. For all the iterative attacks, the step size is 1.</p></div> <div
2">24,</ref>34,</ref>38,</ref>30]</ref> and optimization procedures [5,</ref>12,</ref>45,</ref>59]</ref> for learning better multitask models. Our work complements this body of work by
, we pursue a new line of investigation: how learning on multiple tasks affects adversarial robustness. While previous work shows that multitask learning can improve the performance of specific tasks [4,</ref>48]</ref>, we show that it increases robustness too. See Figure 1</ref>. Unlike prior work that trades off perf > <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We briefly review related work in multitask learning and adversarial attacks.</p><p>Multitask Learning: Multitask learning [4,</ref>15,</ref>10,</ref>25,</ref>48]</ref> a f>, and object detection [29]</ref>. It is hypothesized that multitask learning improves the performance of select tasks by introducing a knowledge-based inductive bias [4]</ref>. However, multi-objective functions are hard to optimize, where researchers design architectures [20,</ref><ref type="bibr" targe
n</head><p>Deep networks obtain high performance in many computer vision tasks [19,</ref>58,</ref>32,</ref>18]</ref>, yet they remain brittle to adversarial examples. A large body of work has demonstrated that images with human-imperceptible noise <ref type="bibr" target="#b3
/p><p>A growing body of research has been dedicated to answering what causes deep networks to be fragile to adversarial examples and how to improve robustness [47,</ref>13,</ref>36,</ref>35,</ref>21,</ref>55,</ref>
,</ref>11,</ref>9,</ref>2,</ref>6,</ref>46,</ref>54,</ref>37]</ref> to fool target models. While attacking single output models [17,</ref><ref type="bibr" t pal curvature (p), reshading (r), and image reconstruction (A). We use the "tiny" version of their dataset splits [1]</ref>. We resize the images to 256 × 256.  We do not use the DAG [54]</ref> attack for segmentation because it is an unrestricted attack without controlling L ∞ bound. For all the iterative attacks, the step size is 1.</p></div> <div
/p><p>A growing body of research has been dedicated to answering what causes deep networks to be fragile to adversarial examples and how to improve robustness [47,</ref>13,</ref>36,</ref>35,</ref>21,</ref>55,</ref>
ty. In the meantime, little attention has been given to the direct design of robust frameworks in an attack-agnostic manner, except a few touches on denoising [25,</ref>29]</ref> and obfuscating gradients [11,</ref>25]</ref> that aim to directly enhance a target network in or their non-differentiable computations. Instead of relying on obfuscating gradients, our differentiable FPD can circumvent the structure-replaced white-box attack. Our proposal is partially related to [29]</ref>, as the denoising layers in our FPD are inspired by their feature denoising approach. Nevertheless, different from [29]</ref>, tack. Our proposal is partially related to [29]</ref>, as the denoising layers in our FPD are inspired by their feature denoising approach. Nevertheless, different from [29]</ref>, the principle behind our FPD is to improve the intrinsic robustness, regardless of conducting adversarial training or not. Consequently, FPD includes not onl blocks of the enhanced CNN, only shallow blocks are enhanced for maintaining high-level abstract semantic information. We will compare the performance between FPD-enhanced CNN and the CNN enhanced by [29]</ref> in Section 4.1.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Feature Pyramid Decoder</head><p>In this section, we introduce each component e regarded as a self-attention mechanism interpreting the relationship between pixels. Compared with the Gaussian filtering operator, the dot product operator helps improve the adversarial robustness [29]</ref>. Meanwhile, as the dot product operator does not involve extra parameters, it contributes to relatively lower computational complexity. We explore two inner d tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we firstly investigate the best framework structure through the exploration study. Moreover, we compare with the most related work [29]</ref> as well. In the comparison experiments, we focus on comparing the robustness between the enhanced CNN and the original one, conducting adversarial training an Fool Average Acc T(m) Acc T(m) Acc T(m) Acc T(m) Acc T(m) Acc T(m) Acc T(m) Acc T(m) O 4% 0.</formula><p>Comparison with the Related Work As mentioned in Section 2, the denoising approach proposed in [29]</ref> is similar to our denoising layers in FPD. Therefore, we conduct a comparison experiment with [29]</ref> as well. In Table <ref k As mentioned in Section 2, the denoising approach proposed in [29]</ref> is similar to our denoising layers in FPD. Therefore, we conduct a comparison experiment with [29]</ref> as well. In Table 1</ref>, X represents the enhanced CNN by [29]</ref>. We observe that our F yers in FPD. Therefore, we conduct a comparison experiment with [29]</ref> as well. In Table 1</ref>, X represents the enhanced CNN by [29]</ref>. We observe that our F 2I−Mid outperforms X . Especially, the performance of thwarting the white-box attack is about 20% higher.</p></div> <div xmlns="http://
= 0.3, step = 40, step size = 0.01 for both whitebox and black-box attacks. Under the black-box condition, we separately train a simple three layers fully-connected network as the substitute network [23]</ref> for each network.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Inner Denoising Layers Implanted Positions Selection</head><p>We firstly explore th
ke Carlini &amp; Wagner attack (C&amp;W) and DeepFool [5,</ref>20]</ref>, while others utilize the decision boundary to attack the network [2,</ref>7]</ref>. Black-box attacks mainly rely on transfer-attack. Attackers substitute the target network with a network, trained with th
arted to pay more attention to investigating the weakness of neural networks, especially in its application to image classification. Since the seminal work by [26,</ref>21]</ref>, many follow-up works have demonstrated a great variety of methods in generating adversarial sam-ples: though easily distinguishable by human eyes, they are of
/ns/1.0"><head n="1.">Introduction</head><p>The ever-growing ability of deep learning has found numerous applications mainly in image classification, object detection, and natural language processing [12,</ref>17,</ref>28]</ref>. While deep learning has brought great convenience to our lives, its weakness esize them to image size 64. Besides, we repeat the channel three times on MNIST for network consistency. For both CALTECH-101 and CALTECH-256, we randomly choose 866 and 1,422 images as test images  [12]</ref> as well as ResNeXt-50 [30]</ref> are enhanced in the following experiments. We use Pytorch to implement the whole experiments.<
e times on MNIST for network consistency. For both CALTECH-101 and CALTECH-256, we randomly choose 866 and 1,422 images as test images  [12]</ref> as well as ResNeXt-50 [30]</ref> are enhanced in the following experiments. We use Pytorch to implement the whole experiments.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.
x or black-box approaches, depending on the knowledge of the target network, and they mostly use gradient-based methods [10,</ref>18,</ref>27]</ref> or score-based methods [4]</ref> to generate adversarial samples.</p><p>To thwart these attacks, many defence methods have been p type="bibr" target="#b0">[1,</ref>14]</ref>. However, as training often targets a specific attack, the resulting defense method can hardly be generalized, as hinted in [27]</ref>. In order to defend against various attacks, a large amount and variety of adversarial samples are required to retrain the classifier, leading to a high time- are applied to the substituted network for generating the adversarial samples.</p><p>Adversarial training, proposed by [10,</ref>18,</ref>27,</ref>32]</ref>, is an approach to improve the robustness of the target network. Normally, it augments the adversarial samples to the t
tz Constant Constrained Classification</head><p>The influence of employing Lipschitz constant on defending against the adversarial samples have been analyzed in [9,</ref>13]</ref>. As stated in our following Theorem 1, the network could be sensitive to some perturbations if Softmax is directly used as the last layer's activation function
arted to pay more attention to investigating the weakness of neural networks, especially in its application to image classification. Since the seminal work by [26,</ref>21]</ref>, many follow-up works have demonstrated a great variety of methods in generating adversarial sam-ples: though easily distinguishable by human eyes, they are of
= 0.3, step = 40, step size = 0.01 for both whitebox and black-box attacks. Under the black-box condition, we separately train a simple three layers fully-connected network as the substitute network [23]</ref> for each network.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Inner Denoising Layers Implanted Positions Selection</head><p>We firstly explore th
>16]</ref>. Some approaches focus on optimizing attack objective function like Carlini &amp; Wagner attack (C&amp;W) and DeepFool [5,</ref>20]</ref>, while others utilize the decision boundary to attack the network [2,</ref>7]</ref>. Black-box atta
to adaptively split the encoded state sequence into small chunks based on the predicted selection probabilities. But complex and tricky training methods make it hard to implement. Triggered attention [9]</ref> utilizes the spikes produced by connectionist temporal classification (CTC) model to split the sequence into many state chunks, and then the decoder predicts th
eiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Attention-based sequence-to-sequence models [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especial et="#b1">2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especially transformer model [2]</ref>, have shown great success in various tasks, e.g. neural machine translation [1,</ref>2]</ref>, image </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SYNCHRONOUS TRANSFORMER</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Model</head><p>Similar to the transformer [2]</ref>, a Sync-Transformer consists of an encoder and a decoder, as depicted in Fig. 1</ref>(a). Both encoder and decoder are compos ocess the input speech feature sequences simply, including dimension transformation(transform feature dimensions from 40 to 256), time-axis down-sampling and adding sine-cosine positional information [2]</ref>. Let x 1:T be the input feature sequence, the processed sequence can be expressed as s 1:L , where T and L are the lengths of these two sequences respectively.< and the right context to 0. More context parameter settings will be explored in the future. What's more, we adopt an Adam optimizer with warmup steps 25000 and the learning rate scheduler reported in [2]</ref>.</p><p>During decoding, we use a beam search with a width of 5 for all the experiments. And set the maximum length of symbols generated in a chunk is 10. We use "#b5">6]</ref>, especially transformer model [2]</ref>, have shown great success in various tasks, e.g. neural machine translation [1,</ref>2]</ref>, image captioning [3]</ref> and speech recognition [4,</ref>5,</ref><re sformer consists of an encoder and a decoder, as depicted in Fig. 1</ref>(a). Both encoder and decoder are composed of multi-head attentions and feed-forward layers [2,</ref>6,</ref>10]</ref>.</p><p>As shown in Fig. 1</ref>(a), we put a 2D
e models [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especially transformer model [2]</ref>, have shown great success in various tasks, e.g. neural machine translation <ref type="bibr ef>2]</ref>, image captioning [3]</ref> and speech recognition [4,</ref>5,</ref>6]</ref>.</p><p>For conventional attention-based sequence-to-sequence models, the inference process can be divided into two stages. The encoder first processes an entire ng methods.</p><p>In this paper, we propose a synchronous transformer model (Sync-Transformer), which can perform encoding and decoding at the same time. The Sync-Transformer combines the transformer [6]</ref> and self-attention transducer (SA-T) [10]</ref> in great depth. Similar to the original transformer, the Sync-Transformer has an e coder, as depicted in Fig. 1</ref>(a). Both encoder and decoder are composed of multi-head attentions and feed-forward layers [2,</ref>6,</ref>10]</ref>.</p><p>As shown in Fig. 1</ref>(a), we put a 2D convolution front end at the bottom of
e models [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especially transformer model [2]</ref>, have shown great success in various tasks, e.g. neural machine translation <ref type="bibr ef>2]</ref>, image captioning [3]</ref> and speech recognition [4,</ref>5,</ref>6]</ref>.</p><p>For conventional attention-based sequence-to-sequence models, the inference process can be divided into two stages. The encoder first processes an entire ng methods.</p><p>In this paper, we propose a synchronous transformer model (Sync-Transformer), which can perform encoding and decoding at the same time. The Sync-Transformer combines the transformer [6]</ref> and self-attention transducer (SA-T) [10]</ref> in great depth. Similar to the original transformer, the Sync-Transformer has an e coder, as depicted in Fig. 1</ref>(a). Both encoder and decoder are composed of multi-head attentions and feed-forward layers [2,</ref>6,</ref>10]</ref>.</p><p>As shown in Fig. 1</ref>(a), we put a 2D convolution front end at the bottom of
ze of the multi-head attention and the feed-forward layers are 256. In order to accelerate the convergence, we replace the ReLU activation function in the feed-forward network with gated linear units [19]</ref>. We empirically set the left context of every node in the encoder to 20 and the right context to 0. More context parameter settings will be explored in the fu
y. Once a fixed-length chunk of state sequence is produced by the encoder, the decoder begins to predict symbols immediately. Similar to the Neural Transducer [11,</ref>12,</ref>13]</ref>, the decoder generates the output sequence chunk by chunk. However, restricted by the time-dependent property of RNNs,
y. Once a fixed-length chunk of state sequence is produced by the encoder, the decoder begins to predict symbols immediately. Similar to the Neural Transducer [11,</ref>12,</ref>13]</ref>, the decoder generates the output sequence chunk by chunk. However, restricted by the time-dependent property of RNNs,
<p>Attention-based sequence-to-sequence models [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especially transformer model [2]</ref>, have shown great success in various tasks, e.g. neur n [1,</ref>2]</ref>, image captioning [3]</ref> and speech recognition [4,</ref>5,</ref>6]</ref>.</p><p>For conventional attention-based sequence-to-sequence models, the inference process can be divided into two stages.
<p>Attention-based sequence-to-sequence models [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especially transformer model [2]</ref>, have shown great success in various tasks, e.g. neur n [1,</ref>2]</ref>, image captioning [3]</ref> and speech recognition [4,</ref>5,</ref>6]</ref>.</p><p>For conventional attention-based sequence-to-sequence models, the inference process can be divided into two stages.
y> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Attention-based sequence-to-sequence models [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especially transformer model <ref type="bibr" ibr" target="#b1">[2]</ref>, have shown great success in various tasks, e.g. neural machine translation [1,</ref>2]</ref>, image captioning [3]</ref> and speech recognition [4,</ref>5,</ref>6]</ref>.</p><p>For convention
y> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Attention-based sequence-to-sequence models [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6]</ref>, especially transformer model <ref type="bibr" ibr" target="#b1">[2]</ref>, have shown great success in various tasks, e.g. neural machine translation [1,</ref>2]</ref>, image captioning [3]</ref> and speech recognition [4,</ref>5,</ref>6]</ref>.</p><p>For convention
get="#b4">5]</ref>.</p><p>The aforementioned insights can be pessimistic in the non-anonymous case, where permutation equivariance is either learned from data [22,</ref>23]</ref> or obtained by design [24]</ref>. With node features acting as identifiers, MPNN were shown to become universal in the limit <re ef>23]</ref> or obtained by design [24]</ref>. With node features acting as identifiers, MPNN were shown to become universal in the limit [23]</ref>, which implies that they can solve the graph isomorphism testing problem if their size is allowed to depend exponentially on the number of nodes <ref type="bi , as they only account for behaviors that occur in the limit. Along those lines, recent work provided evidence that the power of MPNN grows as a function of depth and width for certain graph problems [23]</ref>, showing that (both anonymous and non-anonymous) MPNN cannot solve many tasks when the product of their depth and width does not exceed a polynomial of the nu for problems relating to the capacity of MPNN to distinguish graphs. Even further, it is unclear whether depth and width needs to grow with the number of nodes solely in the worst-case (as proven in [23]</ref>) or with certain probability over the input distribution.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Communication capacity and its cons s depth, width, and message-size, as well as on the cutstructure of the input graph. Communication capacity is an effective generalization of the previously considered product between depth and width [23]</ref>, being able to consolidate more involved properties, as well as to characterize MPNN with global state [8,</ref><ref type="bibr" ers of magnitude tighter than what can be deduced from simpler arguments. In addition, the proposed lower bounds rely on a new technique which renders them applicable not only to worst-case instances [23]</ref>, but in expectation over the input distribution.</p><p>An empirical study reveals strong qualitative and quantitative agreement between the MPNN test accuracy could solve nearly every task up to 100% test accuracy (Table 2 in Appendix A), which corroborates previous theoretical findings that non-anonymous MPNN are universal and can solve graph isomorphism [23,</ref>5]</ref>, as well as that they can learn to be permutation invariant [22]</ref>. On the other hand
>12,</ref>9]</ref>. The rational is that, by the universal approximation theorem and its variants [36]</ref>[37]</ref>[38]</ref>, these networks can approximate any smooth function that maps vectors onto vectors. If the network's output is requir
ef>40]</ref>, though the results may also be easily extended to account for coarsening [41]</ref>[42]</ref>[43]</ref>[44]</ref>[45]</ref>.</p><p>Global state. In the description above, all message exchange needs to
">[5]</ref>[6]</ref>. The most intensely studied model in the literature has been that of message-passing neural networks (MPNN). Since its inception by Scarselli et al. [7]</ref>, MPNN has been extended to include edge [8]</ref> and global features [9]</ref>. The model also enco </p><p>MESSAGE and UPDATE are layer-dependent functions whose parameters are selected based on some optimization procedure. It is common to parametrize these functions by feed-forward neural networks [7,</ref>12,</ref>9]</ref>. The rational is that, by the universal approximation theorem and its variants <re omatic rectangles ≥ log 2 c(v)(c(v) + 1) 2 = 2 log 2 c(v) + log 2 1 + 1 c(v) − 1 ≥ 2 log 2 c(v) − 1<label>(7)</label></formula><p>Substituting ( 6</ref>) into (7)</ref> gives:</p><formula xml:id="formula_35">c both fisom log 2 s ≥ v 2 − 2v log 2 v √ 2 e − 2 log 2 √ ve 2 − 1 + o(1) = v 2 − 2v log 2 v √ 2 e − log 2 2ve 2 + o(1)</
>Datasets. A total of 12 universes were constructed following the theory: X n graph for n = (6, 8, 10, 12) and X n tree for n = (8, 10, . . . , 22). Each X n graph was built in two steps: First, geng [48]</ref> was used to populate X a and X b with all possible connected graphs on v = n /2 nodes. Then, each G ∈ X n graph was generated by selecting G a and G b from X
ef>40]</ref>, though the results may also be easily extended to account for coarsening [41]</ref>[42]</ref>[43]</ref>[44]</ref>[45]</ref>.</p><p>Global state. In the description above, all message exchange needs to
ef type="bibr" target="#b2">3,</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ref>[15]</ref>[16]</ref>.</p><p>Roughly two types of analyses of MPNN may be distinguished. The first bound the expressive power of anonymous
well as the analysis of the power of particular architectures to compute graph properties [17,</ref>18]</ref> and to distinguish graphons [19]</ref>-see also [20,</ref>21,</ref>5]</ref>.</p><p>The aforementioned ins
odel in the literature has been that of message-passing neural networks (MPNN). Since its inception by Scarselli et al. [7]</ref>, MPNN has been extended to include edge [8]</ref> and global features [9]</ref>. The model also encompasses many of the popular graph neural network architectures used today <ref t previously considered product between depth and width [23]</ref>, being able to consolidate more involved properties, as well as to characterize MPNN with global state [8,</ref>9,</ref>28]</ref> and adaptive architecture [29]</ref><ref type="bibr
ref type="bibr" target="#b9">[10,</ref>3,</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ref>[15]</ref>[16]</ref>.</p><p>Roughly two types of analyses of MPNN may be distinguished. The first
2 v log 2 one fisom (B v,p ) log 2 s ≥ c both fisom (B v,p ) log 2 s − max G b ,Gc log s (|{f isom (G a , G b , G c ) : G a ∈ X a }|) log 2 s = c both fisom (B v,p ) log 2 s − log 2According to Otter[51]</ref>, the number of unlabeled trees on v nodes grows liket(v) ∼ c α v v −5/2 ,where the values c and α known to be approximately 0.5349496 and 2.9557652 (sequence
ww.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>illustrates the main idea of stable feature distillation, which consists of a deep global balancing regression (DGBR) algorithm[13]</ref>, a teacher network and a student network. The DGBR algorithm optimizes a deep autoencoder model for feature selection and a global balancing model for learnin ples. How to better combine the imputed label with the true label of 𝑆 𝑐 in a more sophisticated manner is another promising direction.</p><p>Feature-Based Module. The current stable feature approach [13]</ref> needs much time and computing resources. For implementing the industry recommender system, we need more efficient methods to learn the stable features. Beside
tem may suffer from the bias problems such as popularity bias [1,</ref>6]</ref>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref>28]</ref>. Previous studies hav 32">[33]</ref>, propensity computation [24]</ref> and modeling with uniform data directly [5,</ref>11,</ref>16,</ref>23]</ref>. In this paper, we would like to study methods for better use of the uniform data from the perspective of knowledge dis hown that models and evaluation metrics that ignore the biases do not reflect the true performance of a recommender system, and that explicitly handling of the biases may help improve the performance [16,</ref>28,</ref>31]</ref>. Most of the previous works to solve the bias problems of recommender systems not at random (MNAR) [15,</ref>17]</ref>.</p><p>A recent work has shown that a uniform data can alleviate the previous model bias problem [16]</ref>. But the uniform data is always few and expensive to collect in real recommender systems. To collect a uniform data, we must intervene in the system by using uniform data collection within a particularly small traffic (e.g., 1%).</p><p>In this paper, we focus on how to solve the bias problems in a recommender system with a uniform data. Along the line of [16]</ref>, we conduct empirical studies on a real advertising system and a public dataset to validate the usefulness of the uniform data, where the uniform data is simp to study methods for better use of the uniform data from the perspective of knowledge distillation.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATION</head><p>In a recent work [16]</ref>, it is shown that a uniform (i.e., unbiased) data can alleviate the previous model bias problem. In this section, to further verify the usefulness of a unifor
factual learning, such as imputation model learning [33]</ref>, propensity computation [24]</ref> and modeling with uniform data directly [5,</ref>11,</ref>16,</ref>23]</ref>. In this paper, we would like to study m into three subsets by the same way as that of Yahoo! R3, i.e., 5% as training set (𝑆 𝑡 ), 5% as validation set (𝑆 𝑣𝑎 ), and the rest as test set (𝑆 𝑡𝑒 ). Following the settings of the previous works [5,</ref>33]</ref>, we employ two evaluation metrics that are widely used in industry recommendation, including the negative logarithmic lo we use the three strategies adopted in our experiments as examples to illustrate how sample-based distillation can be realized.</p><p>• Causal Embedding Strategy (CausE). The causal embedding method [5]</ref> first considers the scenario of training 𝑀 𝑐 and 𝑀 𝑡 simultaneously. It designs an additional alignment term to explicitly represent the learning of 𝑀 𝑐 for 𝑀 𝑡
ype="bibr" target="#b9">[10]</ref>. By introducing soft-targets related to teacher networks as part of the objective function, the training of student networks is guided to achieve knowledge transfer [18]</ref>. A series of followup works develop different distillation structures (e.g., multiple teachers [8]</ref> and cascade distillatio ype="bibr" target="#b32">[33]</ref>. Moreover, they are also related to the types of knowledge (instance, feature and model) and strategies (adaptive, collective and integrative) in transfer learning [18,</ref>19]</ref>.</p><p>In addition, we must keep in mind that the different considerations when using these four distillation methods.
true performance of a recommender system, and that explicitly handling of the biases may help improve the performance [16,</ref>28,</ref>31]</ref>. Most of the previous works to solve the bias problems of recommender systems can be classified as counterfactual learning-based <ref type="bibr" target="#b24" n [3,</ref>28]</ref>. IPS is one of the most popular counterfactual approaches for recommendation [24,</ref>31]</ref>, where each sample is weighted with an IPS, referring to the likelihood of the sample being logged. If there are no unobserved confounders, IPS methods can get mework. Label-based distillation includes a direct method for learning an imputation model and its variants. Sample-based distillation includes the IPS method [24,</ref>31]</ref> and other approaches as described in Section 2.2. Although we introduce the four distillation methods in different modules, their relations are close. This mea supplied by users during normal interactions, i.e., users pick and rate items as they wish. This can be considered as a stochastic logging policy by following [24,</ref>31]</ref>, and thus the user set is biased. The Yahoo! random set consists of ratings collected during an online survey, when each of the first 5400 users is asked to pr
ype="bibr" target="#b9">[10]</ref>. By introducing soft-targets related to teacher networks as part of the objective function, the training of student networks is guided to achieve knowledge transfer [18]</ref>. A series of followup works develop different distillation structures (e.g., multiple teachers [8]</ref> and cascade distillatio ype="bibr" target="#b32">[33]</ref>. Moreover, they are also related to the types of knowledge (instance, feature and model) and strategies (adaptive, collective and integrative) in transfer learning [18,</ref>19]</ref>.</p><p>In addition, we must keep in mind that the different considerations when using these four distillation methods.
ch as popularity bias [1,</ref>6]</ref>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref>28]</ref>. Previous studies have shown that models and evaluation metri (CRM) principle [25]</ref>, while the latter mainly makes certain assumptions about the data being missing not at random (MNAR) [15,</ref>17]</ref>.</p><p>A recent work has shown that a uniform data can alleviate the previous model bias problem [16]</ref>. But the uniform dat a uniform subset for training and test. We consider the following datasets in the experiments, where the statistics are described in Table 3</ref>.</p><p>• Yahoo! R3 [17]</ref>: This dataset contains ratings collected from two different sources on Yahoo! Music services, involving 15,400 users and 1000 songs. The Yahoo! user set consi
]</ref> proposes a doubly robust method for joint learning of rating prediction and error imputation. Moreover, a uniform data is useful for counterfactual learning, such as imputation model learning [33]</ref>, propensity computation [24]</ref> and modeling with uniform data directly [5,</ref><ref type="bi e. This means that we can design new strategies with different combinations of the four distillation methods, such as the doubly robust method [7]</ref> and its variants [33]</ref>. Moreover, they are also related to the types of knowledge (instance, feature and model) and strategies (adaptive, collective and integrative) in transfer lea that of Yahoo! R3, i.e., 5% as training set (𝑆 𝑡 ), 5% as validation set (𝑆 𝑣𝑎 ), and the rest as test set (𝑆 𝑡𝑒 ). Following the settings of the previous works [5,</ref>33]</ref>, we employ two evaluation metrics that are widely used in industry recommendation, including the negative logarithmic loss (NLL) and the area under the roc cur
>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref>28]</ref>. Previous studies have shown that models and evaluation metrics that ignore the biases do not reflect the true performance of a recommender system, and that ex igorous framework with two counterfactual learning methods, i.e., SVM PropDCG and DeepPropDCG. Some position bias estimation methods for ranking are proposed in [3,</ref>28]</ref>. IPS is one of the most popular counterfactual approaches for recommendation [24,</ref>31]</ref>, hat ignore the biases do not reflect the true performance of a recommender system, and that explicitly handling of the biases may help improve the performance [16,</ref>28,</ref>31]</ref>. Most of the previous works to solve the bias problems of recommender systems can be classified as counterfactual learn
Low Rank Baselines: Biased Matrix Factorization (biasedMF). We first consider the case where the proposed framework is implemented using a lowrank model. We use biased matrix factorization (biasedMF) [12]</ref> as the baseline, which is one of the most classic basic models in recommender systems. In this method, a user 𝑖's preference for an item 𝑗 is formalized as Ŷ𝑖
ype="bibr" target="#b9">[10]</ref>. By introducing soft-targets related to teacher networks as part of the objective function, the training of student networks is guided to achieve knowledge transfer [18]</ref>. A series of followup works develop different distillation structures (e.g., multiple teachers [8]</ref> and cascade distillatio ype="bibr" target="#b32">[33]</ref>. Moreover, they are also related to the types of knowledge (instance, feature and model) and strategies (adaptive, collective and integrative) in transfer learning [18,</ref>19]</ref>.</p><p>In addition, we must keep in mind that the different considerations when using these four distillation methods.
ype="bibr" target="#b9">[10]</ref>. By introducing soft-targets related to teacher networks as part of the objective function, the training of student networks is guided to achieve knowledge transfer [18]</ref>. A series of followup works develop different distillation structures (e.g., multiple teachers [8]</ref> and cascade distillatio ype="bibr" target="#b32">[33]</ref>. Moreover, they are also related to the types of knowledge (instance, feature and model) and strategies (adaptive, collective and integrative) in transfer learning [18,</ref>19]</ref>.</p><p>In addition, we must keep in mind that the different considerations when using these four distillation methods.
>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref>28]</ref>. Previous studies have shown that models and evaluation metrics that ignore the biases do not reflect the true performance of a recommender system, and that ex igorous framework with two counterfactual learning methods, i.e., SVM PropDCG and DeepPropDCG. Some position bias estimation methods for ranking are proposed in [3,</ref>28]</ref>. IPS is one of the most popular counterfactual approaches for recommendation [24,</ref>31]</ref>, hat ignore the biases do not reflect the true performance of a recommender system, and that explicitly handling of the biases may help improve the performance [16,</ref>28,</ref>31]</ref>. Most of the previous works to solve the bias problems of recommender systems can be classified as counterfactual learn
>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref>28]</ref>. Previous studies have shown that models and evaluation metrics that ignore the biases do not reflect the true performance of a recommender system, and that ex igorous framework with two counterfactual learning methods, i.e., SVM PropDCG and DeepPropDCG. Some position bias estimation methods for ranking are proposed in [3,</ref>28]</ref>. IPS is one of the most popular counterfactual approaches for recommendation [24,</ref>31]</ref>, hat ignore the biases do not reflect the true performance of a recommender system, and that explicitly handling of the biases may help improve the performance [16,</ref>28,</ref>31]</ref>. Most of the previous works to solve the bias problems of recommender systems can be classified as counterfactual learn
ommender Systems as a feedback loop system may suffer from the bias problems such as popularity bias [1,</ref>6]</ref>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref><ref type="bibr" target
and the counterfactual risk minimization (CRM) principle [25]</ref>, while the latter mainly makes certain assumptions about the data being missing not at random (MNAR) [15,</ref>17]</ref>.</p><p>A recent work has shown that a uniform data can alleviate the previous model bias problem <ref type="bibr" targ
ef> or the relation between the hidden layers [32]</ref>). Some recent works are no longer limited to model structure, but considers sample-based knowledge distillation [21,</ref>27]</ref>. In this paper, we further expand the definition of distillation to include label-based and feature-based forms. The m d model structure-based distillation. Note that we use a general definition of distillation in the study rather than the past knowledge distillation approaches such as considering the level of sample [21,</ref>27]</ref> and model structure [10,</ref>22]</ref>. Each method is b
ms. The marriage of knowledge distillation and recommender systems has also attracted the attention of the researchers [26,</ref>30,</ref>34]</ref>. Most of these works focus on using knowledge distillation to extract some useful knowledge from some auxiliary models to enhance the performance or interpreta
f>6]</ref>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref>28]</ref>. Previous studies have shown that models and evaluation metrics that ignore the biases do not reflect the true performan provides a general and theoretically rigorous framework with two counterfactual learning methods, i.e., SVM PropDCG and DeepPropDCG. Some position bias estimation methods for ranking are proposed in [3,</ref>28]</ref>. IPS is one of the most popular counterfactual approaches for recommendation [24,</ref><r
ommender Systems as a feedback loop system may suffer from the bias problems such as popularity bias [1,</ref>6]</ref>, previous model bias [9,</ref>16,</ref>17]</ref> and position bias [3,</ref><ref type="bibr" target
olve the bias problems in recommender systems.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Counterfactual Learning for Ranking</head><p>For learning-to-rank tasks, Agarwal et al. [2]</ref> provides a general and theoretically rigorous framework with two counterfactual learning methods, i.e., SVM PropDCG and DeepPropDCG. Some position bias estimati
"bibr" target="#b27">28,</ref>31]</ref>. Most of the previous works to solve the bias problems of recommender systems can be classified as counterfactual learning-based [25]</ref> and heuristic-based approaches. The former mainly uses the inverse propensity score (IPS) [24]</ref> and the counterfactual ris [25]</ref> and heuristic-based approaches. The former mainly uses the inverse propensity score (IPS) [24]</ref> and the counterfactual risk minimization (CRM) principle [25]</ref>, while the latter mainly makes certain assumptions about the data being missing not at random (MNAR) [15,</ref><ref type="bibr"
y complexity. In this paper, we propose a simple scalable graph neural network architecture generalizing GCN, S-GCN, ChebNet and related methods. Our architecture is analogous to the inception module Szegedy et al. (2015)</ref>; Kazi et al. (2019)</ref> and combines graph convolutional filters of different size that are amenable to effi s, e.g. via softmax or sigmoid function, depending on the task at hand. Note that the model in equation ( 4</ref>) is analogous to the popular Inception module Szegedy et al. (2015)</ref> for classic CNN architectures (Figure 1</ref>): it consists of convolutional filters of different sizes determined by the
including timings, are run on an AWS p2.8xlarge instance, with 8 NVIDIA K80 GPUs, 32 vCPUs, a processor Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz and 488GiB of RAM. SIGN is implemented using Pytorch Paszke et al. (2019)</ref>. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Inductive. Table 8</ref>
ar transformation of the node features, followed by one or more iterations of diffusion on the graph.</p><p>Until recently, most of the research in the field has focused on small-scale datasets (CORA Sen et al. (2008)</ref> with only ∼ 5K nodes still being among the most widely used), and relatively little effort has been devoted to scaling these methods to web-scale
Φ G)),</formula><p>where • denotes the element-wise matrix product.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Convolution-like operators on graphs</head><p>Spectral graph CNNs. Bruna et al. Bruna et al. (2014)</ref> used the graph Fourier transform to generalize convolutional neural networks (CNN) LeCun et al. (198 h do not generalize to another.</p><p>ChebNet. A way to address these issues is to model the filter as a transfer function ĝ(λ), applied to the Laplacian as ĝ(∆) = Φĝ(Λ)Φ . Unlike the construction of Bruna et al. (2014)</ref> that does not generalize across graphs, the filter computed in the above manner is stable under graph perturbations <ref type="bibr" target="#b2
rs in the inception module, number of feedforward layers for the final classification) are optimized on the validation sets using bayesian optimization with a tree parzen estimator surrogate function Bergstra et al. (2011)</ref>. Table 3</ref> shows the hyperparameter ranges defining the search space.</p></div> <div xmlns="http://www.
erator. Furthermore, more complex aggregation operations e.g. higher-order Laplacians Barbarossa and Sardellitti (2019)</ref> or directed diffusion based on graph motifs Monti et al. (2018)</ref> can be straightforwardly incorporated as additional channels in the inception module.</p><p>Finally, while our method relies on linear graph ag
of architectures are graph autoencoders Kipf and Welling (2016)</ref> and random walk-based embeddings Grover and Leskovec (2016)</ref>; Perozzi et al. (2014)</ref>.</p><p>A typical graph neural network architecture consists of graph Convolution-like operators (discussed in details in Section 2.3) perform
pe="bibr">), chemistry Duvenaud et al. (2015)</ref>; Gilmer et al. (2017)</ref>, medicine Parisot et al. (2018)</ref>, drug repositioning Zitnik et al. (2018)</ref>, discovery of anti-cancer foods Veselkov et al. (2019)</ref>, modeling of proteins <ref type="bibr" target="#b1
particle physics Choma et al. (2018</ref>), chemistry Duvenaud et al. (2015)</ref>; Gilmer et al. (2017)</ref>, medicine Parisot et al. (2018)</ref>, drug repositioning Zitnik et al. (2018)</ref>, discovery of anti-cancer foods 
erator. Furthermore, more complex aggregation operations e.g. higher-order Laplacians Barbarossa and Sardellitti (2019)</ref> or directed diffusion based on graph motifs Monti et al. (2018)</ref> can be straightforwardly incorporated as additional channels in the inception module.</p><p>Finally, while our method relies on linear graph ag
aph neural network architecture generalizing GCN, S-GCN, ChebNet and related methods. Our architecture is analogous to the inception module Szegedy et al. (2015)</ref>; Kazi et al. (2019)</ref> and combines graph convolutional filters of different size that are amenable to efficient precomputation, allowing extremely fast training and i ion across nodes). Owing to this analogy, we refer to our model as the Scalable Inception Graph Network (SIGN). We notice that one work extending the idea of an Inception module to GNNs is the one in Kazi et al. (2019)</ref>; in this work, however, authors do not discuss the inclusion of a linear, non-diffusive term (r = 0) which effectively accounts for a skip conne
social influence diffusion process from the global social network structure. Recently, we propose a preliminary work of a neural influence Diff usion Network (i.e., DiffNet) for social recommendation [43]</ref>. DiffNet models the recursive social diffusion process for each user, such that the influence diffusion hidden in the higher-order social network is captured rs to alleviate data sparsity and enhancing recommendation performance [19]</ref>, [20]</ref>, [14]</ref>, [43]</ref>.</p><p>In fact, as users play a central role in social platforms with user-user social behavior and user-item interest behavior, the key to social recommendat , some works have applied GCNs separately on these two kinds of graphs [51]</ref>, [41]</ref>, [48]</ref>, [43]</ref>. On one hand, given the useritem interest graph, NGCF is proposed to directly encode the collaborative information of users by exploring the higher-order conn neural Network (DiffNet) to model the recursive social diffusion process in the social network, such that the higher-order social structure is directly modeled in the recursive user embedding process [43]</ref>. These graph based models showed superior performance compared to the previous non-graph based recommendation models by modeling either graph structure. Never y aggregate user embeddings from different nodes in a graph, and then from different graphs. In summary, our main contributions are listed as follows:</p><p>? Compared to our previous work of DiffNet [43]</ref>, we revisit the social recommendation problem as predicting the missing edges in the user-item interest graph by taking both user-item interest graph and user ers could be naturally formulated as a user-user graph, recently we propose a preliminary graph based social recommendation model, DiffNet, for modeling the social diffusion process in recommendation [43]</ref>. DiffNet advances classical embedding based models with carefully designed influence diffusion layers, such that how users are influenced by the recursive inf fNet adopts the recursive influence diffusion process for iterative user embedding learning, such that the up to K-th order social network structure is injected into the social recommendation process [43]</ref>. In this part, we propose DiffNet++, an enhanced model of DiffNet that fuses both influence diffusion in the social network G S and interest diffusion in the aset is also publicly available 5 .</p><p>Among the four datasets, Yelp and Flickr are two datasets with user and item attributes, and are adopted as datasets of our previously proposed DiffNet model [43]</ref>. The remaining two datasets of Epinions and Dianping do not contain user and item attributes. We use the same preprocessing steps of the four datasets. Specif . Please note that, in PinSage, we take the user-item graph with both user and item features as input, in order to transform this model for the recommendation task. For our proposed models of DiffNet [43]</ref> and DiffNet++, since both models are flexible and could be reduced to simpler versions without user and item features, we use DiffNet-nf and DiffNet++-nf to r N ranking evaluation, we use two widely used metrics, Hit Ratio (HR) [9]</ref> and Normalized Discounted Cummulative Gain (NDCG) [9]</ref>, [43]</ref>. Specifically, HR measures the percentage of hit items in the top-N list, and NDCG puts more emphasis on the top ranked items. As we focus on the top-N rankin op-N list, and NDCG puts more emphasis on the top ranked items. As we focus on the top-N ranking performance with large itemset, similar as many other works [17]</ref>, [43]</ref>, to evaluate the performance, for each user, we randomly select 1000 unrated items that a user has not interacted with as negative samples. Then, we mix these
larization based approaches [19]</ref>, [30]</ref>, [21]</ref>, [26]</ref>, [44]</ref> and the user behavior enhancement based approaches [14]</ref>, [15]</ref>. Specifically, the soc us works focused on how to explore the social neighbors, i.e., the observed links in the social network. Recently, CNSR is proposed to leverage the global social network in the recommendation process [44]</ref>. In CNSR, each user's latent embedding is composed of two parts: a free latent embedding (classical CF models), and a social network embedding that captures t ), social based recommendation model (SocialMF [19]</ref>, TrustSVD [14]</ref>, ContextMF [21]</ref>, CNSR [44]</ref>), as well as the graph based recommendation models of GraphRec [10]</ref>, PinSage [48]</ref>, NG
is a diagonal matrix with d aa = M b=1 s ab . Instead of the social regularization term, some researchers argued that the social network provides valuable information to enhance each user's behavior [50]</ref>, [15]</ref>. TrustSVD is such a representative model that shows stateof-the-art performance [14]
larization based approaches [19]</ref>, [30]</ref>, [21]</ref>, [26]</ref>, [44]</ref> and the user behavior enhancement based approaches [14]</ref>, [15]</ref>. Specifically, the soc us works focused on how to explore the social neighbors, i.e., the observed links in the social network. Recently, CNSR is proposed to leverage the global social network in the recommendation process [44]</ref>. In CNSR, each user's latent embedding is composed of two parts: a free latent embedding (classical CF models), and a social network embedding that captures t ), social based recommendation model (SocialMF [19]</ref>, TrustSVD [14]</ref>, ContextMF [21]</ref>, CNSR [44]</ref>), as well as the graph based recommendation models of GraphRec [10]</ref>, PinSage [48]</ref>, NG
en users, or the complex interactions between sparse feature input.</p><p>The social influence and social correlation among users' interests are the foundation for building social recommender systems [29]</ref>, [38]</ref>, [25]</ref>, [24]</ref>. Therefore, the social networ
pe="bibr" target="#b50">[51]</ref>. Therefore, many recent works focus on the spatial based GCNs for recommendation [48]</ref>, [4]</ref>, [49]</ref>, [41]</ref>. PinSage is a GCN based content recommendation model by propagating item features in the item-item correlation grap
llowing output, such that attentive weights are learned with deep neural networks to distinguish important elements [18]</ref>, [3]</ref>, [46]</ref>. Given a user's rated item history, NAIS is proposed to learn the neural attentive weights for item similarity in item based collaborative filtering <ref type
ing is :</p><formula xml:id="formula_26">v * i = [v 0 i ||v 1 i ||...||v K i ].</formula><p>After that, the predicted rating is modeled as the inner product between the final user and item embeddings [7]</ref>:</p><formula xml:id="formula_27">rai = [u 0 a ||u 1 a ||...||u K a ] T [v 0 i ||v 1 i ||...||v K i ].<label>(19)</label></formula><p>Please note that, some prev 2]</ref>. In this paper, to tackle the over-smoothing problem, we adopt the prediction layer as the LR-GCCF model, which receives state-of-the-art performance with user-item bipartite graph structure [7]</ref>. In LR-GCCF, Chen et al. carefully analyzed the simple concatenation of entity embedding at each layer is equivalent to residual preference learning, and why th al. carefully analyzed the simple concatenation of entity embedding at each layer is equivalent to residual preference learning, and why this simple operation could alleviate the over-smoothing issue [7]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Training</head><p>We use a pair-wise ranking based loss function for optimization, which
nfluence and social correlation among users' interests are the foundation for building social recommender systems [29]</ref>, [38]</ref>, [25]</ref>, [24]</ref>. Therefore, the social network among users could be leveraged to alleviate the sparsity in CF and enhance recommend
en sparse feature input.</p><p>The social influence and social correlation among users' interests are the foundation for building social recommender systems [29]</ref>, [38]</ref>, [25]</ref>, [24]</ref>. Therefore, the social network among users could be leveraged to allevia arget="#b23">[24]</ref>. Therefore, the social network among users could be leveraged to alleviate the sparsity in CF and enhance recommendation performance [30]</ref>, [38]</ref>, [15]</ref>. Due to the superiority of embedding based models for recommendation, most social recommendation models are also bu y designed regularization terms [21]</ref>. Social recommendation has also been extended with social circles [34]</ref>, temporal context [38]</ref>, rich contextual information [42]</ref>, user role in the social network [39]</ref>, and efficie process [40]</ref>. In social recommendation, many attention models have been proposed to learn the social influence strength [35]</ref>, [38]</ref>, [13]</ref>, [10]</ref>. E.g., with each user's direct item neighbors and social neighbors, Graph
ype="bibr" target="#b33">[34]</ref>, temporal context [38]</ref>, rich contextual information [42]</ref>, user role in the social network [39]</ref>, and efficient training models without negative sampling [6]</ref>. All these previous works focused on how to explore the socia
a;</ref>Xu et al., 2019]</ref>. This similar idea is widely used in information retrieval to capture the exact and soft matches between a query and a candidate document [Xiong et al., 2017]</ref>. Specifically, we apply the basic BERT unit to obtain {C(e i )}</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>|N (e)| i=1</head><p> hing patterns from the similarity matrix between two sentences. Different from sentences, the neighbors are disordered and independent from each other. Thus we adopt a RBF kernel aggregation function [Xiong et al., 2017]</ref> to extract features about the accumulation of similarities.</p><p>Before making use of the RBF kernel aggregations, we first apply a max pooli

leveraging the graph structures to align entities. The specific technique has evolved from the traditional KG embedding models such as MTransE [Chen et al., 2017]</ref> and IPTransE [Zhu et al., 2017]</ref> to recent emergent graph neural networks such as attention-based GCN [Xu et al., 2019]</ref>, highway <ref type="
ls such as MTransE [Chen et al., 2017]</ref> and IPTransE [Zhu et al., 2017]</ref> to recent emergent graph neural networks such as attention-based GCN [Xu et al., 2019]</ref>, highway GCN [Wu et al., 2019b]</ref>, relation-aware GCN [Wu et al., 2019a]</ref> and VR-GCN <ref type="bibr" rmation and apply variant GCN models to update a node embedding by aggregating all neighbors' embeddings [Wang et al., 2018;</ref>Wu et al., 2019a;</ref>Xu et al., 2019]</ref>. However, since different KGs are highly heterogeneous, it is not always the case that equivalent entities share similar neighbors. Taking an exam et al., 2019]</ref>. Although some works distinguish the influence from different neighbors [Cao et al., 2019;</ref>Wu et al., 2019a;</ref>Xu et al., 2019]</ref>, essentially, the GCNlike models still mix the side information of all the neighbors to represent an entity. HMAN has been aware of the issue, thu pair rather than learning a global representation for e or e ′ by aggregating the names/descriptions of all their neighbors as existing works did [Wu et al., 2019a;</ref>Xu et al., 2019]</ref>. This similar idea is widely used in information retrieval to capture the exact and soft matches between a query and a candidate document <ref typ

ormation of neighbors. Moreover, similar to aggregating neighbors, it aggregates all the attributes together to represent an entity like most of the works did [Sun et al., 2017;</ref>Zhang et al., 2019]</ref>, which also results in noisy matches between entities.</p><p>To deal with the noisy matches caused by aggregat-ing neighbors or attributes, we tions, we also compare each attribute pair rather than learning a global representation for e or e ′ by aggregating all their attributes as existing works did [Sun et al., 2017;</ref>Zhang et al., 2019]</ref>. Specifically, in Figure 3</ref>, we change the similarity matrix between the neighboring entities into that between the emb

nitialize the embedding of each node by its side information and apply variant GCN models to update a node embedding by aggregating all neighbors' embeddings [Wang et al., 2018;</ref>Wu et al., 2019a;</ref>Xu et al., 2019]</ref>. However, since different KGs are highly heterogeneous, it is not always the case that equiva ises and thus harm performance [Yang et al., 2019]</ref>. Although some works distinguish the influence from different neighbors [Cao et al., 2019;</ref>Wu et al., 2019a;</ref>Xu et al., 2019]</ref>, essentially, the GCNlike models still mix the side information of all the neighbors to repre is to compare the names/descriptions of each neighbor pair rather than learning a global representation for e or e ′ by aggregating the names/descriptions of all their neighbors as existing works did [Wu et al., 2019a;</ref>Xu et al., 2019]</ref>. This similar idea is widely used in information retrieval to capture the exact and soft mat lar way is to represent a relation approximately by its associated head-tail entity pairs based on the assumption that two relations are more similar if they associate to more similar head-tail pairs [Wu et al., 2019a]</ref>. Specifically, we average C(e) of all the associated head entities and also average those of all the tail entities, and concatenate them to repre 0"><head>Overall Performance on DBP15K</head><p>We compare all the state-of-the-art models with available results or codes. Some methods such as [Chen et al., 2018;</ref>Trsedya et al., 2019]</ref> are not compared due to the code implementation issue. In principle, we divide them into the category that only utilizes graph structures and
KGs, because: (1) the KGs are usually sparse, with a large number of long-tail entities whose structural embeddings have low * Contact Author  Yang et al., 2019)</ref> expressiveness [Guo et al., 2019]</ref>. For example, in DBpedia-ZH1</ref> , the long-tail entities that appear less than 5 times occupy 74.1%; and (2)
rough the interaction mechanism, which can improve the matching accuracy between entities.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall Performance on DWY100K</head><p>Since CEAFF [Zeng et al., 2020]</ref> has already obtained 100% HR1 on the mono-lingual dataset DWY100K, we only compare our model with it. We use the name as the basic representati 9% HR1 respectively, which are comparable to CEAFF. However, we also observe that the names for most of the aligned entities are exactly the same, which demands more challenging mono-lingual datasets [Zeng et al., 2020]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>We perform ablation study from three aspects and show the res
ormation of neighbors. Moreover, similar to aggregating neighbors, it aggregates all the attributes together to represent an entity like most of the works did [Sun et al., 2017;</ref>Zhang et al., 2019]</ref>, which also results in noisy matches between entities.</p><p>To deal with the noisy matches caused by aggregat-ing neighbors or attributes, we tions, we also compare each attribute pair rather than learning a global representation for e or e ′ by aggregating all their attributes as existing works did [Sun et al., 2017;</ref>Zhang et al., 2019]</ref>. Specifically, in Figure 3</ref>, we change the similarity matrix between the neighboring entities into that between the emb
s of GNNs rather than GCNs. Also, as several heterogeneous graph datasets have been recently studied for other network analysis tasks, such as link prediction [36,</ref>41]</ref> and graph classification [17,</ref>24]</ref>, applying our GTNs to the other tasks can be interes
d transform a heterogeneous graph into a homogeneous graph defined by the meta-paths. Then conventional GNNs can operate on the transformed homogeneous graphs [37,</ref>43]</ref>. This is a two-stage approach and requires hand-crafted meta-paths for each problem. The accuracy of downstream analysis can be significantly affected by the c with non-negative weights from softmax(W 1 φ ).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Meta-Path Generation</head><p>Previous works [37,</ref>43]</ref> require manually defined meta-paths and perform Graph Neural Networks on the meta-path graphs. Instead, our Graph Transformer Networks (GTNs) learn meta-paths
" target="#b32">33]</ref>, functional structure of brains [20]</ref>, recommender systems [1,</ref>27,</ref>39]</ref>. The underlying graph structure is utilized by GNNs to operate convolution directly on graphs by passing node features [12,</ref
GT layers combined with different classes of GNNs rather than GCNs. Also, as several heterogeneous graph datasets have been recently studied for other network analysis tasks, such as link prediction [36,</ref>41]</ref> and graph classification [17,</ref>24]</ref>, applying o
her network analysis tasks, such as link prediction [36,</ref>41]</ref> and graph classification [17,</ref>24]</ref>, applying our GTNs to the other tasks can be interesting future directions.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</hea
[12,</ref>14]</ref> to neighbors, or perform convolution in the spectral domain using the Fourier basis of a given graph, i.e., eigenfunctions of the Laplacian operator [9,</ref>15,</ref>19]</ref>.</p><p>However, one limitation of most GNNs is that they assume the graph struct p>Graph Neural Networks. In recent years, many classes of GNNs have been developed for a wide range of tasks. They are categorized into two approaches: spectral [5,</ref>9,</ref>15,</ref>19,</ref>22,</ref>38]</ref> a
#b17">[18,</ref>30,</ref>42]</ref> and node classification [3,</ref>14,</ref>33]</ref>. The representation learnt by GNNs has been proven to be effective in achieving state-ofthe-art performance in a variety of graph datasets such as social netwo as social networks [7,</ref>14,</ref>35]</ref>, citation networks [19,</ref>33]</ref>, functional structure of brains [20]</ref>, recommender systems [1,</ref><ref type="bibr" target=" [7,</ref>12,</ref>14,</ref>26,</ref>29,</ref>33]</ref>. Based on spectral graph theory, Bruna et al. [5]</ref> proposed a way to perform convolution in the spectral domain using the Fo ed convolution based on spectral convolution [4,</ref>26]</ref>, attention mechanism on neighbors [25,</ref>33]</ref>, subsampling [6,</ref>7]</ref> and inductive representation for a large graph <ref type="bibr" targ of the spectral graph convolution. On the other hand, non-spectral approaches define convolution operations directly on the graph, utilizing spatially close neighbors. For instance, Veličković et al. [33]</ref> applies different weight matrices for nodes with different degrees and Hamilton et al. [14]</ref> has proposed learnable aggreg -gram with negative sampling to generate embeddings.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>GNN-based methods</head><p>We used the GCN [19]</ref>, GAT [33]</ref>, and HAN [37]</ref> as GNN based methods. GCN is a graph convolutional network which utilizes a localized first-order approxima
"#b37">38]</ref> and nonspectral methods [7,</ref>12,</ref>14,</ref>26,</ref>29,</ref>33]</ref>. Based on spectral graph theory, Bruna et al. [5]</ref> proposed a way to perform convolu
mance in a variety of graph datasets such as social networks [7,</ref>14,</ref>35]</ref>, citation networks [19,</ref>33]</ref>, functional structure of brains [20]</ref>, recommender systems <ref type="bibr" target volution in the spectral domain using the Fourier basis of a given graph, i.e., eigenfunctions of the Laplacian operator [9,</ref>15,</ref>19]</ref>.</p><p>However, one limitation of most GNNs is that they assume the graph structure to operate GNNs on is fixed and homogeneous. Since the graph convolutions d oped for a wide range of tasks. They are categorized into two approaches: spectral [5,</ref>9,</ref>15,</ref>19,</ref>22,</ref>38]</ref> and nonspectral methods [7,</ref><ref type="bibr" Based on spectral graph theory, Bruna et al. [5]</ref> proposed a way to perform convolution in the spectral domain using the Fourier basis of a given graph. Kipf et al. [19]</ref> simplified GNNs using the first-order approximation of the spectral graph convolution. On the other hand, non-spectral approaches define convolution operation Conference (APC), which can be represented as A </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Convolutional network (GCN).</head><p>In this work, a graph convolutional network (GCN) [19]</ref> is used to learn useful representations for node classification in an end-to-end fashion. Let H (l) be the feature representations of the lth layer in GCNs, t s meta-path based random walk and utilizes skip-gram with negative sampling to generate embeddings.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>GNN-based methods</head><p>We used the GCN [19]</ref>, GAT [33]</ref>, and HAN [37]</ref> as GNN based methods. GCN is a graph convolutional network w
arkable success in representation learning, GNNs learn a powerful representation for given tasks and data. To improve performance or scalability, generalized convolution based on spectral convolution [4,</ref>26]</ref>, attention mechanism on neighbors [25,</ref>33]</ref>, sub
n proven to be effective in achieving state-ofthe-art performance in a variety of graph datasets such as social networks [7,</ref>14,</ref>35]</ref>, citation networks [19,</ref>33]</ref>, functional structure of brains <ref type="bibr" target="#
get="#b10">[11,</ref>21,</ref>40]</ref>, link prediction [18,</ref>30,</ref>42]</ref> and node classification [3,</ref>14,</ref>33]</ref>. The representa
categorized into two approaches: spectral [5,</ref>9,</ref>15,</ref>19,</ref>22,</ref>38]</ref> and nonspectral methods [7,</ref>12,</ref><ref type="bibr"
27,</ref>39]</ref>. The underlying graph structure is utilized by GNNs to operate convolution directly on graphs by passing node features [12,</ref>14]</ref> to neighbors, or perform convolution in the spectral domain using the Fourier basis of a given graph, i.e., eigenfunct "#b14">15,</ref>19,</ref>22,</ref>38]</ref> and nonspectral methods [7,</ref>12,</ref>14,</ref>26,</ref>29,</ref>33]</ref>
[12,</ref>14]</ref> to neighbors, or perform convolution in the spectral domain using the Fourier basis of a given graph, i.e., eigenfunctions of the Laplacian operator [9,</ref>15,</ref>19]</ref>.</p><p>However, one limitation of most GNNs is that they assume the graph struct p>Graph Neural Networks. In recent years, many classes of GNNs have been developed for a wide range of tasks. They are categorized into two approaches: spectral [5,</ref>9,</ref>15,</ref>19,</ref>22,</ref>38]</ref> a
" target="#b32">33]</ref>, functional structure of brains [20]</ref>, recommender systems [1,</ref>27,</ref>39]</ref>. The underlying graph structure is utilized by GNNs to operate convolution directly on graphs by passing node features [12,</ref
ork is multiple graph structures with different types of nodes and edges. Let T v and T e be the set of node types and edge types respectively. The input graphs can be viewed as a heterogeneous graph [31]</ref> G = (V, E), where V is a set of nodes, E is a set of observed edges with a node type mapping function f v : V → T v and an edge type mapping function</p><form
her network analysis tasks, such as link prediction [36,</ref>41]</ref> and graph classification [17,</ref>24]</ref>, applying our GTNs to the other tasks can be interesting future directions.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</hea
her network analysis tasks, such as link prediction [36,</ref>41]</ref> and graph classification [17,</ref>24]</ref>, applying our GTNs to the other tasks can be interesting future directions.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</hea
ous input graph into useful meta-path graphs for each task and learn node representation on the graphs in an end-to-end fashion. GTNs can be viewed as a graph analogue of Spatial Transformer Networks [16]</ref> which explicitly learn spatial transformations of input images or features. The main challenge to transform a heterogeneous graph into new graph structure def
target="#b18">[19,</ref>33]</ref>, functional structure of brains [20]</ref>, recommender systems [1,</ref>27,</ref>39]</ref>. The underlying graph structure is utilized by GNNs to operate convolution directly on graphs by passing node features
target="#b18">[19,</ref>33]</ref>, functional structure of brains [20]</ref>, recommender systems [1,</ref>27,</ref>39]</ref>. The underlying graph structure is utilized by GNNs to operate convolution directly on graphs by passing node features
annot confirm the source authenticity of data, and network operators also cannot guarantee that the user packets are not detoured in transmission, numerous network attack surfaces are opened up today [2]</ref>- [4]</ref>. For example, an attacker may try to flood arbitrary packets from multiple spoofed sources to waste downstream resource type="bibr" target="#b9">[10]</ref>. Recently, there are several proposals addressing both source and path validation that fill the void, such as ICING [3]</ref> and OPT [2]</ref>. However, for the targeting environment which is adversarial, high-speed, and variable-path, their protocols still have significant processing overhead, and do duct evaluations of our PSVM on a real testbed built upon the prototype using the normal IP routing performance of the Click router as the baseline, and compare our PSVM with the-state-of-the-art OPT [2]</ref>.  Method and parameter setup. For fairness, we use the same 128-bit AES algorithm to compute the PSVM's authentication structure Pic and OPT's validation struct ource and path validation. Current techniques for both source authentication and path verification have been proposed in ICING [3]</ref>, the Origin and Path Trace (OPT) [2]</ref>, Orthogonal Sequence Verification (OSV) [4]</ref>, and PPV [29]</ref>. In ICING, it requires each r
m resources. Traffic hijacking happens frequently [5]</ref> where packets may go through an eavesdropping node, resulting in a potential leakage of sensitive information [6]</ref>. It is easy to tamper packet contents on the path and insert other loads such as malicious code.</p><p>Although a great deal of attention has been paid to sourc

ef type="bibr" target="#b2">[3]</ref>, the Origin and Path Trace (OPT) [2]</ref>, Orthogonal Sequence Verification (OSV) [4]</ref>, and PPV [29]</ref>. In ICING, it requires each router to verify the optimized cryptographic construction PoP for all upstream nodes and generate new PoPs for every downstream no
path has been neglected by comparison. Some existing approaches for IP path tracking fail to solve the above problems, being unable to identify path deviation [9]</ref>, [10]</ref>. Recently, there are several proposals addressing both source and path validation that fill the void, such as ICING [3]</ref> and
Fault localization. Many researches provide path validation by making intermediate routers collect packet information [24]</ref>, and infer path properties of interest [25]</ref>. Fault localization is recognized as a high-quality online service, since it enables receivers to efficiently localize faulty links <ref type="bibr" target="#
m resources. Traffic hijacking happens frequently [5]</ref> where packets may go through an eavesdropping node, resulting in a potential leakage of sensitive information [6]</ref>. It is easy to tamper packet contents on the path and insert other loads such as malicious code.</p><p>Although a great deal of attention has been paid to sourc
ef type="bibr" target="#b2">[3]</ref>, the Origin and Path Trace (OPT) [2]</ref>, Orthogonal Sequence Verification (OSV) [4]</ref>, and PPV [29]</ref>. In ICING, it requires each router to verify the optimized cryptographic construction PoP for all upstream nodes and generate new PoPs for every downstream no
hed for multi-times and in multi-ways in practice to ensure a greater probability of being received. Furthermore, we suppose that node N i and its CGA would use secret methods (such as Diffie-Hellman [19]</ref>) to share the master key (Key N i ), which may be replaced if necessary to prevent cryptanalysis attacks. The session symmetric key of N i (Key Session N i</p
path has been neglected by comparison. Some existing approaches for IP path tracking fail to solve the above problems, being unable to identify path deviation [9]</ref>, [10]</ref>. Recently, there are several proposals addressing both source and path validation that fill the void, such as ICING [3]</ref> and
y ways that end-nodes (i.e.,the sender and receiver) could know path information, such as network topology analysis [14]</ref>, obtained from some BGP related protocols [15]</ref>, [16]</ref>, or employing the existing control plane routing protocols [13]</ref> (especially Pa
network design, but elevated to the population level. In each step of our process the input is an initial design space and the output is a refined design space of simpler or better models. Following [21]</ref>, we characterize the quality of a design space by sampling models and inspecting their error distribution. For example, in the figure above we start with an i (Figure 1</ref>). The overall process is analogous to manual design, elevated to the population level and guided via distribution estimates of network design spaces [21]</ref>.</p><p>As a testbed for this paradigm, our focus is on exploring network structure (e.g., width, depth, groups, etc.) assuming standard model families includi et regime.</p><p>Comparing networks. Given the vast number of possible network design spaces, it is essential to use a reliable comparison metric to guide our design process. Recently, the authors of [21]</ref> proposed a methodology for comparing and analyzing populations of networks sampled from a design space. This distribution-level view is fully-aligned with our design and are more likely to generalize to new settings (unlike a single model tuned for a specific scenario).</p><p>We rely on the concept of network design spaces introduced by Radosavovic et al. [21]</ref>. A design space is a large, possibly infinite, population of model architectures. The core insight from [21]</ref> is that we c etwork design spaces introduced by Radosavovic et al. [21]</ref>. A design space is a large, possibly infinite, population of model architectures. The core insight from [21]</ref> is that we can sample models from a design space, giving rise to a model distribution, and turn to tools from classical statistics to analyze the design space ad n="3.1.">Tools for Design Space Design</head><p>We begin with an overview of tools for design space design. To evaluate and compare design spaces, we use the tools introduced by Radosavovic et al. [21]</ref>, who propose to quantify the quality of a design space by sampling a set of models from that design space and characterizing the resulting model error distrib run is fast: training 100 models at 400MF for 10 epochs is roughly equivalent in flops to training a single ResNet-50 [8]</ref> model at 4GF for 100 epochs.</p><p>As in [21]</ref>, our primary tool for analyzing design space quality is the error empirical distribution function (EDF). The error EDF of n models with errors e i is given by rk design spaces is a promising avenue for future research.     </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C: Optimization Settings</head><p>Our basic training settings follow [21]</ref> as discussed in §3. To tune the learning rate lr and weight decay wd for REG-NET models, we perform a study, described in Figure <ref type="figure" target="#f l network design, but elevated to the population level. In each step of our process the input is an initial design space and the output is a refined design space of simpler or better models. Following[21]</ref>, we characterize the quality of a design space by sampling models and inspecting their error distribution. For example, in the figure above we start with an i .2] RegNetV [41.9|44.3] RegNetR [38.2|41.0] RegNetX</cell></row></table></figure> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">We use the term design space following[21]</ref>, rather than search space, to emphasize that we are not searching for network instances within the space. Instead, we are designing the space itself.</note> 95% CI for the min x value. The median gives the most likely best value.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">Our training setup in §3 exactly follows[21]</ref>. We use SGD with momentum of 0.9, mini-batch size of 128 on 1 GPU, and a half-period cosine schedule with initial learning rate of 0.05 and weight decay of 5•
Recently, the network design process has shifted from a manual exploration to more automated network design, popularized by NAS. NAS has proven to be an effective tool for finding good models, e.g., [35,</ref>23,</ref>17,</ref>20,</ref>18,</ref l body of work on finding better mobile networks via both manual design [9,</ref>25,</ref>19]</ref> and NAS [35,</ref>23,</ref>17,</ref>18]</ref>.</p><p>We emphasize that REGNET models
nception [27,</ref>28]</ref>, ResNet [8]</ref>, ResNeXt [31]</ref>, DenseNet [11]</ref>, and Mo-bileNet [9,</ref>25]</ref>. The design process behind these networks was largely manual a meterization shares similarity with previous work, e.g. how stage widths are set [26,</ref>7,</ref>32,</ref>11,</ref>9]</ref>. However, there are two key differences. First, we provide an empirical study justifying the design choices we make. Seco
Recently, the network design process has shifted from a manual exploration to more automated network design, popularized by NAS. NAS has proven to be an effective tool for finding good models, e.g., [35,</ref>23,</ref>17,</ref>20,</ref>18,</ref l body of work on finding better mobile networks via both manual design [9,</ref>25,</ref>19]</ref> and NAS [35,</ref>23,</ref>17,</ref>18]</ref>.</p><p>We emphasize that REGNET models
ns are more likely to be robust and generalize.</p><p>networks, NAS automatically finds a good model within the search space. Recently, NAS has received a lot of attention and shown excellent results [34,</ref>18,</ref>29]</ref>. Despite the effectiveness of NAS, the paradigm has limitations. The outcome o
Recently, the network design process has shifted from a manual exploration to more automated network design, popularized by NAS. NAS has proven to be an effective tool for finding good models, e.g., [35,</ref>23,</ref>17,</ref>20,</ref>18,</ref l body of work on finding better mobile networks via both manual design [9,</ref>25,</ref>19]</ref> and NAS [35,</ref>23,</ref>17,</ref>18]</ref>.</p><p>We emphasize that REGNET models
fective in this regime considering the substantial body of work on finding better mobile networks via both manual design [9,</ref>25,</ref>19]</ref> and NAS [35,</ref>23,</ref>17,</ref><ref type="bibr" target="#b17"

while most mobile networks use longer schedules with various enhancements, such as deep supervision [16]</ref>, Cutout [4]</ref>, DropPath [14]</ref>, AutoAugment [2]</ref>, and so on. As such, we hope our strong results obtained with a short training schedule without enhanceme xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 7 .</head><label>7</label><figDesc>Training enhancements to EFFICIENTNET-B0. Our EFFICIENTNET-B0 reproduction with DropPath[14]</ref> and a 250 epoch training schedule (third row), achieves results slightly inferior to original results (bottom row), which additionally used RM-SProp<ref type=
with group convolution[31]</ref>. (a) Each X block consists of a 1×1 conv, a 3×3 group conv, and a final 1×1 conv, where the 1×1 convs alter the channel width. BatchNorm[12]</ref> and ReLU follow each conv. The block has 3 parameters: the width wi, bottleneck ratio bi, and group width gi. (b) The stride-two (s = 2) version.</figDesc></f
t [8]</ref>, ResNeXt [31]</ref>, DenseNet [11]</ref>, and Mo-bileNet [9,</ref>25]</ref>. The design process behind these networks was largely manual and focussed on discovering new design choices that improve accuracy e.g., the use of deeper model se this version in §5, and further limit depth to 12 ≤ d ≤ 28 (see also Appendix D).</p><p>Alternate design choices. Modern mobile networks often employ the inverted bottleneck (b &lt; 1) proposed in [25]</ref> along with depthwise conv [1]</ref> (g = 1). In Figure 14</ref> (left), we observe that the i observe that REGNETS are surprisingly effective in this regime considering the substantial body of work on finding better mobile networks via both manual design [9,</ref>25,</ref>19]</ref> and NAS [35,</ref>23,</ref><ref type="bibr" target="#b16"
entation has been proven to significantly enhance the immunity of quantized DNN to such malicious bit-flips in [8]</ref>. However, a newly proposed Bit-Flip Attack (BFA) [17]</ref> whose progressive bit searching algorithm can successfully identify and flip an extremely small number of vulnerable weight bits (e.g., 13 out of 93 millions d Works</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Bit-Flip based Adversarial Weight Attack</head><p>The bit-flip based adversarial weight attack, aka. Bit-Flip Attack (BFA) [17]</ref>, is an adversarial attack variant which performs weight fault injection through flipping the bits. For the machine-imperceptible purpose, the BFA only flips t rching compares the bit candidates selected by the intra-layer search through directly checking the loss increment. Thus, the bit searching in iteration i can be formulated as an optimization process [17]</ref>:</p><formula xml:id="formula_0">max { Bi l } L f x; { Bi l } L l=1 , t s.t. t = f (x; {B l } L l=1 ); L l=1 D( Bi l , B l ) ∈ {0, 1, ..., N b }<label>(1)</lab int counterpart, which is not only more biologically plausible but also practically necessary for the acceleration of modern AI applications. To clarify, we use the same threat model as in prior work [17]</ref>, which is listed in Table 1</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Defense against Adversarial Example</he on 1 BFA is prone to flip bits of close-to-zero weights, and cause large weight shift.</p><p>As depicted in Fig. 2</ref>, the progressive bit search proposed in BFA [17]</ref> is prone to identify vulnerable bit in the weight whose absolute value has a small magnitude (i.e., |w| → 0) then modify it to be a large value (explained in e conducted using Pytorch [16]</ref>, running on NVIDIA Titan-XP GPUs.   BFA Configuration. To evaluate the effectiveness of the proposed defense methods, the code from [17]</ref> is utilized with further modification. The number of bit-flips N BF that degrades the prediction accuracy below 11% is used as the metric to measure the BFA r from the training subset as the default BFA configuration and report the mean±std of N BF with 5 BFA trials. Note that, all the quantized DNN reported hereafter still uses the uniform quantizer as in [17]</ref>, but with quantization-aware training instead of post-training quantization.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Result Evaluati ted by the operating system through the integrity check.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparison of Alternative Defense Methods</head><p>Adversarial weight attack [17]</ref> is a recently developed security threat model for modern DNN. Subsequently, the development of defensive approaches in this field has not received much attent strong PGD input attack. Then, we reverse the role by attacking a strong input defense known as PGD Trained adversarial defense [15]</ref> with strong weight attack BFA [17]</ref>. Again, adversarial input defense fails to defend BFA, requiring even less number of N BF than the baseline shown in Table 5
e the Bit-Flip errors.</p><p>In addition to the batch-normalization, the conventional DNN regularization technique, such as dropout, is also used to enhance the resistance against adversarial example [23]</ref>. As shown in Table 4</ref>, we increase the dropout rate to 0.7 in Will adversarial input defense method improve robustness
xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Defense against Adversarial Example</head><p>As the BFA is an adversarial attack variant, the popular techniques used to defend adversarial example [5]</ref> are investigated to seek potential BFA defense method.</p><p>Adversarial Training. Adversarial training [5,</ref><ref type="bibr" rror introduced by the bit-flips in the frontend can be easily accumulated and amplified during the forward propagation, which is similar to the linear explanation of adversarial example discussed in [5]</ref>.</p><p>1 module index includes all modules within DNN, where small to large index denotes the location from front to rear along the inference path. It is intrig e popular techniques used to defend adversarial example [5]</ref> are investigated to seek potential BFA defense method.</p><p>Adversarial Training. Adversarial training [5,</ref>15]</ref> is by-far the most successful adversarial example defense method, that optimizes the DNN parameters θ w.r.t both the cle

ersarial example [5]</ref> are investigated to seek potential BFA defense method.</p><p>Adversarial Training. Adversarial training [5,</ref>15]</ref> is by-far the most successful adversarial example defense method, that optimizes the DNN parameters θ w.r.t both the clean input x and their adversary examples soft-label as in Eq. (1)</ref>. Such adversarial training is also normally considered as a strong regularization technique.</p><p>Increasing model capacity. Prior works [15,</ref>7]</ref> have experimentally confirmed the resistance improvement against the adversarial attack by increasing the model capacity eight attack, with corresponding defense method. Owing to the lack of competing methods in this research direction, we attempt to transfer several conventional defense methods of adversarial examples [15,</ref>3,</ref>22]</ref>, for providing a comprehensive comparison. Weight Pruning. Both the activation a work performance. So altering any of the remaining non-zero weights still manages to degrade network performance significantly.</p><p>Adversarial Weight Training. Inspired by the adversarial training [15,</ref>4]</ref>, we attempt to adopt the same idea and create a BFA-based adversarial training as an alternative approach to compare wit method. Our proposed method with 4× width requires on average 72 bit-flips to cause complete malfunction of ResNet-20 architecture. In conclusion, similar to the observations from adversarial example [15,</ref>7]</ref>, increasing the network capacity by a large amount will enhance the robustness against BFA.</p></div> <div xmlns="http:/ nfirmed the resistance improvement against the adversarial attack by increasing the model capacity. It is interpreted as that the robust classifiers would require a more complicated decision boundary [15]</ref>, which is expected to benefit the defense against malicious weight change as well. Further in-depth analysis of model capacity and BFA resistance is discussed nd weight parameter defense interplay in increasing the overall robustness of the network. To achieve this, we take the most popular adversarial input attack known as Projected Gradient Descent (PGD) [15]</ref>. We conduct PGD attack on our PC weight defense and observe that the network test accuracy after the PGD attack drops to 0.51% in Table <ref type="table" targ t="#tab_4">5</ref>. Thus, our weight defense completely fails against a strong PGD input attack. Then, we reverse the role by attacking a strong input defense known as PGD Trained adversarial defense [15]</ref> with strong weight attack BFA [17]</ref>. Again, adversarial input defense fails to defend BFA, requiring even less number of N re> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>In this table we report the test accuracy after adversarial input attack (PGD[15]</ref>) on both adversarial input defense[15]</ref> and adversarial weight defense (proposed PC). Then Report N BF after conducting BF <head>Table 5 :</head><label>5</label><figDesc>In this table we report the test accuracy after adversarial input attack (PGD[15]</ref>) on both adversarial input defense[15]</ref> and adversarial weight defense (proposed PC). Then Report N BF after conducting BFA on both adversarial weight defense and input defense.</figDesc><table><row
rization-aware training is originally proposed as an extreme low bit-width model compression technique, which converts the weights from 32-bit floating-point to {-1,+1} binary format encoded by 1-bit [18]</ref>. Here, the binarizationaware training is leveraged as a defense technique against BFA, which can be mathematically described as:</p><formula xml:id="formula_2
xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Defense against Adversarial Example</head><p>As the BFA is an adversarial attack variant, the popular techniques used to defend adversarial example [5]</ref> are investigated to seek potential BFA defense method.</p><p>Adversarial Training. Adversarial training [5,</ref><ref type="bibr" rror introduced by the bit-flips in the frontend can be easily accumulated and amplified during the forward propagation, which is similar to the linear explanation of adversarial example discussed in [5]</ref>.</p><p>1 module index includes all modules within DNN, where small to large index denotes the location from front to rear along the inference path. It is intrig e popular techniques used to defend adversarial example [5]</ref> are investigated to seek potential BFA defense method.</p><p>Adversarial Training. Adversarial training [5,</ref>15]</ref> is by-far the most successful adversarial example defense method, that optimizes the DNN parameters θ w.r.t both the cle
al weight attack.</head><p>Effect of Batch-Normalization and Dropout Nowadays, the presence of Batch-Normalization (BN) layer in the deep neural network is customary to accelerate the training of DNN [11]</ref>, by normalizing the hidden features that forwarded along the inference path. On the other hand, an adversarial weight attack introduces variance in the weight

methods in this research direction, we attempt to transfer several conventional defense methods of adversarial examples [15,</ref>3,</ref>22]</ref>, for providing a comprehensive comparison. Weight Pruning. Both the activation and weight pruning have been investigated as the defense against adversarial exa
ersarial example [5]</ref> are investigated to seek potential BFA defense method.</p><p>Adversarial Training. Adversarial training [5,</ref>15]</ref> is by-far the most successful adversarial example defense method, that optimizes the DNN parameters θ w.r.t both the clean input x and their adversary examples soft-label as in Eq. (1)</ref>. Such adversarial training is also normally considered as a strong regularization technique.</p><p>Increasing model capacity. Prior works [15,</ref>7]</ref> have experimentally confirmed the resistance improvement against the adversarial attack by increasing the model capacity eight attack, with corresponding defense method. Owing to the lack of competing methods in this research direction, we attempt to transfer several conventional defense methods of adversarial examples [15,</ref>3,</ref>22]</ref>, for providing a comprehensive comparison. Weight Pruning. Both the activation a work performance. So altering any of the remaining non-zero weights still manages to degrade network performance significantly.</p><p>Adversarial Weight Training. Inspired by the adversarial training [15,</ref>4]</ref>, we attempt to adopt the same idea and create a BFA-based adversarial training as an alternative approach to compare wit method. Our proposed method with 4× width requires on average 72 bit-flips to cause complete malfunction of ResNet-20 architecture. In conclusion, similar to the observations from adversarial example [15,</ref>7]</ref>, increasing the network capacity by a large amount will enhance the robustness against BFA.</p></div> <div xmlns="http:/ nfirmed the resistance improvement against the adversarial attack by increasing the model capacity. It is interpreted as that the robust classifiers would require a more complicated decision boundary [15]</ref>, which is expected to benefit the defense against malicious weight change as well. Further in-depth analysis of model capacity and BFA resistance is discussed nd weight parameter defense interplay in increasing the overall robustness of the network. To achieve this, we take the most popular adversarial input attack known as Projected Gradient Descent (PGD) [15]</ref>. We conduct PGD attack on our PC weight defense and observe that the network test accuracy after the PGD attack drops to 0.51% in Table <ref type="table" targ t="#tab_4">5</ref>. Thus, our weight defense completely fails against a strong PGD input attack. Then, we reverse the role by attacking a strong input defense known as PGD Trained adversarial defense [15]</ref> with strong weight attack BFA [17]</ref>. Again, adversarial input defense fails to defend BFA, requiring even less number of N re> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>In this table we report the test accuracy after adversarial input attack (PGD[15]</ref>) on both adversarial input defense[15]</ref> and adversarial weight defense (proposed PC). Then Report N BF after conducting BF <head>Table 5 :</head><label>5</label><figDesc>In this table we report the test accuracy after adversarial input attack (PGD[15]</ref>) on both adversarial input defense[15]</ref> and adversarial weight defense (proposed PC). Then Report N BF after conducting BFA on both adversarial weight defense and input defense.</figDesc><table><row
mprovement.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">NIC Offload of TCP Features</head><p>There have been a large number of works and debates on NIC offloading of TCP features [35,</ref>47,</ref>50,</ref>57]</ref>. While AccelTCP pursues the same benef
Most of them employ a fast user-level packet I/O [10]</ref>, and exploit high parallelism on multicore systems by flow steering on NIC. More recently, systems like ZygOS [63]</ref>, Shinjuku [42]</ref>, and Shenango [59]</ref> further improve kernel-bypass stack by reducing th
P connections are prevalent in data centers [31,</ref>65]</ref> as well as in wide-area networks [54,</ref>64,</ref>66]</ref>. L7 proxying is also widely used in middlebox applications such as L7 LBs [6,</ref><ref t
ansfer as short-lived transactions deal with only a few of small packets.</p><p>Full Stack offload: TCP Offload Engine (TOE) takes a more ambitious approach that offloads entire TCP processing to NIC [34,</ref>67]</ref>. Similar to our work, TOE eliminates the CPU cycles and DMA overhead of connection management. It also avoids the DMA
ture. To offload TCP connection management, any L2-L4 NFs that should run prior to TCP stack (e.g., firewalling or host networking) must be offloaded to NIC accordingly. Such NFs can be written in P4 [40,</ref>45,</ref>56]</ref> and easily integrated with AccelTCP by properly placing them at ingress/egress
s. While recent kernel-bypass TCP stacks [5,</ref>30,</ref>41,</ref>55,</ref>61]</ref> have substantially improved the performance of short RPC transactions, they still need to track flow states whose computation cost is as large as 60% of the en ction after a single write, the host stack offloads the teardown and destroys the quasi-TCB.</p><p>Opportunistic zero-copy: Recent high-performance TCP stacks [30,</ref>61,</ref>68]</ref> bypass the socket buffer to avoid extra memory copying. However, this often freezes the application-level buffer even a
efit to real-world applications.</p><p>Key-value store (Redis): We evaluate the effectiveness of AccelTCP with Redis (v.4.0.8) [17], a popular 6 Theoretical maximum throughput is 63 Gbps according to [58]</ref>.  in-memory key-value store. We use Redis on mTCP as a baseline server while we port it to use AccelTCP for comparison. We test with the USR workload from Fac
s. While recent kernel-bypass TCP stacks [5,</ref>30,</ref>41,</ref>55,</ref>61]</ref> have substantially improved the performance of short RPC transactions, they still need to track flow states whose computation cost is as large as 60% of the en ction after a single write, the host stack offloads the teardown and destroys the quasi-TCB.</p><p>Opportunistic zero-copy: Recent high-performance TCP stacks [30,</ref>61,</ref>68]</ref> bypass the socket buffer to avoid extra memory copying. However, this often freezes the application-level buffer even a
celTCP manages the complexity in two respects. First, it exploits modern smart NICs equipped with tens of processing cores and a large memory, which allows flexible packet processing with C and/or P4 [33]</ref>. Second, it limits the complexity by resorting to a stateless protocol or by cooperating with the host stack. As a result, the entire code for the NIC stack i ref type="bibr" target="#b12">14,</ref>25]</ref> are gaining popularity as they support flexible packet processing at high speed with programming languages like C or P4 [33]</ref>. Re- cent smart NICs are flexible enough to run Open vSwitch [62]</ref>, Berkeley packet filter 
alyze the overhead of the TCP stack operations in these workloads.</p><p>To avoid the inefficiency of the kernel stack [38,</ref>39,</ref>60]</ref>, we use mTCP [41]</ref>, a scalable user-level TCP stack on DPDK [10]</ref>, as our baseline stack
</ref>64,</ref>66]</ref>. L7 proxying is also widely used in middlebox applications such as L7 LBs [6,</ref>36]</ref> and application-level gateways [2,</ref>19]</ref>. Unfortunately, application-level performance of ccelTCP by properly placing them at ingress/egress pipelines of the NIC dataplane.</p><p>L7 proxing and short RPCs: Our connection splicing is inspired by the packet tunneling mechanism of Yoda L7 LB [36]</ref>. However, Yoda operates as a packet-level translator without a TCP stack, so it cannot modify any of relayed content. In contrast, an AccelTCP application can
issions. However, DVMT also requires explicit application changes.</p><p>Sub-blocked TLBs [56]</ref>, CoLT [46]</ref>, and Clustered TLBs [45]</ref> combine near virtual-to-physical page translations into single TLB entries. These approaches rely on the default operating system memory allocators assigning
. We have further shown that L1 TLB misses that still hit in the L2 TLB may cause non-trivial performance degradation.</p><p>Redundant Memory Mappings (RMM) [34]</ref>, [35]</ref> is the most closely related work to TPS. RMM leverages arbitrary ranges of contiguous virtual pages that map to contiguous physical frames to provide an alter
4GB of physical memory.</p><p>We thank Intel Corporation and Microsoft Corporation for their generous financial support of the HPS Research Group. Prior work [8]</ref>, [13]</ref>, [23]</ref>, [31]</ref>, [32]</ref>, <ref type="bibr" target="#b3 active area of research. Prior work has shown that excessive page walks may significantly degrade performance in applications suffering from limited TLB reach [8]</ref>, [13]</ref>, [23]</ref>, [31]</ref>, [32]</ref>, <ref type="bibr" target="#b3 >, [12]</ref>, [40]</ref> seek to reduce the number of page walks and improve TLB reach. Prior work has proposed hardware PTE prefetchers [13]</ref>, [33]</ref>, [52]</ref>. These approaches prefetch PTEs into the TLB before they are needed for
set, caching them in the TLB. TPS can work together with these approaches to improve translation latency.</p><p>Prior work in fine-grained memory protection [24]</ref>, [57]</ref>, [58]</ref> identify similarity and contiguity across many conventional base pages, similar to how TPS identifies contiguity in
em proposal that significantly improves on Transparent Huge Pages [16]</ref> by offering cleaner tradeoffs between memory consumption, performance, and latency. HawkEye [43]</ref> is another OS technique that further improves upon Ingens. HawkEye balances fairness in huge page allocation across multiple processes, performs asynchronous
together with these approaches to improve translation latency.</p><p>Prior work in fine-grained memory protection [24]</ref>, [57]</ref>, [58]</ref> identify similarity and contiguity across many conventional base pages, similar to how TPS identifies contiguity in order to tailor a page of appropriate size
ages). The 32-entry any page size TPS TLB should reasonably be able to meet similar timing constraints in similar processors. Alternative skewed-associative [44]</ref>, [53]</ref> TLB designs are possible.</p><p>In the newly added any-page size L1 TLB, we add a page mask field to each TLB entry, as shown in Figure <ref type="figure" tar
ize, and 1536 entries for the 4KB/2MB page sizes. To support TPS, we modify the L1 TLB to contain a 32 entry fully-associative (as in other commercial designs [2]</ref>, [47]</ref>) TPS TLB. The TPS TLB takes the place of the existing 32 entry and 4 entry larger page size L1 TLBs. The TPS TLB supports any page size. We still retain the 6
e (e.g., 8KB), or larger (e.g., &gt;8KB). If the page is larger, then the PTE must have yet another unused PFN bit (e.g., bit s 1 ), and this process can repeat (similar to RISC-V PMP NAPOT encodings [48]</ref>). This can be easily implemented in hardware with a priority encoder to identify the page size. When performing the page walk, hardware has a challenge: the p
oming less common: servers running big memory workloads often run with swapping disabled, preferring to keep entire working sets in memory to minimize latency [8]</ref>, [37]</ref>. Apple iOS also does not swap to secondary storage [4]</ref>. The continuing increase in physical memory capacity significantly
reducing the TLB miss rate. Synergistic TLBs [54]</ref> and shared last-level TLBs [10]</ref>, [12]</ref>, [40]</ref> seek to reduce the number of page walks and improve TLB reach. Prior work has proposed hardware PTE prefetchers [13]</ref>, <re
techniques proposed in Chiu et al., 2015 (CNN + Bidirectional LSTM) and Huang et al., 2015 (Bidirectional LSTM + CRF), respectively, using public word embedding, character features and word features [6,</ref>4]</ref>. We explore existing word embeddings that is distinct from the previous studies including (1) Glove 300 embedding of 42B, 840B word vec

s [9]</ref> : rule-based, machine-deep learning, and hybrid. The rule-based algorithm applies a set of rules in order to extract patterns, i.e., rule base for Malay NER [10]</ref>.</p><p>With the emergence of the machine and deep learning, various models were proposed for the task. The machine learning approach involves the usage of str
s [9]</ref> : rule-based, machine-deep learning, and hybrid. The rule-based algorithm applies a set of rules in order to extract patterns, i.e., rule base for Malay NER [10]</ref>.</p><p>With the emergence of the machine and deep learning, various models were proposed for the task. The machine learning approach involves the usage of str
s [9]</ref> : rule-based, machine-deep learning, and hybrid. The rule-based algorithm applies a set of rules in order to extract patterns, i.e., rule base for Malay NER [10]</ref>.</p><p>With the emergence of the machine and deep learning, various models were proposed for the task. The machine learning approach involves the usage of str



, NER models were based on handcrafted rules, ontologies, lexicon, and orthographic. Subsequently, new approaches like feature-engineering and statistical models like machine learning were introduced [2]</ref>. Later, neural networks became the standard base for the existing state of the art model, starting with Collobert et al., 2011 [3]</ref>. <ref
s, including NER [13,</ref>14]</ref>. Third, a hybrid NER implements both the rule-based machine and deep learning, for instance, Bio-Ner [15]</ref> that was experimented with a rule-based and classification model.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>III. WORD AND CHARACTER FEATURES</h
s [9]</ref> : rule-based, machine-deep learning, and hybrid. The rule-based algorithm applies a set of rules in order to extract patterns, i.e., rule base for Malay NER [10]</ref>.</p><p>With the emergence of the machine and deep learning, various models were proposed for the task. The machine learning approach involves the usage of str
h scenarios, it is exceptionally challenging to probe the model's mechanism without the support of background knowledge [1]</ref>. Although Neural Attention Models (NAM) [2]</ref> are endowed with a certain degree of interpretability in visualizing parts of the sentence which are focused on answering the question, they cannot provide furt results (e.g., identifying emerging sub-events in natural disasters [8]</ref>), (c) discover inherent bias in the model's predictive strategy (e.g., contextual modeling [2]</ref>[9]), (d) prevent prediction errors in unintuitive scenarios (e.g. adversarial examples [10]</ref>, CHECKLIST <ref type="bibr" targ nd unlabeled corpus for transfer learning) [11]</ref>. Also, knowledge-infusion during the model learning using information-theoretic loss function (e.g., KL divergence [2]</ref>) can check conceptual drifting at the representational level through weak-supervision from KG. Alternatively, the loss of information during learning can be sup escriptive performance of generating explanations and interpretations.</p><p>Infusing domain knowledge in DL models can be categorized into the shallow infusion, semi-deep infusion, and deep infusion [2]</ref>. In shallow infusion, both the external information and method of knowledge infusion is shallow, i.e., Word2Vec or GloVE embeddings are reconstructed using doma orms an inherent structure, that raises challenges in natural language understanding: (1) Anaphora-where sentences are purposefully paraphrased to elicit meaningful responses from an agent (or user); (2)</ref> The clinical conversation contains implicit references to healthcare conditions, developing sparsity in the clinically-relevant concepts. Such a problem scenari
of external contextual information required to understand online conversations, mainly when the problem is a low resource (insufficient benchmark datasets and unlabeled corpus for transfer learning) [11]</ref>. Also, knowledge-infusion during the model learning using information-theoretic loss function (e.g., KL divergence [2]</ref>) ca
among them. More often than not, explanations would be in natural language explaining the decision, while interpretations can be statistical or conceptual (using either generic or domain-specific KG [12]</ref>, [9]</ref>) in nature pertaining to its inner functioning."</p><p>Explanations can be thought of as answers to cascading "why qu
formance prediction can be thought of as (a) Academic knowledge graph, set of concepts, it's metadata and relations between concepts that plays an important role in tracing student's concepts mastery [17]</ref> [16]</ref>, and (b) Engagement and learning patterns from historical student's data [13]</ref>. tudents' behavior is an equally important part of tracing learning outcomes [18]</ref>. Assessments or diagnostic tests are also created using such behavioral profiling [17]</ref>. Student's tendency to answer a question without comprehending or thinking through can lead to "Careless Mistakes", which could be the result of guessing the

erent bias in the model's predictive strategy (e.g., contextual modeling [2]</ref>[9]), (d) prevent prediction errors in unintuitive scenarios (e.g. adversarial examples [10]</ref>, CHECKLIST [4]</ref>), (e) make sure minor perturbations in inputs are handled in robust ways, (f) After enhancement of training experts and trust among end-users. The terms explainability and interpretability are often used interchangeably in the prior research without clear distinctions and the different roles that they play [10]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DEFINING EXPLAINABILITY AND INTERPRETABILITY WITH KNOWLEDGE-INFUSION</head><p>Making explanation

rlier findings), and metainformation such as time and space/location may be critical in understanding, interpreting, and explaining results (e.g., identifying emerging sub-events in natural disasters [8]</ref>), (c) discover inherent bias in the model's predictive strategy (e.g., contextual modeling [2]</ref>[9]), (d) prevent prediction e
d from a pre-trained seq2seq model: Yes (the correct answer is no).</p><p>In such scenarios, it is exceptionally challenging to probe the model's mechanism without the support of background knowledge [1]</ref>. Although Neural Attention Models (NAM) [2]</ref> are endowed with a certain degree of interpretability in visualizing parts of th
weak concepts. Infusing academic knowledge graphs and a student's historical knowledge state makes it possible to trace academic weakness until the deepest pre-requisite concept impacts student score [19]</ref>. As shown in Figure 4</ref>, the student has got an attempt wrong on a question of concept "Projectile Motion", using a kno
ons would be in natural language explaining the decision, while interpretations can be statistical or conceptual (using either generic or domain-specific KG [12]</ref>, [9]</ref>) in nature pertaining to its inner functioning."</p><p>Explanations can be thought of as answers to cascading "why questions" in the context of model prediction
to positive examples from the same class and far from negative examples from other classes (Weinberger &amp; Saul, 2009)</ref>. In this paradigm, selecting the hardest (Bucher et al., 2016)</ref> or harder (Schroff et al., 2015)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discuss
ttp://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>negatives has improved both the rate of learning and final performance. Similar to our findings about MoCo,Wu et al. (2017)</ref> find that mining the very hardest negatives hurts performance (purportedly because it increases the variance of the gradients) and suggest mining
ples from other classes (Weinberger &amp; Saul, 2009)</ref>. In this paradigm, selecting the hardest (Bucher et al., 2016)</ref> or harder (Schroff et al., 2015)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Contrastive instance discrimination relies critically o
is common to favor examples on which the model is most uncertain (Fu et al., 2013)</ref>. Work in object detection has also benefited from efforts to find hard examples (Sung, 1996;</ref>Canévet &amp; Fleuret, 2015;</ref>Shrivastava et al., 2016)</ref>. However, none of the aforementioned
type="bibr" target="#b22">(Noroozi &amp; Favaro, 2016)</ref>, DeepCluster (Caron et al., 2018)</ref>, SwAV (Caron et al., 2020)</ref>, SeLa (Asano et al., 2020)</ref>, PCL (Li et al., 2020)</ref>, and BYOL (Grill et al., 2020)</ref>. Since these do


ples from other classes (Weinberger &amp; Saul, 2009)</ref>. In this paradigm, selecting the hardest (Bucher et al., 2016)</ref> or harder (Schroff et al., 2015)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Contrastive instance discrimination relies critically o
et al., 2013)</ref>. Work in object detection has also benefited from efforts to find hard examples (Sung, 1996;</ref>Canévet &amp; Fleuret, 2015;</ref>Shrivastava et al., 2016)</ref>. However, none of the aforementioned work explicitly involves negative examples as in CID.</p><p>Closest to CID is work on metric learnin
type="bibr" target="#b22">(Noroozi &amp; Favaro, 2016)</ref>, DeepCluster (Caron et al., 2018)</ref>, SwAV (Caron et al., 2020)</ref>, SeLa (Asano et al., 2020)</ref>, PCL (Li et al., 2020)</ref>, and BYOL (Grill et al., 2020)</ref>. Since these do

type="bibr" target="#b22">(Noroozi &amp; Favaro, 2016)</ref>, DeepCluster (Caron et al., 2018)</ref>, SwAV (Caron et al., 2020)</ref>, SeLa (Asano et al., 2020)</ref>, PCL (Li et al., 2020)</ref>, and BYOL (Grill et al., 2020)</ref>. Since these do
curring theme in the machine learning literature to focus training on the most difficult examples. In active learning, for example, it is common to favor examples on which the model is most uncertain (Fu et al., 2013)</ref>. Work in object detection has also benefited from efforts to find hard examples (Sung, 1996;</ref><ref type="bibr"

is common to favor examples on which the model is most uncertain (Fu et al., 2013)</ref>. Work in object detection has also benefited from efforts to find hard examples (Sung, 1996;</ref>Canévet &amp; Fleuret, 2015;</ref>Shrivastava et al., 2016)</ref>. However, none of the aforementioned


the early stages of training while harder negatives are more useful later. While developing a negative curriculum is beyond the scope of this work, curricula have shown utility in many other contexts (Bengio et al., 2009)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="
ples from other classes (Weinberger &amp; Saul, 2009)</ref>. In this paradigm, selecting the hardest (Bucher et al., 2016)</ref> or harder (Schroff et al., 2015)</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Contrastive instance discrimination relies critically o
on-instance-discrimination self-supervised learning methods. Beyond CID, a number of other approaches for self-supervised have been proposed that do not work within the CID paradigm, including RotNet (Gidaris et al., 2018)</ref>, Jigsaw (Noroozi &amp; Favaro, 2016)</ref>, DeepCluster (Caron et al., 2018)</r


PHT has been used on z branch predictions since the z196 [15]</ref> as a single table, but starting with z15 it exploits a variation of the TAGE algorithm based off of [8]</ref>. Two TAGE PHT tables are employed in z15-a short and a long table -each 512 rows deep per BTB1 way for a total branch capacity of 8K. Both tables coincidentally se than the alternate.</p><p>In general, if a TAGE PHT table hits, it can provide the prediction. However, a weak TAGE PHT prediction can sometimes be detrimental, particularly after a context switch [8]</ref>. As such, weak filtering is employed. Before allowing a weak TAGE PHT to provide the prediction direction, a weak prediction counter is checked. If the count is
. Starting on z14, a neural-network based perceptron branch direction prediction was introduced to help augment the patternbased auxiliary direction prediction [9]</ref> [18]</ref>. The z15 perceptron carries this design forward.</p><p>As described in [9]</ref> and in patents [
e path history, it struggles with others. Starting on z14, a neural-network based perceptron branch direction prediction was introduced to help augment the patternbased auxiliary direction prediction [9]</ref> [18]</ref>. The z15 perceptron carries this design forward.</p><p>As described in [9]</ref> and in he patternbased auxiliary direction prediction [9]</ref> [18]</ref>. The z15 perceptron carries this design forward.</p><p>As described in [9]</ref> and in patents [13]</ref>[14], the perceptron improves direction accuracy for branches that are not otherwise predictable with su stic to try to identify branches that behave like calls and returns. The mechanism operates in two similar components -detection and prediction. The z14 introduced a basic call/return stack predictor [9]</ref>, which was further enhanced on z15.</p><p>A mechanism at the back-end of the processor pipeline is used to try to detect pairs of branches behaving like calls a



d with taken branches), and how many bytes within the current search stream have been searched. This allows the IDU to know when branch prediction has fallen behind. Starting with the IBM z13 machine [17]</ref>, the branch predictor employs such strict synchronization. Previous mechanisms stalled dispatch when predictions might be coming but were not guaranteed to al
. Starting on z14, a neural-network based perceptron branch direction prediction was introduced to help augment the patternbased auxiliary direction prediction [9]</ref> [18]</ref>. The z15 perceptron carries this design forward.</p><p>As described in [9]</ref> and in patents [


d with taken branches), and how many bytes within the current search stream have been searched. This allows the IDU to know when branch prediction has fallen behind. Starting with the IBM z13 machine [17]</ref>, the branch predictor employs such strict synchronization. Previous mechanisms stalled dispatch when predictions might be coming but were not guaranteed to al
es at each position, as in Figure 1</ref>(b). LR-CNN uses CNN to encode potential words at different window sizes. However, RNN and CNN are hard to model long-distance dependencies (Vaswani et al., 2017)</ref>, which may be useful in NER, such as coreference (Stanislawek et al., 2019)</ref>. Due to the dynamic lattice o use LSTM as the bottom encoder to carry the sequential inductive bias, which makes the model complicated.</p><p>In this paper, we propose FLAT: Flat LAttice Transformer for Chinese NER. Transformer (Vaswani et al., 2017)</ref> adopts fully-connected selfattention to model the long-distance dependencies in a sequence. To keep the position information, Transformer in rmula_10">Rij = ReLU(Wr(p d (hh) ij ? p d (th) ij ? p d (ht) ij ? p d (tt) ij )), (8)</formula><p>where W r is a learnable parameter, ? denotes the concatenation operator, and p d is calculated as in Vaswani et al. (2017)</ref>,</p><formula xml:id="formula_11">p (2k) d = sin d/10000 2k/d model ,<label>(9)</label></formula><formula xml:id="formula_12">p (2k+1) d = cos

r (Mengge et al., 2019)</ref>. 'YJ' denotes the lexicon released by Zhang and Yang (2018)</ref>, and 'LS' denotes the lexicon released by Li et al. (2018)</ref>. The result of other models are from their original paper.</p><formula xml:id="formula_15">A * i,j = W q E x i Ex j W k,E + W q E x i RijW k,R + u nal information. We also compare FLAT with other lexicon-based methods. The embeddings and lexicons are the same as Zhang and Yang (2018)</ref>. When comparing with CGN (Li et al., 2018)</ref>, we use the same lexicon as CGN. The way to select hyper-parameters can be found in the supplementary material. In particular, we use only one la rforms TENER (Yan et al., 2019</ref>) by 1.72 in average F1 score. For lattice LSTM, our model has an average F1 improvement of 1.51 over it. When using another lexicon (Li et al., 2018)</ref>, our model also outperforms CGN by 0.73 in average F1 score. Maybe due to the characteristic of Transformer, the improvement of FLAT over other l
r (Mengge et al., 2019)</ref>. 'YJ' denotes the lexicon released by Zhang and Yang (2018)</ref>, and 'LS' denotes the lexicon released by Li et al. (2018)</ref>. The result of other models are from their original paper.</p><formula xml:id="formula_15">A * i,j = W q E x i Ex j W k,E + W q E x i RijW k,R + u nal information. We also compare FLAT with other lexicon-based methods. The embeddings and lexicons are the same as Zhang and Yang (2018)</ref>. When comparing with CGN (Li et al., 2018)</ref>, we use the same lexicon as CGN. The way to select hyper-parameters can be found in the supplementary material. In particular, we use only one la rforms TENER (Yan et al., 2019</ref>) by 1.72 in average F1 score. For lattice LSTM, our model has an average F1 improvement of 1.51 over it. When using another lexicon (Li et al., 2018)</ref>, our model also outperforms CGN by 0.73 in average F1 score. Maybe due to the characteristic of Transformer, the improvement of FLAT over other l
of nodes as the structure information. In speech translation, Sperber et al. (2019)</ref> used the longest distance to the start node to indicate lattice structure, and Zhang et al. (2019)</ref> used the shortest distance between two nodes. Our span position encoding is more natural, and can be mapped to all the three ways, but not vise
different window sizes. However, RNN and CNN are hard to model long-distance dependencies (Vaswani et al., 2017)</ref>, which may be useful in NER, such as coreference (Stanislawek et al., 2019)</ref>. Due to the dynamic lattice structure, these methods cannot fully utilize the parallel computation of GPU. (2) Another line is to conver
="1">Introduction</head><p>Named entity recognition (NER) plays an indispensable role in many downstream natural language processing (NLP) tasks (Chen et al., 2015;</ref>Diefenbach et al., 2018)</ref>. Compared with English NER (Lample et al., 2016;</ref>Yang et al., 2017;</ref>
ed in speech translation and Chinese-source translation. The main difference between them is the way to 1 https://github.com/fastnlp/fastNLP indicate lattice structure. In Chinese-source translation, Xiao et al. (2019)</ref> take the absolute position of nodes' first characters and the relation between each pair of nodes as the structure information. In speech transl
different window sizes. However, RNN and CNN are hard to model long-distance dependencies (Vaswani et al., 2017)</ref>, which may be useful in NER, such as coreference (Stanislawek et al., 2019)</ref>. Due to the dynamic lattice structure, these methods cannot fully utilize the parallel computation of GPU. (2) Another line is to conver
="1">Introduction</head><p>Named entity recognition (NER) plays an indispensable role in many downstream natural language processing (NLP) tasks (Chen et al., 2015;</ref>Diefenbach et al., 2018)</ref>. Compared with English NER (Lample et al., 2016;</ref>Yang et al., 2017;</ref>
</ref>. Compared with English NER (Lample et al., 2016;</ref>Yang et al., 2017;</ref>Liu et al., 2017;</ref>Sun et al., 2020)</ref>, Chinese NER is more difficult since it usually involves word segmentation.</p><p>Recently, the lattice structure has been proved to have a great
ibr" target="#b20">[21]</ref>36]</ref>. Despite their excellent performance, most of them ignore the interactions' timestamp values. While recent works such as TiSASRec [14]</ref> successfully incorporated time information, their usage of time was also limited to a single embedding scheme. Since the timestamp values are rife with inform t="#b28">29]</ref>. BERT4Rec [19]</ref> improved SASRec by adopting Transformer [22]</ref> and Cloze-task based training method. TiSASRec [14]</ref> enhanced SASRec by merging timestamp information into self-attention operations. Our work seeks to further expand this trend by suggesting a novel model archi >. However, the positional factors have been rather overlooked in these models for many reasons. First, they don't utilize timestamp values which hold important contextual information. While TiSASRec [14]</ref> successfully addressed this issue, they also used a simple embedding scheme for temporal values. This can possibly lead to an information bottleneck since the e the effectiveness of our method, we compare it with the state-of-the-art baselines: MARank [32]</ref>,</p><p>SASRec [10]</ref>, TiSASRec [14]</ref>, and BERT4Rec [19]</ref>. These models are evaluated based on the code provided by the authors. We implemented MEANTIME<ref typ ]</ref> and Amazon Game [16]</ref>. We follow the common data preprocessing procedure from [5,</ref>10,</ref>14,</ref>19]</ref>. We convert each dataset into an implicit dataset by treating each numerical rating or review as a presence of a user-i interactions by user ids and then sort them by timestamps to form a sequence for each user. Following the custom practice [5,</ref>10,</ref>14,</ref>19]</ref>, we discard users and items with less than five interactions to ensure the quality of the dataset.</p></div> <div xmlns user's item sequence, we hold out the last item for test, and the second last item for validation. We use the rest for training. We follow the common practice [10,</ref>14,</ref>19]</ref> of letting the model rank the ground truth item together with 100 randomly sampled negative items which haven't yet bee
cessfully employed self-attention mechanism, which was a huge success in NLP areas [1,</ref>2,</ref>22,</ref>29]</ref>. BERT4Rec [19]</ref> improved SASRec by adopting Transformer [22]</ref> and Cloze-task based trai
="#b20">[21,</ref>30,</ref>33]</ref> were proposed. Some works adopted graph neural network (GNN) to understand user's session as a graph [26]</ref>.</p><p>As for attention mechanisms, NARM [13]</ref> and STAMP [15]</ref> incorporated vanilla at
target="#b34">35]</ref> brought the success of RNN into item sequence understanding. To overcome the strong order constraint of RNN models, CNN-based methods [21,</ref>30,</ref>33]</ref> were proposed. Some works adopted graph neural network (GNN) to understand user's session as a graph <ref type="bibr" t
tp://www.tei-c.org/ns/1.0"><head n="2.2">Sequential Recommendation</head><p>Sequential recommendation aims to suggest relevant items based on the user's sequential history. Markov-chain based methods [4]</ref>[5]</ref>[6]</ref>[7]</ref> assume that users' behaviors are affected o
f type="bibr" target="#b9">10,</ref>[18]</ref>[19]</ref>[20]</ref>[21]</ref>36]</ref>. Despite their excellent performance, most of them ignore the interactions' timestamp values. While recent works such as TiSASRec <ref type="bibr" target="#b13
[8,</ref>17,</ref>23,</ref>24,</ref>31,</ref>34,</ref>35]</ref> brought the success of RNN into item sequence understanding. To overcome the strong order constraint of RNN models, CNN
f type="bibr" target="#b9">10,</ref>[18]</ref>[19]</ref>[20]</ref>[21]</ref>36]</ref>. Despite their excellent performance, most of them ignore the interactions' timestamp values. While recent works such as TiSASRec <ref type="bibr" target="#b13
ww.tei-c.org/ns/1.0"><head n="2.1">Temporal Recommendation</head><p>Since temporal information hold contextual information, they can be very crucial for recommendation performance. TimeSVD++ and BPTF [12,</ref>27]</ref> adopted time factor into the matrix factorization method, and TimeSVD++ was one of the main contributions for the winn
type="bibr" target="#b9">[10]</ref> successfully employed self-attention mechanism, which was a huge success in NLP areas [1,</ref>2,</ref>22,</ref>29]</ref>. BERT4Rec [19]</ref> improved SASRec by adopting Transformer <ref type="bibr" target="#b bibr" target="#b1">2,</ref>22,</ref>29]</ref>. BERT4Rec [19]</ref> improved SASRec by adopting Transformer [22]</ref> and Cloze-task based training method. TiSASRec [14]</ref> enhanced SASRec by merging timestamp information into self-attention ns/1.0"><head n="3.3">Self-Attention Structure</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Attention</head><p>Architecture. Multi-head self-attention proposed in Transformer [22]</ref> shows excellent performance in recommendation tasks [19]</ref>. MEANTIME is also based on this structure. Traditionally, self-a 4h ,W 2 ∈ R 4h×h and b 2 ∈ R h are learnable parameters.</formula><p>Then we stack L such layers. As in previous works [10,</ref>19,</ref>22]</ref>, we apply a residual connection for each sublayer to facilitate training:</p><formula xml:id="formula_8">y = x + Dropout(Attention(LayerNorm(x))) z = y + Dropo ormula xml:id="formula_8">y = x + Dropout(Attention(LayerNorm(x))) z = y + Dropout(FFN(LayerNorm(y)))<label>(4)</label></formula><p>Note that while some works [19,</ref>22]</ref> apply LayerNorm at the very end, we empirically chose to apply LayerNorm in the front. This is also in accordance with the recent report on the order of layer
.tei-c.org/ns/1.0"><head n="4.2">Baselines Models &amp; Implementation Details</head><p>In order to validate the effectiveness of our method, we compare it with the state-of-the-art baselines: MARank [32]</ref>,</p><p>SASRec [10]</ref>, TiSASRec [14]</ref>, and BERT4Rec [19]</
Bernoulli Multiarmed Bandit (BMAB) B(A, f ,T ) between the neighbor selector and the GNN with the similarity measure. A is the action space, f is the reward function, and T is the terminal condition [36]</ref>. Given an initial p (l ) r , the neighbor selector choose to increase or decrease p (l ) r as actions and the reward is dependent on the average distance diff
n connects entities with the same IP address). There are two types of camouflages as follows: 1) Feature camouflage: smart fraudsters may adjust their behaviors [8,</ref>10]</ref>, add special characters in reviews [19,</ref>41]</ref> (so-called spamouflage), or employ deep lan where there are more dissimilar neighbors, it will eliminate the suspiciousness of the center fraudster.</p><p>Considering the agility of real-world fraudsters [8,</ref>10]</ref>, designing GNN-based detectors that exactly capture these camouflaged fraudsters is impractical. Therefore, based on the outcomes of two camouflages and the agg ://www.tei-c.org/ns/1.0"><head n="3.2">Label-aware Similarity Measure</head><p>Previous studies have introduced various fraudster camouflage types from behavior [8,</ref>10]</ref> and semantic [15,</ref>41]</ref> perspectives. Those camouflages could make the features of frauds
t="#b16">[17]</ref>, GAT [34]</ref>, and GraphSAGE [12]</ref>), many GNN-based fraud detectors have been proposed to detect opinion fraud [19,</ref>25,</ref>39]</ref>, financial fraud [23,</ref><ref type="bibr" tar flages as follows: 1) Feature camouflage: smart fraudsters may adjust their behaviors [8,</ref>10]</ref>, add special characters in reviews [19,</ref>41]</ref> (so-called spamouflage), or employ deep language generation models [15]</ref> to gloss 2. Fraud Detection on Graph. For the fraud detection problem, the node v represents the target entity whose suspiciousness needs to be justified. For example, it can be a review on the review website [19,</ref>29]</ref> or a transaction in the trading system [23,</ref>37]</re target="#b7">[8,</ref>15,</ref>16,</ref>49]</ref> and practitioners [2,</ref>19,</ref>41]</ref>. Meanwhile, theoretical studies prove the limitations and vulnerabilities of GNNs when graphs have noisy nodes and edge ing parameters for different homo-graphs, and ASA directly sums information from each homo-graph. Player2Vec leverages GCN &amp; GAT to encode the intra-&amp; inter-relation neighbor information. GAS [19]</ref> learns unique aggregators for different node types and updates the embeddings of each node types iteratively.</p><p>In this paper, CARE-GNN constructs multipl
of CARE-GNN are optimized during training GNN which retains the end-to-end learning fashion.</p><p>GNN sampling methods [5,</ref>46,</ref>51]</ref> also filter the neighbors. While these works only consider selecting representative nodes to accelerate GNN training. For our work, taking account of domain kn
d fraud detectors have been proposed to detect opinion fraud [19,</ref>25,</ref>39]</ref>, financial fraud [23,</ref>24,</ref>37]</ref>, mobile fraud [41]</ref>, and cyber criminal <r s needs to be justified. For example, it can be a review on the review website [19,</ref>29]</ref> or a transaction in the trading system [23,</ref>37]</ref>. The node has a label y v ∈ {0, 1} ∈ Y where 0 represents benign and 1 represents suspicious. The relations R are rule Neighbor Aggregator</head><p>After filtering neighbors under each relation, the next step is to aggregate the neighbor information from different relations. Previous methods adopt attention mechanism [23,</ref>37,</ref>48]</ref> or devise weighting parameters [24]</ref> to le ref type="bibr" target="#b33">[34]</ref>, RGCN [31]</ref>, and GraphSAGE [12]</ref> to represent general GNN models. We choose Ge-niePath [23]</ref>, Player2Vec [48]</ref>, SemiGNN [37]</ref>, and GraphConsis [25]< ="#b38">[39]</ref> and GraphConsis [25]</ref> construct a single homo-graph based on multiple relations and employ GNNs to aggregate neighborhood information. GeniePath [23]</ref> learns convolutional layers and neighbor weights using LSTM and the attention mechanism [34]</ref>. GEM <ref type="bibr" target
eader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>As Internet services thrive, they also incubate various kinds of fraudulent activities [14]</ref>. Fraudsters disguise as regular users to bypass the anti-fraud system and disperse disinformation [44]</ref> or reap end-users'
ters, we compare it with various GNN baselines under the semi-supervised learning setting. We select GCN [17]</ref>, GAT [34]</ref>, RGCN [31]</ref>, and GraphSAGE [12]</ref> to represent general GNN models. We choose Ge-niePath [23]</ref>, Play
get="#b18">[19,</ref>25,</ref>39]</ref>, financial fraud [23,</ref>24,</ref>37]</ref>, mobile fraud [41]</ref>, and cyber criminal [48]</ref>. In contrast to traditional graph-based a can be a review on the review website [19,</ref>29]</ref> or a transaction in the trading system [23,</ref>37]</ref>. The node has a label y v ∈ {0, 1} ∈ Y where 0 represents benign and 1 represents suspicious. The relations R are rules, interactions, or shared attributes bet ing neighbors under each relation, the next step is to aggregate the neighbor information from different relations. Previous methods adopt attention mechanism [23,</ref>37,</ref>48]</ref> or devise weighting parameters [24]</ref> to learn the relation weights during aggregati ref type="bibr" target="#b11">[12]</ref> to represent general GNN models. We choose Ge-niePath [23]</ref>, Player2Vec [48]</ref>, SemiGNN [37]</ref>, and GraphConsis [25]</ref> as four state-of-the-art GNN-based fraud detectors. Their detailed introduction can be found in Sec 2">[23]</ref> learns convolutional layers and neighbor weights using LSTM and the attention mechanism [34]</ref>. GEM [24]</ref>, SemiGNN [37]</ref>, ASA [41]</ref>, and Player2Vec [48]</ref> all construct multiple homo-graphs based on node rela
ters, we compare it with various GNN baselines under the semi-supervised learning setting. We select GCN [17]</ref>, GAT [34]</ref>, RGCN [31]</ref>, and GraphSAGE [12]</ref> to represent general GNN models. We choose Ge-niePath [23]</ref>, Play
ef type="bibr" target="#b18">19,</ref>41]</ref>. Meanwhile, theoretical studies prove the limitations and vulnerabilities of GNNs when graphs have noisy nodes and edges [3,</ref>4,</ref>13,</ref>33]</ref>. Therefore, failing to tackle the camoufla
[12]</ref>), many GNN-based fraud detectors have been proposed to detect opinion fraud [19,</ref>25,</ref>39]</ref>, financial fraud [23,</ref>24,</ref>37]</ref>, mobile fraud <ref t d alleviate the negative effect of camouflaged fraudsters. GNN-based Fraud Detection. Many GNN-based fraud detectors transfer the heterogeneous data into homogeneous data before applying GNNs. Fdgars [39]</ref> and GraphConsis [25]</ref> construct a single homo-graph based on multiple relations and employ GNNs to aggregate neighborhood
ion of our proposed method METANAS and related work. Gray highlights task learning, blue metalearning, and orange NAS components. Top: gradientbased meta-learning with fixed architecture such as MAML [16]</ref> or REPTILE [37]</ref>. Middle: applying NAS to metalearning such as AutoMeta [25]</ref>. Bottom: fig_0">1</ref>, bottom, and in Figure 3</ref>. The key contributions of this work are as follows:</p><p>1. We show that model-agnostic, gradient-based metalearning methods (such as [16]</ref>) can very naturally be combined with recently proposed gradient-based NAS methods, such as DARTS [33]</ref>. This allows for jo raining w. We address this shortcoming in Section 4.</p><p>In our work, we choose DARTS for neural architecture search because of conceptual similarities to gradient-based meta-learning, such as MAML [16]</ref>, which will allow us to combine the two kinds of methods.</p><p>Neural Architecture Search for Meta-Learning There has been some recent work on combining NAS minimiz-  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Gradient-based Meta-Learning of Neural Architectures</head><p>Similar to MAML's meta-learning strategy in the weight space [16]</ref>, our goal is to meta-learn an architecture with corresponding weights which is able to quickly adapt to new tasks. In accordance with MAML we do so by minimiz </ref>) is differentiable with respect to w and ?. This means we can use any gradient-based meta-learning algorithm ? not only for w but also for the architecture ?. As an example, one could use MAML [16]</ref> as a meta-learning algorithm, which runs SGD on the meta-objective, yielding meta-updates</p><formula xml:id="formula_4">w i+1 meta ? i+1 meta = ? M AM L (? i tion set, as this is also not used in our work.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>MiniImagenet</head><p>Omniglot Method # params 1-shot, 5-way 5-shot, 5-way 1-shot, 20 way MAML [16]</ref> 30k 48. which might be of independent interest. Empirical results on standard few-shot learning benchmarks show the superiority with respect to simple CNNs mo tion of our proposed method METANAS and related work. Gray highlights task learning, blue metalearning, and orange NAS components. Top: gradientbased meta-learning with fixed architecture such as MAML[16]</ref> or REPTILE[37]</ref>. Middle: applying NAS to metalearning such as AutoMeta[25]</ref>. Bottom: P 1]</ref>. Here, we consider the problem of few-shot learning, i.e., learning new tasks from just a few examples. Prior work has proposed meta-learning methods for this problem that are model-agnostic [16,</ref>37]</ref> and allow meta-learning weights of fixed neural architectures (see Figure 1,</ref>to sk learning [58,</ref>19]</ref>.</p><p>In this work, we focus on a particular class of approaches denoted as model-agnostic meta-learning [16,</ref>17,</ref>37,</ref>1,</ref>18]</ref>. L Ti the corresponding task loss, and ? k (w, ?, D Ti train ) the task learning algorithm or simply task-learner, where k refers to k iterations of learning/ weight updates (e.g., by SGD). Prior work [16,</ref>37,</ref>25]</ref> considered a fixed, predefined architecture ? fixed and chose ? k to be an opt p><p>14:</p><p>? meta ? ? meta + ? meta Ti (a * Ti -? i meta ) 15: end while 16: return w meta , ? meta 3. This is in contrast to prior work where the architecture is always fixed during meta-testing [16,</ref>37]</ref>. Also prior work using NAS for meta-learning [25]</ref> searches for a single architect h deep learning as neural networks tend to be highly over-parameterized and therefore prone to overfitting when only very little data is available. Prior work [40,</ref>16,</ref>18,</ref>19]</ref> often approaches few-shot learning via meta-learning or learning to learn <ref A.2 for details. Note that naively enlarging models for fewshot learning without regularization does not improve performance due to overfitting as reported by [40,</ref>16]</ref>.</p><p>Results are presented in Table 2</ref>. Again, METANAS improves over the standard REPTILE architecture and Au-toMeta.
previously seen ones [48,</ref>52]</ref> or meta-learning a subset of weights that is shared across tasks but fixed during task learning [58,</ref>19]</ref>.</p><p>In this work, we focus on a particular class of approaches denoted as model-agnostic meta-learning <ref type="b
ures from scratch. Therefore, most recent work focuses on developing more efficient methods, e.g., via network morphisms [12,</ref>6,</ref>13,</ref>47]</ref>, weight sharing [45,</ref>5,</ref><ref type="bibr" target=
hose with the highest operation weighting factor ?i,j o ) for each intermediate node j while all others are pruned. This hard-pruning deteriorates performance [54,</ref>55]</ref>: e.g., Xie et al. [54]</ref> report a performance drop from 88% (one-shot model's accuracy) to 56% (pruned model's accuracy). Th is common practice in the NAS literature [60,</ref>33,</ref>54,</ref>7,</ref>55]</ref>). Both cells are com-posed of three intermediate nodes (i.e., hidden states). The set of candidate operations is MaxPool3x3, AvgPool3x3, SkipConnect, Conv1x5-5
>[16]</ref>, which will allow us to combine the two kinds of methods.</p><p>Neural Architecture Search for Meta-Learning There has been some recent work on combining NAS and metalearning. Wong et al. [53]</ref> train an automated machine learning (AutoML [23]</ref>) system via reinforcement learning on multiple tasks and then use transf
problem is challenging in combination with deep learning as neural networks tend to be highly over-parameterized and therefore prone to overfitting when only very little data is available. Prior work [40,</ref>16,</ref>18,</ref>19]</ref> often approaches few-shot learning via "#b6">7]</ref>. Please refer to Appendix A.2 for details. Note that naively enlarging models for fewshot learning without regularization does not improve performance due to overfitting as reported by [40,</ref>16]</ref>.</p><p>Results are presented in Table 2</ref>. Again, METANAS improves over the stan ad n="5.">Experiments</head><p>We evaluate our proposed method on the standard fewshot image recognition benchmarks Omniglot [26]</ref> and MiniImagenet (as proposed by [40]</ref>) in the n-way, k-shot setting (as proposed by [52]</ref>), meaning that a few-shot learning task is generated by random samplin
4">[45,</ref>5,</ref>4]</ref>, or multifidelity optimization [3,</ref>15,</ref>29,</ref>56]</ref>; however, they are often still restricted to relatively small problems.</p><p>To overcome this problem, Liu et al. <ref
problem is challenging in combination with deep learning as neural networks tend to be highly over-parameterized and therefore prone to overfitting when only very little data is available. Prior work [40,</ref>16,</ref>18,</ref>19]</ref> often approaches few-shot learning via "#b6">7]</ref>. Please refer to Appendix A.2 for details. Note that naively enlarging models for fewshot learning without regularization does not improve performance due to overfitting as reported by [40,</ref>16]</ref>.</p><p>Results are presented in Table 2</ref>. Again, METANAS improves over the stan ad n="5.">Experiments</head><p>We evaluate our proposed method on the standard fewshot image recognition benchmarks Omniglot [26]</ref> and MiniImagenet (as proposed by [40]</ref>) in the n-way, k-shot setting (as proposed by [52]</ref>), meaning that a few-shot learning task is generated by random samplin
, via network morphisms [12,</ref>6,</ref>13,</ref>47]</ref>, weight sharing [45,</ref>5,</ref>4]</ref>, or multifidelity optimization [3,</ref><ref type="b
previously seen ones [48,</ref>52]</ref> or meta-learning a subset of weights that is shared across tasks but fixed during task learning [58,</ref>19]</ref>.</p><p>In this work, we focus on a particular class of approaches denoted as model-agnostic meta-learning <ref type="b
model-agnostic, gradient-based metalearning methods (such as [16]</ref>) can very naturally be combined with recently proposed gradient-based NAS methods, such as DARTS [33]</ref>. This allows for joint meta-learning of not only the weights (for a given, fixed architecture) but also meta-learning the architecture itself (Section 3, see ying a continuous relaxation of the architecture search space. Already in combination with the simple meta-learning algorithm REPTILE [37]</ref> and NAS algorithm DARTS [33]</ref>, METANAS yields state-of-the-art results on the standard few-shot classification benchmarks Omniglot and MiniImagenet. This paper is structured as follows: in ref>29,</ref>56]</ref>; however, they are often still restricted to relatively small problems.</p><p>To overcome this problem, Liu et al. [33]</ref> proposed a continuous relaxation of the architecture search space that allows optimizing the architecture via gradient-based methods. This is achieved by usin ep updates w j+1 = ?(w j , D Ti train ) := w j -? task ? w L T (w j , D Ti train ) and w 0 = w. In contrast, we choose ? k to be k steps of gradient-based neural architecture search inspired by DARTS [33]</ref> with weight learning rate ? task and architecture learning rate ? task :</p><formula xml:id="formula_3">w j+1 ? j+1 = ?(w j , ? j , D Ti train ) = w j -? task ghts w * Ti but also optimizes task architecture ? * Ti . Note that we use the same data set to update w j and ? j (Equation 3</ref>) in contrast to Liu et al. [33]</ref> due to the limited amount of data in the few-shot setting not allowing to split into training and validation per task. Moreover, using the same data set also w i meta , ? i meta , p train , ? k )</formula><p>Algorithm 1 METANAS: Meta-Learning of Neural Architectures 1: Input: distribution over tasks p(T ), task-learner ? k (w, a, D Ti train ) # e.g. DARTS [33]</ref> meta-learner ? w , ? ? # e.g. REPTILE [37]</ref> 2: Initialize w meta , ? meta 3: while not converged do for all T i do 6:</p>< cture along with the weights and adapting it to task-dependent architectures based on few labeled datapoints and with only a few steps of gradient descent. We have also proposed an extension of DARTS [33]</ref> that reduces the performance drop incurred during hard-pruning, 1 We report results without label smoothing and without training on the validation set, as thi ication strategies and impact on pruning</head><p>We recap the three different sparsification strategies discussed in Section 4 and Figure 2:</ref> 1. vanilla DARTS [33]</ref>, i.e., no sparsification (neither operations nor inputs)</p><p>2. sparsifying the operations only (e.g., as in SNAS [54]</ref>) ated these three strategies on the default single-task classification setting on CIFAR-10. We ran the search phase of DARTS with default hyperparameters (i.e., hyperparameters identical to Liu et al. [33]</ref>) on CIFAR-10 and evaluated the drop in accuracy after the search phase when going from the one-shot model to the pruned model. The one-shot model is pruned as "#b32">[33]</ref>) on CIFAR-10 and evaluated the drop in accuracy after the search phase when going from the one-shot model to the pruned model. The one-shot model is pruned as proposed by Liu et al. [33]</ref>. The results can be found in Table 3</ref>. In the vanilla setting without any sparsification, the accuracy drops significan ns="http://www.tei-c.org/ns/1.0"><head>A.2. Detailed experimental setup and hyperparameters</head><p>Our implementation is based on the REPTILE [37]2</ref> and DARTS [33]</ref> 3</ref> code. The data loaders and data splits are adopted from Torchmeta [10]</ref> <ref type would results in selecting exactly one input rather than a predefined number of inputs (e.g., the literature default 2 [60,</ref>54,</ref>33]</ref>). Instead, we weight every combination of k inputs to allow an arbitrary number of inputs k:</p><p>x</p><formula xml:id="formula_12">(j) = i={i1,...,i k }?I ex we consider the following search space based on DARTS and AutoMeta: we search for a normal and reduction cell (which is common practice in the NAS literature [60,</ref>33,</ref>54,</ref>7,</ref>55]</ref>). Both cells are com-posed of three inter (weight decay and DropPath [60]</ref>), which is common practice in the NAS literature [60,</ref>41,</ref>33,</ref>54,</ref>7]</ref>. Please refer to Appendix A.2 for details. Note that naively enlarging models for
itectures to train the matching model (See Section 6 for a detailed summary), D trains the matching models by fine-tuning pre-trained LMs in a simpler architecture.</p><p>Pre-trained LMs such as BERT [13]</ref> and GPT-2 [41]</ref> have demonstrated good performance on a wide range of NLP tasks. They are typically deep neural networks w d network on the training set until it converges.</p><p>The result is a model fine-tuned for the EM task. See Appendix A for the model architecture. In D , we fine-tune the popular 12layer BERT model [13]</ref>, RoBERTa [29]</ref>, and a 6-layer smaller but faster variant DistilBERT [45]</ref>. However, ou target="#b35">[36]</ref> and the Transformers library [58]</ref>. We currently support 4 pre-trained models: Distil-BERT [45]</ref>, BERT [13]</ref>, RoBERTa [29]</ref>, and XLNet [61]</ref>. We use the base uncased variant of each model in all etection and schema matching with the ultimate goal of building a BERT-like model for tables.</p><p>Figure 6</ref> shows the model architecture of D 's language models such as BERT [13]</ref>, DistilBERT [45]</ref>, and RoBERTa [29]</ref>. D serializes the two input entries entries as on ="bibr" target="#b5">[6]</ref>, and the full D . Recall that we construct the baseline by taking the best performing pre-trained model among DistilBERT [45]</ref>, BERT [13]</ref>, XLNet [61]</ref>, and RoBERTa [29]</ref> following [6]</ref>. Alt
ugmenting training data with (difficult) examples. The first two techniques help D focus on the right information for making matching decisions. The last technique, data augmentation, is adapted from [31]</ref> for EM to help D learn "harder" to understand the data invariance properties that may exist but are beyond the provided labeled examples and also, reduce the and the remaining attributes may contain no useful signals to distinguish the two entries.</p><p>To address this issue, D applies MixDA, a recently proposed data augmentation technique for NLP tasks [31]</ref> illustrated in Figure 3</ref>. Instead of using the augmented example directly, MixDA computes a convex interpolation of th -level or attribute-level DA operators listed in Table 2</ref> with the entry_swap operator. We compare the different combinations and report the best one. Following [31]</ref>, we apply MixDA with the interpolation parameter λ sampled from a Beta distribution Beta(0.8, 0.8).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>• [31,</ref>57,</ref>59</ref>]. We designed a set of DA operators suitable for EM and apply them with MixDA [31]</ref>, a recently proposed DA strategy based on convex interpolation. To our knowledge, this is the first time data augmentation has been applied to EM.</p><p>Activ e divided into 3 categories. The first category consists of span-level operators, such as span_del and span_shuffle. These two operators are used in NLP tasks [57,</ref>31]</ref> and shown to be effective for text classification. For span_del, we randomly delete from s a span of tokens of length at most 4 without special tokens (e.g., [ y allowing users to specify and customize rules for preprocessing input entries. Data augmentation (DA) has been extensively studied in computer vision and has recently received more attention in NLP [31,</ref>57,</ref>59</ref>]. We designed a set of DA operators suitable for EM and apply them with MixDA <
13]</ref> and GPT-2 [41]</ref> have demonstrated good performance on a wide range of NLP tasks. They are typically deep neural networks with multiple Transformer layers [51]</ref>, typically 12 or 24 layers, pre-trained on large text corpora such as Wikipedia articles in an unsupervised manner. During pretraining, the model is self-trai
ing problem with rules [11,</ref>15,</ref>47,</ref>53]</ref>, crowdsourcing [18,</ref>22,</ref>52]</ref>, or machine learning [46,</ref><ref type="bibr" get="#b21">22,</ref>52]</ref>, or machine learning [46,</ref>10,</ref>4,</ref>18,</ref>25]</ref>.</p><p>Recently, EM solutions used deep learning and achieved promising results [14,</re
>53]</ref>, crowdsourcing [18,</ref>22,</ref>52]</ref>, or machine learning [46,</ref>10,</ref>4,</ref>18,</ref>25]</ref>.<
e. In D , we fine-tune the popular 12layer BERT model [13]</ref>, RoBERTa [29]</ref>, and a 6-layer smaller but faster variant DistilBERT [45]</ref>. However, our proposed techniques are independent of the choice of pre-trained LMs and D can potentially perform even better with larger pre-trained LMs. The <p>We implemented D in PyTorch [36]</ref> and the Transformers library [58]</ref>. We currently support 4 pre-trained models: Distil-BERT [45]</ref>, BERT [13]</ref>, RoBERTa [29]</ref>, and XLNet [61]</ref>. We us building a BERT-like model for tables.</p><p>Figure 6</ref> shows the model architecture of D 's language models such as BERT [13]</ref>, DistilBERT [45]</ref>, and RoBERTa [29]</ref>. D serializes the two input entries entries as one sequence and feeds it to the model as input. The mod he baseline D , the proposed method in [6]</ref>, and the full D . Recall that we construct the baseline by taking the best performing pre-trained model among DistilBERT [45]</ref>, BERT [13]</ref>, XLNet [61]</ref>, and RoBERTa [29]</ref> follow
provide further justification of this choice in Appendix F.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation and experimental setup</head><p>We implemented D in PyTorch [36]</ref> and the Transformers library [58]</ref>. We currently support 4 pre-trained models: Distil-BERT 
e. In D , we fine-tune the popular 12layer BERT model [13]</ref>, RoBERTa [29]</ref>, and a 6-layer smaller but faster variant DistilBERT [45]</ref>. However, our proposed techniques are independent of the choice of pre-trained LMs and D can potentially perform even better with larger pre-trained LMs. The <p>We implemented D in PyTorch [36]</ref> and the Transformers library [58]</ref>. We currently support 4 pre-trained models: Distil-BERT [45]</ref>, BERT [13]</ref>, RoBERTa [29]</ref>, and XLNet [61]</ref>. We us building a BERT-like model for tables.</p><p>Figure 6</ref> shows the model architecture of D 's language models such as BERT [13]</ref>, DistilBERT [45]</ref>, and RoBERTa [29]</ref>. D serializes the two input entries entries as one sequence and feeds it to the model as input. The mod he baseline D , the proposed method in [6]</ref>, and the full D . Recall that we construct the baseline by taking the best performing pre-trained model among DistilBERT [45]</ref>, BERT [13]</ref>, XLNet [61]</ref>, and RoBERTa [29]</ref> follow
M.</p><p>Active learning is a recent trend in EM to train high-quality matching models with limited labeling resources [19,</ref>23,</ref>30,</ref>40]</ref>. Under the active learning framework, the developer interactively labels a small set of examples to improve the model w with data augmentation in D , they are different solutions, which can be used together; active learning requires human interaction in each iteration, whereas data augmentation does not. According to [30]</ref>, one needs to adjust the model size and/or the training process such that the response time becomes acceptable for user interaction in active learning. Thus,
text corpora such as Wikipedia articles in an unsupervised manner. During pretraining, the model is self-trained to perform auxiliary tasks such as missing token and next-sentence prediction. Studies [9,</ref>50]</ref> have shown that the shallow layers capture lexical meaning while the deeper layers capture syntactic and semantic meanin
ree benchmark datasets: the Entity Resolution benchmark [26]</ref>, the Magellan dataset [25]</ref>, and the WDC product matching dataset [39]</ref> of various sizes and domains. Our experimental results show that D consistently outperforms the previous SOTA EM solutions in all datasets and by up to 31% in ults on benchmark datasets for EM: the ER Benchmark datasets [26]</ref>, the Magellan datasets [25]</ref> and the WDC product data corpus [39]</ref>. D achieves new SOTA results on all these datasets and outperforms the previous best results by up to 31% in F1 score. The results show that D is more robust b16">[17,</ref>23,</ref>34]</ref>. We list the size of each dataset in Table 5</ref>.</p><p>The WDC product data corpus [39]</ref> contains 26 million product offers and descriptions collected from e-commerce websites [56]</ref>. The goal is to find product pe="table">4</ref>: Different subsets of the WDC product data corpus. Each subset (except Test) is split into a training set and a validation set with a ratio of 4:1 according to the dataset provider [39]</ref> Each entry in this dataset has 4 attributes: title, description, brand, and specTable. Following the setting in [39]</ref> for atio of 4:1 according to the dataset provider [39]</ref> Each entry in this dataset has 4 attributes: title, description, brand, and specTable. Following the setting in [39]</ref> for Deep-Matcher, we allow D to use any subsets of attributes to determine the best combination. We found in our experiments that D achieves the best performa arget="#b4">[5]</ref> to train the word embeddings. When reporting DeepMatcher's F1 scores, we use the numbers in [34]</ref> for the ER-Magellan datasets and numbers in [39]</ref> for the WDC datasets. We also reproduced those results using the open-sourced implementation.</p><p>• DeepMatcher+: Follow-up work <ref type="bibr" target="#b get F1 scores closer to the full D .</p><p>DistilBERT  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F. EXPERIMENTS ON DIFFERENT WDC PRODUCT ATTRIBUTES</head><p>Following the settings in [39]</ref> for the evaluated models, we evaluate D on 4 different subsets of the product attributes as input so that D and DeepMatcher are evaluated under the same setti the entries in the full training set. We summarize the results in Table 14</ref>. Among all the tested combinations (the same as the ones tested for DeepMatcher in [39]</ref>), the combination consisting of only the title attribute works significantly better than the others. The difference ranges from 3.2% (computer, xlarge) to ove <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 13 :</head><label>13</label><figDesc>The 4 attributes of the WDC benchmarks used in training D and DM according to[39]</ref>.</figDesc><table><row><cell cols="2">Attributes Examples</cell><cell>%Available</cell></row><row><cell>Title</cell><cell>Corsair Vengeance Red LED 16GB 2x 8GB
text corpora such as Wikipedia articles in an unsupervised manner. During pretraining, the model is self-trained to perform auxiliary tasks such as missing token and next-sentence prediction. Studies [9,</ref>50]</ref> have shown that the shallow layers capture lexical meaning while the deeper layers capture syntactic and semantic meanin
/ref>8,</ref>16,</ref>35,</ref>54</ref>] and the matching problem with rules [11,</ref>15,</ref>47,</ref>53]</ref>, crowdsourcing <ref type="bibr" target
13]</ref> and GPT-2 [41]</ref> have demonstrated good performance on a wide range of NLP tasks. They are typically deep neural networks with multiple Transformer layers [51]</ref>, typically 12 or 24 layers, pre-trained on large text corpora such as Wikipedia articles in an unsupervised manner. During pretraining, the model is self-trai
as input to the LM and the output is a match or no-match decision. D 's architecture is much simpler when compared to many state-of-the-art EM solutions today [34,</ref>14]</ref>. Even though the bulk of the "work" is simply off-loaded to pre-trained LMs, we show that this simple scheme works surprisingly well in our experiments.</p></d s to adhere to the same schema. It also does not require that the attributes of data entries to be matched prior to executing the matcher, which is a sharp contrast to other EM systems such as DeepER [14]</ref> or DeepMatcher3</ref>  [34]</ref>. Furthermore, D can also ingest and match hierarchically st s (one GPU per run). Compared methods. We compare D with the SOTA EM solution DeepMatcher. We also consider other baseline methods including Magellan [25]</ref>, DeepER [14]</ref>, and follow-up works of Deep-Matcher [17,</ref>23]</ref>. We also compare with variants of D wit ref>, the Magellan system ( [25]</ref>, based on classical ML models) outperforms DeepMatcher in the Beer and iTunes-Amazon datasets. We also implemented and ran DeepER [14]</ref>, which is another RNN-based EM solution. We denote by DeepMatcher+ (or simply DM+) the best F1 scores among DeepMatcher and these works aforementioned. We sum "bibr" target="#b13">[14,</ref>17,</ref>23,</ref>34,</ref>64]</ref>. DeepER [14]</ref> trains EM models based on the LSTM [21]</ref> neural network architecture with word embeddings such as GloVe <ref type="bibr" t of how we obtain the DeepMatcher+ (DM+) baseline results. Recall from Section 4.2 that DM+ is obtained by taking the best performance (highest F1 scores) of multiple baseline methods including DeepER [14]</ref>, Magellan [25]</ref>, DeepMatcher [34]</ref>, and DeepMatcher's follow-up work <ref type="bibr" #b22">[23]</ref>.</p><p>We summarize these baseline results in Table 10</ref> on the ER-Magellan benchmarks and explain each method next. DeepER: The original paper [14]</ref> proposes a DL-based framework for EM. Similar to DeepMatcher, DeepER first aggregates both data entries into their vector representations and uses a feedforwa [38]</ref> embeddings per attribute or a RNN module over the serialized data entry. DeepER computes the similarity as the cosine similarity of the two vectors. Although [14]</ref> reported results on the Walmart-Amazon, Amazon-Google, DBLP-ACM, DBLP-Scholar, and the Fodors-Zagat datasets, the numbers are not directly comparable to the p in/valid/test splits according to [34]</ref>). In our experiments, we implemented DeepER with LSTM as the RNN module and GloVe for the tokens embeddings as described in [14]</ref> and with the same hyper-parameters (a learning rate of 0.01 and the Adam optimizer [24]</ref>). We then evaluate DeepER in our >4,</ref>18,</ref>25]</ref>.</p><p>Recently, EM solutions used deep learning and achieved promising results [14,</ref>17,</ref>23,</ref>34,</ref>64]</ref
lit into the training, validation, and test sets using the ratio of 3:1:1. The same split of the datasets is also used in the evaluation of other EM solutions [17,</ref>23,</ref>34]</ref>. We list the size of each dataset in Table 5</ref>.</p><p>The WDC product data corpus <ref type="bibr ble">4</ref>). Table 5</ref>: F1 scores on the ER-Magellan EM datasets. The numbers of DeepMatcher+ (DM+) are the highest available found in [17,</ref>23,</ref>34]</ref>     The use of a pre-trained LM contributes to a large portion of the performance gain. In the ER-Magellan datasets (ex ef type="bibr" target="#b24">25]</ref>.</p><p>Recently, EM solutions used deep learning and achieved promising results [14,</ref>17,</ref>23,</ref>34,</ref>64]</ref>. DeepER [14]</ref> trains EM models based on the data augmentation has been applied to EM.</p><p>Active learning is a recent trend in EM to train high-quality matching models with limited labeling resources [19,</ref>23,</ref>30,</ref>40]</ref>. Under the active learning framework, the developer interactively labels a smal ne methods including Magellan [25]</ref>, DeepER [14]</ref>, and follow-up works of Deep-Matcher [17,</ref>23]</ref>. We also compare with variants of D without the data augmentation (DA) and/or domain knowledge (DK) optimization to evaluate the effectiveness of each componen an datasets and numbers in [39]</ref> for the WDC datasets. We also reproduced those results using the open-sourced implementation.</p><p>• DeepMatcher+: Follow-up work [23]</ref> slightly outperforms Deep-Matcher in the DBLP-ACM dataset and [17]</ref> achieves better F1 in the Walmart-Amazon and Amazon-Go ">[14]</ref>, Magellan [25]</ref>, DeepMatcher [34]</ref>, and DeepMatcher's follow-up work [17]</ref> and [23]</ref>.</p><p>We summarize these baseline results in Table 10</ref> on the ER-Magellan benchmarks and explain each method next. De ll, but it is up to 5.2% in the Abt-Buy dataset. Others: We obtained the results for Magellan by taking the reported results from [34]</ref> and the two follow-up works [23,</ref>17]</ref>   . We also plot the score of DeepMatcher+ on the full datasets (denoted as DM+(full)) as reference. Recall that full
nd in EM to train high-quality matching models with limited labeling resources [19,</ref>23,</ref>30,</ref>40]</ref>. Under the active learning framework, the developer interactively labels a small set of examples to improve the model while the updated model is used to sample
blocking). </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK AND DISCUSSION</head><p>EM solutions have tackled the blocking problem [2,</ref>8,</ref>16,</ref>35,</ref>54</ref>] and the matching problem with rules <ref
arget="#b10">[11,</ref>15,</ref>47,</ref>53]</ref>, crowdsourcing [18,</ref>22,</ref>52]</ref>, or machine learning [46,</ref>10,</ref><ref type="bibr" t
text corpora such as Wikipedia articles in an unsupervised manner. During pretraining, the model is self-trained to perform auxiliary tasks such as missing token and next-sentence prediction. Studies [9,</ref>50]</ref> have shown that the shallow layers capture lexical meaning while the deeper layers capture syntactic and semantic meanin
text corpora such as Wikipedia articles in an unsupervised manner. During pretraining, the model is self-trained to perform auxiliary tasks such as missing token and next-sentence prediction. Studies [9,</ref>50]</ref> have shown that the shallow layers capture lexical meaning while the deeper layers capture syntactic and semantic meanin
entries is serialized (see next section) as input to the LM and the output is a match or no-match decision. D 's architecture is much simpler when compared to many state-of-the-art EM solutions today [34,</ref>14]</ref>. Even though the bulk of the "work" is simply off-loaded to pre-trained LMs, we show that this simple scheme works sur matched prior to executing the matcher, which is a sharp contrast to other EM systems such as DeepER [14]</ref> or DeepMatcher3</ref>  [34]</ref>. Furthermore, D can also ingest and match hierarchically structured data entries by serializing nested attribute-value pairs with special start and end tokens TA EM systems.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Benchmark datasets</head><p>We experimented with all the 13 publicly available datasets used for evaluating DeepMatcher [34]</ref>. These datasets are from the ER Benchmark datasets [26]</ref> and the Magellan data repository [ 25% (Company). The number of attributes ranges from 1 to 8. Among the datasets, the Abt-Buy and Company datasets are textheavy meaning that at least one attributes contain long text. Also, following [34]</ref>, we use the dirty version of the DBLP-ACM, DBLP-Scholar, iTunes-Amazon, and Walmart-Amazon datasets to measure the robustness of the models against noise. The (DK) optimization to evaluate the effectiveness of each component. We summarize these methods below. We report the average F1 of 5 repeated runs in all the settings.</p><p>• DeepMatcher: DeepMatcher [34]</ref> is the SOTA matching solution. Compared to D , DeepMatcher customizes the RNN architecture to aggregate the attribute values, then compares/aligns the aggrega d representations of the attributes. DeepMatcher leverages FastText [5]</ref> to train the word embeddings. When reporting DeepMatcher's F1 scores, we use the numbers in [34]</ref> for the ER-Magellan datasets and numbers in [39]</ref> for the WDC datasets. We also reproduced those results using the open-so 2">[23]</ref> slightly outperforms Deep-Matcher in the DBLP-ACM dataset and [17]</ref> achieves better F1 in the Walmart-Amazon and Amazon-Google datasets. According to [34]</ref>, the Magellan system ( [25]</ref>, based on classical ML models) outperforms DeepMatcher in the Beer and iTunes-Amazon datasets aking the best performance (highest F1 scores) of multiple baseline methods including DeepER [14]</ref>, Magellan [25]</ref>, DeepMatcher [34]</ref>, and DeepMatcher's follow-up work [17]</ref> and [23]</ref>.</p><p>We summarize these baseline r arable to the presented results of D because their evaluation and data preparation methods are different (e.g., they used k-fold cross-validation while we use the train/valid/test splits according to [34]</ref>). In our experiments, we implemented DeepER with LSTM as the RNN module and GloVe for the tokens embeddings as described in [14 the best results obtained by the simple aggregation and the RNN-based method. DeepMatcher (DM): We have summarized DM in Section 4.2. In addition to simply taking the numbers from the original paper [34]</ref>, we also ran their open-source version (DM (reproduced)) with the default settings (the Hybrid model with a batch size of 32 and 15 epochs). The reproduced re -source version (DM (reproduced)) with the default settings (the Hybrid model with a batch size of 32 and 15 epochs). The reproduced results are in general lower than the original reported numbers in [34]</ref> (the 3rd column) because we did not try the other model variants and hyperparameters as in the original experiments. The code failed in the Fodors-Zagat and t d by D . We found that the results do not significantly improved overall, but it is up to 5.2% in the Abt-Buy dataset. Others: We obtained the results for Magellan by taking the reported results from [34]</ref> and the two follow-up works [23,</ref>17]</ref>   . We also plot the score of DeepMatcher+ on th on set. Our evaluation method is more standard since it prevents overfitting the test set (See Chapter 4.6.5 of [33]</ref>) and is also used by DeepMatcher and Magellan [34]</ref>. It is not difficult to see that over the same set of model snapshots, the F1 score computed by the [6]</ref>'s evaluation metho est sets using the ratio of 3:1:1. The same split of the datasets is also used in the evaluation of other EM solutions [17,</ref>23,</ref>34]</ref>. We list the size of each dataset in Table 5</ref>.</p><p>The WDC product data corpus [39]</ref> contains 26 m </ref>: F1 scores on the ER-Magellan EM datasets. The numbers of DeepMatcher+ (DM+) are the highest available found in [17,</ref>23,</ref>34]</ref>     The use of a pre-trained LM contributes to a large portion of the performance gain. In the ER-Magellan datasets (excluding Company), the average improvemen /p><p>Recently, EM solutions used deep learning and achieved promising results [14,</ref>17,</ref>23,</ref>34,</ref>64]</ref>. DeepER [14]</ref> trains EM models based on the LSTM [21
]</ref>. FSVM is based on fuzzy theory to reduce the influence of noises or outliers on the classification hyperplane [61]</ref>[62]</ref>[63]</ref>[64]</ref>[65]</ref>[66]</ref>. Lin et al. <ref type="bibr" target
ref>[32]</ref>[33]</ref>, since these rules are derived from small-scale datasets, is that the rules are constantly updated. Matej et al. [34]</ref> presented a new tool data collection system for Windows PC. Different from previously distributed data collection systems, this system uses less resources bas
ref>[32]</ref>[33]</ref>, since these rules are derived from small-scale datasets, is that the rules are constantly updated. Matej et al. [34]</ref> presented a new tool data collection system for Windows PC. Different from previously distributed data collection systems, this system uses less resources bas
Wael et al. [51]</ref> presented a heterogeneous detector which consisted of sequence time-delay embedding, hidden Markov model [52]</ref>[53]</ref>[54]</ref> and a one-class support machine. In addition to satisfactory results, the heterogeneous detector also exhibits the re
ystem call databases of normal behavior by a sliding window with a single length or multiple lengths [9,</ref>10]</ref>. Aron Laszka et al. [11,</ref>12]</ref> investigated and claimed that the optimal n-gram is 6-gram in UNM dataset and 7-gram in ADFA-LD dataset. Suaad et al. ne in each class is calculated according to (10)</ref>. </p><p>The distance between the sample and its center of the hypersphere in each class is calculated according to (11)</ref>. </p><p>Therefore, membership functions of both positive and negative sample points are constructed according to (12)</ref> and
>[29]</ref>. A search engine is then applied to discover the hidden knowledge [30]</ref>. The drawback of a rule-based approach [31]</ref>[32]</ref>[33]</ref>, since these rules are derived from small-scale datasets, is that the rules are constantly updated. Matej et al. <ref
reduce the influence of noises or outliers on the classification hyperplane [61]</ref>[62]</ref>[63]</ref>[64]</ref>[65]</ref>[66]</ref>. Lin et al. [67]</ref> proposed a method base
at is suitable for classifying system call sequences.</p><p>Support vector machine [3]</ref>[4]</ref>[5]</ref>[6]</ref>, as a machine learning method based on statistical learning theory, derives from the idea of the dual form to solve the large dimensional problems, makes the cl ly.</p><p>If l new + and l new are the number of positive and negative samples in the new sample set, then the distance between the samples and the hyperplane in each class is calculated according to (6)</ref>.</p><formula xml:id="formula_5">{ ?(? ? + ) = |? ? (? -? + )| ??? , ? = 1,2, ? , ? ??? + ?(? ? -) = |? ? (? -? -)| ??? , ? = 1,2, ? , ? ??? -<label>(6)</label><
g the advantages and disadvantages of the filter approach and wrapper approach.</p><p>The enumerating sequences-based [17]</ref>[18]</ref>[19]</ref> methods are simple and efficient to implement by removing system call parameters. During database construction stage, normal behaviors are represented by shor
">[51]</ref> presented a heterogeneous detector which consisted of sequence time-delay embedding, hidden Markov model [52]</ref>[53]</ref>[54]</ref> and a one-class support machine. In addition to satisfactory results, the heterogeneous detector also exhibits the reliability. Michael et al. <ref type="bibr
results in UNM dataset and KD98 dataset. Wael et al. [51]</ref> presented a heterogeneous detector which consisted of sequence time-delay embedding, hidden Markov model [52]</ref>[53]</ref>[54]</ref> and a one-class support machine. In addition to satisfactory results, the he
int. Under review.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Transformer models (Vaswani et al., 2017)</ref> have become ubiquitous for wide variety of problems in natural language processing (NLP), including translation <ref type="bibr" target="#b2 ransformer, while observing significant training and inference speedups.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Architecture</head><p>Complexity per Layer Sequential Operation (Vaswani et al., 2017)</ref> O(n 2 ) O(1) Sparse Tansformer, (Child et al., 2019)</ref> O(n ? n) O(1) Reformer, <ref type="bibr" target="#b
"#b27">(Socher et al., 2013)</ref> (sentiment classification), as well as QNLI (natural language inference) (Rajpurkar et al., 2016)</ref>, and QQP (textual similarity) (Chen et al., 2018)</ref> We do the same with RoBERTa, 12-layer BERT-base and 6-layer distilled BERT. All of our models, including the Transformer baselines, were pretrai

their complexity term has a large constant 128 2 and it is only more efficient than the vanilla transformer when sequence length is extremely long.</p><p>Improving Optimizer Efficiency: Microbatching (Huang et al., 2019)</ref> splits a batch into small microbatches (which can be fit into memory), and then separately runs forward and backward passes on them with gradi
their complexity term has a large constant 128 2 and it is only more efficient than the vanilla transformer when sequence length is extremely long.</p><p>Improving Optimizer Efficiency: Microbatching (Huang et al., 2019)</ref> splits a batch into small microbatches (which can be fit into memory), and then separately runs forward and backward passes on them with gradi


in deep learning, and is also widely used in training Transformers (Ott et al., 2019)</ref>. This technique can be further improved through Quantization Aware Training (Jacob et al., 2018;</ref>Fan et al., 2020)</ref>, where the weights are quantized during training and the gradients are approximated with
/head><p>Transformer models (Vaswani et al., 2017)</ref> have become ubiquitous for wide variety of problems in natural language processing (NLP), including translation (Ott et al., 2018)</ref>, text classification, question answering, among others (Raffel et al., 2019;</ref>
/head><p>Transformer models (Vaswani et al., 2017)</ref> have become ubiquitous for wide variety of problems in natural language processing (NLP), including translation (Ott et al., 2018)</ref>, text classification, question answering, among others (Raffel et al., 2019;</ref>
the standard Transformer model. We then finetune our pretrained models on three tasks from GLUE (Wang et al., 2018)</ref> and one sentiment analysis task, IMDB reviews (Maas et al., 2011)</ref>. On these tasks, we find that our model performs comparably, or even slightly better, than the standard pretrained Transformer, while observing ef type="bibr" target="#b15">(Liu et al., 2019)</ref> on two tasks: masked-language-modeling task on Wiki103 (Merity et al., 2016)</ref> and classification task on IMDB (Maas et al., 2011)</ref>. In Figure 1</ref> (left), we apply singular value decomposition into P across different layers and differen p>Thus far, we have only examined the pretraining perplexities of our model. However, we wish to show that our conclusions hold after finetuning on downstream tasks. We finetune our Linformer on IMDB (Maas et al., 2011)</ref> and SST-2 (Socher et al., 2013)</ref> (sentiment classification), as well as QNLI (natural language inference) <
tation often make the model invariant to the applied noise and enhance its ability to generalize.</p><p>Inspired by the success of augmentation methods in ASR [16,</ref>17]</ref>, as a remedy to avoid overfitting while using lowresource translated speech data, we study the use of spectrogram augmentation (SpecAugment) for direct ST mode
f type="bibr" target="#b4">[5]</ref>[6]</ref> and MT [7]</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref> have inspired the end-to-end direct ST models which can be trained using a translation speech corpus <ref type="bibr" es (LSTMs) [18]</ref> similar to [19]</ref>. We only focus on LSTMbased models and leave the transformer architecture as our future study [10,</ref>20,</ref>21]</ref>. An abstract overview of the network and a summary of the model are shown in Fi
ect model is based on the attention sequence-tosequence model [8]</ref> composed of long short-term memories (LSTMs) [18]</ref> similar to [19]</ref>. We only focus on LSTMbased models and leave the transformer architecture as our future study [10,</ref><ref type="bibr" target= ev and test sets contain 2h and 4h of speech, 1071 and 2048 segments respectively. Here, the dev set is used as our cross-validation set as well as checkpoint selection.</p><p>IWSLT En→De: Similar to [19,</ref>28]</ref>, we extract 80dimensional Mel-frequency cepstral coefficients (MFCC) features. We automatically recompute the provided tention with alignment feedback [34,</ref>35]</ref> is used as our attention component. Similar to [4,</ref>19]</ref>, we apply layer-wise pre-training for the encoder, where we start with two encoder layers and a single max-pool in between BLSTM layers. We apply 2 max-pooling
type="bibr" target="#b5">[6]</ref> and MT [7]</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref> have inspired the end-to-end direct ST models which can be trained using a translation speech corpus [12,</ref><ref type="bibr"
f type="bibr" target="#b4">[5]</ref>[6]</ref> and MT [7]</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref> have inspired the end-to-end direct ST models which can be trained using a translation speech corpus <ref type="bibr" es (LSTMs) [18]</ref> similar to [19]</ref>. We only focus on LSTMbased models and leave the transformer architecture as our future study [10,</ref>20,</ref>21]</ref>. An abstract overview of the network and a summary of the model are shown in Fi
architecture that is used in our experiments. The direct model is based on the attention sequence-tosequence model [8]</ref> composed of long short-term memories (LSTMs) [18]</ref> similar to [19]</ref>. We only focus on LSTMbased models and leave the transformer architecture as our future study <ref type="
anslate reference which have been provided in the dataset package. Hence, we end up to 200h of clean speech corresponding to 94.5k segments for the ST task. We apply 40-dimensional Gammatone features [26]</ref> using the RASR feature extractor [27]</ref>. For MT training, we utilize no additional data and only use the source-target data
is not easy to acquire. Therefore these models tend to overfit easily.</p><p>In the absence of an adequate volume of training data, one remedy is generating synthetic data like back-translation (BT) [14]</ref> as the most common data augmentation method to leverage monolingual data. The idea is to use a pretrained model to convert weakly supervised data into speecht
t="#b8">[9]</ref>[10]</ref>[11]</ref> have inspired the end-to-end direct ST models which can be trained using a translation speech corpus [12,</ref>13]</ref>. Some appealing advantages of the direct models are: (1)</ref> no error accumulation fro
f type="bibr" target="#b4">[5]</ref>[6]</ref> and MT [7]</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref> have inspired the end-to-end direct ST models which can be trained using a translation speech corpus <ref type="bibr" es (LSTMs) [18]</ref> similar to [19]</ref>. We only focus on LSTMbased models and leave the transformer architecture as our future study [10,</ref>20,</ref>21]</ref>. An abstract overview of the network and a summary of the model are shown in Fi
f type="bibr" target="#b4">[5]</ref>[6]</ref> and MT [7]</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref> have inspired the end-to-end direct ST models which can be trained using a translation speech corpus <ref type="bibr" es (LSTMs) [18]</ref> similar to [19]</ref>. We only focus on LSTMbased models and leave the transformer architecture as our future study [10,</ref>20,</ref>21]</ref>. An abstract overview of the network and a summary of the model are shown in Fi
product reviews (CR) (Hu &amp; Liu, 2004)</ref>, and sentiment of movie reviews (MR) (Pang &amp; Lee, 2005)</ref>.</p><p>Comparison with Kalantidis et al. (2020)</ref>: Kalantidis et al. (2020)</ref> also consider ways to sample negatives, and propose a mixing strategy for h Liu, 2004)</ref>, and sentiment of movie reviews (MR) (Pang &amp; Lee, 2005)</ref>.</p><p>Comparison with Kalantidis et al. (2020)</ref>: Kalantidis et al. (2020)</ref> also consider ways to sample negatives, and propose a mixing strategy for hard negatives, called MoCHi. The main points of difference are:


//www.tei-c.org/ns/1.0"><head>D.2 GRAPH REPRESENTATIONS</head><p>All datasets we benchmark on can be downloaded at www.graphlearning.io from the TU-Dataset repository of graph classification problems (Morris et al., 2020)</ref>. Information on basic statistics of the datasets is included in Tables 3 and 4</ref>. For fair comparison t ith learning rate 0.001, and weight decay of 10 −6 . Each embedding is evaluated using the average accuracy 10-fold cross-validation using an SVM as the classifier (in line with the approach taken by Morris et al. (2020)</ref>). Each experiment is repeated from scratch 10 times, and the distribution of results from these 10 runs is plotted in Figure <ref type="figure
assume ρ(c) = τ + is uniform, and let τ − = 1 − τ + be the probability of another class. Since the class-prior τ + is unknown in practice, it must either be treated as a hyperparameter, or estimated (Christoffel et al., 2016;</ref>Jain et al., 2016)</ref>.</p><p>Let h : X → C be the true underlying hypothesis that assigns class labels to inputs. We w inputs for the forward-backward pass. Lemma 11 in the appendix gives a theoretical justification for the choice of M = 1. Choosing the class-prior τ + can be done in two ways: estimating it from data (Christoffel et al., 2016;</ref>Jain et al., 2016)</ref>, or treating it as a hyper-parameter. The first option requires the possession of labeled data b
ughts (QT) vectors framework introduced by Logeswaran &amp; Lee (2018), which uses adjacent sentences (before/after) as positive samples. Embeddings are trained using the unlabeled BookCorpus dataset (Kiros et al., 2015)</ref>, and evaluated following the protocol of Logeswaran &amp; Lee (2018)</ref> on six downstream tasks. The results tal settings, which can be found at https: //github.com/lajanugen/S2V. We keep all hyperparameters at the default values and change only the s2v-model.py script. Since the official BookCorpus dataset Kiros et al. (2015)</ref> is not available, we use an unofficial version obtained using the following repository: https://github. com/soskek/bookcorpus. Since the senten

mpling strategies often apply transformations that preserve semantic content, e.g., jittering, random cropping, separating color channels, etc. (Chen et al., 2020a;</ref>c;</ref>Tian et al., 2019)</ref>. Such transformations have also been effective in learning control policies from raw pixel data <ref type sen to be the marginal distribution p, or, in practice, an empirical approximation of it (Tian et al., 2019;</ref>Chen et al., 2020a;</ref>c;</ref>He et al., 2020;</ref>Chen et al., 2020c;</ref>Oord et al., 2018;</re ar how to sample efficiently from it. To work towards a practical method, note that we can rewrite this distribution by adopting a PU-learning viewpoint (Elkan &amp; Noto, 2008;</ref>Du Plessis et al., 2014;</ref>Chuang et al., 2020)</ref>. That is, by conditioning on the event {h(x) = h(x − )} we can split q β (x − ) as
e become one of the most popular self-supervised approaches for learning representations (Oord et al., 2018;</ref>Tian et al., 2019;</ref>Chen et al., 2020a)</ref>. In computer vision, unsupervised contrastive learning methods have even outperformed supervised pre-training for object detection and segmentat b14">(Gutmann &amp; Hyvärinen, 2010)</ref>, guides the learned representation f to map positive pairs to nearby locations, and negative pairs farther apart; other objectives have also been considered (Chen et al., 2020a)</ref>. The success of the associated methods depends on the design of informative of the positive and negative pairs, which cannot exploit true simil xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">IMAGE REPRESENTATIONS</head><p>We begin by testing the hard sampling method on vision tasks using the STL10, CIFAR100 and CIFAR10 data. We use SimCLR (Chen et al., 2020a)</ref> as the baseline method, and all models are trained for 400 epochs. The results in Fig. 2</ref> show consistent improvement o max G ∈G sp(T h u (G), H(G ) ). Although this is still hard to compute exactly, it can be approximated by, The vision experiments in the main body of the paper are all based off the SimCLR framework (Chen et al., 2020a)</ref>. They use a relatively small batch size (up to 512). In order to test whether our hard negatives sampling method can help when the negative bat w and contrastive learning (Blum &amp; Mitchell, 1998;</ref>Xu et al., 2013;</ref>Bachman et al., 2019;</ref>Chen et al., 2020a;</ref>Tian et al., 2020)</ref>. For image data, positive sampling strategies often apply transformations that preserve s e. The negative sample distribution q is frequently chosen to be the marginal distribution p, or, in practice, an empirical approximation of it (Tian et al., 2019;</ref>Chen et al., 2020a;</ref>c;</ref>He et al., 2020;</ref>Chen et al., 2020c;</re 8">Tian et al., 2020)</ref>. For image data, positive sampling strategies often apply transformations that preserve semantic content, e.g., jittering, random cropping, separating color channels, etc. (Chen et al., 2020a;</ref>c;</ref>Tian et al., 2019)</ref>. Such transformations have also been effective in
r details). In doing so, we illustrate that it is easy to adapt our hard sampling method to other contrastive frameworks.</p><p>Fig. 3</ref> shows the results of fine-tuning an SVM (Boser et al., 1992;</ref>Cortes &amp; Vapnik, 1995)</ref> on the fixed, learned embedding for a range of different values of β. Hard sampl
removing all false negatives becomes larger for harder samples, creating the trade-off. As a special case our our method, when the hardness level is tuned fully down, we obtain the method proposed in (Chuang et al., 2020)</ref> that only upholds Principle 1 (approximately) but not Principle 2. Finally, beyond Principles 1 and 2, we wish to design an efficient sampling DOES AVOIDING FALSE NEGATIVES IMPROVE HARD SAMPLING?</head><p>Our proposed hard negative sampling method conditions on the event {h(x) = h(x − )} in order to avoid false negatives (termed "debiasing" (Chuang et al., 2020)</ref>). But does this help? To test this, we train four embeddings: hard sampling with and without debiasing, and uniform sampling (β = 0) with and y fine-tuning an SVM readout function, and are the average of 10 runs, each using 10-fold cross validation. Results in bold indicate best performer. baseline in 5 out of 6 cases, the debiased baseline(Chuang et al., 2020)</ref> in 4 out of 6, and both in 3 out of 6 cases. Setting τ + &gt; 0 led to numerical issues in optimization for hard sampling.</figDesc><table><ro ical method, note that we can rewrite this distribution by adopting a PU-learning viewpoint (Elkan &amp; Noto, 2008;</ref>Du Plessis et al., 2014;</ref>Chuang et al., 2020)</ref>. That is, by conditioning on the event {h(x) = h(x − )} we can split q β (x − ) as</p><formula xml:id="formula_3">q β (x − ) = τ − q − β (x − ) p>Intuitively, the concentration parameter β in our proposed negative sample distribution q − β controls the level of "hardness" of the negative samples. As discussed earlier, the debiasing method of Chuang et al. (2020)</ref> can be recovered as a special case: taking β = 0 to obtain the distribution q − 0 . This case amounts to correcting for the fact that some samp and all models are trained for 400 epochs. The results in Fig. 2</ref> show consistent improvement over SimCLR (q = p) and the particular case of our method with β = 0 proposed in (Chuang et al., 2020</ref>) (called debiasing) on STL10 and CIFAR100. For N = 510 negative examples per data point we observe absolute improvements of 3% and 7.3% over Si
transferable to different noise distributions at test time? Inspired by recent research in computer vision (Zheng et al., 2016)</ref>, Neural Machine Translation (NMT; Cheng et al., 2018)</ref>, and ASR (Sperber et al., 2017)</ref>, we propose two Noise-Aware Training (NAT) objectives that improve the acc presentation that is less sensitive to noisy input. Zheng et al. (2016)</ref> presented a general method to stabilize model predictions against small input distortions. Cheng et al. (2018)</ref> continued their work and developed the adversarial stability training method for NMT by adding a discriminator term to the objective func-tion.
t. Is it possible to narrow the gap between these two domains and design an approach that is transferable to different noise distributions at test time? Inspired by recent research in computer vision (Zheng et al., 2016)</ref>, Neural Machine Translation (NMT; Cheng et al., 2018)</ref>, and ASR (Sperber et on algorithm ( §3.3) that directly induces noise in the input data to perform training of the neural model using a mixture of noisy and clean samples.</p><p>• We implement a stability training method (Zheng et al., 2016)</ref>, adapted to the sequence labeling scenario, which explicitly addresses the noisy input data problem by encouraging the model to produce a nois ens, not only those present in the corresponding look-up tables.</p><p>Robust representations Another method to improve robustness is to design a representation that is less sensitive to noisy input. Zheng et al. (2016)</ref> presented a general method to stabilize model predictions against small input distortions. Cheng et al. (2018)</
red by recent research in computer vision (Zheng et al., 2016)</ref>, Neural Machine Translation (NMT; Cheng et al., 2018)</ref>, and ASR (Sperber et al., 2017)</ref>, we propose two Noise-Aware Training (NAT) objectives that improve the accuracy of sequence labeling performed on noisy input without reduci o resemble noisy input. The latter technique was successfully applied in other domains, including computer vision (Krizhevsky et al., 2012)</ref> and speech recognition (Sperber et al., 2017)</ref>.</p><p>During training, we artificially induce noise into the original sentences using the algorithm described in §3.2 and train our models
et="#b18">Ebrahimi et al., 2018)</ref> we assume that the attacker has access to the model parameters, in contrast to the black-box scenario (Alzantot et al., 2018;</ref>Gao et al., 2018)</ref>, where the attacker can only sample model predictions on given examples. Adversarial training (Miyato et al., 2017
f type="bibr" target="#b6">(Belinkov and Bisk, 2018)</ref>. Although this problem is not new to NLP, only a few works addressed it explicitly (Piktus et al., 2019;</ref>Karpukhin et al., 2019)</ref>. Other methods must rely on the noise that occurs naturally in the training data.</p><p>In this work, we are concerned with the performance
017;</ref>Flor et al., 2019)</ref>, noisy channel modeling (Brill and Moore, 2000;</ref>Duan and Hsu, 2011)</ref>, voting (Wemhoener et al., 2013)</ref>, sequence to sequence models (Afli et al., 2016;</ref>Schmaltz et al., 2017)<
"#b22">(Goodfellow et al., 2015;</ref>Ebrahimi et al., 2018)</ref> we assume that the attacker has access to the model parameters, in contrast to the black-box scenario (Alzantot et al., 2018;</ref>Gao et al., 2018)</ref>, where the attacker can only sample model predictions on given examples. Adversarial t
ly outperformed the baseline on data perturbed with natural noise. The best accuracy was achieved for η train from 10 to 30%, which roughly corresponds to the label-preserving noise range. Similar to Heigold et al. (2018)</ref> and Cheng et al. (2019)</ref>, we conclude that a non-zero noise level induced during training (η train &gt; 0 nducted in the NMT domain.</p><p>Noise-additive data augmentation A natural strategy to improve robustness to noise is to augment the training data with samples perturbed using a similar noise model. Heigold et al. (2018)</ref>  </p><formula xml:id="formula_5">LD = 0 LD = 1 LD = 2 LD = 3 LD 4</formula><p>Levenshtein Distance (LD) value.  at the maximum rate, only a s
oth the original and the perturbed data using various natural error distributions. We induced OCR errors based on the character confusion matrix Γ ( §3.2) that was gathered on a large document corpus (Namysl and Konya, 2019)</ref> using the Tesseract OCR engine (Smith, 2007)</ref>. Moreover, we employed two sets of misspellings released t="#b3">Alex and Burns (2014)</ref> studied NER performed on several digitized historical text collections and showed that OCR errors have a significant impact on the accuracy of the downstream task. Namysl and Konya (2019)</ref> examined the efficiency of modern OCR engines and showed that although the OCR technology was more advanced than several years ago when man
a leads to some variance in the final scores, we repeated all experiments five times and reported mean and standard deviation.</p><p>Implementation We implemented our models using the FLAIR framework (Akbik et al., 2019)</ref> 8</ref> . We extended their sequence labeling model by integrating our auxiliary training objectives ( §3.3,
d attempted to make our models robust without relying on prior error correction, which, in case of OCR errors, is still far from being solved (Chiron et al., 2017;</ref>Rigaud et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we investigated the difference in accuracy
"#b22">(Goodfellow et al., 2015;</ref>Ebrahimi et al., 2018)</ref> we assume that the attacker has access to the model parameters, in contrast to the black-box scenario (Alzantot et al., 2018;</ref>Gao et al., 2018)</ref>, where the attacker can only sample model predictions on given examples. Adversarial t
okens within a sentence, special tagging schemes are often employed for decoding, e.g., BIOES, where the Beginning, Inside, Outside, End-of-entity and Single-tag-entity subtags are also distinguished (Ratinov and Roth, 2009)</ref>. This method introduces strong dependencies between subsequent labels, which are modeled explicitly by a CRF <ref type="bibr" target="#b28
atic Speech Recognition (ASR; Parada et al., 2011)</ref>. Sequence labeling is also often performed on user-generated text, which may contain spelling mistakes or typos (Derczynski et al., 2013)</ref>. Errors introduced in an upstream task are propagated downstream, diminishing the performance of the end-to-end system <ref type="bibr" t reliably both in ideal and sub-optimal conditions. Unfortunately, this is rarely the case. User-generated text is a rich source of informal language containing misspellings, typos, or scrambled words (Derczynski et al., 2013)</ref>. Noise can also be introduced in an upstream task, like OCR (Alex and Burns, 2014)</ref> or ASR <ref type="
ref type="bibr" target="#b9">(Brill and Moore, 2000;</ref>Duan and Hsu, 2011)</ref>, voting (Wemhoener et al., 2013)</ref>, sequence to sequence models (Afli et al., 2016;</ref>Schmaltz et al., 2017)</ref> and hybrid systems (Schulz and Kuhn, 2017)</ref>.</p><
) systems fail when processing corrupted or noisy text (Belinkov and Bisk, 2018)</ref>. Although this problem is not new to NLP, only a few works addressed it explicitly (Piktus et al., 2019;</ref>Karpukhin et al., 2019)</ref>. Other methods must rely on the noise that occurs naturally in the training data. he Tesseract OCR engine (Smith, 2007)</ref>. Moreover, we employed two sets of misspellings released by Belinkov and Bisk (2018)</ref> and Piktus et al. (2019)</ref>.</p><p>Following the authors, we replaced every original token with the corresponding misspelled variant, sampling uniformly among available r or term to the objective func-tion. They combined data augmentation and stability objectives, while we evaluated both methods separately and provided evaluation results on natural noise distribution. Piktus et al. (2019)</ref> learned representation that embeds misspelled words close to their correct variants. Their Misspelling Oblivious Embeddings (MOE) model jointl

uence labeling models. Unfortunately, such data is scarce. On the other hand, labeled clean text corpora are widely available (Tjong Kim Sang and De Meulder, 2003;</ref>Benikova et al., 2014)</ref>. Hence, we propose to use the standard NER corpora and to induce noise into the input tokens during training synthetically.</p><p>In contrast iliary loss objectives ( §3.3, §3.4)9</ref> . We used the CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003)</ref> and the GermEval 2014 (Benikova et al., 2014)</ref> data sets in this setup10</ref> . The baselines utilized GloVe vectors coupled with FLAIR and character em
scenarios, they often follow an error-prone upstream component, such as Optical Character Recognition (OCR; Neudecker, 2016)</ref> or Automatic Speech Recognition (ASR; Parada et al., 2011)</ref>. Sequence labeling is also often performed on user-generated text, which may contain spelling mistakes or typos <ref type="bibr" target="#b15" al., 2018)</ref>, on the other hand, aims to improve the robustness of the neural models by utilizing adversarial examples during training.</p><p>The impact of noisy input data In the context of ASR, Parada et al. (2011)</ref> observed that named entities are often OOV tokens, and therefore they cause more recognition errors. In the document processing field, <ref ty
#b49">(Wemhoener et al., 2013)</ref>, sequence to sequence models (Afli et al., 2016;</ref>Schmaltz et al., 2017)</ref> and hybrid systems (Schulz and Kuhn, 2017)</ref>.</p><p>In this paper, we have taken a different approach and attempted to make our models robust without relying on prior error correction,
nd we cannot directly apply continuous perturbations for written language. Although some works applied distortions at the level of embeddings (Miyato et al., 2017;</ref>Yasunaga et al., 2018;</ref>Bekoulis et al., 2018)</ref>, we do not have a good intuition how it changes the meaning of the underlying text pe="bibr" target="#b21">Gao et al., 2018)</ref>, where the attacker can only sample model predictions on given examples. Adversarial training (Miyato et al., 2017;</ref>Yasunaga et al., 2018)</ref>, on the other hand, aims to improve the robustness of the neural models by utilizing adversarial examples during training.</p><p>The impact
#b49">(Wemhoener et al., 2013)</ref>, sequence to sequence models (Afli et al., 2016;</ref>Schmaltz et al., 2017)</ref> and hybrid systems (Schulz and Kuhn, 2017)</ref>.</p><p>In this paper, we have taken a different approach and attempted to make our models robust without relying on prior error correction,
al learning Adversarial attacks seek to mislead the neural models by feeding them with adversarial examples (Szegedy et al., 2014)</ref>. In a white-box attack scenario (Goodfellow et al., 2015;</ref>Ebrahimi et al., 2018)</ref> we assume that the attacker has access to the model parameters, in contrast to
nd we cannot directly apply continuous perturbations for written language. Although some works applied distortions at the level of embeddings (Miyato et al., 2017;</ref>Yasunaga et al., 2018;</ref>Bekoulis et al., 2018)</ref>, we do not have a good intuition how it changes the meaning of the underlying text pe="bibr" target="#b21">Gao et al., 2018)</ref>, where the attacker can only sample model predictions on given examples. Adversarial training (Miyato et al., 2017;</ref>Yasunaga et al., 2018)</ref>, on the other hand, aims to improve the robustness of the neural models by utilizing adversarial examples during training.</p><p>The impact
and Konya (2019)</ref> examined the efficiency of modern OCR engines and showed that although the OCR technology was more advanced than several years ago when many historical archives were digitized (Kim and Cassidy, 2015;</ref>Neudecker, 2016)</ref>, the most widely used engines still had difficulties with non-standard or lower qualit
lity distribution over the class labels y(x) as well as the final sequence of labels ŷ = (ŷ 1 , . . . , ŷN ).</p><p>Either a softmax model (Chiu and Nichols, 2016) or a Conditional Random Field (CRF; Lample et al., 2016)</ref> can be used to model the output distribution over the class labels y(x) from the logits l(x), i.e., non-normalized predictions, and to output ed on a large text corpus.</p><p>• Glove/Wiki + Char is a combination of pretrained word embeddings (GloVe for English and Wikipedia FastText for German) and randomly initialized character embeddings (Lample et al., 2016)</ref>.</p><p>Training We trained the sequence labeling model f (x) and the final CRF decoding layer on top of the pre-trained embedding vectors e(x
ly outperformed the baseline on data perturbed with natural noise. The best accuracy was achieved for η train from 10 to 30%, which roughly corresponds to the label-preserving noise range. Similar to Heigold et al. (2018)</ref> and Cheng et al. (2019)</ref>, we conclude that a non-zero noise level induced during training (η train &gt; 0 nducted in the NMT domain.</p><p>Noise-additive data augmentation A natural strategy to improve robustness to noise is to augment the training data with samples perturbed using a similar noise model. Heigold et al. (2018)</ref>  </p><formula xml:id="formula_5">LD = 0 LD = 1 LD = 2 LD = 3 LD 4</formula><p>Levenshtein Distance (LD) value.  at the maximum rate, only a s
ead>Natural noise</head><p>We can estimate the natural error distribution by calculating the alignments between the pairs (x, x) ∈ P of noisy and clean sentences using the Levenshtein distance metric (Levenshtein, 1966)</ref>, where P is a corpus of paired noisy and manually corrected sentences ( §2.2). The allowed edit operations include insertions, deletions, and s
equence labeling problem, where the goal is to locate all named entity mentions in unstructured text and to classify them into pre-defined categories, e.g., person names, organizations, and locations (Tjong Kim Sang and De Meulder, 2003)</ref>. NER systems are often trained on the clean text. Consequently, they exhibit degraded performance in real-world scenarios whe y Data</head><p>To validate our approach, we trained the baseline models with and without our auxiliary loss objectives ( §3.3, §3.4)9</ref> . We used the CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003)</ref> and the GermEval 2014 (Benikova et al., 2014)</ref> data sets in this setup<ref type="foot" tar he noisy sentences annotated with named entity labels for training our sequence labeling models. Unfortunately, such data is scarce. On the other hand, labeled clean text corpora are widely available (Tjong Kim Sang and De Meulder, 2003;</ref>Benikova et al., 2014)</ref>. Hence, we propose to use the standard NER corpora and to induce no
text is to correct it before feeding it to the downstream task. Most popular post-correction techniques include correction candidates ranking (Fivez et al., 2017;</ref>Flor et al., 2019)</ref>, noisy channel modeling (Brill and Moore, 2000;</ref>Duan and Hsu, 2011)</ref>, voting <ref type=

et="#b18">Ebrahimi et al., 2018)</ref> we assume that the attacker has access to the model parameters, in contrast to the black-box scenario (Alzantot et al., 2018;</ref>Gao et al., 2018)</ref>, where the attacker can only sample model predictions on given examples. Adversarial training (Miyato et al., 2017
r methods on real OCR errors and misspellings against state-of-the-art baseline models (Peters et al., 2018;</ref>Akbik et al., 2018;</ref>Devlin et al., 2019)</ref> and demonstrate the effectiveness of our approach ( §4).</p><p>• To support future research in this area and to make our experiments reproduci #b36">(Pennington et al., 2014</ref>; FLAIR + GloVe) for English and Wikipedia FastText embeddings (Bojanowski et al., 2017</ref>; FLAIR + Wiki) for German.</p><p>• BERT (Devlin et al., 2019)</ref> employs a Transformer encoder to learn a BiLM from large unlabeled text corpora and sub-word units to represent textual tokens. We use the BE
resource RNN-T models.</p><p>Besides improving the target model acoustic robustness, TL is also crucial for training large and complex deep learning architectures. RNN-T models are difficult to train [11]</ref> and also require significantly large amount of data to jointly train the acoustic as well as language model attributes. In our study we have noted weaker conv d are often initialized with the pretrained models. Initializing the encoder with connectionist temporal classification (CTC) model [2]</ref> or cross entropy (CE) model [11]</ref>, and the prediction network with LSTM language model (LM) is proven to be beneficial [25]</ref>. Transfer learning can also be rg/ns/1.0"><head>RNN-T training</head><p>Figure 2</ref>: en-US RNN-T initialization.</p><p>model for encoder and prediction network in the context of TL the RNN-T model. Authors in [11]</ref> have shown that CE initialized RNN-T models perform better than CTC initialized models, and hence, we only explore CE models for initialization.</p><p>The fol works are represented by cross lined blocks and randomly initialized layers are represented with plain blocks. gets (necessary for CE training), is obtained from word level alignments as discussed in [11]</ref>. From the word alignments, the start frame, end frame and total number of frames corresponding to each word is known. The words are then divided into correspo s, graphemes with B prefix and &lt;blank&gt; symbol. The word piece targets for en-US model is obtained by using byte pair encoding [26]</ref> algorithm as described in [11]</ref>.</p><p>We also report the word error rate (WER) on hybrid ASR model trained with same amount of data. The AM consists of 6 layers of latency-controlled bidire
">2,</ref>3,</ref>4,</ref>5,</ref>6,</ref>7,</ref>8,</ref>9,</ref>10]</ref>. Recurrent neural network transducer (RNN-T) [1]</ref>
d in the context of hybrid ASR system.</p><p>A few multi-lingual approaches are recently proposed in the E2E framework [21,</ref>22,</ref>23]</ref>. Authors in [21]</ref> propose the multilingual RNN-T model with language specific adapters and datasampling to handle data imba grapheme or word piece units, as bytes are suitable to scale to multiple languages. A transformer based multi-lingual E2E model, along with methods to incorporate language information is proposed in [23]</ref>. Although multi-lingual methods are attractive to address the problem of low-resource languages, the transfer learning methods, besides being simple and effec
ref type="bibr" target="#b11">[12,</ref>13,</ref>14,</ref>15,</ref>16,</ref>17,</ref>18,</ref>19,</ref>20]</ref>. Successful strategies include transfer ng [15,</ref>16]</ref>, that leverage a well trained AM from high-resource language to bootstrap the low-resource AM; multi-task training [17,</ref>18]</ref> and ensemble learning [19,</ref>20]</ref> that aim to ut
onunciation model with a single neural network [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6,</ref>7,</ref>8,</ref>9,</ref><ref type=
">2,</ref>3,</ref>4,</ref>5,</ref>6,</ref>7,</ref>8,</ref>9,</ref>10]</ref>. Recurrent neural network transducer (RNN-T) [1]</ref>
15,</ref>16,</ref>17,</ref>18,</ref>19,</ref>20]</ref>. Successful strategies include transfer learning [15,</ref>16]</ref>, that leverage a well traine to bootstrap the low-resource AM; multi-task training [17,</ref>18]</ref> and ensemble learning [19,</ref>20]</ref> that aim to utilize multi-lingual data and share the model parameters. However, most of these methods are studied in the context of hybrid ASR system.</p><p>A
network [1,</ref>2,</ref>3,</ref>4,</ref>5,</ref>6,</ref>7,</ref>8,</ref>9,</ref>10]</ref>. Recurre
me targets are obtained by combining the the original Hindi graphemes, graphemes with B prefix and &lt;blank&gt; symbol. The word piece targets for en-US model is obtained by using byte pair encoding [26]</ref> algorithm as described in [11]</ref>.</p><p>We also report the word error rate (WER) on hybrid ASR model trained with same amou
me targets are obtained by combining the the original Hindi graphemes, graphemes with B prefix and &lt;blank&gt; symbol. The word piece targets for en-US model is obtained by using byte pair encoding [26]</ref> algorithm as described in [11]</ref>.</p><p>We also report the word error rate (WER) on hybrid ASR model trained with same amou
15,</ref>16,</ref>17,</ref>18,</ref>19,</ref>20]</ref>. Successful strategies include transfer learning [15,</ref>16]</ref>, that leverage a well traine to bootstrap the low-resource AM; multi-task training [17,</ref>18]</ref> and ensemble learning [19,</ref>20]</ref> that aim to utilize multi-lingual data and share the model parameters. However, most of these methods are studied in the context of hybrid ASR system.</p><p>A
l Networks (GNNs) [19]</ref> have exhibited tremendous progress in representation learning for generic graphs (GraphSAGE [6]</ref>, AS-GCN [8]</ref>). In general, GNNs recursively update each node's feature by aggregating its neighbors through message passing, by which not only the patterns of graph topology or are inefficient in scalability.</p><p>In terms of computational inefficiency, scaling up is difficult. Although sampling methods, such as GraphSAGE [6]</ref>, AS-GCN [8]</ref> and FastGCN [1]</ref>), have been proposed to deal with the scalability issue (uncontrollable neighborhood expansion across layers vised representation learning baselines: Node2Vec [5]</ref>, VGAE [10]</ref>, GraphSAGE [6]</ref>, and AS-GCN [8]</ref>. We use a large-scale bipartite graph dataset from the Tencent Platform and also construct three synthesized datasets based on the citation networks Cora, Cites rollable neighborhood expansion of each node layer by layer leads to a low computational speed and high memory cost. Sampling methods like GraphSAGE [6]</ref> and AS-GCN [8]</ref> have been proposed to deal with this issue by reducing the number of neighborhood nodes in each layer. Compared to these methods, since the propagation of our a "#b5">[6,</ref>11]</ref>: We implement two types of aggregator functions: GCN and MEAN aggregator. Node-wise sampling is used to address the scalability issue. • AS-GCN [8]</ref>: This method uses adaptive sampling between each layer to deal with node explosion in large-scale graphs. Since this method is originally designed for supervise
e used as input for the classification model, without using any graph structure information incorporated. • Node2Vec [5]</ref>: This approach is an extension of Word2Vec [15]</ref> on graph, which learns a feature representation by simulating biased random walks on the graph. We run Node2Vec on the bipartite graph and then concatenate th
ve the performance of downstream tasks [25]</ref>. Early classical works include random walk-based methods (DeepWalk [17]</ref>, Node2Vec [5]</ref>), where only graph topology and node relations are embedded as vectors. In light of the rapid advancements of deep learning, Graph Neural Networks (GNNs) <ref t s information from one domain to be incorporated into the other. In our experiments, we contrast the performance of our algorithm with several unsupervised representation learning baselines: Node2Vec [5]</ref>, VGAE [10]</ref>, GraphSAGE [6]</ref>, and AS-GCN [8]</ref>. We use a /p><p>• Raw features: This indicates a naive solution in which only raw features are used as input for the classification model, without using any graph structure information incorporated. • Node2Vec [5]</ref>: This approach is an extension of Word2Vec [15]</ref> on graph, which learns a feature representation by simulating biased random referred to as matrix factorization. Other works explore using random walks on graphs to learn representation with the skip-gram model. DeepWalk [17]</ref> and Node2vec [5]</ref> are typically representative of these methods to model homogeneous graphs. Some others extend this to heterogeneous graphs, where different nodes are in distinc
ly unable to exploit the feature correlations across the two partitions. Alternatively, one can treat bipartite graphs as heterogeneous networks and use random walk-based methods such as Metapath2Vec [2]</ref>. However, Metapath2Vec does not integrate node features into the embedding process. Additionally, a meta-path in a bipartite graph can be equated to a naive unb are typically representative of these methods to model homogeneous graphs. Some others extend this to heterogeneous graphs, where different nodes are in distinct feature domains, such as MethPath2Vec [2]</ref> and PTE [22]</ref>. Although all these methods do not require node labels in their representation learning, they are shallow embe
ommendation system, the two distinct partitions are represented by users and products, and an edge from a member from one partition to a member of the other represents the user purchasing the product [13]</ref>. The ability to utilize information from the graphical structure, such as node features in the two distinct partitions and topology information, plays an impo
ly unable to exploit the feature correlations across the two partitions. Alternatively, one can treat bipartite graphs as heterogeneous networks and use random walk-based methods such as Metapath2Vec [2]</ref>. However, Metapath2Vec does not integrate node features into the embedding process. Additionally, a meta-path in a bipartite graph can be equated to a naive unb are typically representative of these methods to model homogeneous graphs. Some others extend this to heterogeneous graphs, where different nodes are in distinct feature domains, such as MethPath2Vec [2]</ref> and PTE [22]</ref>. Although all these methods do not require node labels in their representation learning, they are shallow embe
nsional vector space which can then be used to improve the performance of downstream tasks [25]</ref>. Early classical works include random walk-based methods (DeepWalk [17]</ref>, Node2Vec [5]</ref>), where only graph topology and node relations are embedded as vectors. In light of the rapid advancements o e similarity among nodes for graph embedding, which is referred to as matrix factorization. Other works explore using random walks on graphs to learn representation with the skip-gram model. DeepWalk [17]</ref> and Node2vec [5]</ref> are typically representative of these methods to model homogeneous graphs. Some others extend this to het
lions of users is manually labeled, which is insufficient for supervised learning. Some unsupervised learning methods have been proposed to address this problem [7,</ref>14]</ref>. However, they either do not apply to bipartite graphs or are inefficient in scalability.</p><p>In terms of computational inefficiency, scaling up is difficult r word, they require labels in downstream tasks to supervise the models. Some works [6,</ref>7,</ref>10,</ref>14]</ref> try to utilize GCN to do unsupervised learning on graphs by performing a random walk or matrix completion on the output of GCN embeddings. However, these appro
lions of users is manually labeled, which is insufficient for supervised learning. Some unsupervised learning methods have been proposed to address this problem [7,</ref>14]</ref>. However, they either do not apply to bipartite graphs or are inefficient in scalability.</p><p>In terms of computational inefficiency, scaling up is difficult r word, they require labels in downstream tasks to supervise the models. Some works [6,</ref>7,</ref>10,</ref>14]</ref> try to utilize GCN to do unsupervised learning on graphs by performing a random walk or matrix completion on the output of GCN embeddings. However, these appro
ly unable to exploit the feature correlations across the two partitions. Alternatively, one can treat bipartite graphs as heterogeneous networks and use random walk-based methods such as Metapath2Vec [2]</ref>. However, Metapath2Vec does not integrate node features into the embedding process. Additionally, a meta-path in a bipartite graph can be equated to a naive unb are typically representative of these methods to model homogeneous graphs. Some others extend this to heterogeneous graphs, where different nodes are in distinct feature domains, such as MethPath2Vec [2]</ref> and PTE [22]</ref>. Although all these methods do not require node labels in their representation learning, they are shallow embe
omplex structural relationships among data items in various domains, including drug discovery [9,</ref>27]</ref>, social networks analysis [18,</ref>24]</ref>, and visual understanding [23,</ref>26]</ref>. Amongst t
ndicates how to perturb the input to alter the network's decision.</p><p>Yet, almost all these gradient obfuscation based defenses have proven vulnerable. In their recent seminal work, Athalye et al. [2]</ref> presented a suite of strategies for estimating network gradients in the presence of gradient obfuscation. Adversarial examples crafted by their method have succ chanism.</p><p>We play devil's advocate in attacking our defense model thoroughly. We examine a wide range of possible attacks, including those having successfully circumvented many previous defenses [2]</ref>. Under these attacks, we compare the worst-case robustness of our method with state-of-the-art defense methods on both CIFAR-10 and Tiny ImageNet datasets. Our type="bibr" target="#b6">7,</ref>39,</ref>33]</ref>.</p><p>Unfortunately, many of these methods have proven vulnerable by Athalye et al. [2]</ref>, who introduced a set of attacking strategies, including a method called Backward Pass Differentiable Approximation (BPDA), to circumvent gradient obfuscation ( et="#b16">[17,</ref>42,</ref>22]</ref>.</p><p>Thus far, gradient obfuscation is generally considered vulnerable (and at least incomplete) [2]</ref>. We revisit gradient obfuscation, and our defense demonstrates unprecedented robustness against BPDA and other possible attacks.</p></div> <div xmlns="http://ww variation minimization [14]</ref>.</p><p>These input-transformation-based defense mechanisms seem plausible. Yet they are all fragile. As demonstrated by Athalye et al. [2]</ref>, with random input transformation, adversarial examples can still be found using Expectation over Transformation [3]</ref>, which he network gradient by taking the average over multiple trials (more details in Sec. 3.3). The noise-removal transformation is also ineffective. One can use Backward Pass Differentiable Approximation [2]</ref> to easily construct effective adversarial examples. In short, the current consensus is that input transformation as a defense mechanism remains vulnerable.</p>< odel.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Backward Pass Differentiable Approximation (BPDA).</head><p>To circumvent the defense using non-differentiable operators, Athalye et al. [2]</ref> introduced a strategy called Backward Pass Differentiable Approximation (BPDA) to estimate the defense model's gradients. The idea is to replace the non-differe os except the j-th element (or pixel) which has a value h.</p><p>Our defense inherently thwarts this attacking strategy. It causes the adversary to suffer from either exploding or vanishing gradients [2]</ref>. Figure 3</ref>-left shows a 1D depiction illustrating this phenomenon in our method. Indeed, our experiments confirm that it exploited as a defense mechanism [39,</ref>33]</ref>. Yet those defenses have been proven vulnerable under a reparameterization strategy [2]</ref>. This strategy aims to find some differentiable function h(•) for a change-of-variable x = h(z) such that g(h(z)) ≈ h(z). If such a function h(•) can be found, e input image [14,</ref>33]</ref>. In those defenses, the transformed image g(x) remain similar to the input x. Consequently, as shown in [2]</ref>, those defenses can be easily circumvented by replacing g(•) with the identity mapping in the backward pass of BPDA attack.</p><p>Similarly, in our defense, if nd as robust accuracy if the tested images consist of adversarially crafted images.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">BPDA Attack and the Variants</head><p>BPDA attack [2]</ref>, as reviewed in Sec. 3.3, is a powerful way to estimate network gradients that are obfuscated by defense methods. The estimated gradients are then used in Figur artifacts; they are not valid.</p><p>Black-box attacks. We also evaluate our defense against the black-box attacks, including the black-box transfer attack [30]</ref>   [2]</ref>. We evaluate other methods using the code provided in the original papers, training them using the same network and hyperparameters as our method. The perturbat d is the standard accuracy tested with clean images, and A rob is the worst-case robust accuracy under all tested attacks. The methods indicated by a star (*) are those circumvented by Athalye et al. [2]</ref>. We include their results therein as a reference. The other defense methods (including ours) all use ResNet18 as their classification model, trained with SGD (l niformly sampled δ i ∼ [−∆, ∆]). Randomization is not new; prior defenses also employ randomized transformations to the input. But they have been circumvented by Expectation Over Transformation (EOT) [2,</ref>3]</ref>. EOT attack first estimates the gradient of expected f (g(x)) with respect to x using the relationship ∇ E g∼T f (g(x)) = tack.</p><p>To break our defense using this strategy, one must find an h(•) that constructs the adversarial examples of f b directly (so that g(h(•)) = h(•)), without solving the optimization problem (2)</ref>. We argue that finding such an h(•) is extremely hard. If h(•) could be constructed, we would have a direct way of crafting adversarial examples; PGD-type itera
of image classification systems. Yet they are prone to adversarial examples. Those are natural images with deliberately crafted, imperceptible noise, aiming to mislead the network's decision entirely [5,</ref>41]</ref>. In numerous applications, from face recognition authorization to autonomous cars [36,</r simultaneously lower training cost and stronger robustness.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Adversarial attack. The seminal work of Biggio et al. [5]</ref> and Szegedy et al. [41]</ref> first suggested the existence of adversarial examples that can mislead deep neural networks. The la ximations of the sgn(•) function, namely, the soft sign function x 1+|x| and tanh function e x −e −x e x +e −x , and the projection operator is replaced by directly approximating its derivative using (5)</ref>.</p><p>Also discussed in Sec. 4.1 is an additional transfer attack: First, we craft adversarial examples by setting the number N of LL-PGD steps to be a small v
del's gradient with respect to its input [50,</ref>14,</ref>49,</ref>7,</ref>39,</ref>33]</ref>, motivated by the fact that the gradient information is essential for crafting adversarial examples: the gradient indic oy stochastic activation functions [10]</ref> and nondifferentiable operators in the model [49,</ref>7,</ref>39,</ref>33]</ref>.</p><p>Unfortunately, many of these methods have proven vulnerable by Athalye et al. [2]< 1.0"><head n="3.2.">Adversarial Transformation</head><p>Our input transformation operation takes an approach opposite to the intuition behind previous methods [14,</ref>39,</ref>33]</ref>. In contrast to those aiming to purge input images of the adversarial noise, we embrace adversarial noise. As we will s rsarial examples. BPDA has circumvented a handful of recent defense techniques [14,</ref>50,</ref>25,</ref>39,</ref>7]</ref> that implement gradient obfuscation, in many defenses resulting in 0% robust accuracy. We therefore evaluate our defense t estimation in BPDA backward pass (recall discussion in Sec. 3.3). We refer this attack as BPDA-I attack. Under this attack, several previous defenses (e.g., [33,</ref>39,</ref>14]</ref>) have been nullified.</p><p>We applied BPDA-I attack on our defense. The attack setup and results are summarized in Fig se in comparison to network training cost, the inference cost is negligible. In fact, almost all adversarial defense methods that rely on input transformation [14,</ref>39,</ref>33]</ref> have a performance overhead at inference time. For example, PixelDefend [39]</ref> proje instance, g(•) has been used to restore a natural image from a potentially adversarial input, by projecting it on a GAN-or PixelCNNrepresented image manifold [33,</ref>39]</ref> or regularizing the input image through total variation minimization [14]</ref>.</p><p>These input-transformation-based defense eliable to estimate derivatives using (4) (see Fig. 3-right</ref>). Reparameterization. Vanishing and exploding gradients have been exploited as a defense mechanism [39,</ref>33]</ref>. Yet those defenses have been proven vulnerable under a reparameterization strategy [2]< ation [14,</ref>39,</ref>33]</ref> have a performance overhead at inference time. For example, PixelDefend [39]</ref> projects the input to a pre-trained PixelCNN-represented manifold through 100 steps of L-BFGS iterations. Their transformation is about 10× slower than ours e
ppendix A.3). We conjecture that this is because the adversarial examples for the model with a small N have a different distribution from that with a larger N [30,</ref>40]</ref>. Identity mapping approximation. Another possible attack is by replacing the input transformation g(•) with the identity mapping for gradient estimation in BPD
ximate our adversarial transformation g(•). As discussed therein, it is extremely hard to directly derive the reparameterization function. Instead, we attempted to train a Fully Convolutional Network [24]</ref> to represent h(z). We denote this network as h(x; θ), whose weights are optimized with the loss function, ℓ(θ) = E x∈X h(x; θ) − g(x)</p><p>2 .</p><p>Here X r h the reparameterization attack, we need to find a forward function h(•) that approximate our adversarial transformation process. To this end, we attempted to train a Fully Convlutional Network (FCN) [24]</ref>, denoted as h(x; θ), through the following optimization,</p><p>where X is the given dataset, δ is the initial input perturbation in the L ∞ ball of size ∆ (as
own model (e.g., using PGD) to attack an unknown model [30]</ref>. Several methods (e.g., [44,</ref>3,</ref>52,</ref>16]</ref>) are proposed to improve the transferability of the adversarial examples so that the adversarial examples generated on
21,</ref>13,</ref>46,</ref>35,</ref>53,</ref>29,</ref>27]</ref>. In comparison to adversarial training, our method offers both stronger robustness and lower training cost.</p><p>To de
of image classification systems. Yet they are prone to adversarial examples. Those are natural images with deliberately crafted, imperceptible noise, aiming to mislead the network's decision entirely [5,</ref>41]</ref>. In numerous applications, from face recognition authorization to autonomous cars [36,</r simultaneously lower training cost and stronger robustness.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Adversarial attack. The seminal work of Biggio et al. [5]</ref> and Szegedy et al. [41]</ref> first suggested the existence of adversarial examples that can mislead deep neural networks. The la ximations of the sgn(•) function, namely, the soft sign function x 1+|x| and tanh function e x −e −x e x +e −x , and the projection operator is replaced by directly approximating its derivative using (5)</ref>.</p><p>Also discussed in Sec. 4.1 is an additional transfer attack: First, we craft adversarial examples by setting the number N of LL-PGD steps to be a small v
</ref>38]</ref>, and a rich set of methods has been proposed to accelerate its training speed or further improve its robustness [51,</ref>54,</ref>21,</ref>13,</ref>46,</ref>35,</ref> d in details in Appendix A.4</ref>. Training cost. Our method has significantly lower training cost than the adversarial training[26,</ref>54,</ref>51]</ref>, while offering stronger robustness. For example, our method takes 82 minutes to train a ResNet18 model on CIFAR-10 for stness of our method under all BPDAtype attacks, while the last row indicates our worst-case robustness under all attacks.</p><p>based on adversarial training [26,</ref>54]</ref>. For all those methods, we use the implementation code provided in their original papers. When comparing with these methods, we use the same training protocol:
pe="bibr" target="#b25">[26]</ref> further formalized the problem of adversarial attacks and proposed Projected Gradient Descent (PGD) method, which further inspires many subsequent attacking methods [11,</ref>8,</ref>28,</ref>19]</ref>. PGDtype methods are considered the stro
urther discussion in Sec. 3.1 and 3.3). Since then, a few other gradient obfuscation based defenses have been proposed [23,</ref>31,</ref>17,</ref>42,</ref>22]</ref>. But those works either report degraded robustness under BPDA attacks <ref type But those works either report degraded robustness under BPDA attacks [23,</ref>31]</ref> or neglected the evaluation against BPDA attacks [17,</ref>42,</ref>22]</ref>.</p><p>Thus far, gradient obfuscation is generally considered vulnerable (and
>(Thorne et al., 2018a)</ref>, a large-scale fact verification benchmark, KGAT achieves a 70.38% FEVER score, significantly outperforming previous BERT and Graph Neural Network (GNN) based approaches (Zhou et al., 2019)</ref>. Our experiments demonstrate KGAT's strong effectiveness especially on facts that require multiple evidence reasoning: our kernel-based attenti arget="#b9">Hanselowski et al., 2018)</ref>. TwoWingOS (Yin and Roth, 2018)</ref> further incorporates evidence identification to improve claim verification.</p><p>GEAR (Zhou et al., 2019)</ref> formulates claim verification as a graph reasoning task and provides two kinds of attentions. It conducts reasoning and aggregation over claim ls (Sec. 3.3) and Evidence Selection with Node Kernels (Sec. 3.4).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Reasoning with Evidence Graph</head><p>Similar to previous research (Zhou et al., 2019)</ref>, KGAT constructs the evidence graph G by using each claim-evidence pair as a node and connects all node pairs with edges, making it a fullyconn 1 , . . . , n p , . . . , n l }.</p><p>KGAT unifies both multiple and single evidence reasoning scenarios and produces a probability P (y|c, D) to predict claim label y. Different from previous work (Zhou et al., 2019)</ref>, we follow the standard graph label prediction setting in graph neural network (Veličković et al., 2017)</ref> and split the p tence Level Attention. The sentence level attention combines neighbor node information to node representation v p . The aggregation is done by a graph attention mechanism, the same with previous work (Zhou et al., 2019)</ref>.</p><p>It first calculate the attention weight β q→p of n q node according to the p-th node n p :</p><formula xml:id="formula_12">β q→p = softm /p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Node Kernel for Evidence Aggregation</head><p>The per-node predictions are combined by the "readout" function in graph neural networks (Zhou et al., 2019)</ref>, where KGAT uses node kernels to learn the importance of each evidence.</p><p>It first uses node kernels to calculate the readout representatio nt.</p><p>The BERT based models are our main baselines, they significantly outperform previous methods without pre-training. BERT-pair, BERT-concat and GEAR are three baselines from the previous work (Zhou et al., 2019)</ref>. BERT-pair and BERTconcat regard claim-evidence pair individually or concatenate all evidence together to predict claim label. GEAR utilizes a helps improve KGAT's reasoning accuracy. Nevertheless, for more fair comparisons, our following experiments are all based on ESIM sentence retrieval, which is the one used by GEAR, our main baseline (Zhou et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance on Different Scenarios</head><p>This experiment studies the effec combining evidence clues from multiple pieces.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Case Study</head><p>Table 5</ref> shows the example claim used in GEAR (Zhou et al., 2019)</ref> and the evidence sentences retrieved by ESIM, among which the first two are required evidence pieces. Figure <ref type="figure" target="#fig_6" Roll Hall of Fame as a member of the Beach Boys.(5) [Jardine] Ray Jardine American rock climber, lightweight backpacker, inventor, author and global adventurer. Label: SUPPORT Table5: An example claim(Zhou et al., 2019)</ref> whose verification requires multiple pieces of evidence.</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fi as also been used for better text representation in FEVER and achieved better performance (Devlin et al., 2019;</ref>Li et al., 2019;</ref>Zhou et al., 2019;</ref>Soleimani et al., 2019)</ref>.</p><p>The recent development of neural information retrieval models, especially the details.</p><p>Document retrieval. The document retrieval step retrieves related Wikipedia pages and is kept the same with previous work (Hanselowski et al., 2018;</ref>Zhou et al., 2019;</ref>Soleimani et al., 2019)</ref>. For a given claim, it first utilizes the constituency parser in AllenNLP <ref type= s: ESIM based sentence retrieval and BERT based sentence retrieval. The ESIM based sentence retrieval keeps the same as the previous work (Hanselowski et al., 2018;</ref>Zhou et al., 2019)</ref>. The base version of BERT is used to implement our BERT based sentence retrieval model. We use the "[CLS]" hidden state to represent claim and e tences, and BERT (Large) Encoder with BERT retrieved sentences.</p><p>Compared with baseline models, KGAT is the best on all testing scenarios. With ESIM sentence retrieval, same as the previous work (Zhou et al., 2019;</ref>Hanselowski et al., 2018)</ref>, KGAT outperforms the graph attention models GEAR and our GAT on both development
embedding space between query and documents. The kernel extracts matching patterns which provide a variety of relevance match signals and shows strong performance in various ad-hoc retrieval dataset (Dai and Callan, 2019)</ref>. Recent research also has shown kernels can be integrated with contextualized representations, i.e., BERT, to better model the relevance betw
elevant sub-components between premise and hypothesis. BERT, the pre-trained deep bidirectional Transformer, has also been used for better text representation in FEVER and achieved better performance (Devlin et al., 2019;</ref>Li et al., 2019;</ref>Zhou et al., 2019;</ref>Sole ">Initial Node Representations</head><p>The node representations are initialized by feeding the concatenated sequence of claim, document (Wiki) title, and evidence sentence, to pre-trained BERT model (Devlin et al., 2019)</ref>. Specifically, in the node n p , the claim and evidence correspond to m tokens (with "[SEP]") and n tokens (with Wikipedia title and "[SEP]")
rnels to extract the matching feature K(M q→p i</p><p>) from the translation matrix M q→p (Xiong et al., 2017;</ref>Dai et al., 2018;</ref>Qiao et al., 2019;</ref>MacAvaney et al., 2019)</ref>:</p><formula xml:id="formula_8">K(M q→p i ) = {K1(M q→p i ), ..., KK (M q→p i )}. (7 face's implementation5</ref> . Adam optimizer is used with learning rate = 5e-5 and warm up proportion = 0.1. The kernel size is set to 21, the same as previous work (Qiao et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation Result</head><p>The experiments are conducted to study the performan
mance. These graph based models establish node interactions for joint reasoning over several evidence pieces.</p><p>Many fact verification systems leverage Natural Language Inference (NLI) techniques (Chen et al., 2017b;</ref>Ghaeini et al., 2018;</ref>Parikh et al., 2016;</ref>Radford et al ter requires systems to find the evidence pieces themselves and there are often multiple evidence pieces. One of the most widely used NLI models in FEVER is Enhanced Sequential Inference Model (ESIM) (Chen et al., 2017b)</ref>, which employs some forms of hard or soft alignment to associate the relevant sub-components between premise and hypothesis. BERT, the pre-trai
recent development of neural information retrieval models, especially the interaction based ones, have shown promising effectiveness in extracting soft match patterns from query-document interactions (Hu et al., 2014;</ref>Pang et al., 2016;</ref>Guo et al., 2016;</ref>Xiong e
erns from query-document interactions (Hu et al., 2014;</ref>Pang et al., 2016;</ref>Guo et al., 2016;</ref>Xiong et al., 2017;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels <ref type 16;</ref>Xiong et al., 2017;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref>Dai et al., 2018)</ref>, which summarize word or phrase interactions in the learned embedding space between query </p><formula xml:id="formula_7">M q→p ij = cos(H q i , H p j ).<label>(6)</label></formula><p>Then we use K kernels to extract the matching feature K(M q→p i</p><p>) from the translation matrix M q→p (Xiong et al., 2017;</ref>Dai et al., 2018;</ref>Qiao et al., 2019;</ref>MacA ) = log j exp(− M q→p ij − µ k 2δ 2 k ),<label>(8)</label></formula><p>where µ k and δ k are the mean and width for the k-th kernel, which captures a certain level of interactions between the tokens (Xiong et al., 2017)</ref>.</p><p>Then each token's attention weight α q→p i is calculated using a linear layer:</p><formula xml:id="formula_10">α q→p i = softmaxi(Linea mula xml:id="formula_21">P (n p |G) = softmaxp(Linear(φ(n p ))). (<label>16</label></formula><formula xml:id="formula_22">)</formula><p>KGAT leverages the kernels multi-level soft matching capability (Xiong et al., 2017)</ref> to weight the node-level predictions in the evidence graph based on their relevance with the claim:</p><formula xml:id="formula_23">P (y|G) =
"bibr" target="#b17">Nie et al. (2019a)</ref> concatenates all evidence together to verify the claim. One can also conduct reasoning for each claim evidence pair and aggregate them to the claim label (Luken et al., 2018;</ref>Yoneda et al., 2018;</ref>Hanselowski et al., 2018)</ref>. TwoWingOS <ref type="bi
arget="#b10">(Hu et al., 2014;</ref>Pang et al., 2016;</ref>Guo et al., 2016;</ref>Xiong et al., 2017;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref><ref typ 7;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref>Dai et al., 2018)</ref>, which summarize word or phrase interactions in the learned embedding space between query and documents. The kernel extracts matching patterns whi p j ).<label>(6)</label></formula><p>Then we use K kernels to extract the matching feature K(M q→p i</p><p>) from the translation matrix M q→p (Xiong et al., 2017;</ref>Dai et al., 2018;</ref>Qiao et al., 2019;</ref>MacAvaney et al., 2019)</ref>:</p><formula xml:id="formula_8"

claim label (Luken et al., 2018;</ref>Yoneda et al., 2018;</ref>Hanselowski et al., 2018)</ref>. TwoWingOS (Yin and Roth, 2018)</ref> further incorporates evidence identification to improve claim verification.</p><p>GEAR (Zhou et al., 2019)</ref

elevant sub-components between premise and hypothesis. BERT, the pre-trained deep bidirectional Transformer, has also been used for better text representation in FEVER and achieved better performance (Devlin et al., 2019;</ref>Li et al., 2019;</ref>Zhou et al., 2019;</ref>Sole ">Initial Node Representations</head><p>The node representations are initialized by feeding the concatenated sequence of claim, document (Wiki) title, and evidence sentence, to pre-trained BERT model (Devlin et al., 2019)</ref>. Specifically, in the node n p , the claim and evidence correspond to m tokens (with "[SEP]") and n tokens (with Wikipedia title and "[SEP]")
arget="#b10">(Hu et al., 2014;</ref>Pang et al., 2016;</ref>Guo et al., 2016;</ref>Xiong et al., 2017;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref><ref typ 7;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref>Dai et al., 2018)</ref>, which summarize word or phrase interactions in the learned embedding space between query and documents. The kernel extracts matching patterns whi p j ).<label>(6)</label></formula><p>Then we use K kernels to extract the matching feature K(M q→p i</p><p>) from the translation matrix M q→p (Xiong et al., 2017;</ref>Dai et al., 2018;</ref>Qiao et al., 2019;</ref>MacAvaney et al., 2019)</ref>:</p><formula xml:id="formula_8"
arget="#b10">(Hu et al., 2014;</ref>Pang et al., 2016;</ref>Guo et al., 2016;</ref>Xiong et al., 2017;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref><ref typ 7;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref>Dai et al., 2018)</ref>, which summarize word or phrase interactions in the learned embedding space between query and documents. The kernel extracts matching patterns whi p j ).<label>(6)</label></formula><p>Then we use K kernels to extract the matching feature K(M q→p i</p><p>) from the translation matrix M q→p (Xiong et al., 2017;</ref>Dai et al., 2018;</ref>Qiao et al., 2019;</ref>MacAvaney et al., 2019)</ref>:</p><formula xml:id="formula_8"
1 All source codes of this work are available at https: //github.com/thunlp/KernelGAT.</p><p>2 https://competitions.codalab.org/ competitions/18814 et al., 2008;</ref>Kipf and Welling, 2017)</ref>. Zhong et al. (2019)</ref> further employs XLNet (Yang et al., 2019)</ref> an
elevant sub-components between premise and hypothesis. BERT, the pre-trained deep bidirectional Transformer, has also been used for better text representation in FEVER and achieved better performance (Devlin et al., 2019;</ref>Li et al., 2019;</ref>Zhou et al., 2019;</ref>Sole ">Initial Node Representations</head><p>The node representations are initialized by feeding the concatenated sequence of claim, document (Wiki) title, and evidence sentence, to pre-trained BERT model (Devlin et al., 2019)</ref>. Specifically, in the node n p , the claim and evidence correspond to m tokens (with "[SEP]") and n tokens (with Wikipedia title and "[SEP]")
recent development of neural information retrieval models, especially the interaction based ones, have shown promising effectiveness in extracting soft match patterns from query-document interactions (Hu et al., 2014;</ref>Pang et al., 2016;</ref>Guo et al., 2016;</ref>Xiong e
arget="#b10">(Hu et al., 2014;</ref>Pang et al., 2016;</ref>Guo et al., 2016;</ref>Xiong et al., 2017;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref><ref typ 7;</ref>Dai et al., 2018)</ref>. One of the effective ways to model text matches is to leverage matching kernels (Xiong et al., 2017;</ref>Dai et al., 2018)</ref>, which summarize word or phrase interactions in the learned embedding space between query and documents. The kernel extracts matching patterns whi p j ).<label>(6)</label></formula><p>Then we use K kernels to extract the matching feature K(M q→p i</p><p>) from the translation matrix M q→p (Xiong et al., 2017;</ref>Dai et al., 2018;</ref>Qiao et al., 2019;</ref>MacAvaney et al., 2019)</ref>:</p><formula xml:id="formula_8"
elevant sub-components between premise and hypothesis. BERT, the pre-trained deep bidirectional Transformer, has also been used for better text representation in FEVER and achieved better performance (Devlin et al., 2019;</ref>Li et al., 2019;</ref>Zhou et al., 2019;</ref>Sole ">Initial Node Representations</head><p>The node representations are initialized by feeding the concatenated sequence of claim, document (Wiki) title, and evidence sentence, to pre-trained BERT model (Devlin et al., 2019)</ref>. Specifically, in the node n p , the claim and evidence correspond to m tokens (with "[SEP]") and n tokens (with Wikipedia title and "[SEP]")
mance. These graph based models establish node interactions for joint reasoning over several evidence pieces.</p><p>Many fact verification systems leverage Natural Language Inference (NLI) techniques (Chen et al., 2017b;</ref>Ghaeini et al., 2018;</ref>Parikh et al., 2016;</ref>Radford et al ter requires systems to find the evidence pieces themselves and there are often multiple evidence pieces. One of the most widely used NLI models in FEVER is Enhanced Sequential Inference Model (ESIM) (Chen et al., 2017b)</ref>, which employs some forms of hard or soft alignment to associate the relevant sub-components between premise and hypothesis. BERT, the pre-trai
mance. These graph based models establish node interactions for joint reasoning over several evidence pieces.</p><p>Many fact verification systems leverage Natural Language Inference (NLI) techniques (Chen et al., 2017b;</ref>Ghaeini et al., 2018;</ref>Parikh et al., 2016;</ref>Radford et al ter requires systems to find the evidence pieces themselves and there are often multiple evidence pieces. One of the most widely used NLI models in FEVER is Enhanced Sequential Inference Model (ESIM) (Chen et al., 2017b)</ref>, which employs some forms of hard or soft alignment to associate the relevant sub-components between premise and hypothesis. BERT, the pre-trai

m deep teachers. Different alternatives have been proposed to this end, which compare networks' internal layers in addition to final predictions (Jiao et al. 2019;</ref>Sun et al. 2020</ref>Sun et al. , 2019))</ref>, but they also suffer from other types of problems. The main goal in this paper is to study such models a layer (h i,j S $ h i,l T ). PKD is not the only model that utilizes internal layers' information. Other models such as TinyBERT (Jiao et al. 2019)</ref> and MobileBERT (Sun et al. 2020</ref>) also found it crucial for training competitive student models. However, as Equation 3</ref>shows, in these models only m teac
and this becomes even more crucial when distilling from deep teachers. Different alternatives have been proposed to this end, which compare networks' internal layers in addition to final predictions (Jiao et al. 2019;</ref>Sun et al. 2020</ref>Sun et al. , 2019))</ref>, but they also suffer from other types of problems usly mentioned, layer connections are denoted by A.</p><p>A common heuristic to devise A is to divide teacher layers into m buckets with approximately the same sizes and pick only one layer from each (Jiao et al. 2019;</ref>Sun et al. 2019)</ref>. Therefore, for the j-th layer of the student model, A(j) returns a single teacher layer among those that j-th student layer should be compared to the output of the l-th teacher layer (h i,j S $ h i,l T ). PKD is not the only model that utilizes internal layers' information. Other models such as TinyBERT (Jiao et al. 2019)</ref> and MobileBERT (Sun et al. 2020</ref>) also found it crucial for training competitive student models. However, as



their teachers and showed how KD could be treated as a complementary training ingredient.</p><p>Tan et al. ( 2019</ref>) squeezed multiple translation engines into one transformer (Vaswani et al. 2017</ref>) and showed that knowledge can be distilled from multiple teachers. Wei et al. (2019)</ref> introduced a novel
ning. In their method, lower layers are trained first and training is progressively shifted to upper layers. They claim that the way internal layers are trained during KD can play a significant role. Liu et al. (2019)</ref> investigated KD from another perspective. Instead of focusing on the compression aspect, they kept the size of student models equal to their teac
a">2019</ref>) squeezed multiple translation engines into one transformer (Vaswani et al. 2017</ref>) and showed that knowledge can be distilled from multiple teachers. Wei et al. (2019)</ref> introduced a novel training procedure where there is no need for an external teacher. A student model can learn from its own checkpoints. At each
ion loss. Furthermore, what is denoted by A directly impacts quality. If A skips an important layer the student model may fail to provide high-quality results.</p><p>To tackle this problem, Wu et al. (2020)</ref> proposed a combinatorial technique, called CKD. In their model, A(j) returns a subset of teacher layers instead of a single layer. Those layers are combined j =F r ( Ĉj ) [ m j=1 A(j) ={h 1 T , ..., h n T } (4)</formula><p>where Ĉj is the result of a combination produced by the function F c given a subset of teacher layers indicated by A(j). In Wu et al. (2020)</ref>, F c is implemented via a simple concatenation. Depending on the form of combination used in Equation 4</ref>, there might be a dimension odels are directly related to this research so we consider them as baselines in our experiments.</p><p>The application of KD in NLP and NLU is not limited to the aforementioned models. Aguilar et al. (2020)</ref> followed the same architecture as PKD but they introduced a new training regime, called progressive training. In their method, lower layers are trained first eed to decide about the learning rate, batch size, the number of fine-tuning epochs, and , ⌘, and . To this end, we run a grid search similar to Sun et al. (2019)</ref> and Wu et al. (2020)</ref>. For our experiments, the batch size is set to 32 and the learning rate is selected from {1e 5, 2e 5, 5e 5}. ⌘ and take values from the set {0, 0.2, 0.5, 0.7

a">2019</ref>) squeezed multiple translation engines into one transformer (Vaswani et al. 2017</ref>) and showed that knowledge can be distilled from multiple teachers. Wei et al. (2019)</ref> introduced a novel training procedure where there is no need for an external teacher. A student model can learn from its own checkpoints. At each

neural networks (Sanh et al. 2019)</ref>. Apart from this, we also consider it as a complementary and generic add-on to enrich the training process of any neural model (Furlanello et al. 2018)</ref>.</p><p>In KD, a student network (S) is glued to a powerful teacher (T ) during training. These two networks can be trained simultaneously
neural networks (Sanh et al. 2019)</ref>. Apart from this, we also consider it as a complementary and generic add-on to enrich the training process of any neural model (Furlanello et al. 2018)</ref>.</p><p>In KD, a student network (S) is glued to a powerful teacher (T ) during training. These two networks can be trained simultaneously
ning. In their method, lower layers are trained first and training is progressively shifted to upper layers. They claim that the way internal layers are trained during KD can play a significant role. Liu et al. (2019)</ref> investigated KD from another perspective. Instead of focusing on the compression aspect, they kept the size of student models equal to their teac
ning. In their method, lower layers are trained first and training is progressively shifted to upper layers. They claim that the way internal layers are trained during KD can play a significant role. Liu et al. (2019)</ref> investigated KD from another perspective. Instead of focusing on the compression aspect, they kept the size of student models equal to their teac
ning. In their method, lower layers are trained first and training is progressively shifted to upper layers. They claim that the way internal layers are trained during KD can play a significant role. Liu et al. (2019)</ref> investigated KD from another perspective. Instead of focusing on the compression aspect, they kept the size of student models equal to their teac

ning. In their method, lower layers are trained first and training is progressively shifted to upper layers. They claim that the way internal layers are trained during KD can play a significant role. Liu et al. (2019)</ref> investigated KD from another perspective. Instead of focusing on the compression aspect, they kept the size of student models equal to their teac
their teachers and showed how KD could be treated as a complementary training ingredient.</p><p>Tan et al. ( 2019</ref>) squeezed multiple translation engines into one transformer (Vaswani et al. 2017</ref>) and showed that knowledge can be distilled from multiple teachers. Wei et al. (2019)</ref> introduced a novel
ning. In their method, lower layers are trained first and training is progressively shifted to upper layers. They claim that the way internal layers are trained during KD can play a significant role. Liu et al. (2019)</ref> investigated KD from another perspective. Instead of focusing on the compression aspect, they kept the size of student models equal to their teac




a">2019</ref>) squeezed multiple translation engines into one transformer (Vaswani et al. 2017</ref>) and showed that knowledge can be distilled from multiple teachers. Wei et al. (2019)</ref> introduced a novel training procedure where there is no need for an external teacher. A student model can learn from its own checkpoints. At each




neural networks (Sanh et al. 2019)</ref>. Apart from this, we also consider it as a complementary and generic add-on to enrich the training process of any neural model (Furlanello et al. 2018)</ref>.</p><p>In KD, a student network (S) is glued to a powerful teacher (T ) during training. These two networks can be trained simultaneously
ning. In their method, lower layers are trained first and training is progressively shifted to upper layers. They claim that the way internal layers are trained during KD can play a significant role. Liu et al. (2019)</ref> investigated KD from another perspective. Instead of focusing on the compression aspect, they kept the size of student models equal to their teac
age passing between direct neighbors in the graph (Kipf and Welling, 2017;</ref>Veličković et al., 2018)</ref> or variants of Transformer (Vaswani et al., 2017)</ref> that apply self-attention on all nodes together, including those that are not directly connected. To avoid losing information, the latter ap ., 2018)</ref>.</p><p>Other approaches (Zhu et al., 2019;</ref>Cai and Lam, 2020)</ref> base their encoder on the Transformer architecture (Vaswani et al., 2017)</ref> and thus, in each layer, compute self-attention on all nodes, not only direct neighbors, facilitating the information flow between distant n view.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Graformer Model</head><p>Graformer follows the general multi-layer encoderdecoder pattern known from the original Transformer (Vaswani et al., 2017)</ref>. In the following, we first describe our formalization of the KG input and then how it is processed by Graformer.</p></div> <div xmlns="http computation of attention weights for multi-head self-attention. Note that the formulas describe the computations for one head. The output of multiple heads is combined as in the original Transformer (Vaswani et al., 2017)</ref>.</p><p>Text self-attention. Shaw et al. (2018)</ref> introduced position-aware self-attention in the Transfor ty SVD is subject to both corresponding facts.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Graformer decoder</head><p>Our decoder follows closely the standard Transformer decoder (Vaswani et al., 2017)</ref>, except for the modifications suggested by Chen et al. (2018)</ref>. Hidden decoder representation. The initial decoder rep d embedding matrix E ∈ R |Σ|×d , i.e., H (0) i = e l(n i ) E where e l(n i ) is the one-hotencoding of the ith node's label.</p><p>To compute the node representation H (L) in the Lth layer, we follow Vaswani et al. (2017)</ref>, i.e., we first normalize the input from the previous layer H (L−1) via layer normalization LN , followed by multi-head graph self-attention
V ij )<label>(5)</label></formula><p>where σ (•) denotes the softmax function, i.e.,</p><formula xml:id="formula_7">σ (b) i = exp (b i ) J j=1 exp (b j )</formula><p>, for b ∈ R J .</p><p>Recent work (Raffel et al., 2019</ref>) has adopted a simplified form where value-modifying embeddings A V are omitted and key-modifying embeddings A K are replaced with learned sca target="#b30">Shaw et al. (2018)</ref> share their position embeddings across attention heads but learn separate embeddings for each layer as word representations from different layers can vary a lot.Raffel et al. (2019)</ref> learn separate S matrices for each attention head but share them across layers. We useRaffel et al. (2019)</ref rd representations from different layers can vary a lot.Raffel et al. (2019)</ref> learn separate S matrices for each attention head but share them across layers. We useRaffel et al. (2019)</ref>'s form of relative position encoding for text self-attention in our decoder ( § 3.4). Graph self-attention.</figDesc></figure> <figure xmlns="
ion before. Various solutions orthogonal to our approach have been proposed in recent work: By 2 abstract meaning representation incorporating a connectivity score into their graph attention network, Zhang et al. (2020)</ref> manage to increase the attention span to k-hop neighborhoods but, finally, only experiment with k = 2. Our graph encoder efficiently handles de
he results of our evaluation on AGENDA in terms of BLEU (Papineni et al., 2002)</ref>, METEOR (Banerjee and Lavie, 2005)</ref>, and CHRF++ (Popović, 2017)</ref>. Like the models we compare with, we report the average and standard deviation of 4 runs with different random seeds.</p><p>Our model outperforms p
et al., 2017); Graph Conv. from(Marcheggiani and Perez-Beltrachini, 2018)</ref>; GTR-LSTM from(Trisedya et al., 2018)</ref>; E2E GRU from(Castro Ferreira et al., 2019)</ref>. Number of parameters in millions.</note></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Tabl
ion before. Various solutions orthogonal to our approach have been proposed in recent work: By 2 abstract meaning representation incorporating a connectivity score into their graph attention network, Zhang et al. (2020)</ref> manage to increase the attention span to k-hop neighborhoods but, finally, only experiment with k = 2. Our graph encoder efficiently handles de
et al., 2017); Graph Conv. from(Marcheggiani and Perez-Beltrachini, 2018)</ref>; GTR-LSTM from(Trisedya et al., 2018)</ref>; E2E GRU from(Castro Ferreira et al., 2019)</ref>. Number of parameters in millions.</note></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Tabl
s the encoder in their encoder-decoder architectures (Marcheggiani and Perez-Beltrachini, 2018;</ref>Koncel-Kedziorski et al., 2019;</ref>Ribeiro et al., 2019;</ref>Guo et al., 2019)</ref>. As one layer of these encoders only considers immediate neighbors, a large number of s
2017)</ref>. While the latter contains crowd-sourced texts corresponding to subgraphs from various DBPedia categories, the former was automatically created by applying an information extraction tool (Luan et al., 2018)</ref> on a corpus of scientific abstracts (Ammar et al., 2018)</ref>. As this process is noisy, we corrected 7 train in
redict the text sequence. Typical encoder choices are graph neural networks based on message passing between direct neighbors in the graph (Kipf and Welling, 2017;</ref>Veličković et al., 2018)</ref> or variants of Transformer (Vaswani et al., 2017)</ref> that apply self-attention on all nodes together, in
="5.1">Overall performance</head><p>Table 2</ref> shows the results of our evaluation on AGENDA in terms of BLEU (Papineni et al., 2002)</ref>, METEOR (Banerjee and Lavie, 2005)</ref>, and CHRF++ (Popović, 2017)</ref>. Like the models we compare with, we report the average and standard dev
et="#b23">[24,</ref>33]</ref>, mispredictions from data-dependent branches remain the single most important category of mispredictions to tackle. Prior works like EXACT [9]</ref>, SLB [18]</ref> have proposed different techniques to lower the mispredictions from such data-dependent branches. These include m hat have addressed data dependent branches and their limitations.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Existing Techniques to Handle Data Dependent Branches</head><p>EXACT [9]</ref> is a branch prediction technique proposed to lower mispredictions from data dependent branches. By distinguishing branch instances based on their feeder load's ing the store-load-branch dependency.</p><p>Though, the set of distinct load-branch and store-branch pairs that need to get tracked quickly increase the storage requirement over 10KB. As mentioned in [9]</ref>, EXACT predictor does not win over an similarly sized TAGE predictor.</p><p>Learning from EXACT's limitations, our proposal targets very specific cases of data ection of the branches that have only one feeding load and only simple computations in the data path leading to the branch. To enable this, we employ a scheme similar to EXACT predictor ID generation [9]</ref> where the ARF is extended to track the load addresses. Instead of tracking the load address, we track the load PCs and any operations that alter the load value igure" target="#fig_4">3(b</ref>)), a possible optimization is to find the store prior to the load that wrote to the same address and use the store data value for override. EXACT's active update unit [9]</ref> and SLB [18]</ref> use this observation, but the hardware requirements were prohibitive for EXACT and SLB requires ISA extensions t="#b38">39]</ref> on enhancing branch predictors based on the correlation with prior data values seen. But, when data has high entropy, it affects their accuracy. Among recent works, EXACT predictor [9]</ref> proposes associating data dependent branches with their corresponding producer load address and using this information to disambiguate and uniquely predict mult earned dependence chains (feeder load PC, intermediate operations and 3D-Branch PC) are sent to the BT. We assume that opcode and other instruction metadata is available with the ROB entry similar to [9,</ref>28]</ref>.</p><p>1) 3D-Branch Tracker Table (BT): Each entry has 1 valid bit, 8 bits for branch PC tag, 4 bits for tracking the pe
This information, referred to as global branch history, is then used to predict the incoming branch's direction. Branch predictor proposals in literature track specific branches in the global history [27]</ref> or only use the specific branch's prior history (referred to as local history) to provide a prediction. TAgged GEometric history length predictor (TAGE) <ref
tors are to track the dependence chain of branches and when some of the registers in the dependence chain are ready, a predictor table is looked up to obtain a prediction. Branch Outcome Anticipation [17]</ref> also looked at reducing the branch misprediction penalty rather than improving the branch accuracy. For unconfident predictions, <ref type="bibr" target="#b9" nalty. These works are complementary to our proposal and can be implemented on top of the 3D-Branch Overrider for additional gains. Even though the target of [10]</ref>, [17]</ref> and our work is to reduce the branch misprediction penalty, our approach is distinctive in two ways: (1) they do not examine the data-dependent branches as th
D-Branch Overrider, i) Accelerate the execution of the feeder load instruction, ii) Feed the value from a prior store that wrote to same address as the feeder load using a memory dependence predictor [40]</ref>, iii) Predict the load address and prefetch the load value. While each of them improve the gains from 3D-Branch Overrider, predicting the load address and pre ile a load-store PC pair sees up to 380 data values and 260 different addresses. Therefore, to limit the hardware requirements, we enhance 3D-Branch Overrider with a Memory Dependence Predictor (MDP) [40]</ref> to capture the strongly correlated store PC-load PC pairs that have producer-consumer relationship. If the load has not yet completed but a strongly correlate
ch Overrider.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RELATED WORK</head><p>Prior works such as [11,</ref>16,</ref>19,</ref>22,</ref>39]</ref> on enhancing branch predictors based on the correlation with prior data values
ATED WORK</head><p>Prior works such as [11,</ref>16,</ref>19,</ref>22,</ref>39]</ref> on enhancing branch predictors based on the correlation with prior data values seen. But, when data has high entropy, it affects their accuracy. Among recent w
#b32">33]</ref>, mispredictions from data-dependent branches remain the single most important category of mispredictions to tackle. Prior works like EXACT [9]</ref>, SLB [18]</ref> have proposed different techniques to lower the mispredictions from such data-dependent branches. These include mechanisms to track the store addresses and th ding near the allocation queue for increased coverage. Further, by computing the actual branch direction from the load value allows us to have higher accuracy.</p><p>Store-Load-Branch (SLB) predictor [18]</ref> tracks the stores that feed the value to the data-dependent branches, and uses profiling and compilers to mark data-dependent branches with ISA extensions. Si ptimization is to find the store prior to the load that wrote to the same address and use the store data value for override. EXACT's active update unit [9]</ref> and SLB [18]</ref> use this observation, but the hardware requirements were prohibitive for EXACT and SLB requires ISA extensions.</p><p>In our studies as well, we find that pai nt branch PC. Unlike the EX-ACT predictor, our work uses the load value to compute the branch direction and accomplishes this at much less storage. We also discussed Store-load-branch (SLB) predictor [18]</ref> which requires compiler support to identify the store that produces the value eventually feeding into the data-dependent branches. Control Flow Decoupling (CF

This information, referred to as global branch history, is then used to predict the incoming branch's direction. Branch predictor proposals in literature track specific branches in the global history [27]</ref> or only use the specific branch's prior history (referred to as local history) to provide a prediction. TAgged GEometric history length predictor (TAGE) <ref
eder load is dependent on). This allows the address computation to be completed early, consequently, allowing the loads value to be available earlier as well. We leverage from prior proposals such as [10,</ref>12]</ref> to build a simple and efficient module to capture the dependence chain of instructions which can then be prioritized fo Branch Outcome Anticipation [17]</ref> also looked at reducing the branch misprediction penalty rather than improving the branch accuracy. For unconfident predictions, [10]</ref> proposes to prioritize the issue of the instructions on the backslice of a branch to reduce the branch misprediction penalty. These works are complementary to anch to reduce the branch misprediction penalty. These works are complementary to our proposal and can be implemented on top of the 3D-Branch Overrider for additional gains. Even though the target of [10]</ref>, [17]</ref> and our work is to reduce the branch misprediction penalty, our approach is distinctive in two ways: (1) they do not

ants operating over real-world services having a very large and dy-namic set of possible values. Addressing these concerns, approaches utilizing a dynamic vocabulary of slot values have been proposed (Rastogi, Gupta, and Hakkani-Tur 2018;</ref>Goel, Paul, and Hakkani-Tür 2019;</ref>Wu et al. 2019</ref>).</p rvices' schemas using descriptions of intents and slots. These models, however, also need access to representations for potentially unseen inputs from new services. Recent pretrained models like ELMo (Peters et al. 2018)</ref> and BERT (Devlin et al. 2019</ref>) can help, since they are trained on very large corpora. Building upon these,
both for end-to-end and modular systems involving dialogue state tracking and policy learning. This line of work has been facilitated by the release of multi-domain dialogue corpora such as MultiWOZ (Budzianowski et al. 2018)</ref>, M2M (Shah et al. 2018</ref>) and FRAMES (El Asri et al. 2017)</ref>.</p><p> s include WOZ2.0 (Wen et al. 2017</ref>), FRAMES (El Asri et al. 2017)</ref>, M2M (Shah et al. 2018</ref>) and Multi-WOZ (Budzianowski et al. 2018</ref>). These datasets have utilized a variety of data collection techniques, falling within two broad categories:</p><p>• Wizard-of-Oz This set
ges (Williams et al. 2013;</ref>Henderson, Thomson, and Williams 2014a;</ref>Henderson, Thomson, and Williams 2014b;</ref>Kim et al. 2017</ref>) contributed to the creation of dialogue datasets with increasing complexity. Other notable related datasets include WOZ2.0 <ref type="bibr" target
rtual assistants incorporate diverse domains, recent work has focused on zero-shot modeling (Bapna et al. 2017;</ref>Xia et al. 2018;</ref>Shah et al. 2019)</ref>, domain adaptation and transfer learning techniques (Rastogi, Hakkani-Tür, and Heck 2017)</ref>. Deep-learning bas
by the release of multi-domain dialogue corpora such as MultiWOZ (Budzianowski et al. 2018)</ref>, M2M (Shah et al. 2018</ref>) and FRAMES (El Asri et al. 2017)</ref>.</p><p>However, existing datasets for multi-domain task-oriented dialogue do not sufficiently capture a number of challenges that arise with s
rtual assistants incorporate diverse domains, recent work has focused on zero-shot modeling (Bapna et al. 2017;</ref>Xia et al. 2018;</ref>Shah et al. 2019)</ref>, domain adaptation and transfer learning techniques (Rastogi, Hakkani-Tür, and Heck 2017)</ref>. Deep-learning bas
by the release of multi-domain dialogue corpora such as MultiWOZ (Budzianowski et al. 2018)</ref>, M2M (Shah et al. 2018</ref>) and FRAMES (El Asri et al. 2017)</ref>.</p><p>However, existing datasets for multi-domain task-oriented dialogue do not sufficiently capture a number of challenges that arise with s
ken language understanding for flights. The Dialogue State Tracking Challenges (Williams et al. 2013;</ref>Henderson, Thomson, and Williams 2014a;</ref>Henderson, Thomson, and Williams 2014b;</ref>Kim et al. 2017</ref>) contributed to the creation of dialogue datasets with increasing comple
ll possible slot-values (Henderson, Thomson, and Young 2014;</ref>Wen et al. 2017)</ref> or individually score all slot-value combinations (Mrkšić et al. 2017;</ref>Zhong, Xiong, and Socher 2018)</ref>. Such approaches are not practical for deployment in virtual assistants ope
hes have achieved state of the art performance on dialogue state tracking tasks. Popular approaches on small-scale datasets estimate the dialogue state as a distribution over all possible slot-values (Henderson, Thomson, and Young 2014;</ref>Wen et al. 2017)</ref> or individually score all slot-value combinations <ref type="bibr" target=
datasets for multi-domain task-oriented dialogue do not sufficiently capture a number of challenges that arise with scaling virtual assistants in production. These assistants need to support a large (Kim et al. 2018)</ref>, constantly increasing number of services over a large number of domains. In comparison, existing public datasets cover few domains. Furthermore,
ges (Williams et al. 2013;</ref>Henderson, Thomson, and Williams 2014a;</ref>Henderson, Thomson, and Williams 2014b;</ref>Kim et al. 2017</ref>) contributed to the creation of dialogue datasets with increasing complexity. Other notable related datasets include WOZ2.0 <ref type="bibr" target
" target="#b0">(Bapna et al. 2017;</ref>Xia et al. 2018;</ref>Shah et al. 2019)</ref>, domain adaptation and transfer learning techniques (Rastogi, Hakkani-Tür, and Heck 2017)</ref>. Deep-learning based approaches have achieved state of the art performance on dialogue state tracking tasks. Popular approach
hes have achieved state of the art performance on dialogue state tracking tasks. Popular approaches on small-scale datasets estimate the dialogue state as a distribution over all possible slot-values (Henderson, Thomson, and Young 2014;</ref>Wen et al. 2017)</ref> or individually score all slot-value combinations <ref type="bibr" target=
a dynamic vocabulary of slot values have been proposed (Rastogi, Gupta, and Hakkani-Tur 2018;</ref>Goel, Paul, and Hakkani-Tür 2019;</ref>Wu et al. 2019</ref>).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Schema-Guided Dialogue Dataset</head><p>An important goal of this work is to cr
hes have achieved state of the art performance on dialogue state tracking tasks. Popular approaches on small-scale datasets estimate the dialogue state as a distribution over all possible slot-values (Henderson, Thomson, and Young 2014;</ref>Wen et al. 2017)</ref> or individually score all slot-value combinations <ref type="bibr" target=
ges (Williams et al. 2013;</ref>Henderson, Thomson, and Williams 2014a;</ref>Henderson, Thomson, and Williams 2014b;</ref>Kim et al. 2017</ref>) contributed to the creation of dialogue datasets with increasing complexity. Other notable related datasets include WOZ2.0 <ref type="bibr" target
he underlying crowd worker task is simpler, and semantic annotations are obtained automatically.</p><p>As virtual assistants incorporate diverse domains, recent work has focused on zero-shot modeling (Bapna et al. 2017;</ref>Xia et al. 2018;</ref>Shah et al. 2019)</ref>, domain adaptation and transfer learn
ll possible slot-values (Henderson, Thomson, and Young 2014;</ref>Wen et al. 2017)</ref> or individually score all slot-value combinations (Mrkšić et al. 2017;</ref>Zhong, Xiong, and Socher 2018)</ref>. Such approaches are not practical for deployment in virtual assistants ope
hes have achieved state of the art performance on dialogue state tracking tasks. Popular approaches on small-scale datasets estimate the dialogue state as a distribution over all possible slot-values (Henderson, Thomson, and Young 2014;</ref>Wen et al. 2017)</ref> or individually score all slot-value combinations <ref type="bibr" target=
a dynamic vocabulary of slot values have been proposed (Rastogi, Gupta, and Hakkani-Tur 2018;</ref>Goel, Paul, and Hakkani-Tür 2019;</ref>Wu et al. 2019</ref>).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Schema-Guided Dialogue Dataset</head><p>An important goal of this work is to cr
nderson, Thomson, and Young 2014;</ref>Wen et al. 2017)</ref> or individually score all slot-value combinations (Mrkšić et al. 2017;</ref>Zhong, Xiong, and Socher 2018)</ref>. Such approaches are not practical for deployment in virtual assistants operating over real-world services having a very large and d
ure-based task.</p><p>Only recently a formal study of the distinguishing power of some GNN variants has been initiated. In two independent studies [Xu et al., 2019</ref>, Morris et al., 2019]</ref> the distinguishing power of GNNs is linked to the distinguishing power of the classical Weisfeiler-Lehman (WL) algorithm. The WL algorithm s Ns that do not use degree information, and degree-aware MPNNs that do use degree information. The former class of MPNNs covers the GNNs studied in [Xu et al., 2019</ref>, Morris et al., 2019]</ref>, the latter class covers the GCNs [Kipf and Welling, 2017]</ref>, among others.</p><p>Contributions. For gener istinguishing power of the classes of anonymous and degree-aware MPNNs matches that of the WL algorithm.</p><p>For anonymous MPNNs related to GNNs [Xu et al., 2019</ref>, Morris et al., 2019]</ref> and degree-aware MPNNs related to GCNs [Kipf and Welling, 2017]</ref>, our main results are the following (see hat will play an important role in Section 5.</p><p>Example 3.1 (GNN architectures). We first consider the graph neural network architectures [Hamilton et al., 2017</ref>, Morris et al., 2019]</ref> defined by:</p><formula xml:id="formula_8">L (t) := σ L (t−1) W (t) 1 + AL (t−1) W (t) 2 + B (t) ,<label>(1)</label></formula><p>where L (t) guishing power of anonymous MPNNs (or aMPNNs, for short) is well understood. Indeed, as we will shortly see, it follows from two independent works [Xu et al., 2019</ref>, Morris et al., 2019]</ref> that the distinguishing power of aMPNNs can be linked to the distinguishing power of the WL algorithm.</p><p>Let (G, ν ν ν) be a labelled gr 5.1 we only need that M anon is weaker than M WL , as is indicated in Figure 1</ref>. Proposition 5.2 (Based on [Xu et al., 2019</ref>, Morris et al., 2019]</ref>). The classes M anon and M WL are equally strong.</p><p>Proof. First, we prove that M WL is weaker than M anon . It suffices to note that M ponding to specific linear-algebra-based architectures of graph neural networks. We again distinguish between anonymous graph neural networks [Hamilton et al., 2017</ref>, Morris et al., 2019]</ref> and degree-aware graph neural networks [Kipf and</ref>Welling, 2017, Meltzer et al., 2019]</r ) The distinguishing power of anonymous MPNNs is bounded by the WL algorithm. This result can be seen as a slight generalisation of the results in [Xu et al., 2019</ref>, Morris et al., 2019</ref>]. (ii) The distinguishing power of degree-aware MPNNs is bounded by the WL algorithm, but they may be one step ahead. Intuitively, degree-awa Propositions 6.9 and 6.10):</p><p>(iv) On a fixed input graph, the WL algorithm can be simulated, step-by-step, by GNNs that use ReLU or sign as activation function. This result refines the result in [Morris et al., 2019]</ref> in that their simulation using the ReLU function requires two GNN "layers" for each step of the WL algorithm. We only require one layer in ea ext. Recall that the class of anonymous MPNNs is denoted M anon . Finally, we introduce two classes of aMPNNs which are of special interest: those arising from the graph neural networks considered in [Morris et al., 2019]</ref>. In Example 3.1 we established that such graph neural networks correspond to aMPNNs. Let us denote by M σ GNN the class of aMPNNs with messag non .</p><p>It remains to argue that M anon is weaker than M WL . The proof is a trivial adaptation of the proofs of Lemma 2 in [Xu et al., 2019]</ref> and Theorem 5 in [Morris et al., 2019]</ref>. We show, by induction on the number of rounds of computation, that ℓ ℓ ℓ</p><formula xml:id="formula_32">(t) MWL ⊑ ℓ ℓ ℓ (t)</formula><p>M f (t) v = UPD (t) (ℓ ℓ ℓ (t−1) M ) w , m (t) w = (ℓ ℓ ℓ (t) M ) w ,</formula><p>as desired.</p><p>We remark that we cannot use the results in [Xu et al., 2019]</ref> and [Morris et al., 2019]</ref> as a black box because the class M anon is more general than the class considered in those papers. The proofs in <ref type="bibr" target="#b1 [Morris et al., 2019]</ref> as a black box because the class M anon is more general than the class considered in those papers. The proofs in [Xu et al., 2019]</ref> and [Morris et al., 2019]</ref> relate to graph neural networks which, in round t ≥ 1, compute for each vertex v a label ℓ ℓ ℓ</p><formula xml:id="formula_39">(t) v , as fol and is thus also weaker than M WL .</p><p>More challenging is to show that M sign GNN , M ReLU GNN and M WL , and thus also M anon , are equally strong. The following results are known. Theorem 5.5 ( [Morris et al., 2019]</ref>). (i) The classes M sign GNN and M WL are equally strong. (ii) The class M ReLU GNN is weaker than M WL , and M WL is weaker than M ReLU GNN wo-fold application of the ReLU function. We next show that this factor of two can be avoided. As a side effect, we obtain a simpler aMPNN M in M GNN , satisfying M WL M , than the one constructed in [Morris et al., 2019]</ref>. The proof strategy is inspired by that of [Morris et al., 2019]</ref>. Crucial in the proof is the notion of de effect, we obtain a simpler aMPNN M in M GNN , satisfying M WL M , than the one constructed in [Morris et al., 2019]</ref>. The proof strategy is inspired by that of [Morris et al., 2019]</ref>. Crucial in the proof is the notion of row-independence modulo equality, which we define next. Definition 5.6 (Row-independence modulo equali Note that, in contrast to aMPNNs of the form (3), we only have one weight matrix per round, instead of two, at the cost of introducing an extra parameter p ∈ A. Furthermore, the aMPNN constructed in [Morris et al., 2019]</ref> uses two distinct weight matrices in A (st−1+s0)×(st+s0) (we come back to this at the end of this section) whereas our weight matrices are el order of rows is irrelevant). We denote the rows in uniq(L (t−1) ) by a 1 , . . . , a m ∈ A st−1 . By the induction hypothesis, these rows are linearly independent. Following the same argument as in [Morris et al., 2019]</ref>, this implies that there exists an (s t−1 × m)-matrix U (t)  such that uniq(L (t−1) )U (t) = I. Let us denote by e 1 , . . . , e m ∈ A m the ion function. Importantly, its application should ensure row-independence modulo equality and make sure the labelling "refines" ℓ ℓ ℓ (t) MWL . To do so, we again follow closely the proof strategy of [Morris et al., 2019]</ref>. More specifically, we will need an analogue of the following result. In the sequel we denote by J a matrix with all entries having value 1 a ly, we will need an analogue of the following result. In the sequel we denote by J a matrix with all entries having value 1 and whose size will be determined from the context. Lemma 5.9 (Lemma 9 from [Morris et al., 2019]</ref>). Let C ∈ A m×w be a matrix in which all entries are non-negative and all rows are pairwise disjoint. Then there exists a matrix X ∈ A w×m su urthermore, at least one entry must be distinct from 0. Also, λ λ λ</p><p>w implies that the positions of the non-zero entries in µ µ µ Regarding future work, we point out that, following the work of [Morris et al., 2019]</ref>, we fix the input graph in our analysis. We use this particularly when we prove that certain classes of MPNNs, based on graph neural network
nsidered the same with regards to any subsequent feature-based task.</p><p>Only recently a formal study of the distinguishing power of some GNN variants has been initiated. In two independent studies [Xu et al., 2019</ref>, Morris et al., 2019]</ref> the distinguishing power of GNNs is linked to the distinguishing power of the classical consider two general classes of MPNNs: anonymous MPNNs that do not use degree information, and degree-aware MPNNs that do use degree information. The former class of MPNNs covers the GNNs studied in [Xu et al., 2019</ref>, Morris et al., 2019]</ref>, the latter class covers the GCNs [Kipf and Welling, 2017 he following (see Propositions 5.2 and 6.3):</p><p>(i) The distinguishing power of anonymous MPNNs is bounded by the WL algorithm. This result can be seen as a slight generalisation of the results in [Xu et al., 2019</ref>, Morris et al., 2019</ref>]. (ii) The distinguishing power of degree-aware MPNNs is bounded by the WL algorithm, bu also as a degree-aware MPNN). As a consequence, the distinguishing power of the classes of anonymous and degree-aware MPNNs matches that of the WL algorithm.</p><p>For anonymous MPNNs related to GNNs [Xu et al., 2019</ref>, Morris et al., 2019]</ref> and degree-aware MPNNs related to GCNs [Kipf and Welling, previous labels of the vertices involved. The distinguishing power of anonymous MPNNs (or aMPNNs, for short) is well understood. Indeed, as we will shortly see, it follows from two independent works [Xu et al., 2019</ref>, Morris et al., 2019]</ref> that the distinguishing power of aMPNNs can be linked to the distinguishing power of th ually strong. We remark that in the proof of Theorem 5.1 we only need that M anon is weaker than M WL , as is indicated in Figure 1</ref>. Proposition 5.2 (Based on [Xu et al., 2019</ref>, Morris et al., 2019]</ref>). The classes M anon and M WL are equally strong.</p><p>Proof. First, we prove that M W assume that the set Σ of labels is A s for some fixed s ∈ N + . We cast the WL algorithm as an anonymous MPNN by using an injection h : A s → Q. What follows is in fact an adaptation of Lemma 5 from [Xu et al., 2019]</ref> itself based on [Zaheer et al., 2017, Theorem 2]</ref>. We crucially rely on the fact that the set A of algebraic numbers is cou ve that M WL is weaker than M anon . It suffices to note that M WL ⊆ M anon .</p><p>It remains to argue that M anon is weaker than M WL . The proof is a trivial adaptation of the proofs of Lemma 2 in [Xu et al., 2019]</ref> and Theorem 5 in [Morris et al., 2019]</ref>. We show, by induction on the number of rounds of computation, that ℓ rmula_38">(ℓ ℓ ℓ (t) M ) v = UPD (t) (ℓ ℓ ℓ (t−1) M ) v , m (t) v = UPD (t) (ℓ ℓ ℓ (t−1) M ) w , m (t) w = (ℓ ℓ ℓ (t) M ) w ,</formula><p>as desired.</p><p>We remark that we cannot use the results in [Xu et al., 2019]</ref> and [Morris et al., 2019]</ref> as a black box because the class M anon is more general than the class considered [Xu et al., 2019]</ref> and [Morris et al., 2019]</ref> as a black box because the class M anon is more general than the class considered in those papers. The proofs in [Xu et al., 2019]</ref> and [Morris et al., 2019]</ref> relate to graph neural networks which, in round t ≥ 1, compute for each vertex v a aggregation functions f</p><formula xml:id="formula_42">(t) aggr { {ℓ ℓ ℓ (t−1) u | u ∈ N G (v)} } can be written in the form g (t) u∈NG(v) h (t) (ℓ ℓ ℓ (t−1) u</formula><p>) , based on Lemma 5 from [Xu et al., 2019]</ref>.</p><p>Suppose that ν ν ν : V → A s0 . It now suffices to define for every t ≥ 1, every x and y in A st−1 , every v ∈ V and u ∈ N G (u):</p><form







mples. First, we provide two examples of anonymous MPNNs that will play an important role in Section 5.</p><p>Example 3.1 (GNN architectures). We first consider the graph neural network architectures [Hamilton et al., 2017</ref>, Morris et al., 2019]</ref> defined by:</p><formula xml:id="formula_8">L (t) := σ L (t−1) W (t) 1 + AL (t−1) W er.</p><p>Furthermore, we identify classes of MPNNs corresponding to specific linear-algebra-based architectures of graph neural networks. We again distinguish between anonymous graph neural networks [Hamilton et al., 2017</ref>, Morris et al., 2019]</ref> and degree-aware graph neural networks [Kipf and</re
algorithm for edge-labelled graphs as is done for graph neural networks in [Jaume et al., 2019]</ref>.</p><p>We also want to compare our formalisation to the MPNNs from [Loukas, 2019]</ref>. In that paper, the message functions can depend on identifiers of the vertices involved. Such position-aware MPNNs correspond to MPNNs in our settin essage functions can depend on identifiers of the vertices involved. Such position-aware MPNNs correspond to MPNNs in our setting in which f assigns to each vertex a unique identifier. We remark that [Loukas, 2019]</ref> shows Turing universality of position-aware MPNNs using close connections with the LOCAL model for distributed graph computations of <ref type="bibr" Turing universality of position-aware MPNNs using close connections with the LOCAL model for distributed graph computations of [Angluin, 1980]</ref>. As such, MPNNs from [Loukas, 2019]</ref> can simulate our MPNNs as one could add a few initialisation rounds to compute f (v) and f (u). We also remark that in the MPNNs from <ref type="bibr ch, MPNNs from [Loukas, 2019]</ref> can simulate our MPNNs as one could add a few initialisation rounds to compute f (v) and f (u). We also remark that in the MPNNs from [Loukas, 2019]</ref> every vertex can also send itself a message. We provide this functionality by parameterising the update functions with the current label of the verte
pair of rational numbers to identify that root. Conveniently, it is known that the operations we will need are indeed computable for algebraic numbers encoded using such a representation (see, e.g., [Ouaknine and Worrell, 2014]</ref>).</p><p>Labelled graphs. Let G = (V, E) be an undirected graph consisting of n ∈ N vertices. Without loss of generality we assume that


pair of rational numbers to identify that root. Conveniently, it is known that the operations we will need are indeed computable for algebraic numbers encoded using such a representation (see, e.g., [Ouaknine and Worrell, 2014]</ref>).</p><p>Labelled graphs. Let G = (V, E) be an undirected graph consisting of n ∈ N vertices. Without loss of generality we assume that
The former class of MPNNs covers the GNNs studied in [Xu et al., 2019</ref>, Morris et al., 2019]</ref>, the latter class covers the GCNs [Kipf and Welling, 2017]</ref>, among others.</p><p>Contributions. For general MPNNs, our main results are the following (see Propositions 5.2 and 6.3):</p><p>(i) The dis ithm.</p><p>For anonymous MPNNs related to GNNs [Xu et al., 2019</ref>, Morris et al., 2019]</ref> and degree-aware MPNNs related to GCNs [Kipf and Welling, 2017]</ref>, our main results are the following (see Theorems 5.5 and 5.7, and Propositions 6.9 and 6.10):</p><p>(iv) On a fixed input graph, the WL al f GCNs over more classical GNNs may explain the success of GCNs in various graph learning tasks. (vi) In contrast, we show that the WL algorithm cannot be simulated by popular GCNs such as those from [Kipf and Welling, 2017]</ref>. This observation is somewhat contradictory to the general belief that GCNs can be seen as a "continuous generalisation" of the WL algorith lation of the WL algorithm can be achieved by GCNs. This minor relaxation of GCNs (see Equation ( 18</ref>) at the end of Section 6) was already suggested in [Kipf and Welling, 2017]</ref> based on empirical results. Our simulation result thus provides a theoretical justification of this parameter.</p><p>Structure of the paper ers. It is well-known that these operations are computable on numbers in N, Z and Q. However, in order to capture numbers used by popular graph neural network architectures, such as roots of integers [Kipf and Welling, 2017]</ref>, we will work with algebraic numbers. An algebraic number is usually represented by a minimal polynomial such that the number is a root of </p><p>We conclude with an example of a degree-aware MPNN. We study degree-aware MPNNs in Section 6. Example 3.3 (GCNs by Kipf and Welling)</ref>. We consider the GCN architecture by [Kipf and Welling, 2017]</ref>, which in round t ≥ 1 computes</p><formula xml:id="formula_19">L (t) := σ (D + I) −1/2 (A + I)(D + I) −1/2 L (t−1) W (t) ,</formula><p>wher asses in Section 5 that are equivalent to M WL . Similarly, for when M g M WL holds.</p><p>Quintessential examples of degree-aware MPNNs are the popular graph convolutional networks, as introduced by [Kipf and Welling, 2017]</ref>. These are of the form:</p><formula xml:id="formula_92">L (t) := σ D + I −1/2 (A + I) D + I −1/2 L (t−1) W (t) ,</formula><p>as already des a labelled graph (G, ν ν ν) such that there exists a round t ≥ 0 for which ℓ ℓ ℓ</p><formula xml:id="formula_95">(t) MWL ⊑ ℓ ℓ ℓ (t)</formula><p>M holds. We construct such an M originating from a GCN [Kipf and Welling, 2017]</ref> defined in Example 3.3. That is, M is a dMPNN in M dGNN 4 . Consider the labelled graph (G, ν ν ν) with vertex labelling ν ν ν v1 = ν ν ν v implies that g = (g(d v1 ), g(d v2 ), . . . , g(d vn )) and h = (h(d v1 ), h(d v2 ), . . . , h(d vn ))</p><p>for some functions g : N + → A + and h : N + → A + . Example 6.5. The GCN architecture of [Kipf and Welling, 2017]</ref> corresponds to graph neural networks of the form (12), with</p><formula xml:id="formula_113">W (t) 1 = 0 ∈ A st−1×st , p = 1, b (t) = 0 ∈ A (1)                = σ                              </formula><p>In particular, the class M dGNN 4 , corresponding to the popular graph neural networks of [Kipf and Welling, 2017]</ref>, is not stronger than M WL . We also remark, based on the first counterexample in the proof, that the class of aMPNNs, corresponding to sim (t) = σ (A + pI)L (t−1) W (t) − qJ results in a class of aMPNNs that is stronger than M WL . It will follow from our next result that a similar extension suffices to make the graph neural networks of [Kipf and Welling, 2017]</ref> stronger than M WL .</p><p>We will now argue that the remaining M dGNN 6 class from Table 1</ref> is stronger than M WL , orks of the form L (t) := σ D + I −1/2 (A + pI) D + I −1/2 L (t−1) W (t) − qJ ,</p><p>with p, q ∈ A, 0 ≤ p, q ≤ 1, is stronger than M WL . The introduction of the parameter p was already suggested in [Kipf and Welling, 2017]</ref>. The proof of Proposition 6.2 shows that this parameter is necessary to encode the WL algorithm. Our result thus provide a theoretical just comparing classes of dMPNNs we consider the notions of being weaker or stronger with 1 step ahead.</p><p>Table 1</ref>: Various graph neural network formalisms, as reported in e.g., [Kipf and Welling, 2017</ref>, Wu et al., 2019a</ref>, Meltzer et al., 2019]</ref>, which correspond to degr sh between anonymous graph neural networks [Hamilton et al., 2017</ref>, Morris et al., 2019]</ref> and degree-aware graph neural networks [Kipf and</ref>Welling, 2017, Meltzer et al., 2019]</ref>. Here, we again make connections to the WL algorithm, identify which architectures of graph neu

which has not been used in previous iterations. When the number of distinct labels in ℓ ℓ ℓ (t) and ℓ ℓ ℓ (t−1) is the same, the WL algorithm terminates. Termination is guaranteed in at most n steps [Immerman and Lander, 1990]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Message Passing Neural Networks</head><p>We start by describing message
which has not been used in previous iterations. When the number of distinct labels in ℓ ℓ ℓ (t) and ℓ ℓ ℓ (t−1) is the same, the WL algorithm terminates. Termination is guaranteed in at most n steps [Immerman and Lander, 1990]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Message Passing Neural Networks</head><p>We start by describing message
algorithm for edge-labelled graphs as is done for graph neural networks in [Jaume et al., 2019]</ref>.</p><p>We also want to compare our formalisation to the MPNNs from [Loukas, 2019]</ref>. In that paper, the message functions can depend on identifiers of the vertices involved. Such position-aware MPNNs correspond to MPNNs in our settin essage functions can depend on identifiers of the vertices involved. Such position-aware MPNNs correspond to MPNNs in our setting in which f assigns to each vertex a unique identifier. We remark that [Loukas, 2019]</ref> shows Turing universality of position-aware MPNNs using close connections with the LOCAL model for distributed graph computations of <ref type="bibr" Turing universality of position-aware MPNNs using close connections with the LOCAL model for distributed graph computations of [Angluin, 1980]</ref>. As such, MPNNs from [Loukas, 2019]</ref> can simulate our MPNNs as one could add a few initialisation rounds to compute f (v) and f (u). We also remark that in the MPNNs from <ref type="bibr ch, MPNNs from [Loukas, 2019]</ref> can simulate our MPNNs as one could add a few initialisation rounds to compute f (v) and f (u). We also remark that in the MPNNs from [Loukas, 2019]</ref> every vertex can also send itself a message. We provide this functionality by parameterising the update functions with the current label of the verte
which has not been used in previous iterations. When the number of distinct labels in ℓ ℓ ℓ (t) and ℓ ℓ ℓ (t−1) is the same, the WL algorithm terminates. Termination is guaranteed in at most n steps [Immerman and Lander, 1990]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Message Passing Neural Networks</head><p>We start by describing message

More importantly, DP is not feasible once the parameter scale of the model exceeds the memory limit of a single device.</p><p>Recently, pipeline parallelism [10]</ref>- [12]</ref> has been proposed as a promising approach for training large DNN models. The idea is to partition model layers into multiple groups (stages) and place them on odes in the computation graph defined by user model, and re-computing the parts of the graph in between those nodes during backpropagation. The other category is asynchronous(async) pipeline training [12]</ref>. This manner inserts mini-batches into pipeline continuously and discards the original sync operations to achieve maximum throughput.</p><p>Although these eff eaches the minimum for given resources. The target optimization space includes DP, pipelined parallelism, and hybrid approaches combining both. Current state-of-theart pipeline partitioning algorithm [12]</ref> is not able to be applied to synchronous training effectively. Some other work [10]</ref>, [16]</ ection VI).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Device Assignment</head><p>Device assignment affects communication efficiency and computing resource utilization. Previous work [12]</ref> uses hierarchical planning and works well for asynchronous training. However, it lacks consideration of synchronous pipeline training, in which the latency of our solution space using memorized search.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Contributions over previous work</head><p>Previous works on pipeline planning includes PipeDream [12]</ref> (for asynchronous training) and torchgpipe [23]</ref>, a community implementation of GPipe [10]</ he second stage for a micro-batch and thus is replicated on two devices. For the first stage, we split the micro-batch further into 2 even slices, and assign each to a device. An alternative approach [12]</ref> (Fig. 8(b)</ref>) is not to split, but to schedule an entire micro-batch to two devices in round robin manner. However, the
target="#b38">[40]</ref> evaluated the hybrid approach without thorough study. Some researchers have been seeking for the optimal placement strategy to assign operations in a DNN to different devices [57]</ref>- [59]</ref> to further improve system efficiency.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</he
nce, but the gradients sychronization overhead can be a major factor preventing linear scalability. While the performance issue can be alleviated by optimizations such as local gradients accumulation [5]</ref>- [7]</ref> or computation and communication overlap techniques [8]</ref>, <ref type="bibr" target="# erarchical NVLink + Ethernet, 25 Gbps and </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MOTIVATION AND DAPPLE OVERVIEW</head><p>We consider pipelines training only if DP optimizations [5]</ref>, [6]</ref>, [8]</ref>, [17]</ref>- [20 et="#b8">[9]</ref>, [44]</ref>- [48]</ref>   data parallelism. As a commonly used performance optimization method, gradients accumulation [5]</ref>, [6]</ref>, [49]</ref> offers an effective approach to reduce communication-to-computation ratio. A
id approach without thorough study. Some researchers have been seeking for the optimal placement strategy to assign operations in a DNN to different devices [57]</ref>- [59]</ref> to further improve system efficiency.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we propose DAPPLE fram
id approach without thorough study. Some researchers have been seeking for the optimal placement strategy to assign operations in a DNN to different devices [57]</ref>- [59]</ref> to further improve system efficiency.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we propose DAPPLE fram
nchronous training) and torchgpipe [23]</ref>, a community implementation of GPipe [10]</ref> which uses "Block Partitioning of Sequences" [24]</ref>. Both aim to balance the workload across all GPUs. While this idea works good in PipeDream's asynchronous scenarios and gives reasonable solutions under GPipe
pipelined manner. Prior research on pipeline training generally falls into two categories. One is on optimizing pipeline parallelism for synchronous training [10]</ref>, [11]</ref>. This approach requires necessary gradients synchronizations between adjacent training iterations to ensure convergence. At runtime, it schedules as many conc arget="#b52">[54]</ref>. This paper focuses on model partition between layers, namely, pipeline parallelism.</p><p>Pipeline parallelism. Pipeline Parallelism [10]</ref>, [11]</ref>, [14]</ref>, [21]</ref>, [55]</ref> has been recently proposed to
buted training of DNN models.</p><p>Data Parallelism [43]</ref> . Some prior studies [9]</ref>, [44]</ref>- [48]</ref>   data parallelism. As a commonly used performance optimization method, gradients accumulation [5]</ref>, <ref type="bibr" targe
nchronous training) and torchgpipe [23]</ref>, a community implementation of GPipe [10]</ref> which uses "Block Partitioning of Sequences" [24]</ref>. Both aim to balance the workload across all GPUs. While this idea works good in PipeDream's asynchronous scenarios and gives reasonable solutions under GPipe
target="#b38">[40]</ref> evaluated the hybrid approach without thorough study. Some researchers have been seeking for the optimal placement strategy to assign operations in a DNN to different devices [57]</ref>- [59]</ref> to further improve system efficiency.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</he
lelism. Pipeline Parallelism [10]</ref>, [11]</ref>, [14]</ref>, [21]</ref>, [55]</ref> has been recently proposed to train DNN in a pipelined manner. GPipe [10]</ref> explores synchronous pipeline approach to train ted GPU memory. PipeDream [14]</ref> explores the hybrid approach of data and pipeline parallelism for asynchronous training. [53]</ref>, [55]</ref>, [56]</ref> make further optimization based on PipeDream. Pal et al. [40]</ref> evaluated the hy
biology [76,</ref>62,</ref>18]</ref>. Learning on such data is possible using graph neural networks (GNNs) [26]</ref> that typically operate by a message passing mechanism [4]</ref> aggregating information in a neighborhood of a node and create n
e it is often possible to apply static graph deep learning models [37]</ref> to dynamic graphs by ignoring the temporal evolution, this has been shown to be sub-optimal [66]</ref>, and in some cases, it is the dynamic structure that contains crucial insights about the system. Learning on dynamic graphs is relatively recent, and most wor rmula xml:id="formula_15">C (l) (t) = [h (l-1) 1 (t) e i1 (t 1 ) ?(t -t 1 ), . . . , h (l-1) N (t) e iN (t N ) ?(t -t N )].<label>(9)</label></formula><p>Here, ?(?) represents a generic time encoding [66]</ref>, is the concatenation operator and</p><formula xml:id="formula_16">z i (t) = emb(i, t) = h (L) i (t).</formula><p>Each layer amounts to performing multi-head- its neighbors. Finally, an MLP is used to combine the reference node representation with the aggregated information. Differently from the original formulation of this layer (firstly proposed in TGAT [66]</ref>) where no node-wise temporal features were used, in our case the input representation of each node h (0) j (t) = s j (t) + v j (t) and as such it allows the m amework (see Table 1</ref>). For example, Jodie [36]</ref> uses the time projection embedding module emb(i, t) = (1+?tw)?s i (t). TGAT [66]</ref> is a specific case of TGN when the memory and its related modules are missing, and graph attention is used as the Embedding module. Finally, we note that TGN the 5000 highest in degrees and 5000 highest out degrees. Dataset statistics together with more details are provided in the supplementary material.</p><p>Tasks. Our experimental setup closely follows [66]</ref> and focuses on the tasks of future edge prediction and dynamic node classification. On the former, we use both the transductive and inductive settings. In the reas in the inductive tasks we predict future links of nodes never observed before. The transductive setting is used for node classification. We perform the same 70%-15%-15% chronological split as in [66]</ref>.</p><p>Future Edge Prediction. The goal is to predict the probability of an edge occurring between two nodes at a given time. Our encoder is combined with a s es. Our strong baselines are state-of-the-art approaches for continuous time dynamic graphs (CTDNE [47]</ref>, Jodie [36]</ref>, and TGAT [66]</ref>) as well as state-of-the-art models for static graphs (GAE [34]</ref>, VGAE [34]</ref>, DeepWalk f type="bibr" target="#b22">[23]</ref>, GAT [61]</ref> and GraphSAGE [27]</ref>, CTDNE [47]</ref> and TGAT [66]</ref> are taken directly from the TGAT paper [66]</ref>.</p><p>For Jodie [36]</ref>, we implement our ref> and GraphSAGE [27]</ref>, CTDNE [47]</ref> and TGAT [66]</ref> are taken directly from the TGAT paper [66]</ref>.</p><p>For Jodie [36]</ref>, we implement our own version in PyTorch, as a specific case of our framework with the temporal emb /p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameters</head><p>For all the models and datasets we used the same hyperparameters, which had been found to work well in the TGAT paper [66]</ref>.</p></div>			</div> 			<div type="references">  				<listBibl>  <biblStruct xml:id="b0"> 	<analytic> 		<title level="a" type="main">An efficient algorithm for
s [5,</ref>52,</ref>42,</ref>10,</ref>16,</ref>20,</ref>49,</ref>53]</ref>, in particular, social sciences [68,</ref><ref t
dated after the event has happened. For node-wise events, only the memory of the related node is updated. Here, mem is a learnable memory update function, e.g. a recurrent neural network such as LSTM [29]</ref> or GRU [9]</ref>.</p><p>Embedding. The embedding module is used to generate the temporal embedding z i (t) of node i at any time
uitously used as models for systems of relations and interactions in many fields [5,</ref>52,</ref>42,</ref>10,</ref>16,</ref>20,</ref>49,</ref>53]</ref>,
of successes, gaining increasing popularity in machine learning. Graphs are ubiquitously used as models for systems of relations and interactions in many fields [5,</ref>52,</ref>42,</ref>10,</ref>16,</ref>20,</ref><
get="#b47">48]</ref>, or learned by imposing a smoothness constraint over time [33,</ref>25,</ref>67,</ref>75,</ref>73,</ref>57,</ref>22,</ref>17,</ref>
state-of-the-art models for static graphs (GAE [34]</ref>, VGAE [34]</ref>, DeepWalk [51]</ref>, Node2Vec [23]</ref>, GAT [61]</ref> and GraphSAGE [27]</ref>).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><h ings for Baselines</head><p>Our results for GAE [34]</ref>, VGAE [34]</ref>, DeepWalk [51]</ref>, Node2Vec [23]</ref>, GAT [61]</ref> and GraphSAGE [27]</ref>, CTDNE [47]</ref> and TG
"#b3">4]</ref> has produced a sequence of successes, gaining increasing popularity in machine learning. Graphs are ubiquitously used as models for systems of relations and interactions in many fields [5,</ref>52,</ref>42,</ref>10,</ref>16,</ref><r
pe="bibr" target="#b48">49,</ref>53]</ref>, in particular, social sciences [68,</ref>43]</ref> and biology [76,</ref>62,</ref>18]</ref>. Learning on such data is possible using graph neural networks (GNNs) <ref typ
arget="#b7">8,</ref>54,</ref>48]</ref>, or learned by imposing a smoothness constraint over time [33,</ref>25,</ref>67,</ref>75,</ref>73,</ref>57,</ref>
nitial snapshot and then modifying the walk behaviour for subsequent snapshots [40,</ref>14,</ref>64,</ref>13,</ref>71]</ref>.</p><p>Only recently have Continuous Time Dynamic Graphs (CTDGs) been addressed. Several approaches use random walk mod
new edge appears. Other recent works have focused on dynamic knowledge graphs [21,</ref>65,</ref>12,</ref>19]</ref>.</p><p>Most recent CTDG learning models can be interpreted as specific cases of our framework (see Table 1</ref>). For exampl
>42,</ref>10,</ref>16,</ref>20,</ref>49,</ref>53]</ref>, in particular, social sciences [68,</ref>43]</ref> and biology [7
67,</ref>75,</ref>73,</ref>57,</ref>22,</ref>17,</ref>50]</ref>. Another line of work encodes DTDGs by first performing random walks on an initial snapshot and then modifying the walk
ticular, social sciences [68,</ref>43]</ref> and biology [76,</ref>62,</ref>18]</ref>. Learning on such data is possible using graph neural networks (GNNs) [26]</ref> that typically operate by a message passing mec
get="#b47">48]</ref>, or learned by imposing a smoothness constraint over time [33,</ref>25,</ref>67,</ref>75,</ref>73,</ref>57,</ref>22,</ref>17,</ref>
>42,</ref>10,</ref>16,</ref>20,</ref>49,</ref>53]</ref>, in particular, social sciences [68,</ref>43]</ref> and biology [7
sing a smoothness constraint over time [33,</ref>25,</ref>67,</ref>75,</ref>73,</ref>57,</ref>22,</ref>17,</ref>50]</ref>
for learning on dynamic graphs focused on Discrete Time Dynamic Graphs (DTDG)s. Such approaches either aggregate graph snapshots and then apply static methods [37,</ref>28,</ref>56,</ref>31,</ref>1,</ref>2]</ref>, as
e="bibr" target="#b52">53]</ref>, in particular, social sciences [68,</ref>43]</ref> and biology [76,</ref>62,</ref>18]</ref>. Learning on such data is possible using graph neural networks (GNNs) [26]</ref> that ty
new edge appears. Other recent works have focused on dynamic knowledge graphs [21,</ref>65,</ref>12,</ref>19]</ref>.</p><p>Most recent CTDG learning models can be interpreted as specific cases of our framework (see Table 1</ref>). For exampl
D PROMPTS</head><p>Prompts are pre-defined text sequences used as the target prefix to constrain decoding. They have been utilized to perform multi-purpose text generation with a single unified model (Radford et al., 2019;</ref>Brown et al., 2020)</ref>. In the CTRLsum framework, prompts are a kind of control token sequence, and we alway >Wuebker et al., 2016)</ref> and also to demonstrate the multi-task ability present in large pretrained models (McCann et al., 2018;</ref>Radford et al., 2019;</ref>Keskar et al., 2019;</ref>Brown et al., 2020)</ref>.</p></div> <div xmlns="http://www.tei-c.org ised setting since our model never sees questions or answers during training. In addition to comparing with the vanilla BART model, we also include the zero-shot performance from GPT2 language models (Radford et al., 2019)</ref> (without fine-tuning) as a reference point. We omit the largest GPT2 model with 1.5B parameters since it cannot be evaluated in our single G

rototypes to control summary length in a similar way to how we use keywords. Interactive summarization provides a way for users to continuously control the information that is included in the summary (Bornstein et al., 1999;</ref>Leuski et al., 2003)</ref>. More broadly, controllable text generation has been studied for styles <ref type=
applied in other contexts with different motivations. Gehrmann et al. (2018)</ref> utilize copying words at test time to mask copying operations in a summarization task. Li et al. (2018)</ref> and Saito et al. (2020b)</ref> use keywords as extra input to improve the uncontrolled summarization performance. <
rform ablation analysis to understand the important gradients that contribute to the success of CTRLsum. We train CTRLsum with another two architectures in addition to BART: (1) convolutional seq2seq (Gehring et al., 2017)</ref> with the same hyperparameters as in (Fan et al., 2018)</ref>, and (2) transformer seq2seq with the same hyperpa
we use keywords. Interactive summarization provides a way for users to continuously control the information that is included in the summary (Bornstein et al., 1999;</ref>Leuski et al., 2003)</ref>. More broadly, controllable text generation has been studied for styles (Hu et al., 2017;</ref><ref type="bibr"
/head><p>Setup. We directly test question-guided summarization on reading comprehension benchmarks in a zero-shot setting. Specifically, we evaluate the CNNDM summarization models on in-domain NewsQA (Trischler et al., 2017)</ref> and out-of-domain SQuAD 1.1 (Rajpurkar et al., 2016)</ref> respectively. We note that some NewsQA test arti
e summary (Bornstein et al., 1999;</ref>Leuski et al., 2003)</ref>. More broadly, controllable text generation has been studied for styles (Hu et al., 2017;</ref>Fu et al., 2018;</ref>He et al., 2020b)</ref>, topics 
formers library (Wolf et al., 2019)</ref>. Complete setup and training details can be found in Appendix A.1.</p><p>For evaluation, we measure commonly used ROUGE scores (Lin, 2004)</ref> and the recently proposed BERTScore (Zhang et al., 2020)</ref> when ground-truth is available. For control-related evaluation where we
tems: extractive summarization that extracts important portions of a document (Cheng &amp; Lapata, 2016;</ref>Nallapati et al., 2017;</ref>Narayan et al., 2018)</ref>, and abstractive summarization that freely generates novel sentences (Rush et al., 2015;</ref><ref type="bibr"
Wiseman et al., 2018;</ref>He et al., 2020a)</ref>.</p><p>Keyword-guided text generation has been applied in other contexts with different motivations. Gehrmann et al. (2018)</ref> utilize copying words at test time to mask copying operations in a summarization task. Li et al. (2018)</ref>
g those that can, and/or compound instability in aqueous solution. However, emerging models in retrosynthesis and physicochemical property prediction may overcome these limitations in the near future (Coley et al., 2018;</ref>Gao et al., 2018)</ref>.</p><p>Where our deep neural network model was trained using a targeted dataset, future e
="#fig_8">S2</ref> and Table S3</ref>.</p><p>potency decreased as pH increased, providing evidence that this compound may be dissipating the DpH component of the proton motive force (Farha et al., 2013)</ref>. Consistent with this observation, the addition of sodium bicarbonate to the growth medium (Farha et al., 2018) pe="table">S4A-S4C</ref>) suggested that this compound complexes with iron in solution, thereby dissipating transmembrane DpH potential similarly to other antibacterial ionophores, such as daptomycin (Farha et al., 2013)</ref>. We note here that daptomycin resistance via deletion of dsp1 in S. aureus did not confer cross-resistance to halicin (Figure <ref type="figur
ndeed, where our screen was largely mechanism of action agnostic, future applications could incorporate phenotypic screening conditions that enrich for molecules against specific biological targets ( Stokes and Brown, 2015;</ref>Stokes et al., 2016</ref>Stokes et al., , 2017;;</ref>Yang et
ing repeatedly discovered (Cox et al., 2017)</ref>. Moreover, given the rapid expansion of chemical spaces that are accessible by the derivatization of complex scaffolds (Ortholand and Ganesan, 2004)</ref>, engineering next-generation versions of existing antibiotics results in substantially more failures than leads. Therefore, many anti
rld Health Organization has designated A. baumannii as one of the highest priority pathogens against which new antibiotics are urgently required (Lee et al., 2017;</ref>Perez et al., 2007)</ref>. In addition to halicin, from a distinct set of 23 empirically tested predictions from &gt;107 million molecules found in the ZINC15 database,
which new antibiotics could be predicted, without the practical hurdles that can be associated with large-scale antibiotic screening efforts. We screened for growth inhibition against E. coli BW25113 (Zampieri et al., 2017)</ref> using a widely available US Food and Drug Administration (FDA)-approved drug library consisting of 1,760 molecules of diverse structure and
a carefully controlled training set would allow for more tractable predictions that avoided potentially unfavorable molecules. Nevertheless, given the increasing volume of screening data that exists (Wang et al., 2017)</ref>, carefully leveraging these resources could result in millions of molecular graph-biological property relationships, provided that the data are


a carefully controlled training set would allow for more tractable predictions that avoided potentially unfavorable molecules. Nevertheless, given the increasing volume of screening data that exists (Wang et al., 2017)</ref>, carefully leveraging these resources could result in millions of molecular graph-biological property relationships, provided that the data are
lusters for our dataset. Transcript cluster enrichment was performed using EcoCyc Pathway Tools (Karp, 2001;</ref>Karp et al., 2016;</ref>Keseler et al., 2013)</ref>. P values were calculated using Fisher's exact test.</p><p>DiSC 3 (5) assays S. aureus USA300 and E. coli MC1061 were streaked onto LB agar a
br" target="#b39">[40]</ref>, many efforts [2,</ref>7,</ref>15,</ref>16,</ref>18,</ref>23,</ref>29,</ref>36,</ref>42,</ref> pothesize this distribution mismatch between clean examples and adversarial examples is a key factor that causes the performance degradation in previous works [16,</ref>18,</ref>45]</ref>.</p><p>In this paper, we propose AdvProp, short for Adversarial Propagation, a new training scheme that bridges the dis ial training, which trains networks with adversarial examples, constitutes the current foundation of state-of-the-arts for defending against adversarial attacks [7,</ref>18,</ref>23,</ref>45]</ref>. Although adversarial training significantly improves model robustness, how to th random noise (e.g., Tab. 5 in [18]</ref> shows the result of training with random normal perturbations) or adversarial noise [16,</ref>18,</ref>42]</ref>, fail to improve accuracy on clean images. ial examples to effectively boost model robustness. However, such trained mo ype="bibr" target="#b19">20]</ref>, or on larger datasets but in the semi-supervised setting [26,</ref>30]</ref>. Meanwhile, recent works [18,</ref>16,</ref>45]</ref> also suggest that training with adversarial examples on large datasets, e.g., s shown in Fig. 4</ref> and Tab. 1, AdvProp improves models for better recognition than the vanilla training baseline. These results contradict previous conclusions [18,</ref>42,</ref>16]</ref> that the performance degradation is always observed if adversarial examples ar ning setting on large networks. For example, our adversarially trained EfficientNet-B7 has 85.1% top-1 accuracy on ImageNet, which beats the vanilla training baseline by 0.6%. However, previous works [18,</ref>16]</ref> show adversarial training always degrades performance.</p><p>Compared to [18,</ref><ref ng baseline by 0.6%. However, previous works [18,</ref>16]</ref> show adversarial training always degrades performance.</p><p>Compared to [18,</ref>16]</ref>, we make two changes in our reimplementation: (1) using stronger networks; and (2) training with weaker attackers. For work can be regarded as one type of data augmentation: creating additional training samples by injecting noise. However, all previous attempts, by augmenting either with random noise (e.g., Tab. 5 in [18]</ref> shows the result of training with random normal perturbations) or adversarial noise [16,</ref>18 on size to be within the -ball, and name this attacker to Gradient Descent (GD) as it removes the projection step in PGD; or (2) we skip the random noise initialization step in PGD, turn it to I-FGSM [18]</ref>. Other attack hyper-parameters are unchanged: the maximum perturbation size =4 (if applicable), number of attack iteration n=5 and attack step size α=1.0.</p> eral mechanism for improving image recognition models with different adversarial attacker. B3 B5 B7 Vanilla Training 81.7 83.7 84.5 PGD [23]</ref> 81.8 84.3 85.2 I-FGSM [18]</ref> 81.9 84. In Sec. 5.3, we show that adversarial training can improve performance if large EfficientNets are used for training. However, this phenomenon is not Therefore we treat adversarial images as additional training samples and train networks with a mixture of adversarial examples and clean images, as suggested in [7,</ref>18]</ref>,</p><formula xml:id="formula_3">arg min θ E (x,y)∼D L(θ, x, y) + max ∈S L(θ, x + , y) .<label>(3)</label></formula><p>Ideally, such trained models should enjoy l>(3)</label></formula><p>Ideally, such trained models should enjoy the benefits from both adversarial and clean domains. However, as observed in former studies [7,</ref>18]</ref>, directly optimizing Eq. ( 3</ref>) generally yields lower performance than the vanilla training setting on clean image n θ</head><p>Experiments show that such disentangled learning framework enables networks to get much stronger performance than the adversarial training baseline [7,</ref>18]</ref>. Besides, compared to the fine-tuning strategy in Sec. 3, Ad-vProp also demonstrates superior performance as it enables networks to jointly learn useful featur
mageNet [6]</ref>. The Stylized-ImageNet dataset is created by removing local texture while retaining global shape information on natural images via AdaIN style transfer [13]</ref>. As suggested in [6]</ref>, networks are required to learn more shape-based representations to improve accuracy on Stylized-Imag
increased sample complexity of adversary [37,</ref>25,</ref>28]</ref>, the limited amount of training data [1,</ref>27,</ref>34,</ref>44,</ref>48]</ref>,
l-preserving transformations to images, serves as an important and effective role to prevent networks from overfitting [17,</ref>35,</ref>8]</ref>. Besides traditional methods like horizontal flipping and random cropping, different augmentation techniques have been proposed, e.g., applying masking out <ref Disentangled Learning via An Auxiliary BN</head><p>Batch normalization (BN) [14]</ref> serves as an essential component for many state-of-the-art computer vision models [8,</ref>12,</ref>39]</ref>. Specifically, BN normalizes input features by the mean and variance computed wi ed with different attackers. With AdvProp, all attackers successfully improve model performance over the vanilla training baseline.ResNet Results. Besides EfficientNets, we also experiment with ResNet[8]</ref>. We compare AdvProp against two baselines: vanilla training and adversarial training. We apply PGD5 ( =4) to generate adversarial examples, and follow the setti ype="bibr" target="#b7">[8]</ref>. We compare AdvProp against two baselines: vanilla training and adversarial training. We apply PGD5 ( =4) to generate adversarial examples, and follow the settings in[8]</ref> to train all networks.We report model performance on ImageNet in Tab. 8. Compared to vanilla training, adversarial training always degrades model performance wh
tics and human perception [43]</ref>. Moreover, such trained models are much more robust to high frequency noise [47]</ref>. Zhang et al. [51]</ref> further suggest these adversarially learned feature representations are less sensitive to texture distortions and focus more on shape information.</p><p>Our p max ∈S L(θ, x + , y) ,<label>(2)</label></formula><p>where is a adversarial perturbation, S is the allowed perturbation range. Though such trained models have several nice properties as described in [51,</ref>47,</ref>43]</ref>, they cannot generalize well to clean images [2
f type="bibr" target="#b13">[14]</ref> serves as an essential component for many state-of-the-art computer vision models [8,</ref>12,</ref>39]</ref>. Specifically, BN normalizes input features by the mean and variance computed within each mini-batch. One intrinsic assumption of utilizing BN is that the inpu
ted generalization ability of ConvNets, but also poses security threats on the real-world deployment of these models. Since the first discovery of the vulnerability of ConvNets to adversarial attacks [40]</ref>, many efforts [2,</ref>7,</ref>15,</ref><ref type="bibr" target="#b
nd Stylized-ImageNet (+4.8%). With an enhanced EfficientNet-B8, our method achieves the state-of-the-art 85.5% ImageNet top-1 accuracy without extra data. This result even surpasses the best model in [24]</ref> which is trained with 3.5B Instagram images (∼3000× more than ImageNet) and ∼9.4× more parameters. Models are available at https://github.com/tensorflow/tpu/t 40">[41]</ref>. With our proposed AdvProp, EfficientNet-B8 achieves the state-of-the-art 85.5% top-1 accuracy on ImageNet without any extra data. This result even surpasses the best model reported in [24]</ref>, which is pretrained on 3.5B extra Instagram images (∼3000× more than ImageNet) and requires ∼9.4× more parameters than our EfficientNet-B8.</p></div> <div xm rop improves the accuracy of EfficientNet-B8 from 84.8% to 85.5%, achieving a new state-of-the-art accuracy on ImageNet without using extra data. This result even surpasses the best model reported in [24]</ref>, which is pretrained on 3.5B extra Instagram images (∼3000× more than ImageNet) and requires ∼9.4× more parameters (829M vs. 88M) than our EfficientNet-B8. </ nd 26.6% top-1 accuracy on Stylized-ImageNet. These are the best results so far if models are not allowed to train with corresponding distortions [6]</ref> or extra data [24,</ref>46]</ref>.</p><p>To summarize, the results suggest that AdvProp significantly boosts the generalization ability by allowing mode
ing an additional auxiliary BN for AutoAugment images.Comparison to AutoAugment. Training with adversarialexamples is a form of data augmentation. We choose the standard Inception-style pre-processing[38]</ref> as baseline, and compare the benefits of additionally applying Au-toAugment or AdvProp. We train networks with PGD5 ( =4) and evaluate performance on ImageNet
y-supervised setting [7,</ref>20]</ref>, or on larger datasets but in the semi-supervised setting [26,</ref>30]</ref>. Meanwhile, recent works [18,</ref>16,</ref>45]</ref> also suggest ning significantly improves model robustness, how to improve clean image accuracy with adversarial training is still under-explored. VAT [26]</ref> and deep co-training [30]</ref> attempt to utilize adversarial examples in semi-supervised settings, but they require enormous extra unlabeled images. Under supervised learning settings, adv
l-preserving transformations to images, serves as an important and effective role to prevent networks from overfitting [17,</ref>35,</ref>8]</ref>. Besides traditional methods like horizontal flipping and random cropping, different augmentation techniques have been proposed, e.g., applying masking out <ref Disentangled Learning via An Auxiliary BN</head><p>Batch normalization (BN) [14]</ref> serves as an essential component for many state-of-the-art computer vision models [8,</ref>12,</ref>39]</ref>. Specifically, BN normalizes input features by the mean and variance computed wi ed with different attackers. With AdvProp, all attackers successfully improve model performance over the vanilla training baseline.ResNet Results. Besides EfficientNets, we also experiment with ResNet[8]</ref>. We compare AdvProp against two baselines: vanilla training and adversarial training. We apply PGD5 ( =4) to generate adversarial examples, and follow the setti ype="bibr" target="#b7">[8]</ref>. We compare AdvProp against two baselines: vanilla training and adversarial training. We apply PGD5 ( =4) to generate adversarial examples, and follow the settings in[8]</ref> to train all networks.We report model performance on ImageNet in Tab. 8. Compared to vanilla training, adversarial training always degrades model performance wh
s. Unlike the goal of recommendation, the pre-training task directly reconstructs the cold-start user/item embeddings by mimicking the meta-learning setting via episode based training, as proposed in [34]</ref>. Specifically, we pick the users/items with sufficient interactions as the target users/items and learn their ground truth embeddings on the observed abundant erns behind the user-item interactions. One kind of the methods is meta-learning [9,</ref>23,</ref>26,</ref>34]</ref>, which consists of metric-based recommendation [29]</ref> and model-based recommendation [7,</ref>
ch as content features of users and items [40,</ref>44]</ref> or external knowledge graphs (KGs) [35,</ref>37]</ref> to compensate the low-quality embeddings caused by sparse interactions. However, the content features are not always available, and it is not easy to link the ="#b9">[10,</ref>36,</ref>41,</ref>42]</ref> and knowledge graphs [35,</ref>37]</ref> to enhance the representations of the cold-start users/items. However, the side information is not always available, making it intractable to improve the cold-
z + q A I 3 e &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E 3 p w o R v g 9 N x c 2 W x s o + P R l L R e X k o = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6</ref>  </p><formula xml:id="formula_2">O U B z E d K R E J R t F K f l 0 M m v V B t e Y 2 3 A X I O v E K U o M C 7 U H 1 q z 9 M W B Z z h U x S Y</formula><p>3 q e m z + q A I 3 e &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E 3 p w o R v g 9 N x c 2 W x s o + P R l L R e X k o = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6</ref>  </p><formula xml:id="formula_3">O U B z E d K R E J R t F K f l 0 M m v V B t e Y 2 3 A X I O v E K U o M C 7 U H 1 q z 9 M W B Z z h U x S Y</formula><p>3 q e m z + q A I 3 e &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E 3 p w o R v g 9 N x c 2 W x s o + P R l L R e X k o = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6</ref>  </p><formula xml:id="formula_4">O U B z E d K R E J R t F K f l 0 M m v V B t e Y 2 3 A X I O v E K U o M C 7 U H 1 q z 9 M W B Z z h U x S Y</formula><p>3 q e m
ch as content features of users and items [40,</ref>44]</ref> or external knowledge graphs (KGs) [35,</ref>37]</ref> to compensate the low-quality embeddings caused by sparse interactions. However, the content features are not always available, and it is not easy to link the ="#b9">[10,</ref>36,</ref>41,</ref>42]</ref> and knowledge graphs [35,</ref>37]</ref> to enhance the representations of the cold-start users/items. However, the side information is not always available, making it intractable to improve the cold-
ne hand, existing recommender systems incorporate the side information such as spatial information [40,</ref>44]</ref>, social trust path [10,</ref>36,</ref>41,</ref>42]</ref> and knowledge graphs <ref type="bibr" t
ining GNNs aim to empower GNNs to capture the structural and semantic properties of an input graph, so that it can easily generalize to any downstream tasks with a few fine-tuning steps on the graphs [17]</ref>. The basic idea is to design a domain specific pretext task to provide additional supervision for exploiting the graph structures and semantic properties. Exa tation and the global graph representations [27,</ref>32]</ref>.</p><p>2) Node-level task, which perform node feature and edge generation [17]</ref> pretext tasks. 3) Hybrid-level task, which considers both node and graph-level tasks [15,</ref>4
34]</ref>, which consists of metric-based recommendation [29]</ref> and model-based recommendation [7,</ref>20,</ref>22,</ref>24]</ref>. However, few of them capture the high-order interactions. Another kind of meth
stems incorporate the side information such as content features of users and items [40,</ref>44]</ref> or external knowledge graphs (KGs) [35,</ref>37]</ref> to compensate the low-quality embeddings caused by sparse interactions. However, the content features are not always a social trust path [10,</ref>36,</ref>41,</ref>42]</ref> and knowledge graphs [35,</ref>37]</ref> to enhance the representations of the cold-start users/items. However, the side information is not always available, m
7 + w Q H 1 I 4 f &lt; / l a t e x i t &gt;</formula></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommendation systems [14,</ref>21]</ref> have been extensively deployed to alleviate information overload in various web services, such as social media, E-commerce websites and news portals. To predic nd news portals. To predict the likelihood of a user adopting an item, collaborative filtering (CF) is the most widely adopted principle. The most common paradigm for CF, such as matrix factorization [21]</ref> and neural collaborative filtering [14]</ref>, is to learn embeddings, i.e. the preferences for users and items and then perfor
ining GNNs aim to empower GNNs to capture the structural and semantic properties of an input graph, so that it can easily generalize to any downstream tasks with a few fine-tuning steps on the graphs [17]</ref>. The basic idea is to design a domain specific pretext task to provide additional supervision for exploiting the graph structures and semantic properties. Exa tation and the global graph representations [27,</ref>32]</ref>.</p><p>2) Node-level task, which perform node feature and edge generation [17]</ref> pretext tasks. 3) Hybrid-level task, which considers both node and graph-level tasks [15,</ref>4

br" target="#b9">[10]</ref>.</p><p>An alternative, is to embed all conflicting requirements in a constrained RL problem and to use a primal-dual algorithm as in [7,</ref>11]</ref> that chooses the parameters automatically. The main advantage of this approach is that constraints ensure satisfying behavior without the need for manually sel "#b11">[12]</ref>). 3. We leverage these theoretical results to establish that the family of primal-dual algorithms for constrained reinforcement learning, e.g. [7,</ref>11]</ref>, in fact converge to the optimal solution under mild assumptions.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>Constr ject the action chosen by the policy to a set that ensures the satisfaction of the constraints [21]</ref>. Primal-dual algorithms [7,</ref>11]</ref>, allow us to choose dynamically the multipliers by find the best policy for the current set of parameters and then taking steps along the gradient of the Lagra type="bibr" target="#b33">[34]</ref>. This idea can be applied in the context of reinforcement learning as well, where a policy gradient -or actor critic as in [7,</ref>11]</ref> -update is followed by an update of the multipliers along the direction of the constraint violation. In these algorithms the update on the policy is on a faste update of the multipliers, and therefore they operate from a theoretical point of view as (1)</ref>. In particular, the proofs in [7,</ref>11]</ref> rely on the fact that this different time-scale is such that allows to consider the multiplier as constant.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"> mean -and in some cases the variance -of a distribution.</p><p>Regardless of these limitations, the primal dual algorithm considered here and those proposed in [7,</ref>11]</ref> provide a manner to solve constrained policy optimization problems without the need to perform an exhaustive search over the weights that we assign to each rew
od" the parametrization is. If we consider, for instance, a neural network-which are universal function approximators [12,</ref>[25]</ref>[26]</ref>[27]</ref>[28]</ref>-the loss in optimality can be made arbitrarily small.</p><p>4 There is (almo
in total variational norm. Notice that this is a milder requirement than approximation in uniform norm which is a property that has been established to be satisfied by radial basis functions networks [29]</ref>, reproducing kernel Hilbert spaces [30]</ref> and deep neural networks [12]</ref>. Notice that t
ef>, networking [15]</ref>, robotics [3,</ref>16,</ref>17]</ref> and finance [18,</ref>19]</ref>. The most common approaches to solve this problems can be divided under the following categories. Manual selection of
these problems are generally addressed by combining modular value functions that encode them individually, by multiplying each signal by its own coefficient, which controls the emphasis placed on it [2]</ref>[3]</ref>[4]</ref>. Although effective, the multi-objective problem [5] following categories. Manual selection of Lagrange multipliers: constrained Reinforcement Learning problems can be solved through by maximizing an unconstrained Lagrangian, for a specific multiplier [2]</ref>. The combination of different rewards with manually selected Lagrange multipliers has been applied for instance to learning complex movements for humanoids <ref
in general intractable, we extend this result to parametrized policies, by showing that the suboptimality bound also holds when the parametrization is a universal approximator, e.g., a neural network [12]</ref>). 3. We leverage these theoretical results to establish that the family of primal-dual algorithms for constrained reinforcement learning, e.g. <ref type="bibr shed to be satisfied by radial basis functions networks [29]</ref>, reproducing kernel Hilbert spaces [30]</ref> and deep neural networks [12]</ref>. Notice that the objective function and the constraints in Problem (PI) involve an infinite horizon and thus, the policy is applied an infinite number of time policies and show that the price to pay in terms of duality gap depends on how "good" the parametrization is. If we consider, for instance, a neural network-which are universal function approximators [12,</ref>[25]</ref>[26]</ref>[27]</ref>[28]<
n terms of duality gap depends on how "good" the parametrization is. If we consider, for instance, a neural network-which are universal function approximators [12,</ref>[25]</ref>[26]</ref>[27]</ref>[28]</ref>-the loss in optimality can be made
in general intractable, we extend this result to parametrized policies, by showing that the suboptimality bound also holds when the parametrization is a universal approximator, e.g., a neural network [12]</ref>). 3. We leverage these theoretical results to establish that the family of primal-dual algorithms for constrained reinforcement learning, e.g. <ref type="bibr shed to be satisfied by radial basis functions networks [29]</ref>, reproducing kernel Hilbert spaces [30]</ref> and deep neural networks [12]</ref>. Notice that the objective function and the constraints in Problem (PI) involve an infinite horizon and thus, the policy is applied an infinite number of time policies and show that the price to pay in terms of duality gap depends on how "good" the parametrization is. If we consider, for instance, a neural network-which are universal function approximators [12,</ref>[25]</ref>[26]</ref>[27]</ref>[28]<

these problems are generally addressed by combining modular value functions that encode them individually, by multiplying each signal by its own coefficient, which controls the emphasis placed on it [2]</ref>[3]</ref>[4]</ref>. Although effective, the multi-objective problem [5] following categories. Manual selection of Lagrange multipliers: constrained Reinforcement Learning problems can be solved through by maximizing an unconstrained Lagrangian, for a specific multiplier [2]</ref>. The combination of different rewards with manually selected Lagrange multipliers has been applied for instance to learning complex movements for humanoids <ref
in total variational norm. Notice that this is a milder requirement than approximation in uniform norm which is a property that has been established to be satisfied by radial basis functions networks [29]</ref>, reproducing kernel Hilbert spaces [30]</ref> and deep neural networks [12]</ref>. Notice that t
al., 2018b)</ref>, which suggests that as the number of layers increases, the representations of the nodes in GCN are inclined to converge to a certain value and thus become indistinguishable. ResNet (He et al., 2016)</ref> solves a similar problem in computer vision with residual connections, which is effective for training very deep neural networks. Unfortunately, ith an initial residual connection to the first layer H (0) ; 2) We add an identity mapping I n to the -th weight matrix W ( ) . Initial residual connection. To simulate the skip connection in ResNet (He et al., 2016)</ref>, (Kipf &amp; Welling, 2017)</ref> proposes residual connection that combines the smoothed representation PH ( ) wi we add an identity matrix I n to the weight matrix W ( ) . In the following, we summarize the motivations for introducing identity mapping into our model.</p><p>• Similar to the motivation of ResNet (He et al., 2016)</ref>, identity mapping ensures that a deep GCNII model achieves at least the same performance as its shallow version does. In particular, by setting β

uc.edu.cn&gt;.</p><p>Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020.</ref> Copyright 2020 by the author(s).</p><p>puter vision (Zhao et al., 2019;</ref>Ma et al., 2019)</ref>.</p><p>Despite their enormous success, most of the current GCN models are shallow. Most of

2018;</ref>Li &amp; Goldwasser, 2019)</ref>, traffic prediction (Guo et al., 2019;</ref>Li et al., 2019)</ref>, biology (Fout et al., 2017;</ref>Shang et al., 2019)</ref>, recommender systems (Ying et al., 2018)</ref>, and com-1

2018;</ref>Li &amp; Goldwasser, 2019)</ref>, traffic prediction (Guo et al., 2019;</ref>Li et al., 2019)</ref>, biology (Fout et al., 2017;</ref>Shang et al., 2019)</ref>, recommender systems (Ying et al., 2018)</ref>, and com-1
2018;</ref>Li &amp; Goldwasser, 2019)</ref>, traffic prediction (Guo et al., 2019;</ref>Li et al., 2019)</ref>, biology (Fout et al., 2017;</ref>Shang et al., 2019)</ref>, recommender systems (Ying et al., 2018)</ref>, and com-1
dwasser, 2019)</ref>, traffic prediction (Guo et al., 2019;</ref>Li et al., 2019)</ref>, biology (Fout et al., 2017;</ref>Shang et al., 2019)</ref>, recommender systems (Ying et al., 2018)</ref>, and com-1 School of Information, Renmin University of China 2 Ga
N (Zhang et al., 2018)</ref> 98.71 GAT (Veličković et al., 2018)</ref> 97.3 JKNet (Xu et al., 2018)</ref> 97.6 GeniePath (Liu et al., 2019)</ref> 98.5 Cluster-GCN (Chiang et al., 2019)</ref> 99.36 GCNII 99.53 ± 0.01 GCNII* 99.56 ± 0.02</p><p>Cornell, Texas, an bibr" target="#b2">(Chen et al., 2018b)</ref>, GaAN (Zhang et al., 2018)</ref>, GAT (Veličković et al., 2018)</ref>, JKNet (Xu et al., 2018), GeniePath (Liu et al., 2019)</ref>, Cluster-GCN (Chiang et al., 2019)</ref>. The metrics are summarized in Table 4<
al., 2019) learn neighborhood mixing relationships by mixing of neighborhood information at various distances but still uses a two-layer model. (Gao &amp; Ji, 2019;</ref>Lee et al., 2019)</ref> devote to extend pooling operations to graph neural network. For unsupervised information, (Velickovic et al., 201
dwasser, 2019)</ref>, traffic prediction (Guo et al., 2019;</ref>Li et al., 2019)</ref>, biology (Fout et al., 2017;</ref>Shang et al., 2019)</ref>, recommender systems (Ying et al., 2018)</ref>, and com-1 School of Information, Renmin University of China 2 Ga
br" target="#b6">(Defferrard et al., 2016;</ref>Veličković et al., 2018)</ref> have been successfully applied to a wide range of applications, including social analysis (Qiu et al., 2018;</ref>Li &amp; Goldwasser, 2019)</ref>, traffic prediction (Guo et al., 2019;</ref><ref t
N (Zhang et al., 2018)</ref> 98.71 GAT (Veličković et al., 2018)</ref> 97.3 JKNet (Xu et al., 2018)</ref> 97.6 GeniePath (Liu et al., 2019)</ref> 98.5 Cluster-GCN (Chiang et al., 2019)</ref> 99.36 GCNII 99.53 ± 0.01 GCNII* 99.56 ± 0.02</p><p>Cornell, Texas, an bibr" target="#b2">(Chen et al., 2018b)</ref>, GaAN (Zhang et al., 2018)</ref>, GAT (Veličković et al., 2018)</ref>, JKNet (Xu et al., 2018), GeniePath (Liu et al., 2019)</ref>, Cluster-GCN (Chiang et al., 2019)</ref>. The metrics are summarized in Table 4<


r k i=0 θ i L i x with arbitrary coefficients θ.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Proof of Theorem 1</head><p>To prove Theorem 1, we need the following Cheeger Inequality (Chung, 2007)</ref> for lazy random walks.</p><p>Lemma 1 ( (Chung, 2007)</ref>). Let p</p><formula xml:id="formula_29">(K) i = In+ Ã D−1 2 K rg/ns/1.0"><head>A.2. Proof of Theorem 1</head><p>To prove Theorem 1, we need the following Cheeger Inequality (Chung, 2007)</ref> for lazy random walks.</p><p>Lemma 1 ( (Chung, 2007)</ref>). Let p</p><formula xml:id="formula_29">(K) i = In+ Ã D−1 2 K e i</formula><p>is the K-th transition probability vector from node i on connected self-
type="bibr" target="#b31">(Pei et al., 2020)</ref>, we use 7 datasets: Cora, Citeseer, Pubmed, Chameleon, Method PPI GraphSAGE (Hamilton et al., 2017)</ref> 61.2 VR-GCN (Chen et al., 2018b)</ref> 97.8 GaAN (Zhang et al., 2018)</ref> 98.71 GAT (Veličković et al., 2018)</ref> 97.3 JKNet <ref CNII* to speed up the convergence of the training process. We compare GCNII with the following state-of-the-art methods: GraphSAGE (Hamilton et al., 2017)</ref>, VR-GCN (Chen et al., 2018b)</ref>, GaAN (Zhang et al., 2018)</ref>, GAT (Veličković et al., 2018)</ref>, JKNet (Xu et al., 2018),
type="bibr" target="#b31">(Pei et al., 2020)</ref>, we use 7 datasets: Cora, Citeseer, Pubmed, Chameleon, Method PPI GraphSAGE (Hamilton et al., 2017)</ref> 61.2 VR-GCN (Chen et al., 2018b)</ref> 97.8 GaAN (Zhang et al., 2018)</ref> 98.71 GAT (Veličković et al., 2018)</ref> 97.3 JKNet <ref CNII* to speed up the convergence of the training process. We compare GCNII with the following state-of-the-art methods: GraphSAGE (Hamilton et al., 2017)</ref>, VR-GCN (Chen et al., 2018b)</ref>, GaAN (Zhang et al., 2018)</ref>, GAT (Veličković et al., 2018)</ref>, JKNet (Xu et al., 2018),


n extensively studied for the past few years. (Li et al., 2018c)</ref> improves flexibility by learning a task-driven adaptive graph for each graph data while training. (Xu et al., 2019)</ref> uses the graph wavelet basis instead of the Fourier basis to improve sparseness and locality. Another line of works focuses on the attention-base
ly the contextualized language model, Algorithm 1: Function F for PSL Rule Grounding and Distance Calculation.</p><p>Input: PSL Rules R, Prediction ŷi , and Probability P(y|s i ), i = {1, 2, 3}; BERT (Devlin et al. 2018)</ref>, to derive the sentence representation v i of d s -dimension to encode the input sequence s i including two marked named entities x i,1 , x i, ions in I2B2-2012 dataset.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>In the framework of CTRL-PG, any contextualized word embedding method, such as BERT (Devlin et al. 2018)</ref>, ELMo (Peters et al. 2018)</ref>, and RoBERTa (Liu et al. 2019b)</ref>, can be u "#b17">(Devlin et al. 2018)</ref>, ELMo (Peters et al. 2018)</ref>, and RoBERTa (Liu et al. 2019b)</ref>, can be utilized. We choose BERT (Devlin et al. 2018)</ref> to derive contextualized sentence embeddings without loss of generality. BERT adds a special token [CLS] at the beginning of each tokenized se ntence embeddings without loss of generality. BERT adds a special token [CLS] at the beginning of each tokenized sequence and learns an embedding vector for it. We follow the experimental settings in (Devlin et al. 2018)</ref> to use 12 Transformer layers and attention heads and set the embedding size d s as 768. The CTRL-PG is implemented in PyTorch and we use the f The CTRL-PG is implemented in PyTorch and we use the fused Adam optimizer (Kingma and Ba 2014)</ref> to optimize the parameters. We follow the experimental settings in (Devlin et al. 2018)</ref> to set the dropout rate, and batch size as 10 1 and 8. We perform grid search for the initial learning rate from a range of {1 ⇥ 10 5</p><p>,
pe="bibr" target="#b46">(Sun, Rumshisky, and Uzuner 2013)</ref> and Clinical TempEval (Bethard et al. 2015</ref>(Bethard et al. , 2016</ref>(Bethard et al. , 2017) )</ref> are some great efforts of building clinical datasets with extensive annotations including labels of clinical events and temporal relations
o 2010; Sun, Rumshisky, and Uzuner 2013; Xu et al. 2013;</ref>Tang et al. 2013;</ref>Lee et al. 2016;</ref>Chikka 2016</ref>) such as SVMs, Max-Ent and CRFs, and neural network based methods (Lin et al. 2017</ref>(
ref type="bibr" target="#b2">(Bach et al. 2017)</ref>.</p><p>Recently, some researchers (Deng and Wiebe 2015;</ref>Chen et al. 2019;</ref>Hu et al. 2016</ref>) have explored Probabilistic Soft Logic (PSL) (Bach et al. 2017)</ref> to tackle the structured prediction problem. In ead><p>In recent years, PSL rules have been applied to various machine learning topics such as Fairness (Farnadi, Babaki, and Getoor 2019)</ref>, Model Interpretability (Hu et al. 2016)</ref>, Probabilistic Reasoning (Augustine, Rekatsinas, and Getoor 2019; Dellert 2020), Knowledge Graph Construction (Puja
ere is a perennial need to automatically and precisely curate the clinical case reports into structured knowledge, i.e. extract important clinical named entities and relationships from the narratives (Aronson and Lang 2010;</ref>Savova et al. 2010;</ref>Soysal et al. 2018;</ref><ref type="bibr" target="#b8"
e for annotating the temporal relations. I2b2-2012 (Sun, Rumshisky, and Uzuner 2013)</ref> and Clinical TempEval (Bethard et al. 2015</ref>(Bethard et al. , 2016</ref>(Bethard et al. , 2017) )</ref> are some great efforts of building clinical datasets with extensive annotations
">(Aronson and Lang 2010;</ref>Savova et al. 2010;</ref>Soysal et al. 2018;</ref>Caufield et al. 2019;</ref>Alfattni, Peek, and Nenadic 2020)</ref>. This would greatly enable both doctors and patients to retrieve related case reports for reference and provide a certain degree o
arget="#b48">Tourille et al. 2017;</ref>Lin et al. 2019;</ref>Guan et al. 2020;</ref>Lin et al. 2020;</ref>Galvan-Sosa et al. 2020)</ref>. They either require expensive feature engineering or fail to consider the dependencies among temporal relations within a document. <ref t
pora in the clinical domain require rich domain knowledge for annotating the temporal relations. I2b2-2012 (Sun, Rumshisky, and Uzuner 2013)</ref> and Clinical TempEval (Bethard et al. 2015</ref>(Bethard et al. , 2016</ref>(Bethard et al. , 2017) )</ref> are some great efforts o
o 2010; Sun, Rumshisky, and Uzuner 2013; Xu et al. 2013;</ref>Tang et al. 2013;</ref>Lee et al. 2016;</ref>Chikka 2016</ref>) such as SVMs, Max-Ent and CRFs, and neural network based methods (Lin et al. 2017</ref>(
te the clinical case reports into structured knowledge, i.e. extract important clinical named entities and relationships from the narratives (Aronson and Lang 2010;</ref>Savova et al. 2010;</ref>Soysal et al. 2018;</ref>Caufield et al. 2019;</ref>A
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There has been a tremendous success in the field of natural language processing (NLP) since the development of Transformers (Vaswani et al. 2017)</ref> which are currently the best performing neural network architectures for handling long-term sequential datasets such as sentences in NLP. Thi genvectors (Belkin and Niyogi 2003)</ref> and use them as node positional information. Since Laplacian PEs are generalization of the PE used in the original transformers (Vaswani et al. 2017)</ref> to graphs and these better help encode distance-aware information (i.e., nearby nodes have similar positional features and farther nodes have Transformer layers.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Transformer Layer</head><p>The Graph Transformer is closely the same transformer architecture initially proposed in (Vaswani et al. 2017)</ref>, see Figure 1</ref> (Left). We now proceed to define the node update equations for a layer .</p><formula xml:id="formula_4 es as a fresh and improved attention based GNN baseline surpassing GAT (see Table 2</ref>), which employs multi-headed attention inspired by the original transformer (Vaswani et al. 2017)</ref> and have been often used in the literature as a baseline for attention-based GNN models. • As expected, sparse graph connectivity is a critic atasets of sentences do not have explicit word interactions available. It thereby makes sense to have each word attending to each other word in a sentence, as followed by the Transformer architecture (Vaswani et al. 2017</ref>). -b) Next, the so-called graph considered in an NLP transformer often has less than tens or hundreds of nodes (i.e. sentences are often less
guyen, and Phung 2019;</ref>Zhang et al. 2020)</ref> with few focused on specialized cases such as on heterogeneous graphs, temporal networks, generative modeling, etc. (Yun et al. 2019;</ref>Xu, Joshi, and Bresson 2019;</ref>Hu et al. 2020;</ref>Zhou et al.

al networks (GNNs) are shown to be the most effective neural network architectures on graph datasets and have achieved significant success on a wide range of applications, such as in knowledge graphs (Schlichtkrull et al. 2018;</ref>Chami et al. 2020)</ref>, in social sciences (Monti et al. 2019)</ref>, in
s, it is ideal and practical to have a Graph Transformer where a node attends to local node neighbors, same as in GNNs (Defferrard, Bresson, and Vandergheynst 2016;</ref>Kipf and Welling 2017;</ref>Monti et al. 2017;</ref>Gilmer et al. 2017;</ref> llelization and efficiency, the original graph structure is not directly used in the layers. Graph-BERT uses  1</ref>) on each dataset against the GNN baselines (GCN (Kipf and Welling 2017)</ref>, GAT (Veličković et al. 2018)</ref>, Gat-edGCN (Bresson and Laurent 2017</ref>
the data as in Dwivedi et al. (2020)</ref>.</p><p>PATTERN, Node Classification PATTERN is a node classification dataset generated using the Stochastic Block Models (SBM) (Abbe 2017</ref>). The task is classify the nodes into 2 communities. PATTERN graphs do not have explicit edge features and hence we use the simple 'Graph Transformer' fo
of letting go sparsity and local contexts. For example, the use of graph-specific positional features (Zhang et al. 2020)</ref>, or node Laplacian position eigenvectors (Belkin and Niyogi 2003;</ref>Dwivedi et al. 2020)</ref>, or relative learnable positional information (You, goal to learn both structural and positional features. In particular, Dwivedi et al. ( 2020</ref>) make the use of available graph structure to pre-compute Laplacian eigenvectors (Belkin and Niyogi 2003)</ref> and use them as node positional information. Since Laplacian PEs are generalization of the PE used in the original transformers <ref type="
of letting go sparsity and local contexts. For example, the use of graph-specific positional features (Zhang et al. 2020)</ref>, or node Laplacian position eigenvectors (Belkin and Niyogi 2003;</ref>Dwivedi et al. 2020)</ref>, or relative learnable positional information (You, goal to learn both structural and positional features. In particular, Dwivedi et al. ( 2020</ref>) make the use of available graph structure to pre-compute Laplacian eigenvectors (Belkin and Niyogi 2003)</ref> and use them as node positional information. Since Laplacian PEs are generalization of the PE used in the original transformers <ref type="
of letting go sparsity and local contexts. For example, the use of graph-specific positional features (Zhang et al. 2020)</ref>, or node Laplacian position eigenvectors (Belkin and Niyogi 2003;</ref>Dwivedi et al. 2020)</ref>, or relative learnable positional information (You, goal to learn both structural and positional features. In particular, Dwivedi et al. ( 2020</ref>) make the use of available graph structure to pre-compute Laplacian eigenvectors (Belkin and Niyogi 2003)</ref> and use them as node positional information. Since Laplacian PEs are generalization of the PE used in the original transformers <ref type="
s, it is ideal and practical to have a Graph Transformer where a node attends to local node neighbors, same as in GNNs (Defferrard, Bresson, and Vandergheynst 2016;</ref>Kipf and Welling 2017;</ref>Monti et al. 2017;</ref>Gilmer et al. 2017;</ref> llelization and efficiency, the original graph structure is not directly used in the layers. Graph-BERT uses  1</ref>) on each dataset against the GNN baselines (GCN (Kipf and Welling 2017)</ref>, GAT (Veličković et al. 2018)</ref>, Gat-edGCN (Bresson and Laurent 2017</ref>
mporal networks, generative modeling, etc. (Yun et al. 2019;</ref>Xu, Joshi, and Bresson 2019;</ref>Hu et al. 2020;</ref>Zhou et al. 2020</ref>). The model proposed in Li et al. (2019)</ref> employs attention to all graph nodes instead of a node's local neigh ation flow in the heterogeneous graphs in the form of relative temporal positional encoding which is based on the timestamp differences of the central node and the message-passing nodes. Furthermore, Zhou et al. (2020)</ref> proposed a transformer based generative model which generates temporal graphs by directly learning from dynamic information in networks. The arc
of letting go sparsity and local contexts. For example, the use of graph-specific positional features (Zhang et al. 2020)</ref>, or node Laplacian position eigenvectors (Belkin and Niyogi 2003;</ref>Dwivedi et al. 2020)</ref>, or relative learnable positional information (You, goal to learn both structural and positional features. In particular, Dwivedi et al. ( 2020</ref>) make the use of available graph structure to pre-compute Laplacian eigenvectors (Belkin and Niyogi 2003)</ref> and use them as node positional information. Since Laplacian PEs are generalization of the PE used in the original transformers <ref type="
s, it is ideal and practical to have a Graph Transformer where a node attends to local node neighbors, same as in GNNs (Defferrard, Bresson, and Vandergheynst 2016;</ref>Kipf and Welling 2017;</ref>Monti et al. 2017;</ref>Gilmer et al. 2017;</ref> llelization and efficiency, the original graph structure is not directly used in the layers. Graph-BERT uses  1</ref>) on each dataset against the GNN baselines (GCN (Kipf and Welling 2017)</ref>, GAT (Veličković et al. 2018)</ref>, Gat-edGCN (Bresson and Laurent 2017</ref>
less we use similar sampling strategy. The WL-PE which are absolute structural roles of nodes in the original graph computed using WL algorithm (Zhang et al. 2020;</ref>Niepert, Ahmed, and Kutzkov 2016)</ref>, are not variant to the subgraphs and can be easily used as a generic PE mechanism. On that account, we swap Laplacian PE in our
mporal networks, generative modeling, etc. (Yun et al. 2019;</ref>Xu, Joshi, and Bresson 2019;</ref>Hu et al. 2020;</ref>Zhou et al. 2020</ref>). The model proposed in Li et al. (2019)</ref> employs attention to all graph nodes instead of a node's local neigh ation flow in the heterogeneous graphs in the form of relative temporal positional encoding which is based on the timestamp differences of the central node and the message-passing nodes. Furthermore, Zhou et al. (2020)</ref> proposed a transformer based generative model which generates temporal graphs by directly learning from dynamic information in networks. The arc
for each word, and eventually preserve distance information. For graphs, the design of unique node positions is challenging as there are symmetries which prevent canonical node positional information (Murphy et al. 2019)</ref>. In fact, most of the GNNs which are trained on graph datasets learn structural node information that are invariant to the node position <ref neighborhood connectivity, instead full-graph connectivity, do not seem to achieve competitive performance on graph datasets. The issue of positional embeddings has been explored in recent GNN works (Murphy et al. 2019;</ref>You, Ying, and Leskovec 2019;</ref>Srinivasan and Ribeiro 2020;</ref><ref type="b
al networks (GNNs) are shown to be the most effective neural network architectures on graph datasets and have achieved significant success on a wide range of applications, such as in knowledge graphs (Schlichtkrull et al. 2018;</ref>Chami et al. 2020)</ref>, in social sciences (Monti et al. 2019)</ref>, in
dix A.1.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Numerical Experiments</head><p>We evaluate the performance of proposed Graph Transformer on three benchmark graph datasets-ZINC (Irwin et al. 2012)</ref>, PATTERN and CLUSTER (Abbe 2017) from a recent GNN benchmark (Dwivedi et al. 2020)</ref>.</p><p>ZINC, Graph Regre bibr" target="#b11">(Irwin et al. 2012)</ref>, PATTERN and CLUSTER (Abbe 2017) from a recent GNN benchmark (Dwivedi et al. 2020)</ref>.</p><p>ZINC, Graph Regression ZINC (Irwin et al. 2012</ref>) is a molecular dataset with the task of graph property regression for constrained solubility. Each ZINC molecule is represented as a graph of a
it impossible to have a fully connected graph for such datasets. On these accounts, it is ideal and practical to have a Graph Transformer where a node attends to local node neighbors, same as in GNNs (Defferrard, Bresson, and Vandergheynst 2016;</ref>Kipf and Welling 2017;</ref>Monti et al. 2017;</ref><ref
the data as in Dwivedi et al. (2020)</ref>.</p><p>PATTERN, Node Classification PATTERN is a node classification dataset generated using the Stochastic Block Models (SBM) (Abbe 2017</ref>). The task is classify the nodes into 2 communities. PATTERN graphs do not have explicit edge features and hence we use the simple 'Graph Transformer' fo
of a GNN applied on a fully connected graph of words (Joshi 2020)</ref>. Transformers based models have led to state-of-the-art performance on several NLP applications (Devlin et al. 2018;</ref>Radford et al. 2018;</ref>Brown et al. 2020</ref>). On the other hand, graph neural use of graph-specific positional features (Zhang et al. 2020)</ref>, or node Laplacian position eigenvectors (Belkin and Niyogi 2003;</ref>Dwivedi et al. 2020)</ref>, or relative learnable positional information (You, Ying, and Leskovec 2019)</ref>, virtual nodes <ref type="bib t GNN works (Murphy et al. 2019;</ref>You, Ying, and Leskovec 2019;</ref>Srinivasan and Ribeiro 2020;</ref>Dwivedi et al. 2020;</ref>Li et al. 2020</ref>) with a goal to learn both structural and positional features. In particular, Dwivedi et al. performance of proposed Graph Transformer on three benchmark graph datasets-ZINC (Irwin et al. 2012)</ref>, PATTERN and CLUSTER (Abbe 2017) from a recent GNN benchmark (Dwivedi et al. 2020)</ref>.</p><p>ZINC, Graph Regression ZINC (Irwin et al. 2012</ref>) is a molecular dataset with the task of graph prop s. Similar to PATTERN, CLUSTER graphs do not have explicit edge features and hence we use the simple 'Graph Transformer' for this task. The size of this dataset is 12K graphs. We refer the readers to (Dwivedi et al. 2020)</ref> for additional information, inlcuding preparation, of these datasets.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Configura edges. Since this dataset have rich feature information in terms of bonds as edge attributes, we use the 'Graph Transformer with edge features' for this task. We use the 12K subset of the data as in Dwivedi et al. (2020)</ref>.</p><p>PATTERN, Node Classification PATTERN is a node classification dataset generated using the Stochastic Block Models (SBM) <ref type="bibr
al networks (GNNs) are shown to be the most effective neural network architectures on graph datasets and have achieved significant success on a wide range of applications, such as in knowledge graphs (Schlichtkrull et al. 2018;</ref>Chami et al. 2020)</ref>, in social sciences (Monti et al. 2019)</ref>, in
target="#b40">Zhou et al. , 2020) )</ref> has achieved promising results in many NLP areas, such as machine translation (Gu et al. 2018)</ref>, task-oriented dialogues (Qian and Yu 2019;</ref>Mi et al. 2019), and</ref>text classification (2019;</ref>2019)</ref>. But there
ype="bibr" target="#b36">Zhang et al. 2020;</ref>Moon et al. 2019)</ref> or retrieved from unstructured documents (Lian et al. 2019;</ref>Zhao et al. 2019;</ref>Kim, Ahn, and Kim 2020)</ref>. Different from them, our MDG model is built on the dedicated medical-domain knowledg



ly in absence of medical knowledge. Recently, large-scale pre-training language models (Devlin et al. 2019;</ref>Radford et al. 2019;</ref>Song et al. 2019</ref>) over unsupervised corpora have achieved significant success. However, fine-tuning such large language models in the medical domain requires suffi
ly in absence of medical knowledge. Recently, large-scale pre-training language models (Devlin et al. 2019;</ref>Radford et al. 2019;</ref>Song et al. 2019</ref>) over unsupervised corpora have achieved significant success. However, fine-tuning such large language models in the medical domain requires suffi

iu et al. 2020)</ref>, symptom extraction (Du et al. 2019a</ref>) and slot-filling (Shi et al. 2020)</ref>. For medical dialogue management, most works (Dhingra et al. 2017;</ref>Li et al. 2017</ref>) focus on reinforcement learning (RL) based task-oriented dialogue system. <ref type="bibr"
/head><p>Medical dialogue system (MDS) aims to converse with patients to inquire additional symptoms beyond their selfreports and make a diagnosis automatically, which has gained increasing attention (Lin et al. 2019;</ref>Wei et al. 2018;</ref>Xu et al. 2019)</ref>. It has a significant potential to simpl onsiderable benefits, many researchers devote substantial efforts to address critical sub-problems in MDS, such as natural language understanding (Shi et al. 2020;</ref>Lin et al. 2019)</ref>,</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Source diseases Target diseases</head><p>Figure 1</ref>: Statistics o taset, called Chunyu2</ref> . It covers 15 kinds of diseases and 12,842 dialogue examples totally, and is much larger than the existing CMDD medical dialogue dataset (Lin et al. 2019)</ref>. The more challenging benchmark can better comprehensively evaluate the performance of medical dialogue systems. Extensive experimental results o "><head>Table 1 :</head><label>1</label><figDesc>In this way, updating the adjacency matrix A meta can reason the existence of edges among entity nodes. The structure of Statistics of the CMDD dataset(Lin et al. 2019)</ref> and our Chunyu dataset.</figDesc><table><row><cell cols="2">Dataset CMDD</cell><cell>Chunyu</cell></row><row><cell># Disease types</cell><cell>4< management (DM) with the line of pipeline-based dialogue system. Various NLU problems have been studied to improve the MDS performance, e.g., entity inference (Du et al. 2019b;</ref>Lin et al. 2019;</ref>Liu et al. 2020)</ref>, symptom extraction (Du et al. 2019a</ref>) and slot-filling <ref type="bibr the challenge, we propose to evolve the commonsense graph capitalized on the dialogue instances and learn the induced meta-knowledge graph during the meta-training and adaptation phases. Inspired by Lin et al. (2019)</ref> that shows the related symptom entities have a certain probability of co-occurrence in the same dialogue, we construct a global-symptom graph G * loss L g and the entity prediction loss L e in Sec. 5.2.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>Here we conduct extensive experiments on the CMDD dataset (Lin et al. 2019</ref>) and the newly-collected Chunyu dataset to demonstrate the benefits of GEML.</p><p>Datasets. The CMDD dataset (Lin ive experiments on the CMDD dataset (Lin et al. 2019</ref>) and the newly-collected Chunyu dataset to demonstrate the benefits of GEML.</p><p>Datasets. The CMDD dataset (Lin et al. 2019</ref>) has 2,067 conversations totally ranging 4 pediatric diseases with approximately equal counts, while neglects the data-imbalance problem among dis
g/ns/1.0"><head n="4.3">Graph-guided Response Generator</head><p>To incorporate the knowledge graph into the generation, we devise a graph-guided response generator with a copy mechanism adapted from (See, Liu, and Manning 2017)</ref>. The main modification is that we apply the copy mechanism over the graph nodes distribution instead of the input source. More concret
f>25,</ref>21,</ref>19,</ref>46,</ref>6,</ref>43]</ref> and have connections to the large literature on metric learning [48,</ref>5]</ref>.</p><p>As the n s with more negatives. The general form of the self-supervised contrastive loss (Eq. 4) is largely motivated by noise contrastive estimation and N-pair losses [17,</ref>43]</ref>, wherein the ability to discriminate between signal and noise (negatives) is improved by adding more examples of negatives. This property has been shown to be bibr" target="#b5">6]</ref>. In these works, the losses are inspired by noise contrastive estimation [17,</ref>32]</ref> or N-pair losses [43]</ref>. Typically, the loss is applied at the last layer of a deep network. At test time, the embeddings from a previous layer are utilized for downstream transfer t
="#b18">19,</ref>46,</ref>6,</ref>43]</ref> and have connections to the large literature on metric learning [48,</ref>5]</ref>.</p><p>As the name suggests, contrastive losses consist of two "opposing forces": for a given anchor point, the first fo ecific target as done in cross-entropy.</p><p>4. We show analytically that the gradient of our loss function encourages learning from hard positives and hard negatives. We also show that triplet loss [48]</ref> is a special case of our loss when only a single positive and negative are used.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work< i.e., ones against which continuing to contrast the anchor only weakly benefits the encoder). The loss can thus be seen to be efficient in its training. Other contrastive losses, such as triplet loss [48]</ref>, often use the computationally expensive technique of hard negative mining to increase training efficacy [40]</ref>. As a bypro e of a normalization in the network.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Connections to Triplet Loss</head><p>Contrastive learning is closely related to the triplet loss [48]</ref>, which is one of the widely-used alternatives to cross-entropy for supervised representation learning. As discussed in Sec 2, the triplet loss has been used t lized for downstream transfer tasks, fine tuning or direct retrieval tasks.</p><p>Closely related to contrastive learning are metric learning and triplet losses [7,</ref>48,</ref>40]</ref>. These losses have been used to learn powerful representations, often in supervised settings, where labels are used to

,</ref>41,</ref>6]</ref>. In these works, the losses are inspired by noise contrastive estimation [17,</ref>32]</ref> or N-pair losses [43]</ref>. Typically, the loss is applied at the last layer of a deep network. At test time, the embeddings fr
etwork, confirming what has been reported by previous work [6]</ref>. With LARS we use a cosine learning rate decay. On the other hand we find that the RMSProp optimizer [47]</ref> works best for training the linear classifier. For RMSProp we use an exponential decay for the learning rate.</p></div> <div xmlns="http://www.tei-c.org/ns/1.
,</ref>41,</ref>6]</ref>. In these works, the losses are inspired by noise contrastive estimation [17,</ref>32]</ref> or N-pair losses [43]</ref>. Typically, the loss is applied at the last layer of a deep network. At test time, the embeddings fr
5,</ref>46,</ref>41,</ref>6]</ref>. In these works, the losses are inspired by noise contrastive estimation [17,</ref>32]</ref> or N-pair losses [43]</ref>. Typically, the loss is applied at the last layer of a deep ec. 4.</p><p>• Contrastive power increases with more negatives. The general form of the self-supervised contrastive loss (Eq. 4) is largely motivated by noise contrastive estimation and N-pair losses [17,</ref>43]</ref>, wherein the ability to discriminate between signal and noise (negatives) is improved by adding more examples of negat
bution (a discrete distribution of 1-hot vectors) and the empirical distribution of the logits. A number of works have explored shortcomings with this loss, such as lack of robustness to noisy labels [59,</ref>44]</ref> and the possibility of poor margins [14,</ref>30]</ref>, target labels vectors e.g. [52]</ref>.</p><p>In addition, a number of papers have studied other drawbacks of the cross-entropy loss, such as sensitivity to noisy labels [59,</ref>44]</ref>, adversarial examples [14,</ref>34]</ref>, and poor marg
ch as lack of robustness to noisy labels [59,</ref>44]</ref> and the possibility of poor margins [14,</ref>30]</ref>, leading to reduced generalization performance. In practice, however, most proposed alternatives do not seem to have worked better for large-scale datasets, su
5,</ref>46,</ref>41,</ref>6]</ref>. In these works, the losses are inspired by noise contrastive estimation [17,</ref>32]</ref> or N-pair losses [43]</ref>. Typically, the loss is applied at the last layer of a deep ec. 4.</p><p>• Contrastive power increases with more negatives. The general form of the self-supervised contrastive loss (Eq. 4) is largely motivated by noise contrastive estimation and N-pair losses [17,</ref>43]</ref>, wherein the ability to discriminate between signal and noise (negatives) is improved by adding more examples of negat
moothing [45]</ref> makes a fuzzy distinction between correct and incorrect labels by moving off-axis, which provides a small but significant boost in many applications [33]</ref>. In self-distillation [24]</ref>, multiple rounds of cross-entropy training are performed by using the "soft" labels from previ proposed; however, the more popular and effective ideas in practice have been approaches that change the reference label distribution, such as label smoothing [45,</ref>33]</ref>, data augmentations such as Mixup [56]</ref> and CutMix [55]</ref>, and knowledge distillation <r

nature of pre-training, a huge amount of unlabeled data can be utilized, along with very large architectures.</p><p>In the image domain, predictive approaches have also been used to learn embeddings [13,</ref>57,</ref>58,</ref>35]</ref>: the typical setup is that some part o
gradually transformed towards the target vector. However, it is unclear why these target labels should be the optimal ones; some work has been done into identifying better target labels vectors e.g. [52]</ref>.</p><p>In addition, a number of papers have studied other drawbacks of the cross-entropy loss, such as sensitivity to noisy labels <ref type="bibr" target="#b
e tuning or direct retrieval tasks.</p><p>Closely related to contrastive learning are metric learning and triplet losses [7,</ref>48,</ref>40]</ref>. These losses have been used to learn powerful representations, often in supervised settings, where labels are used to guide the choice of positive and negativ ative pair. In the supervised metric learning setting, the positive pair is chosen from the same class or category and the negative pair is chosen from other classes, often using hard-negative mining [40]</ref>. Self-supervised contrastive losses similarly use just one positive pair, selected using either co-occurence [21,</ref><ref typ er is always normalized to the unit hypersphere in R D E . We find from experiments that this normalization always improves performance, consistent with other papers that have used metric losses e.g. [40]</ref>. We also find that the new supervised loss is able to train both of these architectures to a high accuracy with no special hyperparameter tuning. In fact, as ning. Other contrastive losses, such as triplet loss [48]</ref>, often use the computationally expensive technique of hard negative mining to increase training efficacy [40]</ref>. As a byproduct of this analysis, we motivate the addition of a normalization layer at the end of the projection network, since its presence allows the gradie sentation learning. As discussed in Sec 2, the triplet loss has been used to generate robust representations via supervised settings where hard negative mining leads to efficient contrastive learning [40]</ref>. The triplet loss, which can only handle one positive and negative at a time, can be shown to be a special case of the contrastive loss when the number of pos at contrastive loss performs better in general than triplet loss on representation tasks. Additionally, whereas triplet loss in practice requires computationally expensive hard negative mining (e.g., [40]</ref>), the discussion in the previous section shows that the gradients of the supervised contrastive loss naturally impose a measure of hard negative reinforcement optimization easier, and classes more separated.</p><p>2. Hard negatives: On the other hand, hard negatives have shown to improve classification accuracy when models are trained with the triplet loss [40]</ref>. Low temperatures are equivalent to optimizing for hard negatives: for a given batch of samples and a specific anchor, lowering the temperature increases the

mbeddings from a previous layer are utilized for downstream transfer tasks, fine tuning or direct retrieval tasks.</p><p>Closely related to contrastive learning are metric learning and triplet losses [7,</ref>48,</ref>40]</ref>. These losses have been used to learn powerful representations, often in supervi
bution (a discrete distribution of 1-hot vectors) and the empirical distribution of the logits. A number of works have explored shortcomings with this loss, such as lack of robustness to noisy labels [59,</ref>44]</ref> and the possibility of poor margins [14,</ref>30]</ref>, target labels vectors e.g. [52]</ref>.</p><p>In addition, a number of papers have studied other drawbacks of the cross-entropy loss, such as sensitivity to noisy labels [59,</ref>44]</ref>, adversarial examples [14,</ref>34]</ref>, and poor marg
ture in the data. In the language domain, state of the art models learn pre-trained embeddings by predicting masked out tokens in a sentence or paragraph e.g. [12,</ref>53,</ref>31]</ref>. Downstream fine-tuning is then used to achieve excellent results on tasks such as sentiment classification and questio
type="bibr" target="#b58">[59,</ref>44]</ref>, adversarial examples [14,</ref>34]</ref>, and poor margins [4]</ref>. Alternative losses have been proposed; however, the more popular and effective ideas in practice have been approaches that change the reference label distribut
amily of contrastive objective functions, which have achieved excellent performance in self-supervised learning in recent years in the image and video domains [50,</ref>25,</ref>21,</ref>19,</ref>46,</ref>6,</ref><r family of models for self-supervised representation learning are collected under the umbrella of contrastive learning [50,</ref>21,</ref>25,</ref>46,</ref>41,</ref>6]</ref>. In these works, the losses are inspired mining [40]</ref>. Self-supervised contrastive losses similarly use just one positive pair, selected using either co-occurence [21,</ref>25,</ref>46]</ref> or using data augmentation [6]</ref>. The major difference is that many negative pairs ar ating from the same source image. In self-supervised contrastive learning (e.g., [6,</ref>46,</ref>21,</ref>25]</ref>), the loss takes the following form.</p><formula xml:id="formula_0">L self = 2N i=1 L self i (1)</formula><formula xml:id="formula_1">L self i = − log exp z i
" target="#b29">30]</ref>, leading to reduced generalization performance. In practice, however, most proposed alternatives do not seem to have worked better for large-scale datasets, such as ImageNet [11]</ref>, as evidenced by the continued use of cross-entropy to achieve state of the art results [9,</ref>1 sification accuracy on ImageNet and robustness to common image corruptions [22]</ref>. After training the embedding network with supervised contrastive loss on ImageNet [11]</ref>, we replace the projection head of the network with a a new randomly initialized linear dense (fully connected) layer. This linear layer is trained with stand
lic and heterophilic node label patterns and determine the trade-off between node and topological feature exploration, we first describe the recently proposed contextual stochastic block model (cSBM) (Deshpande et al., 2018)</ref>. The cSBM allows for smoothly controlling the "informativeness ratio" between node features and graph topology, where the graph can vary f SYNTHETIC AND REAL-WORLD DATASETS</head><p>Synthetic data. In order to test the ability of label learning of GNNs on graphs with arbitrary levels of homophily and heterophily, we propose to use cSBMs (Deshpande et al., 2018)</ref> to generate synthetic graphs. We consider the case with two equal-size classes. In cSBMs, the node features are Gaussian random vectors, w ) 2 . Ideally, GNNs that are able to optimally learn on both homophilic and heterophilic graph should have similar performances for φ and −φ. Due to space limitation we refer the interested reader to (Deshpande et al., 2018)</ref> for a review of all formal theoretical results and only outline the cSBM properties needed for our analysis. Additional information is als vely. Moreover, positive λ s correspond to homophilic graphs while negative λ s correspond to heterophilic graphs. The information-theoretic limits of reconstruction for the cSBM are characterized in Deshpande et al. (2018)</ref>. The results show that, asymptotically, one needs λ 2 + µ 2 /ξ &gt; 1 to ensure a vanishing ratio of the misclassified nodes and the total the node features and the graph structure respectively.</p><p>One reason for using the cSBM to generate synthetic data is that the information-theoretic limit of the model is already characterized in Deshpande et al. (2018)</ref>. This result is summarized below.</p><p>Theorem A.7 (Informal main result in Deshpande et al. (2018)</ref>). tion-theoretic limit of the model is already characterized in Deshpande et al. (2018)</ref>. This result is summarized below.</p><p>Theorem A.7 (Informal main result in Deshpande et al. (2018)</ref>). Assume that n, f → ∞, n f → ξ and d → ∞. Then there exists an estimator v such that lim inf n→∞</p><formula xml:id="formula_28">| v,v | n
le f θ . We can observe from Table 3</ref> that indeed GPR-GNN has a running time similar to that of APPNP. It is nevertheless worth pointing out that the authors of Bojchevski et al. (2020)</ref> successfully scaled APPNP to operate on large graphs. Whether the same techniques may be used to scale GPR-GNNs is an interesting open ques
ental weaknesses which restrict their learning ability on general graph-structured data. First, most of them seem to be tailor-made to work on homophilic (associative) graphs. The homophily principle (McPherson et al., 2001)</ref> in the context of node classification asserts that nodes from the same class tend to form edges. Homophily is also a common assumption in
get="#b19">(Klicpera et al., 2018)</ref>. Methods developed for homophilic graphs are nonuniversal in so far that they fail to properly solve learning problems on heterophilic (disassortative) graphs (Pei et al., 2019;</ref>Bojchevski et al., 2019;</ref>2020)</ref>. In heterophilic graphs, nodes with distinct labels are ying optimal graph filter. This once again shows that large-step propagation is beneficial.</p><p>Universality with respect to node label patterns: Homophily versus heterophily. In their recent work, Pei et al. (2019)</ref> proposed an index to measure the level of homophily of nodes in a graph H(G) = 1</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>|V | v∈ ely. The sparse splittnig is more similar to the original semi-supervised setting considered in Kipf &amp; Welling (2017)</ref> while the dense setting is considered in Pei et al. (2019)</ref> for studying heterophilic graphs. For all datasets, we run each experiment 100 times with multiple random splits and different initializations.</ raphs Computers and Photo (McAuley et al., 2015;</ref>Shchur et al., 2018)</ref>. We also use 5 heterophilic benchmark datasets tested in Pei et al. (2019)</ref>, including Wikipedia graphs Chameleon and Squirrel, the Actor co-occurrence graph, and webpage graphs Texas and Cornell from WebKB<ref type="foot in Kipf &amp; Welling (2017)</ref>; Shchur et al. (2018)</ref>. For the heterophilic datasets, we adopt dense splitting which is used in Pei et al. (2019)</ref>.</p><p>Table 2</ref> shows that, in general, GPR-GNN outperforms all tested methods. On homophilic datasets, GP e two patterns match the results of the cSBM experiments for φ close to −1 and 0, respectively (Figure 2</ref>). Furthermore, the homophily measure H(G) proposed by Pei et al. (2019)</ref> cannot characterize such differences in heterophilic datasets. We relegate the more detailed discussion of this topic along with illustrative exa ref type="bibr" target="#b19">(Klicpera et al., 2018)</ref>, SGC (Wu et al., 2019)</ref>, SAGE (Hamilton et al., 2017)</ref> and Geom-GCN (Pei et al., 2019)</ref>. For all these architectures, we use the corresponding Pytorch Geometric library implementations (Fey &amp; Lenss rs1</ref> . We could not test Geom-GCN on cSBM and other datasets not originally tested in the paper due to a preprocessing subroutine that is not publicly available (Pei et al., 2019)</ref>.</p><p>The GPR-GNN model setup and hyperparameter tuning. We choose random walk path lengths with K = 10 and use a 2-layer (MLP) with 64 hidden the NN part to be 0.5 as APPNP and optimize the dropout rate for the GPR part among {0, 0.5, 0.7}. For Geom-GCN, we choose the datasets already tested in the paper were the method was first described (Pei et al., 2019)</ref>. For SGC, we use the default K = 2 layers after test among {2, 3}. For SAGE, we use 2 SAGE convolutional layers with 64 hidden units.</p><p>The >(Pei et al., 2019)</ref>. For SGC, we use the default K = 2 layers after test among {2, 3}. For SAGE, we use 2 SAGE convolutional layers with 64 hidden units.</p><p>The heterophilic datasets used in (Pei et al., 2019)</ref>. The graphs Chameleon, Actor, Squirrel, Texas and Cornell in their original form are directed graphs (see the github repository of <ref type="bi sets used in (Pei et al., 2019)</ref>. The graphs Chameleon, Actor, Squirrel, Texas and Cornell in their original form are directed graphs (see the github repository of (Pei et al., 2019)</ref>). Since the usual setting for semi-supervised node classifications involves undirected graph, we transformed the graphs into undirected to test w></table></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 :</head><label>7</label><figDesc>Results on homophilic real-world benchmark datasets tested in(Pei et al., 2019)</ref>, dense splitting: Mean accuracy (%) ± 95% confidence interval. Boldface values indicate the best results found while boldface, underlined values tely not made public by the authors. Our homophily measure values H(G) in Table 1</ref> are all based on undirected graphs and hence the numbers are different from those reported in (Pei et al., 2019)</ref>.    </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.10 ADDITIONAL EXPERIMENTAL RESULTS</head></div>			</div> 			<div type="reference

tion graphs Cora, CiteSeer, PubMed (Sen et al., 2008;</ref>Yang et al., 2016)</ref> and the Amazon co-purchase graphs Computers and Photo (McAuley et al., 2015;</ref>Shchur et al., 2018)</ref>. We also use 5 heterophilic benchmark datasets tested in <ref type="bibr" target="#

filter of order K. Thus, learning the optimal GPR weights is equivalent to learning the optimal polynomial graph filter. Note that one can approximate any graph filter using a polynomial graph filter (Shuman et al., 2013)</ref> and hence the GPR method is able to deal with a large range of different node label patterns. Also, increasing K allows one to better approxi

asets. We use 5 homophilic benchmark datasets available from the Pytorch Geometric library, including the citation graphs Cora, CiteSeer, PubMed (Sen et al., 2008;</ref>Yang et al., 2016)</ref> and the Amazon co-purchase graphs Computers and Photo (McAuley et al., 2015;</ref>
mial graph filtering, which can naturally deal with both high and low frequency parts of the graph signals. In contrast, recent GNN models that utilize Personalized PageRanks (PPR) with fixed weights (Wu et al., 2019;</ref>Klicpera et al., 2018;</ref>2019)</ref> inevitably act as low-pass filters. Thus, they fail to lea APPNP (Klicpera et al., 2018)</ref> represents one of the state-of-theart GNNs that is related to our GPR-GNN approach. It can be easily seen that APPNP as well as SGC (Wu et al., 2019)</ref> are special cases of our model since APPNP fixes</p><formula xml:id="formula_3">γ k = α(1−α) k , γ K = (1− α) K ,</formula><p>while SGC removes a ref type="bibr" target="#b37">(Xu et al., 2018)</ref>, GCN-Cheby (Defferrard et al., 2016)</ref>, APPNP (Klicpera et al., 2018)</ref>, SGC (Wu et al., 2019)</ref>, SAGE (Hamilton et al., 2017)</ref> and Geom-GCN (Pei et al., 2019)</ref>. For all
"bibr" target="#b30">[32]</ref>.</p><p>Given the importance of DNNs' performance, researchers and industry practitioners have turned to search-based compilation [2,</ref>10,</ref>29,</ref>45,</ref>53]</ref> for automated generation of tensor progr atrix multiplications with large input sizes. It is hard for compilation-based approaches to beat manually-written assembly code on large matrix multiplications [5,</ref>10,</ref>45]</ref>, as the code has been hand-optimized for decades.  Ablation study. We run variants of Ansor on two test cases in Figure ula><p>Matrix Multiplication 𝐶 ", % = ∑ 𝐴 ", ) 𝐵 ), % ) Figure 1</ref>: The computation definition of matrix multiplication. ple compiler techniques have been introduced (e.g., TVM [10]</ref>, Halide [38]</ref>, Tensor Comprehensions [45]</ref>). Users define the computation in a form sim efficient because it has to deal with the unnecessary exponential explosion of the search space. Typically, the compiler partitions the large computational graph of a DNN into several small subgraphs [10]</ref>. This partition has a negligible effect on the performance thanks to the layer-by-layer construction nature of DNNs. This brings the final challenge of Ansor: ="bibr" target="#b26">28,</ref>33]</ref>. The latest one with beam search and learned cost model performs the best among them, which is also used in our evaluation. TVM [10]</ref> utilizes a similar scheduling language and includes a template-guided search framework AutoTVM [11]</ref>. Similar to the motiva duling language similar to Halide language, and it needs manual scheduling. TensorComprehensions can search for GPU code automatically, but it is not yet meant to be used for compute-bounded problems [10]</ref>. It cannot outperform TVM on operators like conv2d and matmul [10,</ref>44]</ref>. This is because arch for GPU code automatically, but it is not yet meant to be used for compute-bounded problems [10]</ref>. It cannot outperform TVM on operators like conv2d and matmul [10,</ref>44]</ref>. This is because of the lack of certain optimizations and the inaccurate implicit cost model in the polyhedral formulat graph level without changing the internal implementations of operators. The common optimizations at graph level include layout optimizations [29]</ref>, operator fusion [10,</ref>35]</ref>, constant folding [39]</ref>, auto-batching [30]</ref>, a
r most operators, there are always exceptions. For example, some special algorithms (e.g., Winograd convolution [27]</ref>) and accelerator intrinsics (e.g., TensorCore [34]</ref>) require special tile structures to be effective. Although the template-guided search approach (in TVM) can craft a new template for every new case, it needs
hardware platform and operator. The significant manual efforts required to produce efficient operator implementations for each target accelerator limit the development and innovation of new operators [6]</ref> and specialized accelerators [32]</ref>.</p><p>Given the importance of DNNs' performance, researchers and industry practitioners
seful tensor program optimizations. However, existing approaches fail to capture many effective optimization combinations, because they rely on either predefined manually-written templates (e.g., TVM [11]</ref>, FlexTensor [53]</ref>) or aggressive pruning by inaccurately evaluating incomplete programs (e.g. Halide auto-scheduler <ref t earch space an algorithm explores determines the best programs it can find. The considered search spaces in existing approaches are limited by the following factors: (1) Manual enumeration (e.g., TVM [11]</ref>). It is impractical to manually enumerate all possible choices by templates, so existing manual templates only cover a limited search space heuristically.</p> U.</p><p>We include PyTorch [36]</ref>, Halide auto-scheduler [2]</ref>, Flex-Tensor [53]</ref> and AutoTVM [11]</ref> as baseline frameworks.</p><p>PyTorch is backed by the vendor-provided kernel library MKL-DNN [24]</ref>. Halide auto-scheduler the best among them, which is also used in our evaluation. TVM [10]</ref> utilizes a similar scheduling language and includes a template-guided search framework AutoTVM [11]</ref>. Similar to the motivation of this paper, FlexTensor [53]</ref> attempts to reduce human efforts in writing templates. It propo st Model</head><p>A cost model is necessary for estimating the performance of programs during the search. We adopt a learned cost model similar to related works [2,</ref>11]</ref> with newly designed program features. A learned cost model has great portability because a single model design can be reused for different hardware targets by
in the search space in seconds, and pick the promising ones to do actual measurement.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evolutionary Search</head><p>Evolutionary search [49]</ref> is a generic meta-heuristic algorithm inspired by biological evolution. By iteratively mutating highquality programs, we can generate new programs with potent
r.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">End-to-End Network Benchmark</head><p>We benchmark the end-to-end inference execution time of several DNNs, which include ResNet-50 [20]</ref> and MobileNet-V2 [40]</ref> for image classification, 3D-ResNet-18 [19]</ref> for action recognition, DCGAN <r
and specialized accelerators [32]</ref>.</p><p>Given the importance of DNNs' performance, researchers and industry practitioners have turned to search-based compilation [2,</ref>10,</ref>29,</ref>45,</ref>53]</ref> f -c.org/ns/1.0"><head n="5.2">Learned Cost Model</head><p>A cost model is necessary for estimating the performance of programs during the search. We adopt a learned cost model similar to related works [2,</ref>11]</ref> with newly designed program features. A learned cost model has great portability because a single model design can be re that can describe loop optimization primitives. This language is suitable for both manual optimization and automatic search. Halide has three versions of auto-scheduler based on different techniques [2,</ref>28,</ref>33]</ref>. The latest one with beam search and learned cost model performs the best among , TVM [11]</ref>, FlexTensor [53]</ref>) or aggressive pruning by inaccurately evaluating incomplete programs (e.g. Halide auto-scheduler [2]</ref>), which prevents them from covering a large enough search space ( §2). The rules they use to construct the search space are also limited.</p><p>In this paper, w ruction into a fixed sequence of decisions. The compiler then uses an algorithm such as beam search [31]</ref> to search for good decisions (e.g., Halide auto-scheduler [2]</ref>). In this approach, the compiler constructs a tensor program by sequentially unfolding all nodes in the computational graph. For each node, the compiler makes a to manually enumerate all possible choices by templates, so existing manual templates only cover a limited search space heuristically.</p><p>(2) Aggressive early pruning (e.g., Halide auto-scheduler [2]</ref>). Aggressive early pruning based on evaluating incomplete programs prevents the search algorithm from exploring certain regions in the space.</p><p>In this sect operators ×4 shape configurations ×2 batch size (= 80) test cases. We run these test cases on the Intel CPU.</p><p>We include PyTorch [36]</ref>, Halide auto-scheduler [2]</ref>, Flex-Tensor [53]</ref> and AutoTVM [11]</ref> as baseline frameworks.</p><p>PyTorch is backed by curves go up quickly as the programs become complete, which means the cost model performs very well for complete programs but fails to accurately predict the final performance of incomplete programs. (2)</ref> The fixed order of sequential decisions limits the design of the search space. For example, some optimization needs to add new nodes to the computational graph
n="7.3">End-to-End Network Benchmark</head><p>We benchmark the end-to-end inference execution time of several DNNs, which include ResNet-50 [20]</ref> and MobileNet-V2 [40]</ref> for image classification, 3D-ResNet-18 [19]</ref> for action recognition, DCGAN [37]</ref> generator for image
r relies on user-specified search space, while Ansor constructs the search space automatically. Traditional high-performance libraries such as ATLAS [51]</ref> and FFTW [16]</ref> also utilizes auto-tuning. More recent works NeuroVectorizer [17]</ref> and AutoPhase [18,</ref>
in the search space in seconds, and pick the promising ones to do actual measurement.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evolutionary Search</head><p>Evolutionary search [49]</ref> is a generic meta-heuristic algorithm inspired by biological evolution. By iteratively mutating highquality programs, we can generate new programs with potent
are platforms emerge. Besides, constructing a quality template requires expertise in both tensor operators and hardware. It takes non-trivial research efforts [29,</ref>50,</ref>53]</ref> to develop quality templates. Despite the huge efforts in developing templates, existing manual templates only cover li
can automatically generate talking faces from speech in order to provide the visual cues when they are not available [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref>, [10]</ref>, [11] for a single speaker. Another two-stage system is proposed by Chen et al. [5]</ref>. The system first predicts 68 face landmarks from speech using an LSTM-based network [7]</ref>, and then predicts a few talking face images from the condition image and the face landmarks. They employ a discriminator network to improve image quality. In a
or the hardof-hearing population. Consequently, researchers developed systems that can automatically generate talking faces from speech in order to provide the visual cues when they are not available [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</r ibr" target="#b15">[16]</ref>, [9]</ref>, [17]</ref>, [18]</ref>, [10]</ref>, [5]</ref>, [12]</ref> and then estimate video frames using the predicted face landmarks. In Suwajanakorn et al.'s two-stage system <ref typ g to the PCA arXiv:2008.03592v1 [eess.AS] 8 Aug 2020 coefficients and stitches them together. However, this system works only for a single speaker. Another two-stage system is proposed by Chen et al. [5]</ref>. The system first predicts 68 face landmarks from speech using an LSTM-based network [7]</ref>, and then predicts a few talking fa
years. One approach is to first convert the speech input to face landmarks [6]</ref>, [16]</ref>, [9]</ref>, [17]</ref>, [18]</ref>, [10]</ref>, [5]</ref>,  lip-speech synchronization further and showed that it provides better alignment than the baselines.</p><p>Regarding emotional talking face generation, existing work is somewhat limited. Karras et al. [17]</ref> adopted an end-to-end network to learn a latent representation of emotion states and use the latent code as a control to generate 3D mesh animation. This meth ontent was conveyed by point-light displays instead of natural images.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head><p>Instead of inferring emotion from the input speech [17]</ref>, [22]</ref>, in this work, we propose to use emotions as a condition input to our system. The motivation is to decouple the spe
ges for holistic emotion recognition.</p><p>Most of the existing work was focused on emotionally congruent stimuli from these two modalities; little work examined incongruent stimuli. Tsiourti et al. [28]</ref> investigated human responses to emotions expressed by the body and voice of humanoid robots, showing that cross-modal incongruency decreased emotion recogniti
message and can change the meaning drastically [13]</ref>. Studies have shown that predicting emotions purely from speech audio is quite difficult for untrained people [14]</ref> and that we heavily rely on visual cues in emotion interpretation [15]</ref>. Therefore, to make the visual rendering more real t of our emotional classifier in Section IV-C1, showing the challenge of visual speech emotion classification for humans. This observation is similar to a speech emotion classification observation in [14]</ref>.</p><p>Task 1 -Realness Evaluation. For the realness question, the five options are mapped to a scale from 1 to 5, where "definitely real" corresponds to 5 an
type="bibr" target="#b4">[5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref>, [10]</ref>, [11]</ref>, [12]</ref>. These systems can increase the accessibility of abundantly available aud bibr" target="#b5">[6]</ref>, [16]</ref>, [9]</ref>, [17]</ref>, [18]</ref>, [10]</ref>, [5]</ref>, [12]</ref> and then estimate video frames using the predicted face landmarks. In Suwaj l. Vougioukas et al. [18]</ref> proposed a temporal-GAN method to generate more realistic image sequences. They further improved their methods with three discriminators [10]</ref> that focus on improving the realness of video frames, the continuity between generated frames, and the synchronization between audio and visual data. Eskimez e d><p>In this section, we describe the data used in experiments, the hyper-parameters of the neural networks, and objective and subjective evaluations. We choose the temporal GAN approach described in [10]</ref> as our baseline since it is the closest to our method. We use the pre-trained model and inference code provided by the authors to generate baseline videos. Alt te is 30 frames per second (FPS). The audio is sampled at 44.1 kHz. We downsampled the video to 25 FPS and audio to 8 kHz. We followed the same train (70%), validation (15%), and test (15%) splits as [10]</ref>. We used the same files for these splits to ensure a fair comparison. During testing, the speech utterance, the condition emotion and the condition image input n image quality (PSNR and SSIM) is thanks to the perceptual loss. For audiovisual synchronization  (NLMD), even though our method does not use a discriminator calculating a synchronization loss as in [10]</ref>, the improvement is as high as 8.9%, showing the effectiveness of the MRM loss.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Video-based Emotion emotional talking face generation system that is conditioned on speech, reference image, and categorical emotion inputs. We evaluated our network against the ground-truth videos and a baseline system [10]</ref> and validated that our method can generate emotional expressions effectively. In addition, we conducted a subjective study on Amazon Mechanical Turk (AMT) show
ype="bibr" target="#b9">[10]</ref> that focus on improving the realness of video frames, the continuity between generated frames, and the synchronization between audio and visual data. Eskimez et al. [21]</ref> proposed an end-to-end talking face generation system that is robust to noisy speech input. The system contains a frame discriminator to improve image quality . Figure 1</ref> shows the system overview, which employs the generative adversarial network (GAN) framework. Our generator network architecture is built based on our previous work [21]</ref>, with a modification to accept the emotion condition input. For discriminator networks, we use one discriminator to distinguish the emotions expressed in vide e, and emotion encoders, and a video decoder.</p><p>1) Speech Encoder: The speech encoder processes the input speech waveform and outputs a speech embedding. It follows the original implementation of [21]</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>WGAN-GP</head><p>Generator Fig. 1</ref>: Overview of the proposed neural network ding sequence.</p><p>2) Image Encoder: The image encoder computes an image embedding from the input condition face image. The architecture follows the original implementation without any modification [21]</ref>. It contains six layers of 2-D convolutional layers with the following number of filters, kernel sizes, and down-sampling factors: (64, 3, 2), (128, 3, 2), (2 e embedding. This noise embedding models the head movements that are not correlated with the speech, image, and the emotion condition.</p><p>5) Video Decoder: We modify the video decoder described in [21]</ref> to accept the additional emotion embedding. We concatenate the speech, image, noise and emotion embeddings, and feed them into the decoder. For each time step c.org/ns/1.0"><head>D. Objective Functions</head><p>Our system employs multiple objective functions that focus on different aspects of the generated videos: a mouth region mask (MRM) loss proposed in [21]</ref> to improve mouth-audio synchronization, a perceptual loss to improve image quality, a frame GAN loss for image quality, and an emotion GAN loss for emotion ex type="bibr" target="#b35">[36]</ref> between the generated video frames and the ground-truth video frames. To measure the audiovisual synchronization, we used the normalized landmarks distance (NLMD) [21]</ref> between landmarks extracted from the generated and ground-truth video frames.</p><p>The baseline method generates 96x128 images, while our method yields 128x1
type="bibr" target="#b4">[5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref>, [10]</ref>, [11]</ref>, [12]</ref>. These systems can increase the accessibility of abundantly available aud bibr" target="#b5">[6]</ref>, [16]</ref>, [9]</ref>, [17]</ref>, [18]</ref>, [10]</ref>, [5]</ref>, [12]</ref> and then estimate video frames using the predicted face landmarks. In Suwaj l. Vougioukas et al. [18]</ref> proposed a temporal-GAN method to generate more realistic image sequences. They further improved their methods with three discriminators [10]</ref> that focus on improving the realness of video frames, the continuity between generated frames, and the synchronization between audio and visual data. Eskimez e d><p>In this section, we describe the data used in experiments, the hyper-parameters of the neural networks, and objective and subjective evaluations. We choose the temporal GAN approach described in [10]</ref> as our baseline since it is the closest to our method. We use the pre-trained model and inference code provided by the authors to generate baseline videos. Alt te is 30 frames per second (FPS). The audio is sampled at 44.1 kHz. We downsampled the video to 25 FPS and audio to 8 kHz. We followed the same train (70%), validation (15%), and test (15%) splits as [10]</ref>. We used the same files for these splits to ensure a fair comparison. During testing, the speech utterance, the condition emotion and the condition image input n image quality (PSNR and SSIM) is thanks to the perceptual loss. For audiovisual synchronization  (NLMD), even though our method does not use a discriminator calculating a synchronization loss as in [10]</ref>, the improvement is as high as 8.9%, showing the effectiveness of the MRM loss.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Video-based Emotion emotional talking face generation system that is conditioned on speech, reference image, and categorical emotion inputs. We evaluated our network against the ground-truth videos and a baseline system [10]</ref> and validated that our method can generate emotional expressions effectively. In addition, we conducted a subjective study on Amazon Mechanical Turk (AMT) show
signal. Visual cues, when present, also play a vital role. The presence of visual cues improves speech comprehension [1]</ref>, [2]</ref>, [3]</ref>, [4]</ref> in noisy environments and for the hardof-hearing population. Consequently, researchers developed systems that can autom
on does not solely depend on the acoustic signal. Visual cues, when present, also play a vital role. The presence of visual cues improves speech comprehension [1]</ref>, [2]</ref>, [3]</ref>, [4]</ref> in noisy environments and for the hardof-hearing population. Consequently, res
n their daily life. This might also because the generated videos (especially OURS) are quite realistic, lowering the workers' confidence in rating the ground-truth videos. A Wilcoxon signed-rank test [38]</ref> shows that the median difference between our ratings and the baseline ratings is statistically significantly greater than zero, at the significance level of 0
1.0"><head n="1.1">ADDITIONAL RELATED WORK</head><p>The Approximate Personalized Propagation of Neural Predictions (APPNP) framework is most relevant to our work, as they also smooth base predictions (Klicpera et al., 2018)</ref>. However, they focus on integrating this smoothing into the training process so that their model can be trained end to end. Not only is thi rg max j∈{1,...,c} Ŷij .</p><p>As with error correlation, the smoothing here is a post-processing step, decoupled from the other steps. This type of prediction smoothing is similar in spirit to APPNP (Klicpera et al., 2018)</ref>, which we compare against later. However, APPNP is trained end-to-end, propagates on final-layer representations instead of softmaxes, does

cales to large datasets. Our framework also complements the Simplified Graph Convolution (Wu et al., 2019)</ref>, as well as algorithms designed to increase scalability (Bojchevski et al., 2020;</ref>Zeng et al., 2019;</ref>Rossi et al., 2020)</ref>. The primary focus of our a
into the learning algorithm (as was done in traditional techniques) yields easy and substantial performance gains. We can also incorporate our techniques into big GNN models, providing modest gains. Mahoney, 2015)</ref>. The salient point for this paper is that we assume positive correlations on neighboring nodes and that the algorithms work by "propagating" informa
ice31, we reused our base GCN architecture and trained it over spectral and node2vec embeddings. This significantly outperformed the other GNN variants.</p><p>All models were implemented with PyTorch (Paszke et al., 2019)</ref> and PyTorch Geometric (Fey &amp; Lenssen, 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head
hic (Jia &amp; Benson, 2020)</ref>. Finally, we use an email dataset of a European research institute, where classes are department membership and there are no features (Leskovec et al., 2007;</ref>Yin et al., 2017)</ref>.</p><p>Data splits. The training/validation/test splits for Arxiv and Products are gi >• Cora, Citseer, Pubmed (Getoor et al., 2001;</ref>Getoor, 2005;</ref>Namata et al., 2012)</ref> and Email (Leskovec et al., 2007;</ref>Yin et al., 2017)</ref>: 3 layers and 64 hidden channels with learning rate = 0.01.</p><p>• wikiCS: 3 layers

esearch connects GNNs to label propagation (Wang &amp; Leskovec, 2020;</ref>Jia &amp; Benson, 2020)</ref> as well as Markov Random fields (Qu et al., 2019;</ref>Gao et al., 2019)</ref>, and some techniques use ad hoc incorporation of label information in the features <ref type
into the learning algorithm (as was done in traditional techniques) yields easy and substantial performance gains. We can also incorporate our techniques into big GNN models, providing modest gains. Mahoney, 2015)</ref>. The salient point for this paper is that we assume positive correlations on neighboring nodes and that the algorithms work by "propagating" informa
nd natural language processing, there are now a wide range of graph neural networks (GNNs) for making predictions involving relational data (Battaglia et al., 2018;</ref>Wu et al., 2020)</ref>. These models have had much success and sit atop leaderboards such as the Open Graph Benchmark (Hu et al., 2020)</r
label spreading. The term "label propagation" is used in a variety of contexts (Zhu,</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2005" xml:id="foot_2">; Wang &amp; Zhang, 2007;Raghavan et al., 2007;</ref> Gleich &amp;   </note> 		</body> 		<back> 			<div type="annex"> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A MODEL DETAILS</head><p>Here
on graphs such as the spectral graph transducer (Joachims, 2003)</ref>, Gaussian random field models (Zhu et al., 2003)</ref>, and and label spreading (Zhou et al., 2004)</ref> all use this idea. However, the motivation for these methods was semi-supervised learning on point cloud data, so the features were used to con 1)</formula><p>The residuals in rows of E corresponding to training nodes are zero only when the base predictor makes a perfect predictions. We smooth the error using the label spreading technique of Zhou et al. (2004)</ref>, optimizing the objective</p><formula xml:id="formula_1">Ê = arg min W ∈R n×c trace(W T (I − S)W ) + µ W − E 2 F .<label>(2)</label></formula><p of the error estimation over the graph, and is equal to c j=1 w T j (I − S)w j , where w j is the jth column of W . The second term keeps the solution close to the initial guess E of the error. As in Zhou et al. (2004)</ref>, the solution can be obtained via the iteration E (t+1) = (1 − α)E + αSE (t) , where α = 1/(1 + µ) and E (0) = E, which converges rapidly to Ê. e the input features are the raw node features and the spectral embedding. We also use a Plain Linear model that only uses the raw features for comparison and Label Propagation (LP; specifically, the Zhou et al. (2004)</ref> version), which only uses labels. For comparable GNN models to our framework (in terms of simplicity or style), we use GCN, SGC, and APPNP. For round truth labels directly helps, we also experiment with a version of C&amp;S without labels. Instead of running our LP steps, we just smooth the output of the base predictors using the approach of Zhou et al. (2004)</ref> and call this the Basic Model.</p><p>We see that the linear and MLP base predictor can often exceed the performance of a GCN (Table <ref type="t
m Networks (Xu et al., 2018)</ref>, and various deep models (Li et al., 2019;</ref>Rong et al., 2019;</ref>Chen et al., 2020)</ref>. Many ideas for new GNN architectures are adapted from new architectures in models for language (e.g., attention) or vision (e.g., deep CNNs) wit roducts, this is UniMP (Shi et al., 2020)</ref> (top of OGB leaderboard, as of October 1, 2020). For Cora, Citeseer and Pubmed, we reuse the top performance scores from Chen et al. (2020)</ref>. For Email and US County, we use GCNII (Chen et al., 2020)</ref>. For Rice31, we use GCN with spectral and node2vec derboard, as of October 1, 2020). For Cora, Citeseer and Pubmed, we reuse the top performance scores from Chen et al. (2020)</ref>. For Email and US County, we use GCNII (Chen et al., 2020)</ref>. For Rice31, we use GCN with spectral and node2vec (Grover &amp; Leskovec, 2016)</ref> embeddings (this is the be
ta from just the labels (i.e., no features) (Koutra et al., 2011;</ref>Gleich &amp; Mahoney, 2015;</ref>Peel, 2017;</ref>Chin et al., 2019)</ref> but have largely been ignored in GNNs. That being said, we find that even simple label propagation (which ignores features) does surprisingly wel
label spreading. The term "label propagation" is used in a variety of contexts (Zhu,</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2005" xml:id="foot_2">; Wang &amp; Zhang, 2007;Raghavan et al., 2007;</ref> Gleich &amp;   </note> 		</body> 		<back> 			<div type="annex"> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A MODEL DETAILS</head><p>Here
nal Network (GCN) (Kipf &amp; Welling, 2017)</ref> or GraphSAGE (Hamilton et al., 2017a)</ref>; examples include Graph Attention Networks (Veličković et al., 2018)</ref>, Graph Isomorphism Networks (Xu et al., 2018)</ref>, and various deep models <ref type="bibr" target="#b25
#b40">(Veličković et al., 2018)</ref>, Graph Isomorphism Networks (Xu et al., 2018)</ref>, and various deep models (Li et al., 2019;</ref>Rong et al., 2019;</ref>Chen et al., 2020)</ref>. Many ideas for new GNN architectures are adapted from new architectures in models for lan
b15">(Henderson et al., 2011;</ref>2012;</ref>Hamilton et al., 2017b)</ref>. In our pipeline, we augment features with a regularized spectral embedding (Chaudhuri et al., 2012;</ref>Zhang &amp; Rohe, 2018)</ref> coming from the leading k eigenvectors of the matrix</p><formula xml:id="formul
#b40">(Veličković et al., 2018)</ref>, Graph Isomorphism Networks (Xu et al., 2018)</ref>, and various deep models (Li et al., 2019;</ref>Rong et al., 2019;</ref>Chen et al., 2020)</ref>. Many ideas for new GNN architectures are adapted from new architectures in models for lan
ude Graph Attention Networks (Veličković et al., 2018)</ref>, Graph Isomorphism Networks (Xu et al., 2018)</ref>, and various deep models (Li et al., 2019;</ref>Rong et al., 2019;</ref>Chen et al., 2020)</ref>. Many ideas for new GNN architecture
hic (Jia &amp; Benson, 2020)</ref>. Finally, we use an email dataset of a European research institute, where classes are department membership and there are no features (Leskovec et al., 2007;</ref>Yin et al., 2017)</ref>.</p><p>Data splits. The training/validation/test splits for Arxiv and Products are gi >• Cora, Citseer, Pubmed (Getoor et al., 2001;</ref>Getoor, 2005;</ref>Namata et al., 2012)</ref> and Email (Leskovec et al., 2007;</ref>Yin et al., 2017)</ref>: 3 layers and 64 hidden channels with learning rate = 0.01.</p><p>• wikiCS: 3 layers
rrors and labels on connected nodes are positively correlated. Assuming similarity between connected nodes is at the center of much network analysis and corresponds to homophily or assortative mixing (McPherson et al., 2001;</ref>Newman, 2003;</ref>Easley &amp; Kleinberg, 2010)</ref>. In the semi-supervised
es [3,</ref>8,</ref>16,</ref>20,</ref>28,</ref>31]</ref>. The recognition process has become a necessary part of many online systems, such as AMiner [24]</ref> and CiteSeerX <ref type=" ad n="3">JOINT LEARNING FOR BOTH TASKS</head><p>Usually, the plain text of an academic homepage is saved first, then the recognition tasks are conducted on text [1,</ref>31]</ref>. Given the plain text of an academic homepage, we aim to recognise all the person names and publications from the plain text simultaneously. To accomplish this ise it and get a sequence S of n tokens and each token is represented as a d e -dimension word embedding, i.e., S ∈ R n×d e . Following state-of-the-art methods [1,</ref>31]</ref>, we use GloVe [19]</ref> to learn word embeddings on an academic homepage dataset (detailed in Section 4.1.1), although other pr nd every publication as a text string shown in the example.</p><p>Recently, deep learning based methods have been developed to address these problems. The state-of-the-art for publication recognition [31]</ref> uses a Bi-LSTM-CRF based model to learn the page-level and line-level structure. The state-of-the-art for person name in academic homepages <ref type="bibr" t omepage as a document and recognise information from the plain text using deep learning based natural language processing methods. For example, state-of-the-art techniques for publication recognition [31]</ref> and for person names recognition [1]</ref> use Bi-LSTM-CRF based models to recognise information from the plain text of the home tes the memory alternatingly using the knowledge from two correlated tasks.</p><p>Moreover, we use different methods to capture the position patterns. The state-of-the-art for publication recognition [31]</ref> trains webpage-level and line-level models together to capture the position information of academic homepage, whereas our model captures position information > <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>4.1.1 Dataset and Preprocessing. We use the same datasets used by the state-of-the-art for publication recognition [31]</ref> and person name recognition [1]</ref>. Table 2</ref> summarises the dataset statistics.</p><p> arget="#b30">[31]</ref> and person name recognition [1]</ref>. Table 2</ref> summarises the dataset statistics.</p><p>• HomePub dataset [31]</ref> contains the plain text of 2,087 homepages from different universities and research institutes with 12,796 publications annotated. • HomeName dataset <ref typ core since CNN-sentence and Bi-LSTM-CNN-CRF can hardly handle complex homepages without the extra information about the position patterns and person names. PAM also outperforms the hierarchical PubSE [31]</ref> model, which can capture the positional diversity, by 3.64% in F1 score. The advantage of our model is more significant in recall than in precision. This may /p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Error Analysis</head><p>We perform a manual inspection of recognition results of state-ofthe-art models for the two tasks (i.e., PubSE [31]</ref> and CogNN [1]</ref>) and our proposed PAM model on 50 randomly selected homepages. We focus on string level performance for the ask and on name level performance for the person name recognition task. In total, we inspect 1,137 publications and 5,542 person names.</p><p>For publication string recognition, we observe that PubSE [31]</ref> misrecognises strings about patents, grants, and research projects as publications. PAM avoids these errors since it can capture publication block information
twork (DMN) [12]</ref> uses a gated recurrent unit [2]</ref> based controller to update the memory, while Working Memory Network (W-MemNN) [17]</ref> uses a multi-head attention [26]</ref> based controller. All these networks use a memory module for a single task and update th ating the memory representation M, we use a memory updating controller based on multi-head attention [26]</ref>, which is similar to that used in Working Memory Network [17]</ref>. Multi-head attention allows the model to jointly attend to different representation subspaces using projection matrices.</p><p>Let Z j denote the memory repr
p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Person Name Recognition.</head><p>Our proposed PAM model outperforms the baselines that use standard NER models, such as Stanford NER [5]</ref> and Bi-LSTM-CRF [9]</ref>, by at least 5.56% on token level and 7.09% on name level in F1 score. Our improvements mainly lie in th
m academic homepages are two essential tasks for analysing researchers' profiles. There have been extensive research interests in the extraction and mining of such information from academic homepages [3,</ref>8,</ref>16,</ref>20,</ref>28,</ref><re <p>Previous studies on academic homepages usually use rule-based [8,</ref>30]</ref> or a hybrid of machine learning and rule-based methods [3]</ref> on the HTML DOM trees of webpages. Yang and Ho [30]</ref> use heuristic rules to locate the publications in a DOM tree. They assu ef type="bibr" target="#b29">[30]</ref> use heuristic rules to locate the publications in a DOM tree. They assume that publications are listed as nodes at the same level in the DOM tree. Chung et al. [3]</ref> uses a linear chain CRF model to analyse the content in a DOM tree and then refines the publication boundaries by rules.</p><p>Recent studies on academic homepa
ation recognition [31]</ref> uses a Bi-LSTM-CRF based model to learn the page-level and line-level structure. The state-of-the-art for person name in academic homepages [1]</ref> uses a co-guided neural network to learn from fine-grained annotation of names. Despite their success, these studies have tackled the two tasks separately. We o eep learning based natural language processing methods. For example, state-of-the-art techniques for publication recognition [31]</ref> and for person names recognition [1]</ref> use Bi-LSTM-CRF based models to recognise information from the plain text of the homepages. However, they solve the two tasks separately. To the best of our kno Setup</head><p>4.1.1 Dataset and Preprocessing. We use the same datasets used by the state-of-the-art for publication recognition [31]</ref> and person name recognition [1]</ref>. Table 2</ref> summarises the dataset statistics.</p><p>• HomePub dataset [31]</ref> contains t dataset [31]</ref> contains the plain text of 2,087 homepages from different universities and research institutes with 12,796 publications annotated. • HomeName dataset [1]</ref> is constructed from the HomePub dataset by further labeling the person names. All the 70,864 person names are annotated with fine-grained forms such as whether n the publication recognition task. This indicates that our model has better capability to cover more person names with the knowledge from the publication recognition task. PAM also outperforms CogNN [1]</ref> by 1.40% on token level and 2.06% on name level in F1 score. Note that CogNN relies on extra labelling information such as whether the tokens are first names or head n="4.5">Error Analysis</head><p>We perform a manual inspection of recognition results of state-ofthe-art models for the two tasks (i.e., PubSE [31]</ref> and CogNN [1]</ref>) and our proposed PAM model on 50 randomly selected homepages. We focus on string level performance for the publication recognition task and on name level perfo id Graduate Course" Conference on Higher Education Pedagogy, Virginia Tech (Feb 2016) is a talk given by the page owenr but not a publication.</p><p>For person name recognition, we observe that CogNN [1]</ref> tends to produce false negative predictions in groups, i.e., a series of person names in a publication string cannot be recognised. PAM does not make such mista xmlns="http://www.tei-c.org/ns/1.0"><head n="3">JOINT LEARNING FOR BOTH TASKS</head><p>Usually, the plain text of an academic homepage is saved first, then the recognition tasks are conducted on text [1,</ref>31]</ref>. Given the plain text of an academic homepage, we aim to recognise all the person names and publications from the plain of an academic homepage, we first tokenise it and get a sequence S of n tokens and each token is represented as a d e -dimension word embedding, i.e., S ∈ R n×d e . Following state-of-the-art methods [1,</ref>31]</ref>, we use GloVe [19]</ref> to learn word embeddings on an academic homepage dataset (detail
ation recognition [31]</ref> uses a Bi-LSTM-CRF based model to learn the page-level and line-level structure. The state-of-the-art for person name in academic homepages [1]</ref> uses a co-guided neural network to learn from fine-grained annotation of names. Despite their success, these studies have tackled the two tasks separately. We o eep learning based natural language processing methods. For example, state-of-the-art techniques for publication recognition [31]</ref> and for person names recognition [1]</ref> use Bi-LSTM-CRF based models to recognise information from the plain text of the homepages. However, they solve the two tasks separately. To the best of our kno Setup</head><p>4.1.1 Dataset and Preprocessing. We use the same datasets used by the state-of-the-art for publication recognition [31]</ref> and person name recognition [1]</ref>. Table 2</ref> summarises the dataset statistics.</p><p>• HomePub dataset [31]</ref> contains t dataset [31]</ref> contains the plain text of 2,087 homepages from different universities and research institutes with 12,796 publications annotated. • HomeName dataset [1]</ref> is constructed from the HomePub dataset by further labeling the person names. All the 70,864 person names are annotated with fine-grained forms such as whether n the publication recognition task. This indicates that our model has better capability to cover more person names with the knowledge from the publication recognition task. PAM also outperforms CogNN [1]</ref> by 1.40% on token level and 2.06% on name level in F1 score. Note that CogNN relies on extra labelling information such as whether the tokens are first names or head n="4.5">Error Analysis</head><p>We perform a manual inspection of recognition results of state-ofthe-art models for the two tasks (i.e., PubSE [31]</ref> and CogNN [1]</ref>) and our proposed PAM model on 50 randomly selected homepages. We focus on string level performance for the publication recognition task and on name level perfo id Graduate Course" Conference on Higher Education Pedagogy, Virginia Tech (Feb 2016) is a talk given by the page owenr but not a publication.</p><p>For person name recognition, we observe that CogNN [1]</ref> tends to produce false negative predictions in groups, i.e., a series of person names in a publication string cannot be recognised. PAM does not make such mista xmlns="http://www.tei-c.org/ns/1.0"><head n="3">JOINT LEARNING FOR BOTH TASKS</head><p>Usually, the plain text of an academic homepage is saved first, then the recognition tasks are conducted on text [1,</ref>31]</ref>. Given the plain text of an academic homepage, we aim to recognise all the person names and publications from the plain of an academic homepage, we first tokenise it and get a sequence S of n tokens and each token is represented as a d e -dimension word embedding, i.e., S ∈ R n×d e . Following state-of-the-art methods [1,</ref>31]</ref>, we use GloVe [19]</ref> to learn word embeddings on an academic homepage dataset (detail
://www.tei-c.org/ns/1.0"><head n="4.2.1">Publication</head><p>Recognition. The advantage of PAM over neural baselines such as CNN-sentence [10]</ref> and Bi-LSTM-CNN-CRF [14]</ref> is over 15.47% in terms of F1 score since CNN-sentence and Bi-LSTM-CNN-CRF can hardly handle complex homepages without the extra information about the positio
of academic homepage, whereas our model captures position information by integrating them into the memory updating process. Studies have exploited relative token position and importance in a sentence [21,</ref>29]</ref>, whereas our algorithm focuses on relative line position and importance in a page.</p></div> <div xmlns="http://www.te t = emb ([ l 1 − l t ε , ..., l n − l t ε ])<label>(14)</label></formula><p>where t ∈ [1,n], L t ∈ R n×d z and emb is applied to reduce the space complexity when computing U l in multi-head attention [21]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Joint Recognition</head><p>The improved memory representations from PAM is used to produce o
m academic homepages are two essential tasks for analysing researchers' profiles. There have been extensive research interests in the extraction and mining of such information from academic homepages [3,</ref>8,</ref>16,</ref>20,</ref>28,</ref><re <p>Previous studies on academic homepages usually use rule-based [8,</ref>30]</ref> or a hybrid of machine learning and rule-based methods [3]</ref> on the HTML DOM trees of webpages. Yang and Ho [30]</ref> use heuristic rules to locate the publications in a DOM tree. They assu ef type="bibr" target="#b29">[30]</ref> use heuristic rules to locate the publications in a DOM tree. They assume that publications are listed as nodes at the same level in the DOM tree. Chung et al. [3]</ref> uses a linear chain CRF model to analyse the content in a DOM tree and then refines the publication boundaries by rules.</p><p>Recent studies on academic homepa
m academic homepages are two essential tasks for analysing researchers' profiles. There have been extensive research interests in the extraction and mining of such information from academic homepages [3,</ref>8,</ref>16,</ref>20,</ref>28,</ref><re <p>Previous studies on academic homepages usually use rule-based [8,</ref>30]</ref> or a hybrid of machine learning and rule-based methods [3]</ref> on the HTML DOM trees of webpages. Yang and Ho [30]</ref> use heuristic rules to locate the publications in a DOM tree. They assu ef type="bibr" target="#b29">[30]</ref> use heuristic rules to locate the publications in a DOM tree. They assume that publications are listed as nodes at the same level in the DOM tree. Chung et al. [3]</ref> uses a linear chain CRF model to analyse the content in a DOM tree and then refines the publication boundaries by rules.</p><p>Recent studies on academic homepa
loss of generality. Then, we encode the input sequence S via two recurrent neural networks (RNNs), one for person name recognition and the other for publication recognition. Specifically, we use LSTM [7]</ref> as the RNN unit:</p><formula xml:id="formula_0">N = LST M (S ) and P = LST M (S )<label>(1)</label></formula><p>Here, N ∈ R n×d h is the hidden representation f
p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Person Name Recognition.</head><p>Our proposed PAM model outperforms the baselines that use standard NER models, such as Stanford NER [5]</ref> and Bi-LSTM-CRF [9]</ref>, by at least 5.56% on token level and 7.09% on name level in F1 score. Our improvements mainly lie in th
igital libraries is usually well-formatted with few format variations. After recognition, these studies may need to solve the name disambiguation problem (i.e., different people with identical names) [23]</ref> before mining the collaboration networks or research interests of a researcher. Such a problem can be alleviated by recognising information from academic home
igital libraries is usually well-formatted with few format variations. After recognition, these studies may need to solve the name disambiguation problem (i.e., different people with identical names) [23]</ref> before mining the collaboration networks or research interests of a researcher. Such a problem can be alleviated by recognising information from academic home
aptures position information by integrating them into the memory updating process. Studies have exploited relative token position and importance in a sentence [21,</ref>29]</ref>, whereas our algorithm focuses on relative line position and importance in a page.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">JOINT LEARNIN
&lt;0.05 based on McNemar's test.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Publication</head><p>Recognition. The advantage of PAM over neural baselines such as CNN-sentence [10]</ref> and Bi-LSTM-CNN-CRF [14]</ref> is over 15.47% in terms of F1 score since CNN-sentence and Bi-LSTM-CNN-CRF can hardly handle comp
interests in the extraction and mining of such information from academic homepages [3,</ref>8,</ref>16,</ref>20,</ref>28,</ref>31]</ref>. The recognition process has become a necessary part of many online systems, su
www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4. 1 . 4</head><label>14</label><figDesc>Baselines. We compare our proposed model with the following single-task models for publication recognition:• ParsCit[4]</ref> is an open-source package3 for parsing publications based on feature engineering and CRF. • CNN-Sentence [10] is used to classify whether each line in a webpage
igital libraries is usually well-formatted with few format variations. After recognition, these studies may need to solve the name disambiguation problem (i.e., different people with identical names) [23]</ref> before mining the collaboration networks or research interests of a researcher. Such a problem can be alleviated by recognising information from academic home
ng person names and publications simultaneously from the plain text of academic homepages.</p><p>A few other studies recognise person names and publications from research papers and digital libraries [15,</ref>18,</ref>24,</ref>25]</ref>. Such a recognition problem is simpler
igital libraries is usually well-formatted with few format variations. After recognition, these studies may need to solve the name disambiguation problem (i.e., different people with identical names) [23]</ref> before mining the collaboration networks or research interests of a researcher. Such a problem can be alleviated by recognising information from academic home
ng person names and publications simultaneously from the plain text of academic homepages.</p><p>A few other studies recognise person names and publications from research papers and digital libraries [15,</ref>18,</ref>24,</ref>25]</ref>. Such a recognition problem is simpler
ph convolution networks (GCNs), which provide an effective end-to-end way to integrate multi-hop neighbors into node representation learning and achieve state-ofthe-art performance for recommendation [17,</ref>36,</ref>44,</ref>48]</ref>.</p><p>Despite effectiveness, current fectiveness, current GCN-based recommendation models suffer from some limitations:</p><p>• Sparse Supervision Signal. Most models approach the recommendation task under a supervised learning paradigm [17,</ref>19,</ref>32]</ref>, where the supervision signal comes from the observed user-item interactions. of users and items respectively. Let O + = {𝑦 𝑢𝑖 |𝑢 ∈ U, 𝑖 ∈ I} be the observed interactions between users and items, where 𝑦 𝑢𝑖 indicates that user 𝑢 has adopted item 𝑖 before. Most existing models [17,</ref>36,</ref>44]</ref> construct a bipartite graph G = (V, E), where the node set V = U ∪ I involves following research questions: </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We conduct experiments on three widely used benchmark datasets: Yelp2018 [17,</ref>44]</ref>, Amazon-Book [17,</ref>44]</ref>, and Alibaba-iFashion < >Experimental Settings</head><p>We conduct experiments on three widely used benchmark datasets: Yelp2018 [17,</ref>44]</ref>, Amazon-Book [17,</ref>44]</ref>, and Alibaba-iFashion [6]</ref> 1</ref> . Following <r k [17,</ref>44]</ref>, and Alibaba-iFashion [6]</ref> 1</ref> . Following [17,</ref>44]</ref>, we use the same 10-core setting for Yelp2018 and Amazon-Book. Alibaba-iFashion is more sparse, where we randomly samp rget="#b31">[32]</ref>, NeuMF [19]</ref>, GC-MC [36]</ref>, and PinSage [48]</ref> since the previous work [17,</ref>27,</ref>44]</ref> has validated the superiority over the compared ones. Upon LightGCN, we implem been evolved from the random walk that encodes the graph structure as transition probabilities [2]</ref>, to GCN that propagates user and item embeddings over the graph [17,</ref>36,</ref>44,</ref>48]</ref>. Recently, attention mechanism is intr hile mentioning that our SGL is model-agnostic and can be applied to any model that consists of user embedding and item embedding. Here we implement it on a state-of-the-art GCN-based model, LightGCN [17]</ref>. Experimental studies on three benchmark datasets demonstrate the effectiveness of SGL, which significantly improves the recommendation accuracy, especially o be simply set as the last-layer representation [36,</ref>48]</ref>, concatenation [44]</ref>, or summation [17]</ref> over the representations of all layers.</p><p>Supervised Learning Loss. Thereafter, a prediction layer is built upon the final representations of user 𝑢 and i des the second-order feature interaction into the message during message passing. We tune the regularization coefficient 𝜆 2 and the number of GCN layers within the suggested ranges.</p><p>• LightGCN [17]</ref>. This is the state-of-the-art graph-based CF method which devises a light graph convolution to ease the training difficulty and pursue better generation abili ="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The comparison of analytical time complexity between LightGCN and SGL-ED.trainable parameters, the space complexity remains the same as LightGCN[17]</ref>. The time complexity of model inference is also the same, since there is no change on the model structure. In the following part, we will analyze the time com
ance model robustness [8]</ref>. Contrastive models learn to compare through a Noise Contrastive Estimation (NCE) objective, which can be in either global-local contrast [20,</ref>38]</ref> or global-global contrast manner [5,</ref>15]</ref>. The
tion, while the supervision of negative pairs enforces the divergence among different nodes. Formally, we follow SimCLR [5]</ref> and adopt the contrastive loss, InfoNCE [12]</ref>, to maximize the agreement of positive pairs and minimize that of negative pairs:</p><formula xml:id="formula_11">L 𝑢𝑠𝑒𝑟 𝑠𝑠𝑙 = ∑︁ 𝑢 ∈U − log exp(𝑠 (z ′ 𝑢 , z User and Item Sides. As the user-item interaction graph is a heterogeneous graph containing two types of nodes: users and items, we formulate the objective function of SSL as the summation of InfoNCE [12]</ref> losses on both user and item sides. Here we conduct ablation studies to verify the influences of user and item nodes. In particular, we create two variants: S t converge do 2 foreach epoch do 3 Perform Eq. (8) for data augmentation 4 foreach batch do 5 Evaluate L 𝑚𝑎𝑖𝑛 according to Eq. (5) 6 Evaluate L 𝑠𝑒𝑙 𝑓 according to Eq. (11) 7Evaluate L according to Eq.(12)</ref> </figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Performanc
grate multi-hop neighbors into node representation learning and achieve state-ofthe-art performance for recommendation [17,</ref>36,</ref>44,</ref>48]</ref>.</p><p>Despite effectiveness, current GCN-based recommendation models suffer from some limitations:</p><p>• Sparse Supe probabilities [2]</ref>, to GCN that propagates user and item embeddings over the graph [17,</ref>36,</ref>44,</ref>48]</ref>. Recently, attention mechanism is introduced into GCN-based recommendation models [43]</ interactions between users and items, where 𝑦 𝑢𝑖 indicates that user 𝑢 has adopted item 𝑖 before. Most existing models [17,</ref>36,</ref>44]</ref> construct a bipartite graph G = (V, E), where the node set V = U ∪ I involves all users and items, and the edge set E = O + represents observed interactions.</ <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We conduct experiments on three widely used benchmark datasets: Yelp2018 [17,</ref>44]</ref>, Amazon-Book [17,</ref>44]</ref>, and Alibaba-iFashion [6]</ref> <r t experiments on three widely used benchmark datasets: Yelp2018 [17,</ref>44]</ref>, Amazon-Book [17,</ref>44]</ref>, and Alibaba-iFashion [6]</ref> 1</ref> . Following [17,</ref><r f>44]</ref>, and Alibaba-iFashion [6]</ref> 1</ref> . Following [17,</ref>44]</ref>, we use the same 10-core setting for Yelp2018 and Amazon-Book. Alibaba-iFashion is more sparse, where we randomly sample 300k users and use all their interacti ef type="bibr" target="#b35">[36]</ref>, and PinSage [48]</ref> since the previous work [17,</ref>27,</ref>44]</ref> has validated the superiority over the compared ones. Upon LightGCN, we implement four variants of the proposed SGL, named SGL-ID, SGL-IM, SGL-ND and SGL-ED, w , • • • , 𝐿]} ,<label>(3)</label></formula><p>which can be simply set as the last-layer representation [36,</ref>48]</ref>, concatenation [44]</ref>, or summation [17]</ref> over the representations of all layers.</p><p>Supervised Learning Loss. Thereafter, a prediction layer d use all their interactions over the fashion outfits. The statistics of all three datasets are summarized in Table 2</ref>. We follow the same strategy described in [44]</ref> to split the interactions into training, validation, and testing with a ratio of 7:1:2.</p><p>For users in the testing set, we follow the all-ranking protocol ref type="bibr" target="#b43">[44]</ref> to split the interactions into training, validation, and testing with a ratio of 7:1:2.</p><p>For users in the testing set, we follow the all-ranking protocol [44]</ref> to evaluate the top-𝐾 recommendation performance and report the average Recall@𝐾 and NDCG@𝐾 where we set 𝐾 = 20.</p><p>4.1.1 Compared Methods. We compare the e top-𝐾 recommendation performance and report the average Recall@𝐾 and NDCG@𝐾 where we set 𝐾 = 20.</p><p>4.1.1 Compared Methods. We compare the proposed SGL with the following CF models:</p><p>• NGCF [44]</ref>. This is a graph-based CF method largely follows the standard GCN [10]</ref>, including the use of nonlinear activation and feat
[17,</ref>44]</ref>, Amazon-Book [17,</ref>44]</ref>, and Alibaba-iFashion [6]</ref> 1</ref> . Following [17,</ref>44]</ref>, we use the same 10-core
t from user-item interactions, which ranges from user social relations [1]</ref>, item co-occurrence [2]</ref>, to user and item attributes [26]</ref>. Recently, Knowledge Graph (KG) is also unified with the user-item graph, which enables considering the detailed types of linkage between items <ref type="bib
s/1.0"><head>4.3.2</head><p>Training Efficiency. Self-supervised learning has proved its superiority in pre-training natural language model [8]</ref> and graph structure [21,</ref>31]</ref>. Thus, we would like to study its influence on training efficiency. Fig. 3</ref> shows the training " target="#b32">[33]</ref> and DGI [40]</ref> learns node representations according to mutual information between a node and the local structure. In addition, Hu et al. [21]</ref> extend the idea to learn GCN for graph representation. Furthermore, Kaveh et al. [14]</ref> adopt the contrastive model for lea
ons of the generative model and contrastive model, this work adopts the contrastive model to avoid additional model parameters.</p><p>SSL has also been applied on graph data. For instance, Info-Graph [33]</ref> and DGI [40]</ref> learns node representations according to mutual information between a node and the local structure. In addit
this work adopts the contrastive model to avoid additional model parameters.</p><p>SSL has also been applied on graph data. For instance, Info-Graph [33]</ref> and DGI [40]</ref> learns node representations according to mutual information between a node and the local structure. In addition, Hu et al. [21]
l information between a node and the local structure. In addition, Hu et al. [21]</ref> extend the idea to learn GCN for graph representation. Furthermore, Kaveh et al. [14]</ref> adopt the contrastive model for learning both node and graph representation, which contrasts node representations from one view with graph representation of a
ed Learning</head><p>Studies on self-supervised learning can be roughly categorized into two branches: generative models [8,</ref>29,</ref>37]</ref> and contrastive models [5,</ref>9,</ref>15,</ref><ref type="bibr" ta
atively poor performance and exponential intermediate data for storing candidates. For example, RStream generates about 1.2TB intermediate data to count 4-motif on the MiCo graph with 1 million edges [18]</ref>.</p><p>Recently, specialized systems have been developed for pattern matching [12]</ref>, [19]</ few embeddings in the graph, which are common for some real graph mining applications.</p><p>Algorithms in these specialized pattern matching systems can be described with nested loops, and AutoMine [18]</ref> and GraphZero [12]</ref> represent relatively good performance in such systems. Observing that even a single-thread program out f type="bibr" target="#b11">[12]</ref> and Fractal [26]</ref>, the state-of-the-art singlemachine pattern matching systems. GraphZero is an upgraded version of AutoMine [18]</ref>, and it outperforms AutoMine by up to 40×. Fractal is a JVM-based system, and it outperforms several JVM-based specialized algorithms (MRSUB <ref type="bibr" "#b18">[19]</ref>- [21]</ref>, [29]</ref>, [39]</ref>, [40]</ref>. Automine [18]</ref> is built upon a set-based representation and uses compilation techniques to generate efficient pattern matching code. However, due to the inherent symmetry in
terns show that GraphPi outperforms the state-of-the-art pattern matching system by several orders of magnitude. Specifically, GraphPi is up to 105× faster than GraphZero and 154× faster than Fractal [26]</ref> running on the same single node. After using the Inclusion-Exclusion Principle (IEP) for counting the number of embeddings, GraphPis performance can be furthe nd it is trivial to predict the performance of different schedules for them.</p><p>Comparison We evaluate GraphPi's performance against GraphZero [12]</ref> and Fractal [26]</ref>, the state-of-the-art singlemachine pattern matching systems. GraphZero is an upgraded version of AutoMine [18]</ref>, and it o
graph and the pattern respectively. We can find 4 distinct one-to-one correspondences ([4,5,6,7,3]</ref>, [5,</ref>4,</ref>7,</ref>6,</ref>3]</ref>, etc.) satisfying the definition of "isomorphic". Therefore, there are 4 embeddings o quare bracket denote a one-to-one correspondence (a bijective function). For example,[4,</ref>5,</ref>6,</ref>7,</ref>3]</ref> denotes the function id where id(A) = 4, id(B) = 5, etc.</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml
ph Counting Some computation engines and systems have been designed to estimate an approximate number of embeddings [2]</ref>, [42]</ref>, [43]</ref>. ASAP [23]</ref> is the state-of-the-art one among them. ASAP is a distributed approximate computation engine for graph pattern
the MiCo graph with 1 million edges [18]</ref>.</p><p>Recently, specialized systems have been developed for pattern matching [12]</ref>, [19]</ref>- [21]</ref>, approximate pattern mining [22]</ref>, [23]</ref>, a pose graph mining systems provide flexible programming models to express complex graph mining algorithms, their performance is relatively poor. Specialized pattern matching systems have been proposed [19]</ref>- [21]</ref>, [29]</ref>, [39]</ref>, <ref type="bibr" target="#b3
ms have been developed for pattern matching [12]</ref>, [19]</ref>- [21]</ref>, approximate pattern mining [22]</ref>, [23]</ref>, and frequent subgraph mining (FSM) [24]</ref>, [25]<
[12]</ref>, [19]</ref>- [21]</ref>, approximate pattern mining [22]</ref>, [23]</ref>, and frequent subgraph mining (FSM) [24]</ref>, [25]</ref>. ASAP  ibr" target="#b21">[22]</ref>, [23]</ref>, and frequent subgraph mining (FSM) [24]</ref>, [25]</ref>. ASAP [23]</ref> is a distributed approximate pattern matching system for estimating the count of embeddings (instances of the input pattern). It allows users to make a trade- have been designed to estimate an approximate number of embeddings [2]</ref>, [42]</ref>, [43]</ref>. ASAP [23]</ref> is the state-of-the-art one among them. ASAP is a distributed approximate computation engine for graph pattern matching. Based on the neighborhood sampling al
on Automine, GraphZero [12]</ref> provides an algorithm based on group theory to break the inherent symmetry in patterns and eliminate redundant computation. Peregrine [41]</ref> is another DFS-based system which provides a pattern-based programming model and a workflow similar to GraphZero. Peregrine also has a schedule generation mod
s can be mainly classified into two types: graph computation and graph mining. Graph computation problems have been extensively studied, and many efficient graph processing systems have been proposed [4]</ref>- [11]</ref>. On the other hand, efficient and scalable graph mining algorithms, which are widely used to discover complex structu here are 8 and 5 vertices in the data graph and the pattern respectively. We can find 4 distinct one-to-one correspondences ([4,5,6,7,3]</ref>, [5,</ref>4,</ref>7,</ref>6,</ref>3]</ref>, etc.) satisfying the definition of "isomorphic ssible relative magnitudes of n vertices in an embedding (e.g., when n = 5, they are [1,</ref>2,</ref>3,</ref>4,</ref>5]</ref>, [1,</ref>2,</ref>3,</ref><ref ty ,</ref>3,</ref>5,</ref>4]</ref>, [1,</ref>2,</ref>4,</ref>3,</ref>5]</ref>, etc). f i is the probability that one embedding will be filtered out by the restrict ,</ref>5]</ref>, [1,</ref>2,</ref>3,</ref>5,</ref>4]</ref>, [1,</ref>2,</ref>4,</ref>3,</ref><ref ty For example, in order to calculate A1,2 T A2,3 \ A4,5 when k = 6, we need to add the three edges (1, 2), (2, 3)and(4, 5) into g. After partitioning g, there are three connected components: [1,2,3] , [4,</ref>5]</ref> and [6]</ref>. Then we have A1,2</p><formula xml:id="formula_19">T A2,3 \ A4,5 = S1 T S2 T S turn intersection card A 1,2 A 2,3 ∩ A 4,5 when k = 6</formula><p>, we need to add three edges (1, 2), (2, 3), and (4, 5) into g. After partitioning g, there are three connected components: [1,2,3] , [4,</ref>5]</ref>, and [6]</ref>. Then we have A 1,2 A 2,3 ∩A 4,5 = S 1 S 2 S 3 × S 4 S 5 × S 6 .</p><p>Note t rtices in the input graph. The capital letters denote different vertices in the pattern. The numeric numbers in a square bracket denote a one-to-one correspondence (a bijective function). For example,[4,</ref>5,</ref>6,</ref>7,</ref>3]</ref> denotes
terns show that GraphPi outperforms the state-of-the-art pattern matching system by several orders of magnitude. Specifically, GraphPi is up to 105× faster than GraphZero and 154× faster than Fractal [26]</ref> running on the same single node. After using the Inclusion-Exclusion Principle (IEP) for counting the number of embeddings, GraphPis performance can be furthe nd it is trivial to predict the performance of different schedules for them.</p><p>Comparison We evaluate GraphPi's performance against GraphZero [12]</ref> and Fractal [26]</ref>, the state-of-the-art singlemachine pattern matching systems. GraphZero is an upgraded version of AutoMine [18]</ref>, and it o
graph and the pattern respectively. We can find 4 distinct one-to-one correspondences ([4,5,6,7,3]</ref>, [5,</ref>4,</ref>7,</ref>6,</ref>3]</ref>, etc.) satisfying the definition of "isomorphic". Therefore, there are 4 embeddings o quare bracket denote a one-to-one correspondence (a bijective function). For example,[4,</ref>5,</ref>6,</ref>7,</ref>3]</ref> denotes the function id where id(A) = 4, id(B) = 5, etc.</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml
sensitivity to data alignment, often involve complicated architectures [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>, and typically require pixel-level correspondences of sensor data. On the other hand, late fusion systems are much simpler to build as they incorporate pre-tr the optimal way for fusing features. In order to fuse features from different sensor modalities with better correspondence, MMF [26]</ref> adopts continuous convolution [14]</ref> to build dense LiDAR BEV feature maps and do point-wise feature fusion with dense image feature maps. MMF is currently one of the best public multi-modal fusi
own pros and cons. While early and deep fusion have greatest potential to leverage cross modality information, they suffer from sensitivity to data alignment, often involve complicated architectures [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>, and typically require pixel- row down the 3D processing domain to the corresponding cropped region in the image. But the 2D image-based proposal generation might fail in some cases that could only be observed from 3D space. MV3D [11]</ref> and AVOD [12]</ref> project the raw point cloud into bird's eye view (BEV) to form a multi-channel BEV image. A deep fusion bas
sion have greatest potential to leverage cross modality information, they suffer from sensitivity to data alignment, often involve complicated architectures [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>, and typically require pixel-level correspondences of sensor data. On th ing cropped region in the image. But the 2D image-based proposal generation might fail in some cases that could only be observed from 3D space. MV3D [11]</ref> and AVOD [12]</ref> project the raw point cloud into bird's eye view (BEV) to form a multi-channel BEV image. A deep fusion based 2D CNN is used to extract features from this BEV
er 3D information. [16]</ref>, [17]</ref> estimate 3D object information by calculating the similarity between 3D objects and CAD models. [18]</ref> and [19]</ref> explore using stereo images to generate dense point cloud and conduct object detection using that cloud. These i
targets. In addition, LiDAR methods [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref> are hampered by typically lower input data resolution than video which has a large adverse impact on accuracy at longer ranges. Fig. <ref type="figure" target=" ade version of [5]</ref>, since raw LiDAR point cloud has very sparse data structure, it uses sparse 3D CNNs which reduces the inference time significantly. PointPillars [9]</ref> uses PointNets [7]</ref> in an encoder that represents point clouds organized in vertical columns (pillars) followed with a 2D CNN ef type="bibr" target="#b29">[30]</ref> and Cascade R-CNN [31]</ref>. The 3D detectors we incorporated are: SECOND [6]</ref>, PointPillars [9]</ref>, PointRCNN [8]</ref> and PV-RCNN [22]</ref>. While not the top performers within the KITTI leaderbo lts of pedestrian and cyclist on KITTI validation set. The IoU threshold for pedestrian and cyclist is 0.5. Here for 3D detectors, only SECOND [6]</ref> and PointPillars [9]</ref> publish their training configurations for class pedestrian and cyclist; for 2D detectors, only MSCNN [30]</ref> does. Therefore,
1.0"><head>C. 3D Detection Using Multi-modal Fusion</head><p>We focus on camera-LiDAR fusion methods in this section since this is the most common sensor setup for self-driving cars. Frustum PointNet [24]</ref>, Pointfusion [13]</ref> and Frustum ConvNet [25]</ref> are the representatives of 2D driven 3D d
>, [4]</ref>, 3D object detection is more challenging with more output parameters needed to specify 3D oriented bounding boxes around targets. In addition, LiDAR methods [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</r sor calibration and synchronization issues. However, object detection performance at longer distance is still relatively poor. Methods vary by how they encode and learn features from raw point cloud. [5]</ref> uses voxels to encode the raw point cloud, and 3D CNNs (Convolutonal Neural Networks) are applied to learn voxel features for classification and bounding box re and 3D CNNs (Convolutonal Neural Networks) are applied to learn voxel features for classification and bounding box regression. SECOND [6]</ref> is the upgrade version of [5]</ref>, since raw LiDAR point cloud has very sparse data structure, it uses sparse 3D CNNs which reduces the inference time significantly. PointPillars <ref type="bibr
urate correspondence between these feature vectors and therefore is not the optimal way for fusing features. In order to fuse features from different sensor modalities with better correspondence, MMF [26]</ref> adopts continuous convolution [14]</ref> to build dense LiDAR BEV feature maps and do point-wise feature fusion with dense imag
head>A. 3D Detection Using 2D Images</head><p>Mousavian et al. [15]</ref> leverage the geometric constraints between 2D and 3D bounding boxes to recover 3D information. [16]</ref>, [17]</ref> estimate 3D object information by calculating the similarity between 3D objects and CAD models. <ref type="bibr" ta
>, 3D object detection is more challenging with more output parameters needed to specify 3D oriented bounding boxes around targets. In addition, LiDAR methods [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref> are hampered by typically lower input target="#b4">[5]</ref> uses voxels to encode the raw point cloud, and 3D CNNs (Convolutonal Neural Networks) are applied to learn voxel features for classification and bounding box regression. SECOND [6]</ref> is the upgrade version of [5]</ref>, since raw LiDAR point cloud has very sparse data structure, it uses sparse 3D CNNs which redu t with it and so most elements are empty. The fusion network only needs to learn from these intersected examples. Because we take the raw predictions before NMS, k and n are large numbers, for SECOND [6]</ref>, there are 70400 (200 × 176 × 2) predictions in each frame. It would be impractical to do 1 × 1 convolution on a dense tensor with this shape. We propose an imp C [29]</ref>, MS-CNN [30]</ref> and Cascade R-CNN [31]</ref>. The 3D detectors we incorporated are: SECOND [6]</ref>, PointPillars [9]</ref>, PointRCNN [8]</ref> and PV-RCNN [22]</ref>. KITTI has some restrictions on the number of submissions, we only show the results evaluated on the official KITTI test server from three fusion combinations of 2D and 3D detectors, which are SECOND [6]</ref> and Cascade R-CNN [31]</ref>, written as CLOCs SecCas, PointRCNN [8]</ref> and Cascade R-CNN, as CL get="#tab_4">IV</ref> show the 3D and BEV evaluation results of pedestrian and cyclist on KITTI validation set. The IoU threshold for pedestrian and cyclist is 0.5. Here for 3D detectors, only SECOND [6]</ref> and PointPillars [9]</ref> publish their training configurations for class pedestrian and cyclist; for 2D detectors, only MSCNN <r
oss modality information, they suffer from sensitivity to data alignment, often involve complicated architectures [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>, and typically require pixel-level correspondences of sensor data. On the other hand, late fusion systems are much ad><p>We focus on camera-LiDAR fusion methods in this section since this is the most common sensor setup for self-driving cars. Frustum PointNet [24]</ref>, Pointfusion [13]</ref> and Frustum ConvNet [25]</ref> are the representatives of 2D driven 3D detectors, which exploit mature 2D detectors to generate
f> and STD [21]</ref> applies a two-stage architecture that first generate 3D proposals in a bottomup manner and then refines these proposals in a second stage. PV-RCNN [22]</ref> leverages the advantages of both 3D voxel CNN and PointNet-based set abstraction to learn more discriminative features. Besides, Part-A 2 in <ref type="bibr" e 3D detectors we incorporated are: SECOND [6]</ref>, PointPillars [9]</ref>, PointRCNN [8]</ref> and PV-RCNN [22]</ref>. While not the top performers within the KITTI leaderboard, we have selected these methods as they are the best currently-available open-source detectors. Our t="#b5">[6]</ref> and Cascade R-CNN [31]</ref>, written as CLOCs SecCas, PointRCNN [8]</ref> and Cascade R-CNN, as CLOCs PointCas, PV-RCNN [22]</ref> and Cascade R-CNN, as CLOCs PVCas. All the other combinations are evaluated on the validation set. Table I</ref> shows the p
atial path planning for object avoidance and navigation. Compared to 2D object detection, which has been well-studied [1]</ref>, [2]</ref>, [3]</ref>, [4]</ref>, 3D object detection is more challenging with more output parameters needed to specify 3D oriented bounding boxes aroun
<p>Mousavian et al. [15]</ref> leverage the geometric constraints between 2D and 3D bounding boxes to recover 3D information. [16]</ref>, [17]</ref> estimate 3D object information by calculating the similarity between 3D objects and CAD models. [18]</ref> and <ref type="bibr"
targets. In addition, LiDAR methods [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref> are hampered by typically lower input data resolution than video which has a large adverse impact on accuracy at longer ranges. Fig. <ref type="figure" target=" ade version of [5]</ref>, since raw LiDAR point cloud has very sparse data structure, it uses sparse 3D CNNs which reduces the inference time significantly. PointPillars [9]</ref> uses PointNets [7]</ref> in an encoder that represents point clouds organized in vertical columns (pillars) followed with a 2D CNN ef type="bibr" target="#b29">[30]</ref> and Cascade R-CNN [31]</ref>. The 3D detectors we incorporated are: SECOND [6]</ref>, PointPillars [9]</ref>, PointRCNN [8]</ref> and PV-RCNN [22]</ref>. While not the top performers within the KITTI leaderbo lts of pedestrian and cyclist on KITTI validation set. The IoU threshold for pedestrian and cyclist is 0.5. Here for 3D detectors, only SECOND [6]</ref> and PointPillars [9]</ref> publish their training configurations for class pedestrian and cyclist; for 2D detectors, only MSCNN [30]</ref> does. Therefore,
>, 3D object detection is more challenging with more output parameters needed to specify 3D oriented bounding boxes around targets. In addition, LiDAR methods [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref> are hampered by typically lower input target="#b4">[5]</ref> uses voxels to encode the raw point cloud, and 3D CNNs (Convolutonal Neural Networks) are applied to learn voxel features for classification and bounding box regression. SECOND [6]</ref> is the upgrade version of [5]</ref>, since raw LiDAR point cloud has very sparse data structure, it uses sparse 3D CNNs which redu t with it and so most elements are empty. The fusion network only needs to learn from these intersected examples. Because we take the raw predictions before NMS, k and n are large numbers, for SECOND [6]</ref>, there are 70400 (200 × 176 × 2) predictions in each frame. It would be impractical to do 1 × 1 convolution on a dense tensor with this shape. We propose an imp C [29]</ref>, MS-CNN [30]</ref> and Cascade R-CNN [31]</ref>. The 3D detectors we incorporated are: SECOND [6]</ref>, PointPillars [9]</ref>, PointRCNN [8]</ref> and PV-RCNN [22]</ref>. KITTI has some restrictions on the number of submissions, we only show the results evaluated on the official KITTI test server from three fusion combinations of 2D and 3D detectors, which are SECOND [6]</ref> and Cascade R-CNN [31]</ref>, written as CLOCs SecCas, PointRCNN [8]</ref> and Cascade R-CNN, as CL get="#tab_4">IV</ref> show the 3D and BEV evaluation results of pedestrian and cyclist on KITTI validation set. The IoU threshold for pedestrian and cyclist is 0.5. Here for 3D detectors, only SECOND [6]</ref> and PointPillars [9]</ref> publish their training configurations for class pedestrian and cyclist; for 2D detectors, only MSCNN <r
y in detecting vehicles from just a few points and no texture at long range. Human annotators use both the camera images together with the LiDAR point clouds to create the ground truth bounding boxes [10]</ref>. This motivates multi-modal sensor fusion as a way to improve single-modal methods.</p><p>While sensor fusion has potential to address the shortcomings of vide shown in Fig 2 .</ref> 3D detection systems generate classified oriented 3D bounding boxes with confidence scores, as shown in Fig 2 .</ref> In the KITTI dataset [10]</ref> only rotation in z axis is considered (yaw angle), while rotations in x and y axis is set to zero for simplicity. Using calibration parameters of the camera an 2D i is the confident score. The output of 3D object are 3D oriented bounding boxes in LiDAR coordinate and confident scores. There are multiple ways to encode the 3D bounding boxes, in KITTI dataset [10]</ref>, a 7-digit vector containing 3D dimension (height, width and length), 3D location (x,y,z) and rotation (yaw angle) is used. For n 3D detection candidates in on mental setup and results, including dataset, platform, performance results and analyses. For all experiments, we focus on the car class since it has the most training and testing samples in the KITTI [10]</ref> dataset.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>Our fusion system is evaluated on the challenging 3D object detection ben et="#b9">[10]</ref> dataset.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>Our fusion system is evaluated on the challenging 3D object detection benchmark KITTI dataset [10]</ref> which has both LiDAR point clouds and camera images. There are 7481 training samples and 7518 testing samples. Ground truth labels are only available for train ointRCNN, while CLOCs could utilize 2D detections to improve the performance. Fig. 5</ref> shows some qualitative results of our proposed fusion method on the KITTI [10]</ref> test set. Red bounding boxes represent wrong detections (false positives) from SECOND that are deleted by our CLOCs, blue bounding boxes stand for missed detec
urate correspondence between these feature vectors and therefore is not the optimal way for fusing features. In order to fuse features from different sensor modalities with better correspondence, MMF [26]</ref> adopts continuous convolution [14]</ref> to build dense LiDAR BEV feature maps and do point-wise feature fusion with dense imag
ion, 3D-based object detection enables spatial path planning for object avoidance and navigation. Compared to 2D object detection, which has been well-studied [1]</ref>, [2]</ref>, [3]</ref>, [4]</ref>, 3D object detection is more challenging with more output parameters needed to
oss modality information, they suffer from sensitivity to data alignment, often involve complicated architectures [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>, and typically require pixel-level correspondences of sensor data. On the other hand, late fusion systems are much ad><p>We focus on camera-LiDAR fusion methods in this section since this is the most common sensor setup for self-driving cars. Frustum PointNet [24]</ref>, Pointfusion [13]</ref> and Frustum ConvNet [25]</ref> are the representatives of 2D driven 3D detectors, which exploit mature 2D detectors to generate
since this is the most common sensor setup for self-driving cars. Frustum PointNet [24]</ref>, Pointfusion [13]</ref> and Frustum ConvNet [25]</ref> are the representatives of 2D driven 3D detectors, which exploit mature 2D detectors to generate 2D proposals and narrow down the 3D processing domain to the
on; it enables inference at 62 Hz; Compared with one-stage methods discussed above, PointRCNN [8]</ref>, Fast PointRCNN [20]</ref> and STD [21]</ref> applies a two-stage architecture that first generate 3D proposals in a bottomup manner and then refines these proposals in a second stage. PV-RCNN <ref type="
labels are only available for training samples. For the evaluation of testing samples, one needs to submit the detection results to KITTI server. For experimental studies, we follow the convention in [28]</ref> to split the original training samples into 3712 training samples and 3769 validation samples. We compare our method with sate-of-the-art multimodal fusion me
y in detecting vehicles from just a few points and no texture at long range. Human annotators use both the camera images together with the LiDAR point clouds to create the ground truth bounding boxes [10]</ref>. This motivates multi-modal sensor fusion as a way to improve single-modal methods.</p><p>While sensor fusion has potential to address the shortcomings of vide shown in Fig 2 .</ref> 3D detection systems generate classified oriented 3D bounding boxes with confidence scores, as shown in Fig 2 .</ref> In the KITTI dataset [10]</ref> only rotation in z axis is considered (yaw angle), while rotations in x and y axis is set to zero for simplicity. Using calibration parameters of the camera an 2D i is the confident score. The output of 3D object are 3D oriented bounding boxes in LiDAR coordinate and confident scores. There are multiple ways to encode the 3D bounding boxes, in KITTI dataset [10]</ref>, a 7-digit vector containing 3D dimension (height, width and length), 3D location (x,y,z) and rotation (yaw angle) is used. For n 3D detection candidates in on mental setup and results, including dataset, platform, performance results and analyses. For all experiments, we focus on the car class since it has the most training and testing samples in the KITTI [10]</ref> dataset.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>Our fusion system is evaluated on the challenging 3D object detection ben et="#b9">[10]</ref> dataset.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>Our fusion system is evaluated on the challenging 3D object detection benchmark KITTI dataset [10]</ref> which has both LiDAR point clouds and camera images. There are 7481 training samples and 7518 testing samples. Ground truth labels are only available for train ointRCNN, while CLOCs could utilize 2D detections to improve the performance. Fig. 5</ref> shows some qualitative results of our proposed fusion method on the KITTI [10]</ref> test set. Red bounding boxes represent wrong detections (false positives) from SECOND that are deleted by our CLOCs, blue bounding boxes stand for missed detec
1.0"><head>C. 3D Detection Using Multi-modal Fusion</head><p>We focus on camera-LiDAR fusion methods in this section since this is the most common sensor setup for self-driving cars. Frustum PointNet [24]</ref>, Pointfusion [13]</ref> and Frustum ConvNet [25]</ref> are the representatives of 2D driven 3D d
>, [4]</ref>, 3D object detection is more challenging with more output parameters needed to specify 3D oriented bounding boxes around targets. In addition, LiDAR methods [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>, [9]</r sor calibration and synchronization issues. However, object detection performance at longer distance is still relatively poor. Methods vary by how they encode and learn features from raw point cloud. [5]</ref> uses voxels to encode the raw point cloud, and 3D CNNs (Convolutonal Neural Networks) are applied to learn voxel features for classification and bounding box re and 3D CNNs (Convolutonal Neural Networks) are applied to learn voxel features for classification and bounding box regression. SECOND [6]</ref> is the upgrade version of [5]</ref>, since raw LiDAR point cloud has very sparse data structure, it uses sparse 3D CNNs which reduces the inference time significantly. PointPillars <ref type="bibr
1.0"><head>C. 3D Detection Using Multi-modal Fusion</head><p>We focus on camera-LiDAR fusion methods in this section since this is the most common sensor setup for self-driving cars. Frustum PointNet [24]</ref>, Pointfusion [13]</ref> and Frustum ConvNet [25]</ref> are the representatives of 2D driven 3D d
urate correspondence between these feature vectors and therefore is not the optimal way for fusing features. In order to fuse features from different sensor modalities with better correspondence, MMF [26]</ref> adopts continuous convolution [14]</ref> to build dense LiDAR BEV feature maps and do point-wise feature fusion with dense imag
d stage. PV-RCNN [22]</ref> leverages the advantages of both 3D voxel CNN and PointNet-based set abstraction to learn more discriminative features. Besides, Part-A 2 in [23]</ref> explores predicting intra-object part locations (lower left, upper right, etc.) in the first stage, and such part locations can assist accurate 3D bounding bo
2D CNN detection head to perform 3D object detection; it enables inference at 62 Hz; Compared with one-stage methods discussed above, PointRCNN [8]</ref>, Fast PointRCNN [20]</ref> and STD [21]</ref> applies a two-stage architecture that first generate 3D proposals in a bottomup manner and then refines thes
<p>Mousavian et al. [15]</ref> leverage the geometric constraints between 2D and 3D bounding boxes to recover 3D information. [16]</ref>, [17]</ref> estimate 3D object information by calculating the similarity between 3D objects and CAD models. [18]</ref> and <ref type="bibr"
2D/3D Detector Setup</head><p>We apply our fusion network for a combination of different 2D and 3D detectors to demonstrate the flexibility of our proposed pipeline. The 2D detectors we used are: RRC [29]</ref>, MS-CNN [30]</ref> and Cascade R-CNN [31]</ref>. The 3D detectors we incorporated are: SECOND <r
f> and STD [21]</ref> applies a two-stage architecture that first generate 3D proposals in a bottomup manner and then refines these proposals in a second stage. PV-RCNN [22]</ref> leverages the advantages of both 3D voxel CNN and PointNet-based set abstraction to learn more discriminative features. Besides, Part-A 2 in <ref type="bibr" e 3D detectors we incorporated are: SECOND [6]</ref>, PointPillars [9]</ref>, PointRCNN [8]</ref> and PV-RCNN [22]</ref>. While not the top performers within the KITTI leaderboard, we have selected these methods as they are the best currently-available open-source detectors. Our t="#b5">[6]</ref> and Cascade R-CNN [31]</ref>, written as CLOCs SecCas, PointRCNN [8]</ref> and Cascade R-CNN, as CLOCs PointCas, PV-RCNN [22]</ref> and Cascade R-CNN, as CLOCs PVCas. All the other combinations are evaluated on the validation set. Table I</ref> shows the p
" target="#b18">[19]</ref>, [20]</ref>, [21]</ref>, [22]</ref>, [23]</ref>, [24]</ref>. The main concept behind these approaches is to interpret protein sequences as sentences and their constituent -amino acids -as single words. Protein sequence able 1</ref> for model parameters). Largely, we used configurations successfully transferred from NLP to protein sequences [21]</ref>, [24]</ref>, [52]</ref>, with the exception of the number of layers that was increased to optimize memory utilization. Bert, TransformerXL layer visualized information extracted by the LMs representing individual amino acids irrespective of their surrounding context (residues next to it). As previously established for another protein LM [24]</ref>, the t-SNE projections (e.g. ProtBert Fig. 6A</ref>) suggested that all LMs captured essential biophysical aspects of amino acids. These in " target="#b17">[18]</ref>, [19]</ref>, [20]</ref>, [21]</ref>, [22]</ref>, [24]</ref>, we might expect an upper limit for what protein LMs can learn when using auto-regressive or auto-encoding exclusively. Although this work explicitly addresse
biology and bioinformatics.</p><p>Recently, the leap of NLP through advanced LMs have successfully been generalized toward understanding the language of life through advanced LMs trained on proteins [16]</ref>, [17]</ref>, [18]</ref>, [19]</ref>, <ref type="bibr" target="#b1 (see Table 2</ref>) on the inference speed of different protein LMs. When using a single Nvidia Titan V on varying batch-sizes (1,</ref>16,</ref>32)</ref> as well as sequence lengths (128, 256, 512), SeqVec provided the fastest inference with an average of 0.02 seconds per ns="http://www.tei-c.org/ns/1.0"><head>-1.2 Protein LM inference speed</head><p>The effect of varying sequence lengths (128, 256, 512) and different batch sizes (1,</ref>16,</ref>32)</ref> on the inference time of the protein LMs introduced here is reported in table 2. The effect of sequence length on diffe
d visually by projecting the high-dimensional representations down to two dimensions using t-SNE [45]</ref>. A non-redundant (PIDE&lt;40%) version of the SCOPe database [46]</ref> (release 2.07 with 14323 proteins) served as one way to interpret the t-SNE plots. For a subset of those proteins, we used experimentally annotated EC (Enzyme e averaged over the length-dimension of the representations derived from the last layer of each model. This created fixed-size representations for each protein. These we applied to the SCOPe database [46]</ref> classifying proteins by their 3D structures (Methods). On the most coarse-grained level, SCOPe distinguishes between all-alpha, all-beta, al-pha|beta, alpha&a
v> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data for Language Models (LMs)</head><p>In this work, we assessed the impact of database size on performance through two data sets: UniRef100 [35]</ref> (with 216M protein sequences) and BFD [36]</ref>, [37]</ref> (with 2,122M sequences). The latter
upercomputers [1]</ref>, [2]</ref> and advanced libraries [3]</ref>, [4]</ref>, [5]</ref>, [6]</ref>, [7]</ref> enable the training of ever more complex models on bigger data sets using adva
v> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data for Language Models (LMs)</head><p>In this work, we assessed the impact of database size on performance through two data sets: UniRef100 [35]</ref> (with 216M protein sequences) and BFD [36]</ref>, [37]</ref> (with 2,122M sequences). The latter
nfortunately, this brings up training efficiency as recently investigated by sparse Transformers [73]</ref> or attention optimized with locality-sensitive hashing (LSH) [74]</ref> as introduced recently by the Reformer model [75]</ref>. and solve all the related Google TPU and servers issues. Last, not lea
" target="#b17">[18]</ref>, [19]</ref>, [20]</ref>, [21]</ref>, [22]</ref>, [23]</ref>, [24]</ref>. The main concept behind these approaches is to interpret protein sequences as sentences and their constituent -ami
, each with &lt;25% PIDE to the training set: CB513 (513 proteins; [42]</ref>), TS115 (115 proteins; [43]</ref>) and CASP12 (21 proteins; [44]</ref>).</p><p>Per-protein prediction: For the prediction of features of entire proteins, the DeepLoc [26]</ref> data set was used to
ein sequences. During training, the LM learns to extract those constraints from millions of examples and store the derived knowledge in its weights. While existing solutions in Protein Bioinformatics [25]</ref>, [26]</ref>, [27]</ref>, [28]</ref>, <ref type="bibr" target="#b2 tion and to methods extracting features through pretrained LMs.</p><p>Per-residue prediction: When predicting properties on the level of single residues, the data set published alongside NetSurfP-2.0 [25]</ref> was used for 3-and 8-state secondary structure prediction. The NetSurfP-2.0 dataset was created through PISCES [40]</ref> selec prediction (y-axis: Q3). To simplify comparability to other approaches, we used the same training and test data sets (red:CASP12, yellow:TS115, blue:CB513) as an existing approach, i.e. NetSurfP-2.0 [25]</ref>. All LMs developed here were evaluated by training a simple network on top of the representations extracted from the last layer of the pre-trained LMs. As com ein LMs or mmseqs2 [62]</ref>, the fastest tool to gather evolutionary information from protein sequence databases at the moment. The same parameters as in NetSurfP-2.0 [25]</ref> were used to search with mmseqs2 the human proteome against two large protein sequence database (UniRef90=113M and UniRef100=216M proteins), i.e. the number o e (20.353 proteins) is compared using either our protein LMs or mmseqs2 (protein sequence search tool [62]</ref> used to generate evolutionary information; NetSurfP-2.0 [25]</ref> parameters are used). Here, we used mmseqs2 (red bar) to search each protein in the human proteome against two large protein sequence database (UniRef90 and U proposed Language models (LMs) trained here (ProtBert, ProtAlbert, ProtTXL, ProtXLNet) were also evaluated on eight-state secondary structure prediction (y-axis: Q8). The same datasets (NetSurfP-2.0 [25]</ref>), pre-processing steps as well as the same supervised models were used for this analysis, confirming the trend suggested by the three-state secondary structur
d n="2.3">Data: unsupervised embeddings</head><p>The embeddings extracted by the LMs were also evaluated visually by projecting the high-dimensional representations down to two dimensions using t-SNE [45]</ref>. A non-redundant (PIDE&lt;40%) version of the SCOPe database [46]</ref> (release 2.07 with 14323 proteins) served as one way to nsupervised learning. To establish that our protein LMs have extracted an understanding akin to the grammar in NLP, we projected the highdimensional embedding space down to two dimensions using t-SNE [45]</ref> and visualized proteins according to annotated structural, functional or evolutionary information.</p><p>Capturing biophysical features of amino acids. Applyi
le time-series. For example, in the traffic forecasting task, adjacent roads naturally interplay with each other. Current state-of-the-art models highly depend on Graph Convoluational Networks (GCNs) [13]</ref> originated from the theory of Graph Fourier Transform (GFT). These models [31,</ref>17]</ref> st d by M r (x r u ) + iM i (x i u ), and IDFT is applied on the final output.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Spectral Graph Convolution</head><p>The Spectral Graph Convolution [13]</ref> is composed of three steps.</p><p>(1) The multivariate time-series input is projected to the spectral domain by GFT. (2) The spectral representation is filter
. For instance, State Frequency Memory (SFM) network [32]</ref> combines the advantages of DFT and LSTM jointly for stock price prediction; Spectral Residual (SR) model [23]</ref> leverages DFT and achieves state-of-the-art performances in time-series anomaly detection. Another important aspect of multivariate time-series forecasting is
nd on Graph Convoluational Networks (GCNs) [13]</ref> originated from the theory of Graph Fourier Transform (GFT). These models [31,</ref>17]</ref> stack GCN and temporal modules (e.g., LSTM, GRU) directly, which only capture temporal patterns in the time domain and require a pre-defined topology of inter- >32,</ref>19,</ref>18]</ref> and multivariate techniques [24,</ref>21,</ref>17,</ref>31,</ref>3,</ref>29,</ref>25,</ref><r ith other state-of-the-art models, including FC-LSTM [26]</ref>, SFM [32]</ref>, N-BEATS [19]</ref>, DCRNN [17]</ref>, LSTNet [14]</ref>, ST-GCN [31]</ref>, DeepState [21]</ref>, TCN
f>17,</ref>31,</ref>3,</ref>29,</ref>25,</ref>16,</ref>15]</ref>. Univariate techniques analyze each individual time-series separately without considering the correlations between diff
tly in the spectral domain. In this paper, StemGNN is proposed to address these issues. We refer you to recent surveys [28,</ref>34,</ref>33]</ref> for more details about related works.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Definition</head><p>In order to emphasize the rela
a graph convolution operator with learnable kernels. (3) Inverse Graph Fourier Transform (IGFT) is applied on the spectral representation to generate final output.</p><p>Graph Fourier Transform (GFT) [8]</ref> is a basic operator for Spectral Graph Convolution. It projects the input graph to an orthonormal space where the bases are constructed by eigenvectors of the n
asting is an emerging topic in machine learning, which can be divided into two major categories: univariate techniques [20,</ref>22,</ref>18,</ref>27,</ref>32,</ref>19,</ref>18]</ref> 22,</ref>18,</ref>27,</ref>32,</ref>19,</ref>18]</ref> and multivariate techniques [24,</ref>21,</ref>17,</ref><ref type=
f>21,</ref>17,</ref>31,</ref>3,</ref>29,</ref>25,</ref>16,</ref>15]</ref>. Univariate techniques analyze each individual time-series separately without c pState [21]</ref> marries state space models with deep recurrent neural networks and learns the parameters of the entire network through maximum log likelihood. DeepGLO [25]</ref>   incorporates both spatial and temporal dependencies in the convolutional recurrent neural network for traffic forecasting. ST-GCN <ref type="bibr" target="# ="bibr" target="#b30">[31]</ref>, DeepState [21]</ref>, TCN [3]</ref>, Graph Wavenet [29]</ref> and DeepGLO [25]</ref>. We tune the hyper-parameters on the validation data by grid search for StemGNN. Finally, the channel size of each graph convolution layer is set as 64 and th TS[19]</ref> TCN[3]</ref> DeepState[21]</ref> GraphWaveNet[29]</ref> DeelpGLO[25]</ref> StemGNN (ours)</note></figure> 		</body> 		<back> 			<div type="references">  				<listBibl>  <biblStruct xml:id="b0"> 	<analytic> 		<title level="a" type="ma
r for Spectral Graph Convolution. It projects the input graph to an orthonormal space where the bases are constructed by eigenvectors of the normalized graph Laplacian. The normalized graph Laplacian [1]</ref> can be computed as:</p><formula xml:id="formula_4">L = I N − D − 1 2 W D − 1 2 ,</formula><p>where I N ∈ R N ×N is the identity matrix and D is the diagonal deg
. For instance, State Frequency Memory (SFM) network [32]</ref> combines the advantages of DFT and LSTM jointly for stock price prediction; Spectral Residual (SR) model [23]</ref> leverages DFT and achieves state-of-the-art performances in time-series anomaly detection. Another important aspect of multivariate time-series forecasting is
f>17,</ref>31,</ref>3,</ref>29,</ref>25,</ref>16,</ref>15]</ref>. Univariate techniques analyze each individual time-series separately without considering the correlations between diff
arget="#b28">29,</ref>23]</ref>), in this direction Adversarial Training (AT) procedure [13,</ref>35,</ref>22,</ref>40]</ref> shows promising results.</p><p>In adversarial training regime, models are trained with mini-batches containing adversar proposed. Further, in order to defend against adversarial attacks, various schemes such as adversarial training (e.g., [13,</ref>18,</ref>22,</ref>40,</ref>5,</ref>4]</ref>) and input pre-processing (e.g., <ref type= 21,</ref>14,</ref>38,</ref>32,</ref>31,</ref>22,</ref>21,</ref>9]</ref> accepted to ICLR 2018. In this direction, adversarial training method <ref type=" he input image. Gradient masking effect causes this linear approximation of loss function to become unreliable for generating adversarial samples during single-step adversarial training. Madry et al. [22]</ref> demonstrated that models trained using adversarial samples that maximize the training loss are robust against single-step and multi-step at-tacks. Such sample ">31,</ref>22,</ref>21,</ref>9]</ref> accepted to ICLR 2018. In this direction, adversarial training method [22]</ref>, shows promising results for learning robust deep learning models. Kurakin et al. [18]</ref> observed that models trained using ibit gradient masking effect, and proposed Ensemble Adversarial Training (EAT) method. However, models trained using EAT are still susceptible to multi-step attacks in white-box setting. Madry et al. [22]</ref> demonstrated that adversarially trained model can be made robust against white-box attacks, if perturbation crafted while training maximizes the loss. Zhang e this criteria is not satisfied during single-step adversarial training method. Most importantly, we show that over-fitting effect is the reason for failure to satisfy the criteria.</p><p>Madry et al. [22]</ref> demonstrated that it is possible to learn robust models using adversarial training method, if adversarial perturbations (l ∞ norm bounded) crafted while train ersarial perturbations that maximizes the training loss should be generated. Further, the model's parameters (θ) should be updated so as to decrease the loss on such adversarial samples. Madry et al. [22]</ref> solves the maximization step by generating adversarial samples using an iterative method named Projected Gradient Descent (PGD). In order to quantify the exte l.</p><p>We obtain the plot of R versus iteration for models trained using single-step adversarial training method [13]</ref> and multi-step adversarial training method [22]</ref>. Column-1 of Fig. 1</ref> and Fig. 2</ref> show these plots obtained for LeNet+ trained aster than multi-step adversarial training methods.   8</ref> shows the setup used for EAT method. PGD Adversarial Training (PAT): Multi-step adversarial training method proposed by [22]</ref>. At each iteration all the clean samples in the mini-batch are replaced with their corresponding adversarial samples generated using the model being trained. g trained or by one of the model from the fixed set of pre-trained models. Table8shows the setup used for EAT method. PGD Adversarial Training (PAT): Multi-step adversarial training method proposed by[22]</ref>. At each iteration all the clean samples in the mini-batch are replaced with their corresponding adversarial samples generated using the model being trained. erative version of FGSM attack. At each iteration, adversarial perturbation of small step size (α) is added to the image. In our experiments, we set α = /steps.</p><p>Projected Gradient Descent (PGD) [22]</ref>: Initially, a small random noise sampled from Uniform distribution (U ) is added to the image. Then at each iteration, perturbation of small step size ( step
d broke seven out of nine defense papers [6,</ref>21,</ref>14,</ref>38,</ref>32,</ref>31,</ref>22,</ref>21,</ref>9]</ref> a
tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Machine learning models are susceptible to adversarial samples: samples with imperceptible, engineered noise designed to manipulate model's output [15,</ref>2,</ref>34,</ref>3,</ref>13,</ref><re
[13,</ref>18,</ref>22,</ref>40,</ref>5,</ref>4]</ref>) and input pre-processing (e.g., [14,</ref>31]</ref>) have been proposed. Athalye et al. <ref type=
ut [15,</ref>2,</ref>34,</ref>3,</ref>13,</ref>27]</ref>. Further, Szegedy et al. [34]</ref> observed that these adversarial samples are transferable across multiple models i.e., advers
g et al. [40]</ref> proposed a regularizer for multi-step adversarial training, that encourages the output of the network to be smooth. On the other hand, works such as [30]</ref> and [36]</ref> propose a method to learn models that are provably robust against norm bounded adversarial attacks. However, sca
[13,</ref>18,</ref>22,</ref>40,</ref>5,</ref>4]</ref>) and input pre-processing (e.g., [14,</ref>31]</ref>) have been proposed. Athalye et al. <ref type=
on</head><p>Machine learning models are susceptible to adversarial samples: samples with imperceptible, engineered noise designed to manipulate model's output [15,</ref>2,</ref>34,</ref>3,</ref>13,</ref>27]</ref>. Fu
on</head><p>Machine learning models are susceptible to adversarial samples: samples with imperceptible, engineered noise designed to manipulate model's output [15,</ref>2,</ref>34,</ref>3,</ref>13,</ref>27]</ref>. Fu
>18,</ref>22,</ref>40,</ref>5,</ref>4]</ref>) and input pre-processing (e.g., [14,</ref>31]</ref>) have been proposed. Athalye et al. [1]</ref> showed that obfuscated gradients give a fa >[1]</ref> showed that obfuscated gradients give a false sense of robustness, and broke seven out of nine defense papers [6,</ref>21,</ref>14,</ref>38,</ref>32,</ref>31,</ref>22,</ref>
>18,</ref>22,</ref>40,</ref>5,</ref>4]</ref>) and input pre-processing (e.g., [14,</ref>31]</ref>) have been proposed. Athalye et al. [1]</ref> showed that obfuscated gradients give a fa >[1]</ref> showed that obfuscated gradients give a false sense of robustness, and broke seven out of nine defense papers [6,</ref>21,</ref>14,</ref>38,</ref>32,</ref>31,</ref>22,</ref>
the product of the feature matrix and the k-th power of the normalized adjacency matrix during the preprocessing step and performs standard logistic regression to remove redundant computation. PPRGo [4]</ref> uses Personalized PageRank to capture multi-hop neighborhood information and uses a forward push algorithm [2]</ref> to accelerate . SGC [30]</ref> repeatedly perform multiplication of normalized adjacency matrix Ã and feature matrix X in the precomputation phase, which requires O(LmF ) time. PPRGo [4]</ref> calculates approximate the Personalized PageRank (PPR) matrix ∞ =0 α(1 − α) Ã by forward push algorithm [2]</ref> and then applies ) for some constant decay factor α ∈ (0, 1), in which case P becomes the Personalized PageRank used in APPNP and PPRGo [16,</ref>17,</ref>4]</ref>; 2) w = 0 for = 0, . . . , L − 1 and w L = 1, in which case P degenerates to the L-th transition probability matrix in SGC [30]</r layer sampling) [40]</ref>, GraphSAINT (graph sampling) [37]</ref>, SGC and PPRGo (linear model) [30,</ref>4]</ref>.</p><p>We implement GBP in PyTorch and C++, and employ initial residual connection [12]</ref> across the hidden layers to facilita
a sub-graph at the beginning of each batch and perform forward propagation on the same subgraph across all layers. Cluster-GCN [8]</ref> uses graph clustering techniques [14]</ref> to partition the original graph into several sub-graphs, and samples one sub-graph to perform feature propagation in each mini-batch. In the worst case, the n
tion with only the graph structural information. This setting has been adapted in various works on community detection [19,</ref>18,</ref>35]</ref>. For each node, we generate a sparse random feature by randomly set one entry to be 1 in an d-dimensional all-zero vector. Note that even with a random feature
the largest community as its label. The goal is to perform multi-class classification with only the graph structural information. This setting has been adapted in various works on community detection [19,</ref>18,</ref>35]</ref>. For each node, we generate a sparse random feature by randomly set one entry
the largest community as its label. The goal is to perform multi-class classification with only the graph structural information. This setting has been adapted in various works on community detection [19,</ref>18,</ref>35]</ref>. For each node, we generate a sparse random feature by randomly set one entry
F 2 O LmF + LnF 2 GraphSAINT - O LbdF + LnF 2 O LmF + LnF 2 GBP (This paper) O LnF + L √ m lg n ε F O LnF 2 O LnF 2</formula><p>Other related work. Another line of research devotes to attention model [29,</ref>27,</ref>22]</ref>, where the adjacency matrix of each layer is replaced by a learnable attention of transductive semi-supervised on billion-scale network Friendster.</p><p>Baselines and detailed setup. We adopt three state-of-the-art GNN methods GCN [15]</ref>, GAT [29]</ref>, GDC [17]</ref> and APPNP [16]</ref> as the baselines for evaluation on small graphs. We also us
ions such as social analysis [23,</ref>20,</ref>28]</ref>, biology [10,</ref>26]</ref>, recommendation systems [36]</ref>, and computer vision [39,</ref>7
arget="#b35">[36]</ref>, and computer vision [39,</ref>7,</ref>13]</ref>. Graph Convolutional Network (GCN) [15]</ref> adopts a message-passing approach and gathers information from the neighbors of each node from the previous layer to form the new representation. The vanilla tical time complexity. We consider an undirected graph G=(V, E), where V and E represent the set of vertices and edges, respectively. For ease of presentation, we assume that G is a self-looped graph [15]</ref>, with a self-loop attached to each node in V . Let n = |V | and m = |E| denote the number of vertices and edges in G, respectively. Each node is associated wi diagonal degree matrix of G, respectively. For each node u ∈ V , N (u) is the set of neighbors of u, and d(u) = |N (u)| is the degree of u. We use d = m n to denote the average degree of G. Following [15]</ref>, we define the normalized adjacency matrix of G as Ã = D −1/2 AD −1/2 . The ( + 1)-th layer H ( +1) of the vanilla GCN is defined as</p><formula xml:id="formu Finally, we present the first empirical study of transductive semi-supervised on billion-scale network Friendster.</p><p>Baselines and detailed setup. We adopt three state-of-the-art GNN methods GCN [15]</ref>, GAT [29]</ref>, GDC [17]</ref> and APPNP [16]</ref> as the basel able 4</ref> shows the results for the semi-supervised transductive node classification task on the three small standard graphs Cora, Citeseer, and Pubmed. Following [15]</ref>, we apply the standard fixed training/validation/testing split with 20 nodes per class for training, 500 nodes for validation and 1,000 nodes for testing. For get="#formula_2">2</ref>) can be easily generalized to various existing models. By setting r = 0.5, 0 and 1, the convolution matrix D r−1 AD −r represents the symmetric normalization adjacency matrix [15,</ref>30,</ref>16]</ref>, the transition probability matrix AD −1 [11,</
oal is to perform multi-class classification with only the graph structural information. This setting has been adapted in various works on community detection [19,</ref>18,</ref>35]</ref>. For each node, we generate a sparse random feature by randomly set one entry to be 1 in an d-dimensional all-zero vect
tion with only the graph structural information. This setting has been adapted in various works on community detection [19,</ref>18,</ref>35]</ref>. For each node, we generate a sparse random feature by randomly set one entry to be 1 in an d-dimensional all-zero vector. Note that even with a random feature
F 2 O LmF + LnF 2 GraphSAINT - O LbdF + LnF 2 O LmF + LnF 2 GBP (This paper) O LnF + L √ m lg n ε F O LnF 2 O LnF 2</formula><p>Other related work. Another line of research devotes to attention model [29,</ref>27,</ref>22]</ref>, where the adjacency matrix of each layer is replaced by a learnable attention of transductive semi-supervised on billion-scale network Friendster.</p><p>Baselines and detailed setup. We adopt three state-of-the-art GNN methods GCN [15]</ref>, GAT [29]</ref>, GDC [17]</ref> and APPNP [16]</ref> as the baselines for evaluation on small graphs. We also us
e implemented by using other differentiable architectures, for this work we opted for a simple but still very effective Bag of Embeddings model (White et al. 2015;</ref>Arora, Liang, and Ma 2017)</ref> showing that, even in this case, A related field is differentiable interpreters-program interpreters where declarative or procedural know
strategy for overcoming these issues consists of combining neural models and symbolic reasoning, given their complementary strengths and weaknesses (d'Avila Garcez et al. 2015;</ref>Rocktäschel and Riedel 2017;</ref>Yang, Yang, and Cohen 2017;</ref>Evans and Grefenstette 2018;</ref><ref type="bibr" tar related field is differentiable interpreters-program interpreters where declarative or procedural knowledge is compiled into a neural network architecture (Bošnjak et al. 2017;</ref>Rocktäschel and Riedel 2017;</ref>Evans and Grefenstette 2018)</ref>. This family of models allows imposing strong inductive biases on the models by par end differentiable reasoning models that can be trained via backpropagation while maintaining interpretability and generalisation, thereby inheriting the best of both worlds. Among such systems, NTPs (Rocktäschel and Riedel 2017;</ref>Minervini et al. 2018</ref>) are end-to-end differentiable deductive reasoners based on Prolog's backwa al surface patterns in a shared space by using an end-to-end differentiable reading component.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>End-to-end Differentiable Proving</head><p>NTPs (Rocktäschel and Riedel 2017)</ref> recursively build a neural network enumerating all the possible proof paths for proving a query (or goal) on a given KB, and aggregat q(X, Z), r(Z, Y) via backward chaining causes an increase of the sub-goals to prove, both because all atoms in the body need to be proven, and because Z is a free variable with many possible bindings (Rocktäschel and Riedel 2017)</ref>. We consider two problems -given a sub-goal G such as [p, A, B], we need to efficiently select i) the k f facts that are most likely l. 2016)</ref>:</p><formula xml:id="formula_5">L K (θ) = − F :-[]∈K log ntp K\F θ (F, d) − F∼corrupt(F) log[1 − ntp K θ ( F, d)]<label>(4)</label></formula><p>NTPs can also learn interpretable rules. Rocktäschel and Riedel (2017)</ref> show that it is possible to learn rules from data by specifying rule templates, such as H :</p><formula xml:id="formula_6">-B with H y the rules where heads are in the neighbourhood N P (G) of G.</p><p>Learning to Attend Over Predicates. Although NTPs can be used for learning interpretable rules from data, the solution proposed by Rocktäschel and Riedel (2017)</ref> can be quite inefficient, as the number of parameters associated to rules can be quite large. For instance, the rule H :-B, with H = ef type="bibr" target="#b3">(Bouchard, Singh, and Trouillon 2015)</ref>, Nations, UMLS, and Kinship (Kemp et al. 2006</ref>) -following the same evaluation protocols as Rocktäschel and Riedel (2017)</ref>. Furthermore, since GNTPs allows to experiment on significantly larger datasets, we also report results on the WN18 <ref type="bibr" for additional experiments showing run-time improvements by several orders of magnitude.</p><p>Link Prediction Results. We compare GNTPs and NTPs on a set of link prediction benchmarks, also used in Rocktäschel and Riedel (2017)</ref>. Results, presented in Table 1, show that GNTPs achieves better or on-par results in comparison with NTPs and baselines MINERVA <ref f>. UMLS contains 49 predicates, 135 constants and 6529 true facts, while Nations contains 56 binary predicates, 111 unary predicates, 14 constants and 2565 true facts. We follow the protocol used by Rocktäschel and Riedel (2017)</ref> and split every dataset into training, development, and test facts, with a 80%/10%/10% ratio. For evaluation, we take a test fact and ble><row><cell>hyponym(Y, X) :-hypernym(X, Y)</cell></row></table></figure> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">For consistency, we use the same notation asRocktäschel and Riedel (2017)</ref>.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">We consider binary predicates, without loss o /1.0" place="foot" n="5" xml:id="foot_3">Grouping rules with the same structure together makes allows parallel inference to be implemented very efficiently on GPU. This optimisation is also present inRocktäschel and Riedel (2017)</ref>.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4">The Appendix can be found at https://github.c lace="foot" n="6" xml:id="foot_4">The Appendix can be found at https://github.com/uclnlp/gntp</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5">Results reported inRocktäschel and Riedel (2017)</ref> were calculated with an incorrect evaluation function, causing artificially better results. We corrected the issues, and recalculated 244 countries, 5 regions (e.g. EUROPE), 23 sub-regions (e.g. WESTERN EU-ROPE, NORTH AMERICA), and 1158 facts about the neighbourhood of countries, and the location of countries and subregions. As in Rocktäschel and Riedel (2017)</ref>, we randomly split countries into a training set of 204 countries (train), a development set of 20 countries (validation), and a test
z et al. 2015;</ref>Rocktäschel and Riedel 2017;</ref>Yang, Yang, and Cohen 2017;</ref>Evans and Grefenstette 2018;</ref>Weber et al. 2019)</ref>. While symbolic models can generalise well from a small number of examples, they are brittle and prone to failure when the observations are nois
in terms of instruction sets or rules. A major drawback of differentiable interpreters, however, is their computational complexity, so far deeming them unusable except for smaller learning problems. Rae et al. (2016)</ref> use an approximate nearest neighbour data structures for sparsifying read operations in memory networks. Riedel et
p>Our work is also related to path encoding models (Das et al. 2017)</ref> and random walk approaches (Lao, Mitchell, and Cohen 2011;</ref>Gardner et al. 2014)</ref>, both of which lack a rule induction mechanisms, and to approaches combining observable and latent features of the graph <ref type="bibr" targ
in terms of instruction sets or rules. A major drawback of differentiable interpreters, however, is their computational complexity, so far deeming them unusable except for smaller learning problems. Rae et al. (2016)</ref> use an approximate nearest neighbour data structures for sparsifying read operations in memory networks. Riedel et
ion protocols as Rocktäschel and Riedel (2017)</ref>. Furthermore, since GNTPs allows to experiment on significantly larger datasets, we also report results on the WN18 (Bordes et al. 2013)</ref> Baselines. On benchmark datasets, we compare GNTPs with NTPs and two other neuro-symbolic reasoning systems, MINERVA <ref type="bibr" target="# run experiments on the following datasets, and report results in terms of Area Under the Precision-Recall Curve (Davis and Goadrich 2006)</ref> (AUC-PR), MRR, and HITS@m (Bordes et al. 2013)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Countries, UMLS, Nations</head><p>Countries Countries is a dataset introduced by <ref one(X, Y) :-containedBy(X, Z), timeZone(Z, Y). nearbyAirports(X, Y) :-containedBy(X, Z), contains(Z, Y). children(X, Y) :parents(Y, X). spouse(X, Y) :spouse(Y, X).</p><p>We also evaluate GNTP on WN18 (Bordes et al. 2013) and</ref>WN18RR (Dettmers et al. 2018)</ref>. In terms of ranking accuracy, GNTPs is comparable to state-of-the-art models, such as
and Cohen 2011;</ref>Gardner et al. 2014)</ref>, both of which lack a rule induction mechanisms, and to approaches combining observable and latent features of the graph (Nickel, Jiang, and Tresp 2014;</ref>Minervini et al. 2016)</ref>. Lastly, our work is related to Yang, Yan
014)</ref>, both of which lack a rule induction mechanisms, and to approaches combining observable and latent features of the graph (Nickel, Jiang, and Tresp 2014;</ref>Minervini et al. 2016)</ref>. Lastly, our work is related to Yang, Yang, and Cohen (2017)</ref>, a scalable rule induction approach for KB
Semantic Parsing (Bos 2008)</ref>, Natural Language Inference and Recognising Textual Entailment (Fyodorov, Winter, and Francez 2000;</ref>Bowman et al. 2015)</ref>, and Question Answering (Hermann et al. 2015)</ref>. Nonetheless, such methods suffer from several limitations. They rely on si
rm of a KB (Niklaus et al. 2018)</ref>. However, the compiled KBs tend to be incomplete, ambiguous, and noisy, impairing the application of standard deductive reasoners (Huang, van Harmelen, and ten Teije 2005)</ref>.</p><p>A rich and broad literature in MR has approached this problem within a variety of frameworks, including Natural Lo
are brittle and prone to failure when the observations are noisy or ambiguous, or when the properties of the domain are unknown or hard to formalise, all of which being the case for natural language (Raedt et al. 2008;</ref>Garnelo and Shanahan 2019)</ref>. Contrarily, neural models are robust to noise and ambiguity but not easily inte
lo and Shanahan 2019)</ref>. Contrarily, neural models are robust to noise and ambiguity but not easily interpretable, making them unable to provide explanations or incorporating background knowledge (Guidotti et al. 2018)</ref>.</p><p>Recent work in neuro-symbolic systems has made progress towards end-to-end differentiable reasoning models that can be trained via ba rediction.</p><p>Table 2</ref>: Link prediction results on the Test-I, Test-II and Test-ALL on FB122. Note that KALE, ASR methods, and KBLR have access to a set of rules provided by Guo et al. (2016)</ref>, while neural link predictors and GNTPs do not. Test-II (6,186 triples) denotes a subset of FB122 that can be inferred via logic rules, while Tes div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>WordNet and Freebase</head><p>We also evaluate the proposed method on WordNet (WN18) and Freebase (FB122) jointly with the set of rules released by Guo et al. (2016)</ref>. WordNet (Miller 1995</ref>) is a lexical knowledge base for the English language, where entities correspond to wo of people, location and sports, and contains 9,738 entities, 122 relation types, and 112,476 triples.</p><p>For both data sets, we used the fixed training, validation, test sets and rules provided by Guo et al. (2016)</ref>; a subset of the rules is shown in Table 5</ref>. Note that a subset of the test triples can be inferred by ded ubset of the rules is shown in Table 5</ref>. Note that a subset of the test triples can be inferred by deductive logic inference.</p><p>For such a reason, following Guo et al. (2016)</ref>, we also partition the test set in two subsets, namely Test-I and Test-II: Test-I contains triples that cannot be inferred by deductive logic inf

are noisy or ambiguous, or when the properties of the domain are unknown or hard to formalise, all of which being the case for natural language (Raedt et al. 2008;</ref>Garnelo and Shanahan 2019)</ref>. Contrarily, neural models are robust to noise and ambiguity but not easily interpretable, making them unable to provide explanations or
fact is composed of a predicate symbol and a sequence of arguments, e.g. [locationOf, LONDON, UK].</p><p>On the other hand, a mention is a textual pattern between two co-occurring entities in the KB (Toutanova et al. 2015)</ref>, such as "LONDON is located in the UK". We represent mentions jointly with facts and rules in K by considering each textual surface pattern
owledge, and reason with it (Etzioni, Banko, and Cafarella 2006;</ref>Hermann et al. 2015;</ref>Weston et al. 2015;</ref>Das et al. 2017)</ref>. This ability facilitates both the synthesis of new knowledge and the possibility to verify and update a given assertion. Traditionally, automated n setting, and more elaborate mention encoders were investigated by McCallum, Neelakantan, and Verga (2017)</ref>.</p><p>Our work is also related to path encoding models (Das et al. 2017)</ref> and random walk approaches (Lao, Mitchell, and Cohen 2011;</ref>Gardner et al. 2014)
ing to prove them using other available facts and rules.</p><p>Negative examples are obtained via a corruption process, denoted by corrupt(•), by modifying the subject and object of triples in the KB (Nickel et al. 2016)</ref>:</p><formula xml:id="formula_5">L K (θ) = − F :-[]∈K log ntp K\F θ (F, d) − F∼corrupt(F) log[1 − ntp K θ ( F, d)]<label>(4)</label></formula>< facts in a real-world KB can be in the order of millions or billions.</p><p>For instance, Freebase contains over 637 × 10 6 facts, while the Google Knowledge Graph contains more than 18 × 10 9 facts (Nickel et al. 2016)</ref>. Identifying the facts F ∈ K that yield the maximum proof score for a sub-goal G reduces to solving the following optimisation problem:</p><fo is especially evident in cases where the number of held-out facts is higher, as it is often the case in real-world use cases, where there is an abundance of text but the KBs are sparse and incomplete (Nickel et al. 2016)</ref>. GNTPs are extremely efficient at learning rules involving both logic atoms and textual mentions.</p><p>For instance, by analysing the learned
and Cohen 2017)</ref>, which compiles inference tasks in a sequence of differentiable operations. In addition, we consider DistMult (Yang et al. 2015)</ref> and ComplEx (Trouillon et al. 2016)</ref>, two state-of-the-art black-box neural link predictors suited for large datasets.</p><p>Run-Time Evaluation. To assess the benefits of GNTP
are brittle and prone to failure when the observations are noisy or ambiguous, or when the properties of the domain are unknown or hard to formalise, all of which being the case for natural language (Raedt et al. 2008;</ref>Garnelo and Shanahan 2019)</ref>. Contrarily, neural models are robust to noise and ambiguity but not easily inte
are noisy or ambiguous, or when the properties of the domain are unknown or hard to formalise, all of which being the case for natural language (Raedt et al. 2008;</ref>Garnelo and Shanahan 2019)</ref>. Contrarily, neural models are robust to noise and ambiguity but not easily interpretable, making them unable to provide explanations or
and Machine Reading (MR) aim at building models and systems with the ability to read text, extract meaningful knowledge, and reason with it (Etzioni, Banko, and Cafarella 2006;</ref>Hermann et al. 2015;</ref>Weston et al. 2015;</ref>Das et al. 2017)</ref>. This ability facilitates both the
0 training instances (Devlin et al., 2018;</ref>Phang et al., 2018)</ref>.</p><p>When finetuning a big, pretrained language model, dropout (Srivastava et al., 2014)</ref> has been used as a regularization technique to prevent co-adaptation of neurons (Vaswani et al., 2017;</re (p), a neuron is retained with a probability of 1−p during training. If we denote the weight parameter of that neuron as w during training, then we use (1 − p)w for that weight parameter at test time (Srivastava et al., 2014)</ref>. This ensures that the expected output of a neuron is the same as the actual output at test time. In this paper, dropout(p) refers to inv ula><p>instead of the original loss function L(w) where λ is a regularization coefficient. Usual weight decay of λ is equivalent to wdecay(0, λ).</p><p>Probability for Dropout and Dropconnect Dropout (Srivastava et al., 2014</ref>) is a regularization technique selecting a neuron to drop with a probability of p. Dropconnect (Wan et al.,
f dropout and its variants, such as Gaussian dropout (Wang &amp; Manning, 2013</ref>), variational dropout (Kingma et al., 2015)</ref>, and dropconnect (Wan et al., 2013)</ref>, as an adaptive L 2 -penalty toward the origin (all zero parameters 0) and generalize dropout by considering a target model parameter u (instead bility for Dropout and Dropconnect Dropout (Srivastava et al., 2014</ref>) is a regularization technique selecting a neuron to drop with a probability of p. Dropconnect (Wan et al., 2013)</ref> chooses a parameter to drop with a probability of p. To emphasize their hyperparameter p, we write dropout and dropconnect with a drop probabili ="bibr" target="#b27">Yang et al., 2019)</ref>, dropout has been used as one of several regularization techniques. The theoretical analysis for dropout as an L 2 -regularizer toward 0 was explored by Wan et al. (2013)</ref> where 0 is the origin. They provided a sharp characterization of dropout for a simplified setting (generalized linear model). <ref type="bibr" ta get="#b14">Mianjy &amp; Arora (2019)</ref> gave a formal and complete characterization of dropout in deep linear networks with squared loss as a nuclear norm regularization toward 0. However, neither Wan et al. (2013)</ref> nor Mianjy &amp; Arora (2019)</ref> gives theoretical analysis for the extension of dropout which uses a point oth

f dropout and its variants, such as Gaussian dropout (Wang &amp; Manning, 2013</ref>), variational dropout (Kingma et al., 2015)</ref>, and dropconnect (Wan et al., 2013)</ref>, as an adaptive L 2 -penalty toward the origin (all zero parameters 0) and generalize dropout by considering a target model parameter u (instead bility for Dropout and Dropconnect Dropout (Srivastava et al., 2014</ref>) is a regularization technique selecting a neuron to drop with a probability of p. Dropconnect (Wan et al., 2013)</ref> chooses a parameter to drop with a probability of p. To emphasize their hyperparameter p, we write dropout and dropconnect with a drop probabili ="bibr" target="#b27">Yang et al., 2019)</ref>, dropout has been used as one of several regularization techniques. The theoretical analysis for dropout as an L 2 -regularizer toward 0 was explored by Wan et al. (2013)</ref> where 0 is the origin. They provided a sharp characterization of dropout for a simplified setting (generalized linear model). <ref type="bibr" ta get="#b14">Mianjy &amp; Arora (2019)</ref> gave a formal and complete characterization of dropout in deep linear networks with squared loss as a nuclear norm regularization toward 0. However, neither Wan et al. (2013)</ref> nor Mianjy &amp; Arora (2019)</ref> gives theoretical analysis for the extension of dropout which uses a point oth
hen finetuning a big, pretrained language model, dropout (Srivastava et al., 2014)</ref> has been used as a regularization technique to prevent co-adaptation of neurons (Vaswani et al., 2017;</ref>Devlin et al., 2018;</ref>Yang et al., 2019)</ref>. We provide a theoretical und ning stability in a wider range of its hyperparameter p than dropout.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">RELATED WORK</head><p>For large-scale pretrained language models (Vaswani et al., 2017;</ref>Devlin et al., 2018;</ref>Yang et al., 2019)</ref>, dropout has been used as one
er> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Transfer learning has been widely used for the tasks in natural language processing (NLP) (Collobert et al., 2011;</ref>Devlin et al., 2018;</ref>Yang et al., 2019;</ref><ref type="bibr" target="#b13
fic layers, and it can be done by constructing M in a particular way. We demonstrate this approach in Supplement B and show that mixout for specific layers adaptively L 2 -penalizes their parameters. Hoffer et al. (2017)</ref> have empirically shown that w t − w 0 ∼ log t, (10) where w t is a model parameter after the t-th SGD step. When training from scratch, we usua
hen finetuning a big, pretrained language model, dropout (Srivastava et al., 2014)</ref> has been used as a regularization technique to prevent co-adaptation of neurons (Vaswani et al., 2017;</ref>Devlin et al., 2018;</ref>Yang et al., 2019)</ref>. We provide a theoretical und ning stability in a wider range of its hyperparameter p than dropout.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">RELATED WORK</head><p>For large-scale pretrained language models (Vaswani et al., 2017;</ref>Devlin et al., 2018;</ref>Yang et al., 2019)</ref>, dropout has been used as one



"#b18">[19]</ref>.</p><p>To this end, we propose to explicitly encode structural roles as part of message passing, in order to capture richer topological properties. Our method draws inspiration from [33]</ref>, where it was shown that GNNs become universal when the vertices in the graph are uniquely identified, i.e when they are equipped with different features. How positional encodings in language models [35]</ref>, [36]</ref>.</p><p>It is important to note here that contrary to identifierbased GNNs [33]</ref>, [37]</ref>, [38]</ref> that obtain universality at the expense of permutation equivariance (sin ertex disambiguation, similarly to identifier-based approaches. Whenever these subgraph counts can provide a unique identification of the vertices, then universality will also hold (Corollary 3.1. in [33]</ref>).</p><p>We conjecture, that in real-world scenarios the number of subgraphs needed for unique, or near-unique identification, are far fewer than those dictate he expressive power of MPNNs and other more powerful variants and provided generalisation bounds.</p><p>Unique identifiers. From a different perspective, [68]</ref> and [33]</ref> showed the connections between GNNs and distributed local algorithms [69]</ref>, [70]</ref>, <re
side note, approximate counting algorithms are also widely used, especially for counting frequent network motifs [58]</ref>, [59]</ref>, [60]</ref>, [61]</ref>, and can provide a considerable speed-up. Furthermore, recent neural approaches [62]
aphlet counting.</p><p>Substructures have been also used in the context of ML. In particular, subgraph patterns have been used to define Graph Kernels (GKs) [83]</ref>, [84]</ref>, [85]</ref>, [86]</ref>, [87]</ref>, with the most prominent bein t="#b83">[84]</ref>, [85]</ref>, [86]</ref>, [87]</ref>, with the most prominent being the graphlet kernel [84]</ref>. Motifbased vertex embeddings [88]</ref>, [89]</ref> and diffusion operators <ref type="bibr" ta
ng and inference are linear w.r.t the number of edges, O(|E|), as opposed to higherorder methods [17]</ref>, [24]</ref> with O(n k ), and [48]</ref> with O(n 2 ) training complexity and relational pooling [49]</ref> with O(n!) training complexity in absence of approximations. In contrast, in GSN, usually the substructure collection is small (∼5-10 graphs) and the substructures are repetitive in the graph distribution, and as a result generalisation improves. Vignac et al. [48]</ref> propose a message passing scheme where matrices of order equal to the size of the graph are propagated instead of vectors. This can be perceived as a practica N [74]</ref> 0.219±0.010 0.168±0.003 GNNML [109]</ref> 0.1612 ± 0.006 -HIMP [110]</ref> -0.151±0.006 SMP [48]</ref> 0.219± 0.138± GSN 0.140±0.006 0.115±0.012</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">ZINC Molecular graphs</head><p>We evaluate GSN on t >[25]</ref> and the evaluation metric is the Mean Absolute Error (MAE). We compare against a variety of baselines, ranging from traditional message passing NNs to recent more expressive architectures [48]</ref>, [74]</ref>, [108]</ref>, [109]</ref> and a molecular-specific
r images [29]</ref> or positional encodings in language models for sequential data [30]</ref>, [31]</ref>, [32]</ref>. Nevertheless, GNNs are usually unaware of the vertices' different structural roles, since all vertices are treated equally when performing local operations.
geometric graphs, such as 3D molecular graphs and meshes, directional biases are usually employed in order to model the positional information of the vertices [9]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>; for proteins, ordering inform 0.002 -GIN [16]</ref> 0.408±0.008 -GraphSage [105]</ref> 0.410±0.005 -GAT [106]</ref> 0.463±0.002 -MoNet [10]</ref> 0.407±0.007 -GatedGCN [107]</ref> 0.422±0.006 0.363±0.009 MPNN 0.254±0.014 0.209±0.018 MPNN-r 0.322±0.026 0.279±0.023 PNA <ref
define Graph Kernels (GKs) [83]</ref>, [84]</ref>, [85]</ref>, [86]</ref>, [87]</ref>, with the most prominent being the graphlet kernel [84]</ref>. Motifbased vertex embeddings [88]
side note, approximate counting algorithms are also widely used, especially for counting frequent network motifs [58]</ref>, [59]</ref>, [60]</ref>, [61]</ref>, and can provide a considerable speed-up. Furthermore, recent neural approaches [62]
ref type="bibr" target="#b16">[17]</ref>, [24]</ref> with O(n k ), and [48]</ref> with O(n 2 ) training complexity and relational pooling [49]</ref> with O(n!) training complexity in absence of approximations.</p><p>The worst-case complexity of subgraph enumeration for arbitrary subgraph patterns of size k e orderings/identifiers. To date this is an open problem in graph theory called graph canonisation and it is at least as hard as solving graph isomorphism itself. A possible workaround is proposed in [49]</ref>, where the authors take into account all possible vertex permutations. However, obviously this quickly becomes intractable (O(n!)) even when considering small
oNet [10]</ref> 0.407±0.007 -GatedGCN [107]</ref> 0.422±0.006 0.363±0.009 MPNN 0.254±0.014 0.209±0.018 MPNN-r 0.322±0.026 0.279±0.023 PNA [108]</ref> 0.320±0.032 0.188±0.004 DGN [74]</ref> 0.219±0.010 0.168±0.003 GNNML [109]</ref> 0.1612 ± 0.0 inst a variety of baselines, ranging from traditional message passing NNs to recent more expressive architectures [48]</ref>, [74]</ref>, [108]</ref>, [109]</ref> and a molecular-specific one (HIMP) which is based on the junction-tree molecular decomposition <ref type="bibr able" target="#tab_2">3</ref> we compare against the following baselines: GCN [104]</ref> and GIN [16]</ref>, two conventional GNNs, PNA [108]</ref> and DGN [74]</ref> two modern GNNs with provably increased expressivity and strong empirical performance, and HIMP, a molecul
esult, there have been several efforts to analyse the power of k-WL tests in comparison to other graph invariants [18]</ref>, [76]</ref>, [77]</ref>, [78]</ref>, while recently [19]</ref> approached GNN expressivity by studying their ability to
to attack.</p><p>Most existing methods tackle name disambiguation separately [5]</ref>, [6]</ref>, [9]</ref>, [11]</ref>, [13]</ref>, [15]</ref>, [17]</ref>, <ref type="bibr" target="#b16 wever, by tackling each name separately and independently, these methods neglect the connection between these sub-problems. For example, coauthors, which are used as a strong evidence in many methods [11]</ref>, [32]</ref>, [39]</ref>, may also be ambiguous. Fig. 1</ref> hat they refer to the same person. In fact, there are two different "Wei Xu" and two different "Ying Zhang" in this example. More troubles may appear when multi-hop coauthorships are used as features [11]</ref>, [32]</ref>. For instance, "Jianxin Li" in the University of Western Australia is a coauthor and 2-hop coauthor of "Wei Wang" in ets (AMiner, ACM, and DBLP) to evaluate NDCC. We find that our method NDCC is both effective and efficient, compared with the state-ofthe-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>. Specifically, where W AA 2 i,j is the number of valid 2-hop coauthorship paths connecting authors i and j. To avoid the redundant information, we only consider valid 2-hop coauthorship paths connecting two authors [11]</ref>. Specifically, a valid 2-hop coauthorship path in G is an AP AP A path a i -p i -a j -p j -a k , where a i = a j , a i = a k , a j = a k and p i = p j .</p><p> ing three real datasets, we conduct four sets of experiments to evaluate (1) the effectiveness and efficiency of NDCC versus state-of-the-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>, (2) the effec relational data. Its similarity function considers both attributes and relational information, and a greedy agglomerative clustering method is used to merge the most similar clusters.</p><p>(2) GHOST [11]</ref> is a graph-based method employing coauthorship only. Its similarity function considers both quantity and quality (length) of paths, and an affinity propagation citation information is available.</p><p>Exp-1.2: Efficiency performance comparison. Among the chosen baselines, only CE and GHOST analyze the time complexity [7]</ref>, [11]</ref>. The time complexity of CE is O(|A (0) |k log |A (0) |), where |A (0) | is the number of atomic authors, and k is largest number of buckets that a buckets conn 36">[38]</ref>, [40]</ref>, [44]</ref> and unsupervised [7]</ref>, [9]</ref>, [11]</ref>, [19]</ref>, [28]</ref>, [29]</ref>, <ref type="bibr" target="#b30 hods use clustering, e.g., agglomerative clustering [9]</ref>, [19]</ref>, [39]</ref>, affinity propagation [11]</ref> and Markov clustering [41]</ref>, or topic modeling [28]</ref>, [2
nd Microsoft Academic Search [3], and has raised various troubles in scholar search, document retrieval and so on [21]</ref>, [24]</ref>, [32]</ref>, [44]</ref>. For example, we read an interesting paper written by "Wei Wang" in DBLP, and we want to find more his/her publicat " target="#b13">[15]</ref>, [17]</ref>, [18]</ref>, [19]</ref>, [29]</ref>, [32]</ref>, [35]</ref>, [36]</ref>, [37]</ref>, <ref type="bibr" target="#b3 d independently, these methods neglect the connection between these sub-problems. For example, coauthors, which are used as a strong evidence in many methods [11]</ref>, [32]</ref>, [39]</ref>, may also be ambiguous. Fig. 1</ref> is an example to demonstrate this problem, , there are two different "Wei Xu" and two different "Ying Zhang" in this example. More troubles may appear when multi-hop coauthorships are used as features [11]</ref>, [32]</ref>. For instance, "Jianxin Li" in the University of Western Australia is a coauthor and 2-hop coauthor of "Wei Wang" in the University of New South Wales, and "J the initial network, and improve the efficiency. Bootstrap strategies, such as rule based methods, are used widely in the previous name disambiguation methods [7]</ref>, [32]</ref>, [37]</ref>. Note that using improper rules may include false positive pairs and impair the accuracy performance, such as the e ww.tei-c.org/ns/1.0"><head n="6.1">Experimental Settings</head><p>We first introduce our experimental settings. Datasets. We use three commonly used real-life datasets AMiner (http://www. aminer.org) [32]</ref>, [33]</ref>, [34]</ref>, [37]</ref> , ACM (http://dl.acm.org) <re statistics of these datasets are listed in Table 2</ref>.</p><p>The test set comes from https://aminer.org/disambiguation, commonly used in name disambiguation tasks [32]</ref>, [37]</ref>. It contains 6,730 labeled papers of 110 author names. We compare the labeled papers with each dataset and use thei abstracts, homepages, and email addresses, the datasets that we use only contain citation information, like many other digital libraries. Thus, we dismiss baselines relying on these external features [32]</ref>, [37]</ref>, [38]</ref>. Besides, some methods require the number of authors for each name <ref ibr" target="#b7">[9]</ref>, [11]</ref>, [19]</ref>, [28]</ref>, [29]</ref>, [32]</ref>, [34]</ref>, [37]</ref>, [39]</ref>, <ref type="bibr" target="#b3 year. Our work only uses citation information, and applies to most digital libraries. It is also known that the usage of new evidence, e.g., wiki [19]</ref>, abstracts [32]</ref>, [37]</ref>, and homepages [37]</ref>, usually improves the disambiguation performance. These me
ibr" target="#b7">[9]</ref>, [11]</ref>, [13]</ref>, [15]</ref>, [17]</ref>, [18]</ref>, [19]</ref>, [29]</ref>, [32]</ref>, <ref type="bibr" target="#b3 nd efficient, compared with the state-ofthe-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>. Specifically, (a) NDCC on average improves the Macro-F1 over (CE, GHOST, CSLR, MIX, AM) by (17.87%, 23.25%, one title contains the word "hardware" and the other contains the word "circuit". Both are related to computer hardware. In this case, the traditional unigram model returns a low similarity score. In [18]</ref>, [19]</ref>, the string level or character level tolerance is used when comparing two titles. However, these methods cannot cap and efficiency of NDCC versus state-of-the-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>, (2) the effectiveness of author number estimation, (3) effects of important components in NDCC, and (4) the get="#b17">[19]</ref> first groups the author references based on coauthorships to generate initial clusters. Then these clusters are merged by venue-based and title-based similarities.</p><p>(4) MIX [18]</ref> is a supervised method. Random forests are used to calculate pairwise distances, and DBSCAN is used to group the author references. For effectiveness evaluati 8.47%, 50.37%, 9.86%) on DBLP, on average, respectively. MIX adopts random forests to learn pairwise similarities, which works well when many features are available, such as abstract, and affiliation [18]</ref>. While, in this study, we address the scholarly name disambiguation problem in a more challenging setting, where only basic citation features are available. W scholar name disambiguation can be divided into two classes: supervised [4]</ref>, [15]</ref>, [17]</ref>, [18]</ref>, [35]</ref>, [38]</ref>, [40]</ref>, <ref type="bibr" target="#b4 target="#b40">[42]</ref>. Supervised methods use labeled data to train a classifier, e.g., SVM [38]</ref> and random forests [17]</ref>, [18]</ref>, [35]</ref>, which is then used to assign publications to different author entities. However, labeling data is time-consuming a X, AM) by (17.87%, 23.25%, 16.65%, 45.39%, 21.24%) on AMiner, (25.36%, 24.26%, 14.16%, 37.46%, 14.96%) on ACM, and (13.11%, 23.31%, 8.47%, 50.37%, 9.86%) on DBLP, respectively. (b) NDCC is on average (18,</ref>195,</ref>19)</ref> times faster than (CE, CSLR and MIX) on AMiner, (15,</ref><r iguate all names in the smallest dataset AMiner within 12 hours. Thus, its running time is not reported here.</p><p>The results show that NDCC is more efficient than the baseline methods. (a) NDCC is (18,</ref>195,</ref>19)</ref> times faster than (CE, CSLR and MIX) on AMiner, (15, 8) times faster than    Exp-2: Effecti
>), denoted by K (line 12). It then calculates pairwise author similarity scores in A n , and finds K-th largest score t by using a K-size minimum heap (lines [13]</ref>[14]</ref>. Then it merges author pairs whose similarity scores are no less than t, and updates the network G (equally, the matrix W AP ) accordingly (lines <ref type="b me disambiguation in a collective way. There are also some collective entity resolution methods that can be used to solve multiple name disambiguation problem [7]</ref>, [14]</ref>, [27]</ref>. However, they are not designed for scholar name disambiguation, as they mainly aim to deal with duplication proble olar name disambiguation, as they mainly aim to deal with duplication problems in relational databases caused by different forms of the same names. Most of them need another clean knowledge base (KB) [14]</ref>, [27]</ref>, which is unavailable in most cases. [7]</ref> is a collective entity resolution meth
aised various troubles in scholar search, document retrieval and so on [21]</ref>, [24]</ref>, [32]</ref>, [44]</ref>. For example, we read an interesting paper written by "Wei Wang" in DBLP, and we want to find more his/her publications. However, over 200 authors share the s " target="#b34">[36]</ref>, [37]</ref>, [38]</ref>, [39]</ref>, [40]</ref>, [44]</ref>. For each name to be disambiguated, these methods only deal with the papers having that author name. However, by tackling each name separately and independent thods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>. Specifically, (a) NDCC on average improves the Macro-F1 over (CE, GHOST, CSLR, MIX, AM) by (17.87%, 23.25%, 16.65%, 45.39%, 21.24%) on AMiner, (25.36%, 24.26 thods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>, (2) the effectiveness of author number estimation, (3) effects of important components in NDCC, and (4) the impacts of parameters on accuracy and efficiency. beled names as the training set for each author name to be disambiguated. For efficiency evaluation, we randomly choose 5 labeled names to train the model and use the others for testing.</p><p>(5) AM [44]</ref> is the method deployed in AMiner to tackle the name disambiguation. A representation learning method is used to include global and local information. An end-t generated subsets are dense. Although AM is deployed with thousands of millions of papers, it is not efficient to compute the clustering from scratch due to the local linkage learning and IO overhead [44]</ref>. Indeed, this method even cannot disambiguate all names in the smallest dataset AMiner within 12 hours. Thus, its running time is not reported here.</p><p>The " target="#b15">[17]</ref>, [18]</ref>, [35]</ref>, [38]</ref>, [40]</ref>, [44]</ref> and unsupervised [7]</ref>, [9]</ref>, [11]</ref>, <ref type="bibr"
2">[44]</ref>. For example, we read an interesting paper written by "Wei Wang" in DBLP, and we want to find more his/her publications. However, over 200 authors share the same name "Wei Wang" in DBLP [19]</ref>, and the total number of their publications is over 2,000. Hence, it is timeconsuming to find those publications written by the "Wei Wang" in whom we are inte r" target="#b9">[11]</ref>, [13]</ref>, [15]</ref>, [17]</ref>, [18]</ref>, [19]</ref>, [29]</ref>, [32]</ref>, [35]</ref>, <ref type="bibr" target="#b3 e find that our method NDCC is both effective and efficient, compared with the state-ofthe-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>. Specifically, (a) NDCC on average improves the Macro-F1 over the other contains the word "circuit". Both are related to computer hardware. In this case, the traditional unigram model returns a low similarity score. In [18]</ref>, [19]</ref>, the string level or character level tolerance is used when comparing two titles. However, these methods cannot capture the semantic relation between two word >Author Similarity Assembling</head><p>The author similarity is assembled by four similarities (coauthor, venue, title, and coauthor name). Given two authors i and j with the same name n, inspired by [19]</ref>, we consider each pair and define the author similarity as:</p><formula xml:id="formula_5">sim = x =y sim x ? sim y ,<label>(1)</label></formula><p>where x, y ype="bibr" target="#b24">[26]</ref> Specifically, a name is considered as fully disambiguated if the number of authors of this name reaches the estimated one. Inspired by name ambiguity estimation in [19]</ref>, we introduce a statistical method, which is based on the statistics of author names in the bibliography data.</p><p>In most cases, a name consist of a fixed me that these parts are chosen independently from different multinomial distributions, and the probability of a full name Algorithm 1: Collective Clustering is the joint probability of its components [19]</ref>. Here we use the two-component names as an example to explain the main idea. Given a name n, its first name and last name are denoted by F (n) and L(n), which f experiments to evaluate (1) the effectiveness and efficiency of NDCC versus state-of-the-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>, (2) the effectiveness of author number estimation, (3) effec [33]</ref>, [34]</ref>, [37]</ref> , ACM (http://dl.acm.org) [37]</ref> and DBLP (http://dblp.unitrier.de) [19]</ref> for scholar name disambiguation. Different from previous works that use small size subsets, we build datasets from the whole public available meta-data files ity function considers both quantity and quality (length) of paths, and an affinity propagation clustering method is used to generate clusters of author references of the focused name.</p><p>(3) CSLR [19]</ref> first groups the author references based on coauthorships to generate initial clusters. Then these clusters are merged by venue-based and title-based similari b38">[40]</ref>, [44]</ref> and unsupervised [7]</ref>, [9]</ref>, [11]</ref>, [19]</ref>, [28]</ref>, [29]</ref>, [32]</ref>, <ref type="bibr" target="#b3 ever, labeling data is time-consuming and impractical when the bibliography data is large. Unsupervised methods use clustering, e.g., agglomerative clustering [9]</ref>, [19]</ref>, [39]</ref>, affinity propagation [11]</ref> and Markov clustering <ref type="bibr" target="#b39" explored by disambiguation methods [12]</ref>: citation information [7]</ref>, [38]</ref>, web information [19]</ref>, affiliation [5]</ref>, and implicit evidence [28]</ref>, [29]</re ds, including author names, title, venue, publication year. Our work only uses citation information, and applies to most digital libraries. It is also known that the usage of new evidence, e.g., wiki [19]</ref>, abstracts [32]</ref>, [37]</ref>, and homepages [37]</ref>, usua %, 24.26%, 14.16%, 37.46%, 14.96%) on ACM, and (13.11%, 23.31%, 8.47%, 50.37%, 9.86%) on DBLP, respectively. (b) NDCC is on average (18,</ref>195,</ref>19)</ref> times faster than (CE, CSLR and MIX) on AMiner, (15,</ref>8)</ref> times faster than (CE, MIX) on s, its running time is not reported here.</p><p>The results show that NDCC is more efficient than the baseline methods. (a) NDCC is (18,</ref>195,</ref>19)</ref> times faster than (CE, CSLR and MIX) on AMiner, (15, 8) times faster than    Exp-2: Effectiveness of estimating author numbers. In the second set of experiment
ibr" target="#b7">[9]</ref>, [11]</ref>, [13]</ref>, [15]</ref>, [17]</ref>, [18]</ref>, [19]</ref>, [29]</ref>, [32]</ref>, <ref type="bibr" target="#b3 nd efficient, compared with the state-ofthe-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>. Specifically, (a) NDCC on average improves the Macro-F1 over (CE, GHOST, CSLR, MIX, AM) by (17.87%, 23.25%, one title contains the word "hardware" and the other contains the word "circuit". Both are related to computer hardware. In this case, the traditional unigram model returns a low similarity score. In [18]</ref>, [19]</ref>, the string level or character level tolerance is used when comparing two titles. However, these methods cannot cap and efficiency of NDCC versus state-of-the-art methods CE [7]</ref>, GHOST [11]</ref>, CSLR [19]</ref>, MIX [18]</ref>, and AM [44]</ref>, (2) the effectiveness of author number estimation, (3) effects of important components in NDCC, and (4) the get="#b17">[19]</ref> first groups the author references based on coauthorships to generate initial clusters. Then these clusters are merged by venue-based and title-based similarities.</p><p>(4) MIX [18]</ref> is a supervised method. Random forests are used to calculate pairwise distances, and DBSCAN is used to group the author references. For effectiveness evaluati 8.47%, 50.37%, 9.86%) on DBLP, on average, respectively. MIX adopts random forests to learn pairwise similarities, which works well when many features are available, such as abstract, and affiliation [18]</ref>. While, in this study, we address the scholarly name disambiguation problem in a more challenging setting, where only basic citation features are available. W scholar name disambiguation can be divided into two classes: supervised [4]</ref>, [15]</ref>, [17]</ref>, [18]</ref>, [35]</ref>, [38]</ref>, [40]</ref>, <ref type="bibr" target="#b4 target="#b40">[42]</ref>. Supervised methods use labeled data to train a classifier, e.g., SVM [38]</ref> and random forests [17]</ref>, [18]</ref>, [35]</ref>, which is then used to assign publications to different author entities. However, labeling data is time-consuming a X, AM) by (17.87%, 23.25%, 16.65%, 45.39%, 21.24%) on AMiner, (25.36%, 24.26%, 14.16%, 37.46%, 14.96%) on ACM, and (13.11%, 23.31%, 8.47%, 50.37%, 9.86%) on DBLP, respectively. (b) NDCC is on average (18,</ref>195,</ref>19)</ref> times faster than (CE, CSLR and MIX) on AMiner, (15,</ref><r iguate all names in the smallest dataset AMiner within 12 hours. Thus, its running time is not reported here.</p><p>The results show that NDCC is more efficient than the baseline methods. (a) NDCC is (18,</ref>195,</ref>19)</ref> times faster than (CE, CSLR and MIX) on AMiner, (15, 8) times faster than    Exp-2: Effecti
" target="#b11">[13]</ref>, [15]</ref>, [17]</ref>, [18]</ref>, [19]</ref>, [29]</ref>, [32]</ref>, [35]</ref>, [36]</ref>, <ref type="bibr" target="#b3 "bibr" target="#b5">[7]</ref>, [9]</ref>, [11]</ref>, [19]</ref>, [28]</ref>, [29]</ref>, [32]</ref>, [34]</ref>, [37]</ref>, <ref type="bibr" target="#b3 [39]</ref>, affinity propagation [11]</ref> and Markov clustering [41]</ref>, or topic modeling [28]</ref>, [29]</ref> to divide the set of author references into different subsets. Our work belongs to the second category.</p><p>There are three kinds of evidences that are comm get="#b36">[38]</ref>, web information [19]</ref>, affiliation [5]</ref>, and implicit evidence [28]</ref>, [29]</ref>. Citation information is extracted directly from citation records, including author names, title, venue, publication year. Our work only uses citation informa
" target="#b30">[32]</ref>, [34]</ref>, [37]</ref>, [39]</ref>, [41]</ref>, [42]</ref>. Supervised methods use labeled data to train a classifier, e.g., SVM [38]</ref> and random forests <ref type="bibr" target="#b
the string level or character level tolerance is used when comparing two titles. However, these methods cannot capture the semantic relation between two words either.</p><p>We propose to use Word2vec [25]</ref>, which is an effective word embedding method, to capture the semantic correlations between words. It takes a text corpus as input and maps each word in the te
kle name disambiguation separately [5]</ref>, [6]</ref>, [9]</ref>, [11]</ref>, [13]</ref>, [15]</ref>, [17]</ref>, [18]</ref>, <ref type="bibr" target="#b1 ype="formula" target="#formula_14">6</ref>), denoted by K (line 12). It then calculates pairwise author similarity scores in A n , and finds K-th largest score t by using a K-size minimum heap (lines [13]</ref>[14]</ref>. Then it merges author pairs whose similarity scores are no less than t, and updates the network G (equally, the matr
ized with MDP and solved with the classic policy gradient algorithm of REINFORCE. Similar MDP con gurations are used to model the sequential document selection process in search result diversi cation [11,</ref>35]</ref> and multi-page search [41]</ref>. The query change model <ref type="bibr" target="#b36"
pointwise approaches [8,</ref>23]</ref>, pairwise approaches [1,</ref>3,</ref>16]</ref>, and listwise approaches [2,</ref>4,</ref>36]</ref>. Speci cally, th Speci cally, for MSLR-Web10K dataset, we normalize each provided feature by the mean/standard deviation. We compared the proposed PPG to the traditional learning to rank baselines, including RankSVM [16]</ref>, RankNet [2]</ref>, ListNet [4]</ref>, AdaRank [36]</ref>, and MDPR

o rank studies can be categorized into pointwise approaches [8,</ref>23]</ref>, pairwise approaches [1,</ref>3,</ref>16]</ref>, and listwise approaches [2,</ref>4,</ref><ref type="bibr" ta
P. The win-win search framework models session search as a dual-agent stochastic game, on the basis of partially observed Markov decision process (POMDP) [22]</ref>. In [42]</ref>, a log-based document re-ranking algorithm is proposed, also based on POMDP. DRM [24]</ref> makes use of deep RL to deal with t
get="#b0">[1,</ref>3,</ref>16]</ref>, and listwise approaches [2,</ref>4,</ref>36]</ref>. Speci cally, the pairwise methods consider the preference pairs composed of two documents with di erent relevance levels under the same query and construct cl onal learning to rank baselines, including RankSVM [16]</ref>, RankNet [2]</ref>, ListNet [4]</ref>, AdaRank [36]</ref>, and MDPRank [40]</ref>.</p><p>In both MDPRank and PPG, the rewards are calculated based on DCG and the discount factor γ = 1.
iments on text retrieval</head><p>We also conducted experiments on the task of text retrieval. The experiments were conducted on three traditional learning to rank benchmark datasets: OHUSMED, MQ2008 [25]</ref>, and MSLR-Web10K. Each dataset consists of queries, corresponding retrieved documents and human judged labels, and the statistics over the three dataset  <ref
arkov decision process (POMDP) [22]</ref>. In [42]</ref>, a log-based document re-ranking algorithm is proposed, also based on POMDP. DRM [24]</ref> makes use of deep RL to deal with the complex ranking problems in which both the user preferred document order and display position order for result presentat
</div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Existing learning to rank studies can be categorized into pointwise approaches [8,</ref>23]</ref>, pairwise approaches [1,</ref>3,</ref>16]</ref>, and listwise approa
euristic methods of MMR [5]</ref>, xQuAD [28]</ref>, and PM-2 [9]</ref>; and the learning methods of SVM-DIV [38]</ref>, R-LTR [45]</ref>, PAMM [33]</ref>, NTN-DIV [34]</ref>, and MDP-D
arkov decision process (POMDP) [22]</ref>. In [42]</ref>, a log-based document re-ranking algorithm is proposed, also based on POMDP. DRM [24]</ref> makes use of deep RL to deal with the complex ranking problems in which both the user preferred document order and display position order for result presentat
ard sample to be weaker than an easy sample; and 3) the degree of weight reduction can be easily adjusted so that it can fit different models and datasets.</p><p>Inspired by the success of Focal Loss [30]</ref>, we estimate 𝜔 (𝑢, 𝑖) with a function of 𝑓 ( ŷ𝑢𝑖 ) that takes the prediction score as the input. Note that the prediction score and CE loss are equivalent to
</head><p>Recommender systems have been a promising solution for mining user preference over items in various online services such as Ecommerce [29]</ref>, news portals [32]</ref> and social media [3]</ref>. As the clue to user choices, implicit feedback (e.g., click and purchase) are typically the default p [7]</ref>) and the item characteristics [32,</ref>33]</ref> to predict the user's satisfaction. Lu et al. [32]</ref> predicted users' actual preference in news recommendation based on various user behaviors, news quality, and the interaction context. However, these methods n dditional feedback and extensive manual label work, e.g., users have to tell if they are satisfied for each interaction. Besides, the quantification of item quality and characteristics is non-trivial [32]</ref>, which largely relies on the manually feature design and the labeling of domain experts [32,</ref><ref type="bibr" target="#b32 r choices, implicit feedback (e.g., click and purchase) are typically the default choice to train a recommender due to their large volume. However, prior work [18,</ref>32,</ref>39]</ref> points out the gap between implicit feedback and the actual user satisfaction due to the prevailing presence of noisy i ck (e.g., dwell time [21]</ref>, gaze patterns [46]</ref>, and skip [7]</ref>) and the item characteristics [32,</ref>33]</ref> to predict the user's satisfaction. Lu et al. [32]</ref> predicted users' actual prefer the quantification of item quality and characteristics is non-trivial [32]</ref>, which largely relies on the manually feature design and the labeling of domain experts [32,</ref>33]</ref>. The unaffordable labor cost hinders the practical usage of these methods, especially in the scenarios with constantly either adopts the additional feedback by multi-task learning [9,</ref>10]</ref>, or leverages it to identify the true-positive interactions [32,</ref>39]</ref>. In this work, we introduce two classical models for comparison: Neural Multi-Task Recommendation (NMTR) <ref type="bi
eshold function which can be tuned more granularly. Further improvement might be achieved by a finer-grained user-specific or item-specific tuning of these parameters, which can be done automatically [5]</ref>. • Across the recommenders, NeuMF performs worse than GMF and CDAE, especially on Amazon-book and Yelp, which is criticized for the vulnerability to noisy inter 1.0" place="foot" n="1" xml:id="foot_0">Each false-positive interaction is identified by auxiliary information of postinteraction behaviors, e.g., rating score ([1,</ref>5]</ref>) &lt; 3, indicating that the interacted item dissatisfies the user. Refer to</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_
ecause implicit interactions are easily affected by the first impression of users and other factors such as caption bias [4,</ref>17,</ref>33]</ref> and position bias [19]</ref>. Moreover, existing studies [33,</ref><ref type="bibr" target="#b38" ef type="bibr" target="#b40">41]</ref> have been dedicated to eliminating the effects of false-positive interactions by: 1) negative experience identification [21,</ref>33]</ref> (illustrated in Figure 1(b)</ref>); and 2) the incorporation of various feedback [41,</ref><r get="#b20">[21]</ref>, gaze patterns [46]</ref>, and skip [7]</ref>) and the item characteristics [32,</ref>33]</ref> to predict the user's satisfaction. Lu et al. [32]</ref> predicted users' actual preference in news recommendation based on vari aracteristics is non-trivial [32]</ref>, which largely relies on the manually feature design and the labeling of domain experts [32,</ref>33]</ref>. The unaffordable labor cost hinders the practical usage of these methods, especially in the scenarios with constantly changing items.</p><p>Incorporating Vari e="bibr" target="#b3">[4,</ref>17,</ref>33]</ref> and position bias [19]</ref>. Moreover, existing studies [33,</ref>39]</ref> have demonstrated the detrimental effect of such false-positive interactions on user experience of online services. Ne commender training. Note that we do not incorporate any additional data such as explicit feedback or reliable implicit feedback into the task of denoising, despite their success in a few applications [33,</ref>39]</ref>. This is because such feedback is of a smaller scale in most cases, suffering more severely from the sparsity issue. ecommender training. Note that we do not incorporate any additional data such as explicit feedback or reliable implicit feedback into the task of denoising, despite their success in a few applications[33,</ref>39]</ref>. This is because such feedback is of a smaller scale in most cases, suffering more severely from the sparsity issue.</ mplicit feedback in advance by predicting the false-positive ones with additional user behaviors (e.g., dwell time and gaze pattern) and auxiliary item features (e.g., length of the item description) [33]</ref>. The latter incorporates extra feedback (e.g., favorite and skip) into recommender training to prune the effects of false-positive interactions <ref type="bib s on recommending satisfying items to users. Worse still, recommendations from normal training have higher risk on leading to further false-positive interactions, which would hurt the user experience [33]</ref>. Despite the success of clean training in the pilot study, it is not a reasonable choice in practical applications because of the sparsity issues of reliable

n for mining user preference over items in various online services such as Ecommerce [29]</ref>, news portals [32]</ref> and social media [3]</ref>. As the clue to user choices, implicit feedback (e.g., click and purchase) are typically the default choice to train a recommender due to their large volume. Ho
rget="#b24">[25]</ref> and fuzzing attacks [36]</ref>. To build more robust recommender systems, some auto-encoder based models [28,</ref>37,</ref>40]</ref> introduce the denoising techniques. These approaches (e.g., CDAE [40]</ref>) first corru
ses, and then employs a MLP model to reconstruct the original input.</p><p>We only tested neural recommenders and omit conventional ones such as MF [24]</ref> and SVD++ [23]</ref> due to their inferior performance [16,</ref>40]</ref>.</p><p>Parameter Settings. For the three t
rget="#b24">[25]</ref> and fuzzing attacks [36]</ref>. To build more robust recommender systems, some auto-encoder based models [28,</ref>37,</ref>40]</ref> introduce the denoising techniques. These approaches (e.g., CDAE [40]</ref>) first corru
it feedback and eliminate the impact of false-positive interactions for recommender training.</p><p>Indeed, some efforts [7,</ref>21,</ref>41]</ref> have been dedicated to eliminating the effects of false-positive interactions by: 1) negative experience identification [21,</re n [21,</ref>33]</ref> (illustrated in Figure 1(b)</ref>); and 2) the incorporation of various feedback [41,</ref>43]</ref> (shown in Figure 1(c)</ref>). The former processes the implicit feedback in advance ack. To alleviate the impact of false-positive interactions, previous approaches [8,</ref>26,</ref>31,</ref>41,</ref>44]</ref> also consider incorporating more feedback (e.g., dwell time [43]</ref>, skip <ref type="
k and purchase) are typically the default choice to train a recommender due to their large volume. However, prior work [18,</ref>32,</ref>39]</ref> points out the gap between implicit feedback and the actual user satisfaction due to the prevailing presence of noisy interactions (a.k.a. false-positive inter "bibr" target="#b16">17,</ref>33]</ref> and position bias [19]</ref>. Moreover, existing studies [33,</ref>39]</ref> have demonstrated the detrimental effect of such false-positive interactions on user experience of online services. Nevertheless, little work on recommendation ncorporate any additional data such as explicit feedback or reliable implicit feedback into the task of denoising, despite their success in a few applications [33,</ref>39]</ref>. This is because such feedback is of a smaller scale in most cases, suffering more severely from the sparsity issue.  </p></div> <div xmlns="http://www.tei-c.o multi-task learning [9,</ref>10]</ref>, or leverages it to identify the true-positive interactions [32,</ref>39]</ref>. In this work, we introduce two classical models for comparison: Neural Multi-Task Recommendation (NMTR) [10]</ref> and Negative incorporate any additional data such as explicit feedback or reliable implicit feedback into the task of denoising, despite their success in a few applications[33,</ref>39]</ref>. This is because such feedback is of a smaller scale in most cases, suffering more severely from the sparsity issue.</figDesc></figure> <figure xmlns="http://w type="bibr" target="#b42">[43]</ref>, skip [27,</ref>45]</ref>, and adding to favorites) into training directly. For instance, Wen et al. [39]</ref> proposed to train the recommender using three kinds of items: "click-complete", "click-skip", and "non-click" ones. The last two kinds of items are both treat b38">39]</ref>. In this work, we introduce two classical models for comparison: Neural Multi-Task Recommendation (NMTR) [10]</ref> and Negative feedback Reweighting (NR) [39]</ref>. In particular, NMTR with multi-task learning is to capture multiple user behaviors (i.e., click and satisfaction) while NR uses the addition feedback (i.e.,
sed black-box attacks devise adversarial samples with off-the-shelf local models (i.e., source models) and directly harness the resultant example to fool the remote target model (i.e., victim models) [41,</ref>8]</ref>.</p><p>Among these two sorts of black-box attacks, the transfer-based one has attracted ever-increasing attention recent he mechanism they adopt. One is query-based [24,</ref>2,</ref>10]</ref>, and the other one is transfer-based [41,</ref>39,</ref>8,</ref>21,</ref>23]</ref>. utional layer of the source model in our regularization term based on our preliminary experiments. For fair comparisons, we adopt default parameters as recommended in benchmark approaches and Foolbox [41,</ref>28]</ref>. The random noise is sampled from a clipped normal distribution with mean 0 and variance 1.  Following <ref type="bibr the malicious images synthesized by such a scheme are prone to overfit to the exclusive blind spots of the source model [39,</ref>8,</ref>41,</ref>7]</ref>. Specifically, although the crafted adversarial samples can attack Inception V3 VGG 16</re ref type="bibr" target="#b7">8,</ref>23]</ref>. More related to our work is the regularization-based approach: transferable adversarial perturbation (TAP) introduced by [41]</ref>. TAP injects two regularization terms into the vanilla training loss function of the model to guide the search of adversarial manipulations, which alleviates t broadly recognized benchmark task for transfer-based black-box attacks [20,</ref>4]</ref>. We follow the protocol of the baseline method [41]</ref> to curate experimental datasets and target models for fair comparisons.</p><p>Dataset. We need two sorts of datasets to develop and assess our attacks, respec e and improving the transferability of white-box attacks. Since the original C&amp;W implementation cannot strictly meet the l ∞ budget, we employ the modified l ∞ version of C&amp;W as introduced by [41]</ref>, which can explicitly satisfy the l ∞ norm constraint. Similar to our strategy, TAP [41]</ref> boosts adversarial transferabili ∞ budget, we employ the modified l ∞ version of C&amp;W as introduced by [41]</ref>, which can explicitly satisfy the l ∞ norm constraint. Similar to our strategy, TAP [41]</ref> boosts adversarial transferability through two regularization terms and is the state-of-the-art approach under this category. Therefore, we also include TAP i es and Foolbox [41,</ref>28]</ref>. The random noise is sampled from a clipped normal distribution with mean 0 and variance 1.  Following [41]</ref>, we fix the perturbation budget ǫ to 16 for all methods. We conduct grid search on the development dataset to settle the best hyper-parameter for our algorith e attention-weighed internal feature distances, our method outperforms TAP in almost all cases. We next attack models defended by adversarial training. For fair comparisons with the baseline approach [41]</ref>, we stick to employing undefended models as local source models. Therefore, we explore a more challenging black-box scenario where the source and target model mble-based translationinvariant attack (TI) developed by [8]</ref>, and the other one is the regularization-based transferable adversarial perturbation (TAP) proposed by [41]</ref>. With the integrated attacks, we conduct experiments similar to Section 5.2. Specifically, the combination of TI and ATA will only modify the update rule of A
ef>, and the other one is transfer-based [41,</ref>39,</ref>8,</ref>21,</ref>23]</ref>.</p><p>Query-based black-box attacks can settle the susceptible direction of the victim model as per the response of the target model to given inputs <ref type ul for an ensemble of models [21,</ref>32]</ref> or images [39,</ref>8,</ref>23]</ref>. More related to our work is the regularization-based approach: transferable adversarial perturbation (TAP) introduced by [41]</
with diverse architectures, including ResNet V2 [12,</ref>13]</ref>, Inception V3 [35]</ref>, Inception V4 [34]</ref>, and Inception-ResNet V2 [34]</ref>  We also attack the corresponding ensemble model (referred to as Ensemble), whose predictio rget="#b11">[12,</ref>13]</ref>, Inception V3 [35]</ref>, Inception V4 [34]</ref>, and Inception-ResNet V2 [34]</ref>  We also attack the corresponding ensemble model (referred to as Ensemble), whose prediction is the average probability output of all the above models. When i
inst DNN image classifiers [3]</ref>. To simulate the threat a DNN image classifier may face, there are generally two kinds of threat models considered in the literature [20]</ref>. One is white-box settings, where attackers have full access to the victim model, such as the model architectures and parameters. The other one is black-box s ly, offering input images and obtaining output predictions.</p><p>Corresponding to the threat models that they are tailored for, there exist two sorts of attacks: white-box attacks and black-box ones [20]</ref>. White-box attacks can exploit the exact gradient information of the victim model to craft malicious instances [36,</ref><ref t target="#b28">[29]</ref>, where we finetune our hyper-parameters. The test data adopted to assess our technique is the ImageNet-compatible dataset released by the NeurIPS 2017 adversarial competition [20]</ref>. This test set contains 1000 images that are not included in the original ImageNet dataset. Therefore, it satisfies the requirement of evaluating the generali tively craft deceptive images for their model and augment the clean training data with such instances to train the model [9,</ref>22,</ref>20]</ref>. Moreover, exploiting the malicious examples tailored for diverse hold-out models can further strengthen defense and confer robustness to transferbased black-b ead><p>We focus on attacking image classifiers trained on Im-ageNet [29]</ref>, which is the most broadly recognized benchmark task for transfer-based black-box attacks [20,</ref>4]</ref>. We follow the protocol of the baseline method [41]</ref> to curate experimental datasets
magnitude to improve attack success rates [18]</ref>. Projected gradient descent (PGD) extends BIM with random start to diversify the synthesized adversarial instances [22]</ref>. Carlini and Wagner attacks (C&amp;W) devise a novel attack object to absorb the perturbation budget constraint [5]</ref>, which ned models as remote targets [37,</ref>19]</ref>, since adversarial training is arguably the most promising and effective defense to date [22]</ref>. These adversarially trained models include adversarially trained Inception V3 (Adv-Inc-v3), adversarially trained Inception-ResNet V2 (Adv-IncRes-v2), advers g defense to date, where defenders proactively craft deceptive images for their model and augment the clean training data with such instances to train the model [9,</ref>22,</ref>20]</ref>. Moreover, exploiting the malicious examples tailored for diverse hold-out models can further strengthen defense and co
cks (C&amp;W) devise a novel attack object to absorb the perturbation budget constraint [5]</ref>, which also admits the employment of sophisticated optimizers like Adam [17]</ref> during the search for deceptive noises. Jacobian-based Saliency Map Attack (JSMA) [25]</ref> is tailored for seeking the advers
ef>, which also admits the employment of sophisticated optimizers like Adam [17]</ref> during the search for deceptive noises. Jacobian-based Saliency Map Attack (JSMA) [25]</ref> is tailored for seeking the adversarial noise with the minimal l 0 norm. Therefore, it proposes to prioritize the modification of the most important image pix /master/research/adv_ imagenet_models.</p><p>ing FGSM [9]</ref>, BIM [18]</ref>, C&amp;W [5]</ref>, and JSMA [25]</ref>, to showcase the effectiveness of our algorithm in alleviating the overfitting issue and improving the transferability of white-box attacks. Since the origina
ce against adversaries due to the prevailing reactive defense methodology [3]</ref>. Failed attempts include pre-processing the input images to diminish malicious noises [11,</ref>1]</ref>, defensive distillation to mask gradients [26,</ref>6]</ref
regularization term based on our preliminary experiments. For fair comparisons, we adopt default parameters as recommended in benchmark approaches and Foolbox [41,</ref>28]</ref>. The random noise is sampled from a clipped normal distribution with mean 0 and variance 1.  Following [41]</ref>, we fix the pe
ts: a hierarchical feature extraction module and a softmax classifier. The learned feature extractors of a DNN image classifier are often so generic that they can adapt to different domains and tasks [31]</ref>. Inspired by the fact, we expect that lots of feature descriptors are shared among different architectures for the same task, for example, the edge detector f
">[36,</ref>9,</ref>5]</ref>, while black-box attacks can be further divided into two categories according to the mechanism attackers adopt [8]</ref>. One is query-based, and the other one is transfer-based. Query-based black-box attacks usually require excessive queries before a successful trial <ref type="b f type="bibr" target="#b40">[41,</ref>8]</ref>.</p><p>Among these two sorts of black-box attacks, the transfer-based one has attracted ever-increasing attention recently [8]</ref>. In general, only costly query access to deployed models is available in practice. Therefore, whitebox attacks hardly reflect the possible threat to a model, wh ttacks hardly reflect the possible threat to a model, while query-based attacks have less practical applicability than the transfer-based counterparts due to the prohibitive query cost they may incur [8]</ref>.</p><p>Thanks to the observed cross-model transferability of adversarial samples, a popular practice is to freely employ any white-box attack strategy as transf finite difference techniques [2]</ref>. However, such attacks usually require excessive queries before a successful trial and thus have limited applicability in practice [8]</ref>.</p><p>Transfer-based black-box attacks are motivated by the transferability of adversarial samples across different models. Concretely, attackers first launch We select two sorts of cutting-edge transfer-based attacks to corroborate the complementing effect introduced by our strategy. One is the ensemble-based translationinvariant attack (TI) developed by [8]</ref>, and the other one is the regularization-based transferable adversarial perturbation (TAP) proposed by [41]</ref>. With the integ samples with off-the-shelf local models (i.e., source models) and directly harness the resultant example to fool the remote target model (i.e., victim models) [41,</ref>8]</ref>.</p><p>Among these two sorts of black-box attacks, the transfer-based one has attracted ever-increasing attention recently [8]</ref rget="#b20">[21]</ref>. Unfortunately, the malicious images synthesized by such a scheme are prone to overfit to the exclusive blind spots of the source model [39,</ref>8,</ref>41,</ref>7]</ref>. Specifically, although the crafted adversarial samples can attack Inception V3 VGG ref>2,</ref>10]</ref>, and the other one is transfer-based [41,</ref>39,</ref>8,</ref>21,</ref>23]</ref>.</p><p>Query-based black-box attacks can settle the susceptible direction of the the deduced distortion to remain harmful for an ensemble of models [21,</ref>32]</ref> or images [39,</ref>8,</ref>23]</ref>. More related to our work is the regularization-based approach: transferable adversarial perturbation (TAP) introduced by
cks (C&amp;W) devise a novel attack object to absorb the perturbation budget constraint [5]</ref>, which also admits the employment of sophisticated optimizers like Adam [17]</ref> during the search for deceptive noises. Jacobian-based Saliency Map Attack (JSMA) [25]</ref> is tailored for seeking the advers
ckers adopt [8]</ref>. One is query-based, and the other one is transfer-based. Query-based black-box attacks usually require excessive queries before a successful trial [16]</ref>. On the contrary, without the feedback information from the target model, transfer-based black-box attacks devise adversarial samples with off-the-shelf local ref type="bibr" target="#b7">8,</ref>41,</ref>7]</ref>. Specifically, although the crafted adversarial samples can attack Inception V3 VGG 16</ref> ResNet V2</p><p>Figure 1</ref>: The attention heatmaps of three representative models (VGG 16 [33]</ref>, ResN
dversarial samples can attack Inception V3 VGG 16</ref> ResNet V2</p><p>Figure 1</ref>: The attention heatmaps of three representative models (VGG 16 [33]</ref>, ResNet V2 [12,</ref>13]</ref>, and Inception V3 [35]</ref>) for
ion recently. There are roughly two sorts of black-box attacks according to the mechanism they adopt. One is query-based [24,</ref>2,</ref>10]</ref>, and the other one is transfer-based [41,</ref>39,</ref>8,</ref><ref 21,</ref>23]</ref>.</p><p>Query-based black-box attacks can settle the susceptible direction of the victim model as per the response of the target model to given inputs [10]</ref>. Alternatively, attackers can approximate the loss gradient of the target model through training a local replica [24]</ref> or f
ckers adopt [8]</ref>. One is query-based, and the other one is transfer-based. Query-based black-box attacks usually require excessive queries before a successful trial [16]</ref>. On the contrary, without the feedback information from the target model, transfer-based black-box attacks devise adversarial samples with off-the-shelf local ref type="bibr" target="#b7">8,</ref>41,</ref>7]</ref>. Specifically, although the crafted adversarial samples can attack Inception V3 VGG 16</ref> ResNet V2</p><p>Figure 1</ref>: The attention heatmaps of three representative models (VGG 16 [33]</ref>, ResN
7">[8]</ref>.</p><p>Thanks to the observed cross-model transferability of adversarial samples, a popular practice is to freely employ any white-box attack strategy as transfer-based black-box attacks [21]</ref>. Unfortunately, the malicious images synthesized by such a scheme are prone to overfit to the exclusive blind spots of the source model <ref type="bibr" targe ref>10]</ref>, and the other one is transfer-based [41,</ref>39,</ref>8,</ref>21,</ref>23]</ref>.</p><p>Query-based black-box attacks can settle the susceptible direction of the victim model as per the response of th ttacks.</p><p>There also exist two sorts of methods to promote adversarial transferability. Ensemble-based mechanisms of-ten require the deduced distortion to remain harmful for an ensemble of models [21,</ref>32]</ref> or images [39,</ref>8,</ref><ref type="bibr" target="#b22
ion recently. There are roughly two sorts of black-box attacks according to the mechanism they adopt. One is query-based [24,</ref>2,</ref>10]</ref>, and the other one is transfer-based [41,</ref>39,</ref>8,</ref><ref 21,</ref>23]</ref>.</p><p>Query-based black-box attacks can settle the susceptible direction of the victim model as per the response of the target model to given inputs [10]</ref>. Alternatively, attackers can approximate the loss gradient of the target model through training a local replica [24]</ref> or f
20]</ref>. White-box attacks can exploit the exact gradient information of the victim model to craft malicious instances [36,</ref>9,</ref>5]</ref>, while black-box attacks can be further divided into two categories according to the mechanism attackers adopt [8]</ref>. One is qu >The white-box attack enjoys great popularity among early work on attacking DNNs [36,</ref>9,</ref>18,</ref>5]</ref>. Different from the process of model training, they feature an optimization in input space to elevate training loss. Fast gradient sign method (FGSM) alters clea versify the synthesized adversarial instances [22]</ref>. Carlini and Wagner attacks (C&amp;W) devise a novel attack object to absorb the perturbation budget constraint [5]</ref>, which also admits the employment of sophisticated optimizers like Adam [17]</ref> during the search for deceptive noises. Jacobi able at https://github. com/tensorflow/models/tree/master/research/adv_ imagenet_models.</p><p>ing FGSM [9]</ref>, BIM [18]</ref>, C&amp;W [5]</ref>, and JSMA [25]</ref>, to showcase the effectiveness of our algorithm in alleviating the overfitting issue and improving the trans
egy on compatible algorithms in Section 5.4.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>We focus on attacking image classifiers trained on Im-ageNet [29]</ref>, which is the most broadly recognized benchmark task for transfer-based black-box attacks [20,</ref><ref type="bibr" target="#b ets and target models for fair comparisons.</p><p>Dataset. We need two sorts of datasets to develop and assess our attacks, respectively. The development dataset is the ILSVRC 2012 validation dataset [29]</ref>, where we finetune our hyper-parameters. The test data adopted to assess our technique is the ImageNet-compatible dataset released by the NeurIPS 2017 adversa
hine translation [27]</ref>. Despite the impressive performance of these deep learning techniques, they are surprisingly vulnerable to the so-called adversarial samples [36]</ref>. For example, by imposing human-imperceptible noises on legitimate images purposefully, the resultant adversarial input can incur erroneous predictions from s attacks: white-box attacks and black-box ones [20]</ref>. White-box attacks can exploit the exact gradient information of the victim model to craft malicious instances [36,</ref>9,</ref>5]</ref>, while black-box attacks can be further divided into two categories according to t re tailored for, attacks are coined white-box attacks and black-box ones [3]</ref>.</p><p>The white-box attack enjoys great popularity among early work on attacking DNNs [36,</ref>9,</ref>18,</ref>5]</ref>. Different from the process of model train
magnitude to improve attack success rates [18]</ref>. Projected gradient descent (PGD) extends BIM with random start to diversify the synthesized adversarial instances [22]</ref>. Carlini and Wagner attacks (C&amp;W) devise a novel attack object to absorb the perturbation budget constraint [5]</ref>, which ned models as remote targets [37,</ref>19]</ref>, since adversarial training is arguably the most promising and effective defense to date [22]</ref>. These adversarially trained models include adversarially trained Inception V3 (Adv-Inc-v3), adversarially trained Inception-ResNet V2 (Adv-IncRes-v2), advers g defense to date, where defenders proactively craft deceptive images for their model and augment the clean training data with such instances to train the model [9,</ref>22,</ref>20]</ref>. Moreover, exploiting the malicious examples tailored for diverse hold-out models can further strengthen defense and co
ach training example by the inverse of the predicted propensity.</p><p>While constructing the propensity model typically involves perturbing the search results to collect examples of counterfactuals, [1]</ref> describes methods to construct the propensity model without additional interventions.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Position
capacity, it took the average number of bookings for all listings within a small radius of the new listing with a capacity of two.</p><p>is is conceptually similar to the Naive Bayes recommender from [11]</ref> which used a generative method to estimate the missing information.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Test Results</head><p>In
licitly, like deep and wide [3]</ref>, where query-listing feature crosses were added to the wide part.</p><p>is was followed by variants of a ention based networks from [16]</ref>.</p><p>e intention there was to make the hidden layer derived from query features focus its a ention on certain parts of the hidden layer derived from listing
nt model becomes dependent on previous models as a result.</p><p>Ideally we would like the model to focus exclusively on P(rele ant = 1|l, u, q) and rank listings by relevance alone. To achieve that, [9]</ref> describes a method with two key concepts:</p><p>? A propensity model to predict P(examined = 1|k, u, q). ? Weighing each training example by the inverse of the
14]</ref>, we met nothing but neutral test results. Trying to decipher why increasing layers was not showing any gains led us to borrow more ideas from the literature, like applying residual learning [7]</ref> and batch normalization [8]</ref>. Still, NDCG refused to budge in o ine tests. Our takeaway from the exercise was that increasing
trying to make general statements about how price in uenced the DNN, we focused on interpreting one search result at a time. Borrowing the idea of individual conditional expectation (ICE) plots from [5]</ref>, we took listings from a single search result, swept across the price range while keeping all other features invariant, and constructed plots of the model score
y consists of a location, number of guests and checkin/checkout dates. Transitioning to deep learning was a major milestone in the evolution of search ranking at Airbnb. Our account of the journey in [6]</ref> brought us in conversation with many industry practitioners, allowing us to exchange insights and critiques. One question that frequently followed such conversa lead to a complete revision of our strategy on how to iterate on deep learning beyond the rst launch. In this paper we capture the major enhancements that followed the launch of the DNN described in [6]</ref>. In addition to delving into the core machine learning techniques themselves, we focus on the process and the reasoning that lead to the breakthroughs. With the r problem. Model tweaks come a erwards, and in response to the user problem.</p><p>Along those lines, we started with the observation that the series of successful ranking model launches described in [6]</ref> were not only associated with an increase in bookings, but also a reduction in the average listing price of search results. is indicated the model iterations we 0.9, the plot is shown in Figure 2</ref> over the typical range of P encountered during ranking.</p><p>When tested online as an A/B experiment against the two hidden layer DNN from [6]</ref>, average price of search results dropped by -5.7%, in con rmation with o ine analysis. But the interpretability of price came at a heavy cost as bookings droppe tures invariant, and constructed plots of the model score. An example plot is shown in Figure 4</ref>. e plots suggested that the fully connected two layer DNN from [6]</ref> already understood cheaper was be er. Repeating the ICE analysis on a collection of randomly selected searches from the logs further strengthened this conclusio imize for training speed.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Test Results</head><p>When tested online in an A/B experiment against the fully connected two layer DNN from [6]</ref>, the two tower architecture recorded a bookings gain of +0.6%. e gain was driven by increased ease of search, as the NDCG computed online improved by +0.7%. Alt
f the listing l. e in uence of the listing on the booking event is completely accounted for by P(rele ant = 1|l, u, q)</p><p>Using the simplifying assumptions of the position based model described in [4]</ref>, we represent the probability of the user booking a listing simply as a product of the two decomposed probabilities.</p><p>P bookin = P(rele ant = 1|l, u, q) * l (listing features), ? (DNN parameters), we express the output of the DNN as dnn ? (q, u, l) = rel ? (q, u, l) * pbias ? (q, u, l)</p><p>mirroring the assumption made by the position based model in [4]</ref>.</p><p>Here rel ? (q, u, l) estimates P(rele ance = 1|l, u, q) which we refer to as the relevance prediction. And pbias ? (q, u, l) estimates P(examination = 1|
na?ve interpretation a er reviewing the series of advances that ushered in the current deep learning era. But as we sought to replicate the bene ts of scaling data and adding layers as summarized in [14]</ref>, we met nothing but neutral test results. Trying to decipher why increasing layers was not showing any gains led us to borrow more ideas from the literature,
14]</ref>, we met nothing but neutral test results. Trying to decipher why increasing layers was not showing any gains led us to borrow more ideas from the literature, like applying residual learning [7]</ref> and batch normalization [8]</ref>. Still, NDCG refused to budge in o ine tests. Our takeaway from the exercise was that increasing
like. For analysis, we ran the two tower DNN on a random sample of searches and collected the output vector of the query tower. Since the 100-d vectors were not human interpretable, we applied t-SNE [17]</ref> to reduce them to 2-d vectors, which are shown in Figure 8</ref>. eries corresponding to some of the cities in Figure <ref
training and fine-tuning paradigm, exemplified by methods like ELMo (Peters et al., 2018)</ref>, GPT-2 (Radford et al., 2019)</ref>, BERT (Devlin et al., 2019)</ref>, XLNet (Yang et al., 2019)</ref> and RoBERTa (Liu et al., 2019)</ref>, has drastically reshape n-domain supervised data for target applications. Despite its conceptual simplicity, this paradigm has reestablished the new state-ofthe-art baselines across various tasks, such as question answering (Devlin et al., 2019)</ref>, coreference resolution (Joshi et al., 2019b)</ref>, relation extraction (Soares i et al., 2019a;</ref>b)</ref>. Ad-hoc handling of long sequences is also required in the pre-training stage, such as updating the model using only short sequences in the early stage (Devlin et al., 2019)</ref>.</p><p>Common strategies for reducing memory consumption, unfortunately, do not work. For instance, shrinking the model by lowering the number ENECK IN TRAINING BERT</head><p>We briefly review BERT and introduce its memory profiling in this section. Following the paradigm of language model pre-training and down-stream task fine-tuning, BERT (Devlin et al., 2019)</ref> consists of multiple layers of bidirectional Transformers (Vaswani et al., 2017)</ref>, where each Transformer encoder has a Transformers (Vaswani et al., 2017)</ref>, where each Transformer encoder has a multi-head self-attention layer and a position-wise feed-forward layer. Using the same notation as in (Devlin et al., 2019)</ref>, we denote the number of Transformer layers by L, the number of hidden units by H, the number of attention heads by A, the sequence length by ho, 2019)</ref>, to name a few.</p><p>Building such models in practice, however, is an extremely resource-intensive process. For instance, the training of BERT-family models is notoriously expensive. Devlin et al. (2019)</ref> report that it takes four days for pre-training BERT-Base/BERT-Large on 4/16 Cloud TPUs, respectively. In order to reduce the pre-training time onfiguration which assigns 8, 2, 2 heads to permutation (1, 2, 3), (2, 3, 1), and (3, 1, 2), resp. We compare BlockBERT with the following baselines:</p><p>Google BERT The pre-trained base model from Devlin et al. (2019)</ref>.</p><p>RoBERTa-2seq and RoBERTa-1seq We compare with two versions of RoBERTa (Liu et al., 2019)</ref>. RoBERTa-2 e half of the context. The detailed paragraph length distributions can be found in Figure 6</ref>.</p><p>For all the pre-trained models, we adopt the same fine-tuning QA setup from Devlin et al. (2019)</ref>.</p><p>The tokenized paragraph (p 1 , • • • , p s ) and question (q 1 , • • • , q t ) are concatenated to be a sequence</p><formula xml:id="for k. For instance, shrinking the model by lowering the number of layers L, attention heads A, or hidden units H leads to significant performance degradation (Vaswani et al., 2017;</ref>Devlin et al., 2019)</ref> and does not address the long sequence issue. Alternatively, general low-memory training techniques, such as microbatching <ref type="bibr" tar f>. Since the invention of Transformer (Vaswani et al., 2017;</ref>Dai et al., 2019)</ref> and its successful application on language model pre-training (Devlin et al., 2019;</ref>Radford et al., 2019;</ref>Yang et al., 2019;</ref>
oot_5">6</ref> -HotpotQA (Yang et al., 2018</ref>), NewsQA (Trischler et al., 2017)</ref>, SearchQA (Dunn et al., 2017)</ref>, TriviaQA (Joshi et al., 2017)</ref> and NaturalQA (Kwiatkowski et al., 2019)</ref> These QA datasets have different paragraph length distribution p
e more applications of BlockBERT on NLP tasks involving long sequences such as coreference resolution (Joshi et al., 2019b</ref>) and document-level machine translation (Miculicich et al., 2018)</ref>, and also non-NLP tasks such as protein sequence modeling (Rives et al., 2019)</ref>. </p><formula xml:id=

text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent emergence of the pre-training and fine-tuning paradigm, exemplified by methods like ELMo (Peters et al., 2018)</ref>, GPT-2 (Radford et al., 2019)</ref>, BERT (Devlin et al., 2019)</ref>, <ref type
text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent emergence of the pre-training and fine-tuning paradigm, exemplified by methods like ELMo (Peters et al., 2018)</ref>, GPT-2 (Radford et al., 2019)</ref>, BERT (Devlin et al., 2019)</ref>, <ref type
ype="bibr">), NewsQA (Trischler et al., 2017)</ref>, SearchQA (Dunn et al., 2017)</ref>, TriviaQA (Joshi et al., 2017)</ref> and NaturalQA (Kwiatkowski et al., 2019)</ref> These QA datasets have different paragraph length distribution patterns and are thus ideal for testing the effectiveness of BlockBERT. F
rget="#b14">(Joshi et al., 2019b</ref>) and document-level machine translation (Miculicich et al., 2018)</ref>, and also non-NLP tasks such as protein sequence modeling (Rives et al., 2019)</ref>. </p><formula xml:id="formula_11">B</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1<
ype="bibr">), NewsQA (Trischler et al., 2017)</ref>, SearchQA (Dunn et al., 2017)</ref>, TriviaQA (Joshi et al., 2017)</ref> and NaturalQA (Kwiatkowski et al., 2019)</ref> These QA datasets have different paragraph length distribution patterns and are thus ideal for testing the effectiveness of BlockBERT. F
rget="#b14">(Joshi et al., 2019b</ref>) and document-level machine translation (Miculicich et al., 2018)</ref>, and also non-NLP tasks such as protein sequence modeling (Rives et al., 2019)</ref>. </p><formula xml:id="formula_11">B</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1<
rget="#b14">(Joshi et al., 2019b</ref>) and document-level machine translation (Miculicich et al., 2018)</ref>, and also non-NLP tasks such as protein sequence modeling (Rives et al., 2019)</ref>. </p><formula xml:id="formula_11">B</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1<
2019)</ref>. It has been shown that relative position representations are more effective for natural language understanding and generation tasks (Dai et al., 2019;</ref>Shaw et al., 2018)</ref>. The proposed Disentangled Attention mechanism differs from all existing approaches in that we represent each input word using two separate vect matrices on their contents and positions as content-to-content, content-to-position, position-to-content, and position-to-position1</ref> .</p><p>Existing approaches (Shaw et al., 2018;</ref>Huang et al., 2018)</ref> to relative position encoding use a separate embedding matrix to compute the relative p r large-scale PLMs.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">EFFICIENT IMPLEMENTATION</head><p>For an input sequence of length N , it requires a space complexity of OpN 2 dq (Shaw et al., 2018;</ref>Huang et al., 2018;</ref>Dai et al., 2019)</ref> to store the relative position emb
al., 2017)</ref>, paraphrase detection (Dolan &amp; Brockett, 2005)</ref>, and natural language inference (NLI) (Dagan et al., 2006;</ref>Bar-Haim et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivogli et al., 2009;</ref><ref type="bibr" tar
al., 2017)</ref>, paraphrase detection (Dolan &amp; Brockett, 2005)</ref>, and natural language inference (NLI) (Dagan et al., 2006;</ref>Bar-Haim et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivogli et al., 2009;</ref><ref type="bibr" tar
it includes question answering (Rajpurkar et al., 2016)</ref>, linguistic acceptability (Warstadt et al., 2018)</ref>, sentiment analysis (Socher et al., 2013</ref>), text similarity (Cer et al., 2017)</ref>, paraphrase detection (Dolan &amp; Bro
ll><cell></cell></row></table></figure> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">In this sense, our model shares some similarity to Tensor Product Representation(Smolensky, 1990;</ref>Schlag et al.,</ref> </note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2019" xml:id="foot_1">;<r
in parallel every word from the input text an attention weight that gauges the influence each word has on another, thus allowing for much more parallelization than RNNs for large-scale model training (Vaswani et al., 2017)</ref>. Since 2018, we have seen the rise of a set of large-scale Transformer-based Pre-trained Language Models (PLMs), such as GPT <ref type="bibr ><head n="2">BACKGROUND</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TRANSFORMER STRUCTURE</head><p>A Transformer-based language model is composed of stacked Transformer blocks (Vaswani et al., 2017)</ref>. Each block contains a multi-head self-attention layer followed by a fully connected positional feed-forward network. The standard self-atte ition-to-position term does not provide much additional information and is removed from equation 2 in our implementation.</p><p>Taking single-head attention as an example, the standard self-attention (Vaswani et al., 2017)</ref> can be formulated as:</p><formula xml:id="formula_2">Q " HW q , K " HW k , V " HW v , A " QK ? d H o " softmaxpAqV</formula><p>where H P R N each input word embedding so that each input word is represented by a vector whose value depends on its content and position. The positional bias can be implemented using absolute position embedding (Vaswani et al., 2017;</ref>Radford et al., 2019;</ref>Devlin et al., 2019)</ref> or relative position embe calculated as K c j Q r δpj,iq . The content-to-position term is calculated in a similar way.</p><p>Finally, we apply a scaling factor of 1 ? 3d on Ã which is important for stabilizing model training Vaswani et al. (2017)</ref>, especially for large-scale PLMs.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">EFFICIENT IMPLEMENTATION</head><p>For an
model training (Vaswani et al., 2017)</ref>. Since 2018, we have seen the rise of a set of large-scale Transformer-based Pre-trained Language Models (PLMs), such as GPT (Radford et al., 2019;</ref>Brown et al., 2020)</ref>, BERT (Devlin et al., 2019)</ref>, RoBERTa <ref type=" .org/ns/1.0"><head>Model</head><p>CoLA We pre-train our large models following the setting of BERT (Devlin et al., 2019)</ref>, except that we use the BPE vocabulary as (Radford et al., 2019;</ref>Liu et al., 2019c)</ref>. For training data, we use Wikipedia (English Wikipedia dump<ref type="foot" target=" sented by a vector whose value depends on its content and position. The positional bias can be implemented using absolute position embedding (Vaswani et al., 2017;</ref>Radford et al., 2019;</ref>Devlin et al., 2019)</ref> or relative position embedding (Huang et al., 2018;</
model training (Vaswani et al., 2017)</ref>. Since 2018, we have seen the rise of a set of large-scale Transformer-based Pre-trained Language Models (PLMs), such as GPT (Radford et al., 2019;</ref>Brown et al., 2020)</ref>, BERT (Devlin et al., 2019)</ref>, RoBERTa <ref type=" .org/ns/1.0"><head>Model</head><p>CoLA We pre-train our large models following the setting of BERT (Devlin et al., 2019)</ref>, except that we use the BPE vocabulary as (Radford et al., 2019;</ref>Liu et al., 2019c)</ref>. For training data, we use Wikipedia (English Wikipedia dump<ref type="foot" target=" sented by a vector whose value depends on its content and position. The positional bias can be implemented using absolute position embedding (Vaswani et al., 2017;</ref>Radford et al., 2019;</ref>Devlin et al., 2019)</ref> or relative position embedding (Huang et al., 2018;</
et al., 2006;</ref>Bar-Haim et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivogli et al., 2009;</ref>Levesque et al., 2012;</ref>Williams et al., 2018)</ref>. The diversity of the tasks makes GLUE very suitable for evaluating the generaliz
2018;</ref>Yang et al., 2019)</ref>. It has been shown that relative position representations are more effective for natural language understanding and generation tasks (Dai et al., 2019;</ref>Shaw et al., 2018)</ref>. The proposed Disentangled Attention mechanism differs from all existing approaches in tha /head><p>For an input sequence of length N , it requires a space complexity of OpN 2 dq (Shaw et al., 2018;</ref>Huang et al., 2018;</ref>Dai et al., 2019)</ref> to store the relative position embedding for each token. However, taking content-to-position as an example, we note that since δpi, jq P r0, 2kq a nce on long sequence handling (Beltagy et al., 2020;</ref>Kitaev et al., 2020;</ref>Child et al., 2019;</ref>Dai et al., 2019)</ref>. One of the potential future works is to extend DeBERTa to deal with extremely long sequences and compare it with existing approaches.</p></div> <
">(Lai et al., 2017)</ref>, ReCoRD (Zhang et al., 2018)</ref> and SWAG (Zellers et al., 2018)</ref>; (2) Natural Language Inference: MNLI (Williams et al., 2018)</ref>; and (3) NER: CoNLL-2003. For comparison, we also include Megatron (Shoeybi et al., 2019)</ref> with three d et al., 2006;</ref>Giampiccolo et al., 2007;</ref>Bentivogli et al., 2009;</ref>Levesque et al., 2012;</ref>Williams et al., 2018)</ref>. The diversity of the tasks makes GLUE very suitable for evaluating the generalization and robustness of NLU models.</p><p>‚ ReCoRD is a com
ks (GNNs) [9,</ref>22]</ref>. While early work mostly deals with simple graphs with unlabeled edges, recently proposed relation-aware GNNs [38,</ref>39]</ref> consider multi-relational graphs with labels and directions on the edges. These multi-relational graphs expand the app ractical importance. Directed-GCN [25]</ref> and Weighted-GCN [39]</ref> consider direction and relation types, respectively. Also, R-GCN [38]</ref> considers direction and relation types simultaneously. Recently, Vashishth et al. [46]</ref> propose to jointly embed nodes and ComplEx. Semantic matching based embedding methods [57,</ref>45]</ref>. 5) R-GCN. This is a GNN-based method for modeling relational data [38]</ref>. 6) MEAN. 7) LAN. These are GNN models for a out-of-knowledge base task, which tackle unseen entities without meta-learning [17 36]</ref>. 2) MPNN. Graph Neural Networks that use edge-conditioned convolution [15]</ref>. 3) R-GCN. The same model used in the entity prediction on KG completion task [38]</ref>. 4) I-GEN. Inductive GEN, which only uses feature representation of an entity e k , instead of a relation-entity pair (r k , e k ). This is because the relati b44">[45]</ref>.</p><p>5) R-GCN. This is a GNN-based method for modeling relational data, which extends the graph convolutional network to consider multi-relational structure, by Schlichtkrull et al. [38]</ref>.</p><p>6) MEAN. This model computes the embedding of entities by GNN based neighboring aggregation scheme, where they only train for seen-to-seen link predict since we consider a highly multi-relational graph, we use the basis decomposition on weight matrices W r and W r to prevent the excessive increase in the model size, proposed in Schlichtkrull et al. [38]</ref>: W r = B b=1 a r b V b , where B is the number of basis, a r b is a coefficient of each relation r ∈ R and V b ∈ R d×2d is a shared representation of various >57,</ref>45]</ref> and deep neural network based methods [31,</ref>10,</ref>38,</ref>30]</ref>. While they require a large amount of training instances, many real-world graphs exhibit long-tail distribution. Few-sh gative triplets for each positive triplet. For both datasets, we consider the inverse relation as suggested by several recent works on multi-relational graphs [25,</ref>38,</ref>46]</ref>, where directed relation information flows along with both directions.</p><p>Drug-to-Drug Interaction For both I-GEN an lets and H@n is the ratio of the correct triplets ranked smaller than or equal to n. Moreover, as done in previous works [5,</ref>31,</ref>38]</ref>, we measure the ranks in a filtered setting where we do not consider triplets that appeared in either training, validation, or test sets.</p><p>Results Table <
ges. These multi-relational graphs expand the application of GNNs to more real-world domains such as social networks modeling [18]</ref>, natural language understanding [25]</ref>, modeling protein structure [13]</ref>, and drug-to-drug interaction prediction [60]</ref>.</p>< t="#b46">[47]</ref>, to name a few. While most of the existing models work with simple undirected graphs, some recent work tackles multi-relational graphs for their practical importance. Directed-GCN [25]</ref> and Weighted-GCN [39]</ref> consider direction and relation types, respectively. Also, R-GCN [38 th FB15k-237, except that we sample 64 negative triplets for each positive triplet. For both datasets, we consider the inverse relation as suggested by several recent works on multi-relational graphs [25,</ref>38,</ref>46]</ref>, where directed relation information flows along with both directions.</p><p>D
ref type="bibr" target="#b23">[24]</ref> propose end-to-end GNNs to tackle this problem, which demonstrate comparatively better performance over non-GNN methods [2,</ref>34,</ref>58]</ref>.</p><p>3 Few-Shot Out-Of-Graph Link Prediction</p><p>Our goal is to perform link prediction for emerging entities of a
-S 3-S 1-S 3-S 1-S 3-S 1-S 3-S 1-S 3-S 1-S 3-S 1-S 3-S Seen to Seen TransE [5]</ref> .   Evaluation Metrics For evaluation, we use the ranking procedure by Bordes et al. [4]</ref>. For a triplet with an unseen head entity, we replace its corresponding tail entity with candidate entities from the dictionary to construct corrupted triplets.
bibr" target="#b59">[60]</ref>.</p><p>Among multi-relational graphs, Knowledge Graphs (KGs), which represent knowledge bases (KBs) such as Freebase [3]</ref> and WordNet [27]</ref>, get the most attention. They represent entities as nodes and relations among the entities as edges, in the form of a triplet: (head entity, relation, tail en
n of tasks, is an essential approach for our few-shot OOG link prediction framework, where we simulate the unseen test nodes with a subset of training nodes. To mention a few, metric-based approaches [48,</ref>41]</ref> learn a shared metric space to minimize the distance between correct and instance embeddings. Also, gradient-based app
ore real-world domains such as social networks modeling [18]</ref>, natural language understanding [25]</ref>, modeling protein structure [13]</ref>, and drug-to-drug interaction prediction [60]</ref>.</p><p>Among multi-relational graphs, Knowledge Graphs (KGs), which represe
n of tasks, is an essential approach for our few-shot OOG link prediction framework, where we simulate the unseen test nodes with a subset of training nodes. To mention a few, metric-based approaches [48,</ref>41]</ref> learn a shared metric space to minimize the distance between correct and instance embeddings. Also, gradient-based app
tructured data which works on a non-Euclidean domain, several recent works propose graph-based neural architectures, referred to as Graph Neural Networks (GNNs) [9,</ref>22]</ref>. While early work mostly deals with simple graphs with unlabeled edges, recently proposed relation-aware GNNs [38,</ref><ref typ eatures from the neighboring nodes, that use recurrent neural networks [16,</ref>37]</ref>, mean pooling with layer-wise propagation rule [22]</ref>, learnable attention-weighted combination of the features [47]</ref>, to name a few. While most of the existing models work wit
iplets, achieving impressive performances [5,</ref>57,</ref>10,</ref>31,</ref>30]</ref>.</p><p>LAN [Wang et al. 19]</ref> Seen Unseen Ours  Despite this success, the link prediction for KGs in real-world scenarios remains to be ch >45]</ref> and deep neural network based methods [31,</ref>10,</ref>38,</ref>30]</ref>. While they require a large amount of training instances, many real-world graphs exhibit long-tail distribution. Few-shot relational learning methods tackle th
istance based [5,</ref>51]</ref>, semantic matching based [33,</ref>57,</ref>45]</ref> and deep neural network based methods [31,</ref>10,</ref>38,</ref>< onal graph [5,</ref>43]</ref>. 3) DistMult. 4) ComplEx. Semantic matching based embedding methods [57,</ref>45]</ref>. 5) R-GCN. This is a GNN-based method for modeling relational data [38]</ref>. 6) MEAN. 7) LAN. These are GNN models for a out-o ead><p>ComplEx. This model extends the DistMult by introducing embeddings on a complex space to consider asymmetric relations, where scores are differently measured based on the order of the entities [45]</ref>.</p><p>5) R-GCN. This is a GNN-based method for modeling relational data, which extends the graph convolutional network to consider multi-relational structure
embeddings have seen significant success in entity type and new fact predictions [Nickel et al., 2012</ref>, Trouillon et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref><ref type="bibr" tar ning over longer chains of facts. Specifically, we use Probabilistic Soft Logic (PSL) that can incorporate inference rules and ontologies, along with state-of-the-art KG embedding methods,viz., ConvE [Dettmers et al., 2018]</ref> and ComplEx [Trouillon et al., 2016]</ref>, which do not make use of any ontological rules.</p><p>The resulti SL-KGI, embedding-based methods can also be used to predict type labels of entities (the typeOf relation). We work with ComplEx [Trouillon et al., 2016]</ref> and ConvE [Dettmers et al., 2018]</ref> embeddings which have shown state of the art performance in many KG prediction tasks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><he y information-and also shows that state-of-the-art embeddings like ComplEx [Trouillon et al., 2016]</ref>, SimplE [Kazemi and Poole, 2018]</ref>, ConvE [Dettmers et al., 2018]</ref> cannot enforce subsumption. Taking a different approach [Jain et al., 2018]</ref> propose extending standard K :type entities at leaves of taxonomy (from YAGO simple types) and the first level of YAGO taxonomy. Then all facts upto length 3 in the hierarchy of taxonomy were included.</p><p>FB15K-237: FB15K-237 [Dettmers et al., 2018]</ref>, another popular benchmark does not have ontological and type label information. Therefore, we use the type labels for entities from <ref ty tal Evaluation</head><p>We evaluate the performance of TypeE-X models in the KG refinement task, and compare them with Com-plEx [Trouillon et al., 2016]</ref> and ConvE [Dettmers et al., 2018]</ref>, two state-of-the-art KG embeddings methods, 4. https://www.w3.org/2006/03/wn/wn20/ and PSL-KGI. We also use ComplEx and ConvE as base embed e original dataset does not have validation set, we split the test set into 2 equal halves preserving the same class balance, and use them as our validation and test split.</p><p>YAGO3-10: YAGO3-10 [ Dettmers et al., 2018]</ref> is a subset of the YAGO3 [Suchanek et al., 2007]</ref> knowledge graph. It is often used for evaluating the KG
https://github.com/linqs/psl-examples/tree/master/knowledge-graph-identification</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Class</head><p>Ontological Rule</p><p>Uncertain Extractions  [Blum and Mitchell, 1998]</ref>, to combine the strengths of PSL-KGI and KG embeddings. The mechanism consists of two stages, as shown in Figure <ref type="figure" target
predictions by the embeddings based methods are often due to the lack of type compatibility between the entities due to their typeagnostic nature [Xie et al., 2016</ref>, Jain et al., 2018]</ref>. Since PSL-KGI is able to predict entity types by making use of ontological information along with many candidate facts derived using its infer n improves the weighted F1-score of embeddings by up to 9% over those which do not have type supervision.</p><p>(ii) Explicit type supervised models also outperform the implict type supervised models [Jain et al., 2018]</ref>.</p><p>The margin of improvement is large when the ontological information is sufficiently rich to begin with.</p><p>(iii) Rich ontological info an overview). While these works have their own strengths and weaknesses, our focus in this paper is on the use of ontological rules (exemplified by PSL-KGI) and embeddings (we use ComplEx, ConvE and [Jain et al., 2018]</ref>). Rule induction methods are orthogonal to our work, and may augment or replace the set of rules we use. Further, evidence from diverse extracto et al., 2016]</ref>, SimplE [Kazemi and Poole, 2018]</ref>, ConvE [Dettmers et al., 2018]</ref> cannot enforce subsumption. Taking a different approach [Jain et al., 2018]</ref> propose extending standard KG embeddings without explicit type supervision by representing entities as a two-part vector with one part encoding on the size of the KG and the prediction accuracy in Section 6.4.  To incorporate the type inferences for entities generated by PSL-KGI in KG embeddings (the second stage), we modify the typed model [Jain et al., 2018]</ref> as follows:</p><p>Instead of just using the implicit type embeddings, we concatenate them with embeddings of explicit types transferred from PSL generated by our TypeE-X methods compared with ComplEx, ConvE and PSL-KGI. In addition, we also compare our explicitly supervised TypeE-X methods with the implicitly supervised embeddings proposed by [Jain et al., 2018]</ref>.</p><p>• In Section 6.3, we analyse how our accuracy changes as we increase the number of feedback iterations.</p><p>• In Section 6.4, we discus e="table" target="#tab_7">7</ref> we compare the performance of TypeE-ComplEx which has explicit type supervision with the unsupervised type-compatible embeddings-based method proposed by Jain et al. [Jain et al., 2018]</ref>. As these results indicate, while explicitly ensuring type compatibility helps to improve performance, adding type inferences from PSL-KGI to Ty compatibility helps to improve performance, adding type inferences from PSL-KGI to TypeE-ComplEx significantly improves the relation scores, improving weighted F1 up to 18% (over NELL).</p><p>Dataset [Jain et al., 2018]</ref>  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Analysis of feedback iterations</head><p>We have already shown in Table <ref he KG refinement task and methods for the same, from probabilistic rule based methods like PSL-KGI [Pujara et al., 2013]</ref> to KG embedding methods like type-ComplEx [Jain et al., 2018]</ref>. We showed their performance on existing datasets in the literature, and how the extent pf ontology plays a crucial role in performance of PSL-K Desc><table /></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Weighted F1 scores on relation triples in the test set by[Jain et al., 2018]</ref> and TypeE-ComplEx.Anecdotes. Looking at the example predictions by both TypeE-ComplEx and ComplEx on YAGO3-10, we observed that TypeE-ComplEx is
ion label as well as incorrect linkage altogether-between entities (e.g., matt flynn, athleteplayssport, baseball is false since Matt Flynn is an NFL player), incompatible entity types, and many more [Pujara et al., 2013]</ref>. It has also been observed that such noise can significantly degrade the performance of KG embeddings [Pujara as noise removal stages of the KG completion problem. They can also make use of ontological rules effectively, and specifically, the PSL-KGI implementation uses rules defined on schema-level features [Pujara et al., 2013]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Contributions</head><p>In this paper we investigate the combined use of ont range of relations (DOM, RNG); "same" entities (SAMEENT), entities and relations that are mutually exclusive (MUT and RMUT); and inverse relations (INV). We reproduce the list of information used in [Pujara et al., 2013]</ref> in tabular form in Table 1</ref>.</p><p>(iii) Inference rules -specifically, there are 7 general constraint inement settings, we further add extraction scores generated by sampling them from two different normal distributions: N (0.7, 0.2) for facts in the original KG and N (0.3, 0.2) for added noisy facts [Pujara et al., 2013]</ref>. The SAMEENT facts between entities are generated by calculating the average of the two Jaccard similarity score over sets of relationships w ng models for our TypeE-X method to get TypeE-ComplEx and TypeE-ConvE respectively. We use a single hyper-parameter threshold as the cutoff for classifying a test triple based on the prediction score [Pujara et al., 2013]</ref>. Our experiments were run on Intel(R) Xeon(R) x86-64 machine with 64 CPUs using 1 NVIDIA GTX 1080 Ti GPU. We observe the average running time ns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and Future work</head><p>We have looked at the KG refinement task and methods for the same, from probabilistic rule based methods like PSL-KGI [Pujara et al., 2013]</ref> to KG embedding methods like type-ComplEx [Jain et al., 2018]</ref>. We showed their performance on existing da with the help of various symbolic (logical)</p><p>rules. An important input to these formulations are the probabilistic sources of information such as the confidence scores obtained during extraction [Pujara et al., 2013</ref>, Jiang et al., 2012]</ref> from multiple sources. Of these methods, PSL-KGI [Puja e scores obtained during extraction [Pujara et al., 2013</ref>, Jiang et al., 2012]</ref> from multiple sources. Of these methods, PSL-KGI [Pujara et al., 2013</ref>[Pujara et al., , 2017] ]</ref> is shown not only to perform better with KG noise and sparsity, but also to be q part of the original benchmark test collection.   The NELL subset taken from its 165 th iteration [Carlson et al., 2010]</ref>) has been used for the KG refinement task [Pujara et al., 2013</ref>, Jiang et al., 2012]</ref>. It comes with a rich ontology from the NELL system, and contains multiple sources of
heim, 2017]</ref>. On the other hand, neural and tensor-based embeddings have seen significant success in entity type and new fact predictions [Nickel et al., 2012</ref>, Trouillon et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions <ref type="b t Logic (PSL) that can incorporate inference rules and ontologies, along with state-of-the-art KG embedding methods,viz., ConvE [Dettmers et al., 2018]</ref> and ComplEx [Trouillon et al., 2016]</ref>, which do not make use of any ontological rules.</p><p>The resulting framework called IterefinE is based on the observation that the mispr or more components of the triple. With this dataset containing both positive and negative samples, training can be done for the refinement task with a negative log-likelihood loss function as follows [Trouillon et al., 2016]</ref>.</p><formula xml:id="formula_0">L(G) = (s,r,o,y)∈G y log f (s, r, o) + (1 − y) log (1 − f (s, r, o))<label>(1)</label></formula><p>where ( triple is given positive label or negative. Similar to the setting for PSL-KGI, embedding-based methods can also be used to predict type labels of entities (the typeOf relation). We work with ComplEx [Trouillon et al., 2016]</ref> and ConvE [Dettmers et al., 2018]</ref> embeddings which have shown state of the art performance in many KG mplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty information-and also shows that state-of-the-art embeddings like ComplEx [Trouillon et al., 2016]</ref>, SimplE [Kazemi and Poole, 2018]</ref>, ConvE [Dettmers et al., 2018]</ref> cannot enforce p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Evaluation</head><p>We evaluate the performance of TypeE-X models in the KG refinement task, and compare them with Com-plEx [Trouillon et al., 2016]</ref> and ConvE [Dettmers et al., 2018]</ref>, two state-of-the-art KG embeddings methods, 4. https://www.w3.org/2 ay as to maximise the plausibility of the triples that are already present in the KG [Nickel et al., 2011</ref>, Socher et al., 2013</ref>, Trouillon et al., 2016]</ref>.</p><p>An important step in learning is the generation of negative samples since the existing triples are all labeled positive. The negat
rth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rules when available. Methods such as Probabilistic Soft Logic (PSL) and Markov Logic Network e type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty information-and also shows that state-of-the-art embeddings like ComplEx <ref ty
rth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rules when available. Methods such as Probabilistic Soft Logic (PSL) and Markov Logic Network e type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty information-and also shows that state-of-the-art embeddings like ComplEx <ref ty
An important input to these formulations are the probabilistic sources of information such as the confidence scores obtained during extraction [Pujara et al., 2013</ref>, Jiang et al., 2012]</ref> from multiple sources. Of these methods, PSL-KGI [Pujara et al., 2013</ref>[Puja LL subset taken from its 165 th iteration [Carlson et al., 2010]</ref>) has been used for the KG refinement task [Pujara et al., 2013</ref>, Jiang et al., 2012]</ref>. It comes with a rich ontology from the NELL system, and contains multiple sources of information i.e., a single fact is present with multiple pe="table" target="#tab_0">1</ref>.</p><p>(iii) Inference rules -specifically, there are 7 general constraints that were first introduced in the earlier work on Markov Logic Networks (MLN) based work [Jiang et al., 2012]</ref>. These rules are listed in Appendix A in Table 2</ref>. Based on these PSL-KGI defines a PSL program that com
n be used in conjunction with this approach to effectively embed Uncertain graphs. There has also been some research in using rule-based reasoning and KG embeddings together in an iterative manner in [Zhang et al., 2019]</ref>.</p><p>They achieve improvements in the performance of link prediction tasks for sparse entities which cannot be effectively modelled by stand
es s,r,o where r is the relation between entities s and o. A critical issue in large-scale KGs is the presence of noise from the automatic extraction methods used to populate them. For instance, NELL [Carlson et al., 2010]</ref> is known to contain various kinds of errors including: different names for the same entity (e.g., australia and austalia), incorrect relation ndomly partitioning the KG. Note that for all datasets the test set also includes the facts that were part of the original benchmark test collection.   The NELL subset taken from its 165 th iteration [Carlson et al., 2010]</ref>) has been used for the KG refinement task [Pujara et al., 2013</ref>, Jiang et a
rth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rules when available. Methods such as Probabilistic Soft Logic (PSL) and Markov Logic Network e type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty information-and also shows that state-of-the-art embeddings like ComplEx <ref ty
lar methods.</p><p>α -model: This baseline is a simple score combination of two different methods (in contrast to the two stages with iterations of our method). We use the setting introduced in R-GCN (Schlichtkrull et al. [2018]</ref>) to combine scores of KG embeddings and PSL-KGI methods using the equation given below:</p><formula xml:id="formula_6">f (h, r, t) α−m
led IterefinE is based on the observation that the mispredictions by the embeddings based methods are often due to the lack of type compatibility between the entities due to their typeagnostic nature [Xie et al., 2016</ref>, Jain et al., 2018]</ref>. Since PSL-KGI is able to predict entity types by making use of ontological information a v xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type and Taxonomy Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> 5K-237 [Dettmers et al., 2018]</ref>, another popular benchmark does not have ontological and type label information. Therefore, we use the type labels for entities from [Xie et al., 2016]</ref> which also provides the domain and range information for relations. The subclass information is populated by reconstructing the type hierarchy f
edding methods define a scoring function f to score the plausibility of a triple 1 and learn embeddings in such a way as to maximise the plausibility of the triples that are already present in the KG [Nickel et al., 2011</ref>, Socher et al., 2013</ref>, Trouillon et al., 2016]</ref>.</p><p>An important st

led IterefinE is based on the observation that the mispredictions by the embeddings based methods are often due to the lack of type compatibility between the entities due to their typeagnostic nature [Xie et al., 2016</ref>, Jain et al., 2018]</ref>. Since PSL-KGI is able to predict entity types by making use of ontological information a v xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type and Taxonomy Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> 5K-237 [Dettmers et al., 2018]</ref>, another popular benchmark does not have ontological and type label information. Therefore, we use the type labels for entities from [Xie et al., 2016]</ref> which also provides the domain and range information for relations. The subclass information is populated by reconstructing the type hierarchy f
lausibility of a triple 1 and learn embeddings in such a way as to maximise the plausibility of the triples that are already present in the KG [Nickel et al., 2011</ref>, Socher et al., 2013</ref>, Trouillon et al., 2016]</ref>.</p><p>An important step in learning is the generation of negative samples sinc
on), but also eliminating incorrect facts. Methods for noise reduction in KG include the use of association rule mining over the noisy KG to induce rules which can help in eliminating incorrect facts [Ma et al., 2014]</ref>; reconciling diverse evidence from multiple extractors [Dong et al., 2014]</ref>; the use of ontology reasoners <re finement is accomplished by methods based on inference rules and embeddings-based methods. There are other research directions for (partially) solving the KG refinement problem such as rule induction [Ma et al., 2014]</ref>, classification with diverse extractors [Dong et al., 2014]</ref>, crowdsourcing, etc., (see <ref type="bibr" targe
lausibility of a triple 1 and learn embeddings in such a way as to maximise the plausibility of the triples that are already present in the KG [Nickel et al., 2011</ref>, Socher et al., 2013</ref>, Trouillon et al., 2016]</ref>.</p><p>An important step in learning is the generation of negative samples sinc
rth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rules when available. Methods such as Probabilistic Soft Logic (PSL) and Markov Logic Network e type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty information-and also shows that state-of-the-art embeddings like ComplEx <ref ty
my Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty infor
ts [Ma et al., 2014]</ref>; reconciling diverse evidence from multiple extractors [Dong et al., 2014]</ref>; the use of ontology reasoners [Nakashole et al., 2011</ref>] and many more. A detailed survey of approaches for KG refinement is available in [Paulheim, 2017]</ref>. On
n be used in conjunction with this approach to effectively embed Uncertain graphs. There has also been some research in using rule-based reasoning and KG embeddings together in an iterative manner in [Zhang et al., 2019]</ref>.</p><p>They achieve improvements in the performance of link prediction tasks for sparse entities which cannot be effectively modelled by stand


n be used in conjunction with this approach to effectively embed Uncertain graphs. There has also been some research in using rule-based reasoning and KG embeddings together in an iterative manner in [Zhang et al., 2019]</ref>.</p><p>They achieve improvements in the performance of link prediction tasks for sparse entities which cannot be effectively modelled by stand

led IterefinE is based on the observation that the mispredictions by the embeddings based methods are often due to the lack of type compatibility between the entities due to their typeagnostic nature [Xie et al., 2016</ref>, Jain et al., 2018]</ref>. Since PSL-KGI is able to predict entity types by making use of ontological information a v xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type and Taxonomy Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> 5K-237 [Dettmers et al., 2018]</ref>, another popular benchmark does not have ontological and type label information. Therefore, we use the type labels for entities from [Xie et al., 2016]</ref> which also provides the domain and range information for relations. The subclass information is populated by reconstructing the type hierarchy f
my Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty infor
led IterefinE is based on the observation that the mispredictions by the embeddings based methods are often due to the lack of type compatibility between the entities due to their typeagnostic nature [Xie et al., 2016</ref>, Jain et al., 2018]</ref>. Since PSL-KGI is able to predict entity types by making use of ontological information a v xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type and Taxonomy Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> 5K-237 [Dettmers et al., 2018]</ref>, another popular benchmark does not have ontological and type label information. Therefore, we use the type labels for entities from [Xie et al., 2016]</ref> which also provides the domain and range information for relations. The subclass information is populated by reconstructing the type hierarchy f

compatible entity types, and many more [Pujara et al., 2013]</ref>. It has also been observed that such noise can significantly degrade the performance of KG embeddings [Pujara et al., 2017]</ref>.</p><p>The KG refinement task aims to reduce the noise in KG by not only predicting additional links (relations) and types for entities (i.e. random 25% of all facts (including the typeOf relations) and corrupt them by randomly changing their subject, relation label or object. Note that this was the same model followed in an earlier study [Pujara et al., 2017]</ref>.</p><p>• We further refine the noise model by ensuring that half of the corrupted facts have entities that are type compatible to the relatio et="#b18">[Pujara et al., 2013</ref>, Jiang et al., 2012]</ref> from multiple sources. Of these methods, PSL-KGI [Pujara et al., 2013</ref>[Pujara et al., , 2017] ]</ref> is shown not only to perform better with KG noise and sparsity, but also to be quite scalable. It uses the following sources of informati
lar methods.</p><p>α -model: This baseline is a simple score combination of two different methods (in contrast to the two stages with iterations of our method). We use the setting introduced in R-GCN (Schlichtkrull et al. [2018]</ref>) to combine scores of KG embeddings and PSL-KGI methods using the equation given below:</p><formula xml:id="formula_6">f (h, r, t) α−m
edding methods define a scoring function f to score the plausibility of a triple 1 and learn embeddings in such a way as to maximise the plausibility of the triples that are already present in the KG [Nickel et al., 2011</ref>, Socher et al., 2013</ref>, Trouillon et al., 2016]</ref>.</p><p>An important st
[Dong et al., 2014]</ref>; the use of ontology reasoners [Nakashole et al., 2011</ref>] and many more. A detailed survey of approaches for KG refinement is available in [Paulheim, 2017]</ref>. On the other hand, neural and tensor-based embeddings have seen significant success in entity type and new fact predictions <ref type="bibr" targ uch as rule induction [Ma et al., 2014]</ref>, classification with diverse extractors [Dong et al., 2014]</ref>, crowdsourcing, etc., (see [Paulheim, 2017]</ref> for an overview). While these works have their own strengths and weaknesses, our focus in this paper is on the use of ontological rules (exemplifi
rth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rules when available. Methods such as Probabilistic Soft Logic (PSL) and Markov Logic Network e type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty information-and also shows that state-of-the-art embeddings like ComplEx <ref ty
, 2012</ref>, Trouillon et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref
n et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rule
lar methods.</p><p>α -model: This baseline is a simple score combination of two different methods (in contrast to the two stages with iterations of our method). We use the setting introduced in R-GCN (Schlichtkrull et al. [2018]</ref>) to combine scores of KG embeddings and PSL-KGI methods using the equation given below:</p><formula xml:id="formula_6">f (h, r, t) α−m


led IterefinE is based on the observation that the mispredictions by the embeddings based methods are often due to the lack of type compatibility between the entities due to their typeagnostic nature [Xie et al., 2016</ref>, Jain et al., 2018]</ref>. Since PSL-KGI is able to predict entity types by making use of ontological information a v xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type and Taxonomy Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> 5K-237 [Dettmers et al., 2018]</ref>, another popular benchmark does not have ontological and type label information. Therefore, we use the type labels for entities from [Xie et al., 2016]</ref> which also provides the domain and range information for relations. The subclass information is populated by reconstructing the type hierarchy f
compatible entity types, and many more [Pujara et al., 2013]</ref>. It has also been observed that such noise can significantly degrade the performance of KG embeddings [Pujara et al., 2017]</ref>.</p><p>The KG refinement task aims to reduce the noise in KG by not only predicting additional links (relations) and types for entities (i.e. random 25% of all facts (including the typeOf relations) and corrupt them by randomly changing their subject, relation label or object. Note that this was the same model followed in an earlier study [Pujara et al., 2017]</ref>.</p><p>• We further refine the noise model by ensuring that half of the corrupted facts have entities that are type compatible to the relatio et="#b18">[Pujara et al., 2013</ref>, Jiang et al., 2012]</ref> from multiple sources. Of these methods, PSL-KGI [Pujara et al., 2013</ref>[Pujara et al., , 2017] ]</ref> is shown not only to perform better with KG noise and sparsity, but also to be quite scalable. It uses the following sources of informati
, 2012</ref>, Trouillon et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref
led IterefinE is based on the observation that the mispredictions by the embeddings based methods are often due to the lack of type compatibility between the entities due to their typeagnostic nature [Xie et al., 2016</ref>, Jain et al., 2018]</ref>. Since PSL-KGI is able to predict entity types by making use of ontological information a v xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Type and Taxonomy Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> 5K-237 [Dettmers et al., 2018]</ref>, another popular benchmark does not have ontological and type label information. Therefore, we use the type labels for entities from [Xie et al., 2016]</ref> which also provides the domain and range information for relations. The subclass information is populated by reconstructing the type hierarchy f
, 2012</ref>, Trouillon et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref
rth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rules when available. Methods such as Probabilistic Soft Logic (PSL) and Markov Logic Network e type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty information-and also shows that state-of-the-art embeddings like ComplEx <ref ty
my Enhanced Embeddings</head><p>There are some recent efforts to incorporate type hierarchy information in KG embeddings -e.g., TKRL [Xie et al., 2016]</ref> and TransC [Lv et al., 2018]</ref>. Recently, SimplE + [Fatemi et al., 2019]</ref> includes taxonomic information -i.e., subtype and subproperty infor
n be used in conjunction with this approach to effectively embed Uncertain graphs. There has also been some research in using rule-based reasoning and KG embeddings together in an iterative manner in [Zhang et al., 2019]</ref>.</p><p>They achieve improvements in the performance of link prediction tasks for sparse entities which cannot be effectively modelled by stand
lausibility of a triple 1 and learn embeddings in such a way as to maximise the plausibility of the triples that are already present in the KG [Nickel et al., 2011</ref>, Socher et al., 2013</ref>, Trouillon et al., 2016]</ref>.</p><p>An important step in learning is the generation of negative samples sinc
n et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref>, do not make use of rich taxonomic/ontological rule
n be used in conjunction with this approach to effectively embed Uncertain graphs. There has also been some research in using rule-based reasoning and KG embeddings together in an iterative manner in [Zhang et al., 2019]</ref>.</p><p>They achieve improvements in the performance of link prediction tasks for sparse entities which cannot be effectively modelled by stand
, 2012</ref>, Trouillon et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref
, 2012</ref>, Trouillon et al., 2016</ref>, Dettmers et al., 2018]</ref>. It is worth noting that embeddings, with a few recent exceptions [Guo et al., 2016</ref>, Minervini et al., 2017</ref>, 2018</ref>, Fatemi et al., 2019]</ref
on), but also eliminating incorrect facts. Methods for noise reduction in KG include the use of association rule mining over the noisy KG to induce rules which can help in eliminating incorrect facts [Ma et al., 2014]</ref>; reconciling diverse evidence from multiple extractors [Dong et al., 2014]</ref>; the use of ontology reasoners <re finement is accomplished by methods based on inference rules and embeddings-based methods. There are other research directions for (partially) solving the KG refinement problem such as rule induction [Ma et al., 2014]</ref>, classification with diverse extractors [Dong et al., 2014]</ref>, crowdsourcing, etc., (see <ref type="bibr" targe
e by fixing the remaining mispredictions. The core architecture could be tuned to be wider if it had the support of better branch prediction, which could potentially offer more IPC gains. Prior works [13]</ref>, [14]</ref> have tried to address different types of hardto-predict branches. A vital observation of these works is that most b at a considerable proportion of hard-to-predict data-dependent branches are dependent on the loads whose address is very predictable. Moreover, we do not make any modifications to the ISA. Gao et al. [13]</ref> proposed a closely related work. They correlate the branch outcome to the load address and provide a prediction based on the confidence of the correlation. Ne
6 benchmarks is good enough to capture the energy dissipation behavior of GAP benchmarks with a good level of accuracy.</p><p>Energy Per Access (EPA) for IMLI and LDBP were calculated using CACTI 6.0 [23]</ref>. For IMLI, we model an ideal structure with a single port. LDBP has 55% lesser EPA than IMLI even if we assume all the tables are accessed when not in low pow
ictor [24]</ref>. The ensuing works on branch prediction gradually raised the bar for the prediction accuracy. Yeh and Patt came up with the two-level branch predictors [25]</ref>. McFarling [26]</ref> proposed optimizations over their work. These works leverage the high correlation between the outcome of
above would reflect the prediction accuracy of the latest Zen 2 CPU [10]</ref> using a 256-Kbit TAGE-based predictor. For this work, we use the 256-Kbit TAGE-GSC + IMLI [11]</ref>, which combines the global history components of the TAGE-SC-L with a loop predictor and local history as our baseline system.</p><p>Recent work <ref type="bi tion of branches having an irregular periodicity or when a branch outcome history is too long or too random to capture.</p><p>Statistical correlator [28]</ref> and IMLI [11]</ref> components are augmented to TAGE to mitigate some of the mispredictions. Several studies and extensive workload analysis have identified different types of ha
ictor [24]</ref>. The ensuing works on branch prediction gradually raised the bar for the prediction accuracy. Yeh and Patt came up with the two-level branch predictors [25]</ref>. McFarling [26]</ref> proposed optimizations over their work. These works leverage the high correlation between the outcome of
s a deeper instruction window in the pipeline and supports multiple outstanding memory operations.</p><p>Current branch prediction championships and CPU designs use either perceptron-based predictors [1]</ref> [2] [3] [4]</ref> or TAGEbased predictors [5]</ref>  [6]</ref>. These
contribute to a high percentage of mispredictions with TAGEbases predictors. It is impossible to capture the history of such branches competently, even with an unusually large predictor. Prior works [32]</ref>, [33]</ref> show that using data values as an input to the branch predictor improves the misprediction rate. Farooq et al. <ref
tion.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RELATED WORK</head><p>The strides in branch prediction accuracy have improved several folds since the counter-based bimodal predictor [24]</ref>. The ensuing works on branch prediction gradually raised the bar for the prediction accuracy. Yeh and Patt came up with the two-level branch predictors <ref t
contribute to a high percentage of mispredictions with TAGEbases predictors. It is impossible to capture the history of such branches competently, even with an unusually large predictor. Prior works [32]</ref>, [33]</ref> show that using data values as an input to the branch predictor improves the misprediction rate. Farooq et al. <ref
above would reflect the prediction accuracy of the latest Zen 2 CPU [10]</ref> using a 256-Kbit TAGE-based predictor. For this work, we use the 256-Kbit TAGE-GSC + IMLI [11]</ref>, which combines the global history components of the TAGE-SC-L with a loop predictor and local history as our baseline system.</p><p>Recent work <ref type="bi tion of branches having an irregular periodicity or when a branch outcome history is too long or too random to capture.</p><p>Statistical correlator [28]</ref> and IMLI [11]</ref> components are augmented to TAGE to mitigate some of the mispredictions. Several studies and extensive workload analysis have identified different types of ha
d to TAGE to mitigate some of the mispredictions. Several studies and extensive workload analysis have identified different types of hard-to-predict branches and ways to resolve them. Sherwood et al. [29]</ref> and Morris et al. [30]</ref> proposed prediction mechanisms to tackle loop-termination branches. The Wormhole predictor <ref ty
" target="#b37">[38]</ref> brings the feature-map attention across two network branches. Inspired by the previous methods, our Fig. 1</ref>: Comparing our ResNeSt block with SE-Net [30]</ref> and SK-Net [38]</ref>. A detailed view of Split-Attention unit is shown in Figure 2</ref>. F is G = KR. We may apply a series of transformations {F 1 , F 2 , ...F G } to each individual group, then the intermediate representation of each group is Split Attention in Cardinal Groups. Following [30,</ref>38]</ref>, a combined representation for each cardinal group can be obtained by fusing via an element-wise summation across mult rmation. Recent ResNet implementations usually apply the strided convolution at the 3 × 3 layer instead of the 1 × 1 layer to better preserve such information [26,</ref>30]</ref>. Convolutional layers require handling featuremap boundaries with zero-padding strategies, which is often suboptimal when transferring to other dense predictio
ure-map Attention. Multi-path representation has shown success in GoogleNet [52]</ref>, in which each network block consists of different convolutional kernels. ResNeXt [61]</ref> adopts group convolution [34]</ref> in the ResNet bottle block, which converts the multi-path structure into a unified operatio t, consisting feature-map group and split attention operations. Figure 1</ref> (Right) depicts an overview of a Split-Attention Block.</p><p>Feature-map Group. As in ResNeXt blocks [61]</ref>, the feature can be divided into several groups, and the number of feature-map groups is given by a cardinality hyperparameter K. We refer to the resulting fe
ti-path structure into a unified operation. SE-Net [29]</ref> introduces a channel-attention mechanism by adaptively recalibrating the channel feature responses. SK-Net [38]</ref> brings the feature-map attention across two network branches. Inspired by the previous methods, our Fig. 1</ref>: Comparing our ResNeSt blo ention across two network branches. Inspired by the previous methods, our Fig. 1</ref>: Comparing our ResNeSt block with SE-Net [30]</ref> and SK-Net [38]</ref>. A detailed view of Split-Attention unit is shown in Figure 2</ref>. For simplicity, we show ResNeSt block in cardinality-m t-Attention block is applying a squeeze-and-attention operation to each cardinal group, while the SE-Net operates on top of the entire block regardless of multiple groups. Previous models like SK-Net [38]</ref> introduced feature attention between two network branches, but their operation is not optimized for training efficiency and scaling to large neural networks. type="bibr" target="#b22">[23]</ref>, ResNeXt [60]</ref>, SENet [29]</ref>, ResNet-D [26]</ref> and SKNet [38]</ref>. Remarkably, our ResNeSt-50 achieves 80.64 top-1 accuracy, which is the first 50-layer ResNet variant that surpasses 80% on ImageNet.</p><p>Other CNN Models. formations {F 1 , F 2 , ...F G } to each individual group, then the intermediate representation of each group is Split Attention in Cardinal Groups. Following [30,</ref>38]</ref>, a combined representation for each cardinal group can be obtained by fusing via an element-wise summation across multiple splits. The representation for k-th p sizes. Global contextual information with embedded channel-wise statistics can be gathered with global average pooling across spatial dimensions s k ∈ R C/K [29,</ref>38]</ref>. Here the c-th component is calculated as:</p><formula xml:id="formula_0">U i = F i (X), for i ∈ {1, 2, ...G}.</formula><formula xml:id="formula_1">dinal group but their operation is not optimized for training efficiency and scaling to large neural networks. Our method generalizes prior work on feature-map attention [29,</ref>38]</ref> within a cardinal group setting [60]</ref>, and its implementation remains computationally efficient. Figure 
entation also predicts object masks, for which a more accurate dense image representation is desirable.</p><p>We evaluate the Mask-RCNN [22]</ref> and Cascade-Mask-RCNN [2]</ref> models with ResNeSt-50 and ResNeSt-101 as their backbones. All models are trained along with FPN [41]</ref> and synchronized batc
ecomes essential to preserve spatial information. Recent ResNet implementations usually apply the strided convolution at the 3 × 3 layer instead of the 1 × 1 layer to better preserve such information [26,</ref>30]</ref>. Convolutional layers require handling featuremap boundaries with zero-padding strategies, which is often suboptimal w r" target="#b18">[19,</ref>37]</ref>, we train our models using 8 servers (64 GPUs in total) in parallel. Our learning rates are adjusted according to a cosine schedule [26,</ref>31]</ref>. We follow the common practice using linearly scaling-up the initial learning rate based on the minibatch size. The in c = −z c + log( K j=1 exp(z j )). During the final phase of training, the logits z j tend to be very small for j = c, while z c is being pushed to its optimal value ∞, and this can induce overfitting [26,</ref>53]</ref>. Rather than assigning hard labels as targets, label smoothing uses a smoothed ground truth probability:</p><formula x spatial resolution is downsampled), we use an average pooling layer with a kernel size of 3 × 3 .</p><p>Tweaks from ResNet-D. We also adopt two simple yet effective ResNet modifications introduced by [26]</ref>: (1) The first 7 × 7 convolutional layer is replaced with three consecutive 3 × 3 convolutional layers, which have the same receptive field size with a simila ibr" target="#b25">26]</ref>. We do not subject any of the other network parameters to weight decay, including bias units, γ and β in the batch normalization layers.</p><p>#P GFLOPs acc(%) ResNetD-50 [26]</ref>  For example 2s2x40d denotes radix=2, cardinality=2 and width=40. Note that even radix=1 does not degrade any existing approach (see Equation <ref type="formu he lighting. Finally, the image data are RGB-normalized via mean/standard-deviation rescaling. For mixup training, we simply mix each sample from the current mini-batch with its reversed order sample [26]</ref>. Batch Normalization [32]</ref> is used after each convolutional layer before ReLU activation [4 t="#b20">[21]</ref> with MXNet [9]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation Study</head><p>ResNeSt is based on the ResNet-D model [26]</ref>  ResNeSt-fast setting, the effective average downsampling is applied prior to the 3 × 3 convolution to avoid introducing extra computational costs in the mode are shown in Table 2</ref>, where s denotes the radix, x the cardinality, and d the network width (0s represents the use of a standard residual block as in ResNet-D [26]</ref>). We empirically find that increasing the radix from 0 to 4 continuously improves the top-1 accuracy, while also increasing latency and memory usage. Although network parameters and FLOPS, including: ResNet [23]</ref>, ResNeXt [60]</ref>, SENet [29]</ref>, ResNet-D [26]</ref> and SKNet [38]</ref>. Remarkably, our ResNeSt-50 achieves 80.64 top-1 accuracy, which is the first 50-layer ResNet variant that lize training. Prior work on large mini-batch training suggests weight decay should only be applied to the weights of convolutional and fully connected layers [19,</ref>26]</ref>. We do not subject any of the other network parameters to weight decay, including bias units, γ and β in the batch normalization layers.</p><p>#P GFLOPs acc(%) Size. Image classification research typically compares the performance of different networks operating on images that share the same crop size. ResNet variants[23,</ref>26,</ref>29,</ref>60]</ref> usually use a fixed training crop size of 224, while the Inception-Net family<r
type="bibr" target="#b13">[14,</ref>58]</ref>. Recent work has significantly boosted image classification accuracy through large scale neural architecture search (NAS) [45,</ref>55]</ref>. Despite their state-of-the-art performance, these NAS-derived models are usually not optimized for training efficienc y tailored to a particular task. Recent neural architecture search algorithms have adaptively produced CNN architectures that achieved state-of-the-art classification performance, such as: Amoe-baNet [45]</ref>, MNASNet [54]</ref>, and EfficientNet [55]</ref>. Despite their great success in image classific
n/standard-deviation rescaling. For mixup training, we simply mix each sample from the current mini-batch with its reversed order sample [26]</ref>. Batch Normalization [32]</ref> is used after each convolutional layer before ReLU activation [44]</ref>. Network weights are initialized using Kaiming Initial

Top-1 accuracy on ImageNet using ResNeSt. (Right-Bottom) Transfer learning results: object detection mAP on MS-COCO [42]</ref> and semantic segmentation mIoU on ADE20K [71]</ref>.</p><p>not even trainable on a GPU with an appropriate per-device batch-size2</ref>  [55]</re
</div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Modern CNN Architectures. Since AlexNet [34]</ref>, deep convolutional neural networks [35]</ref> have dominated image classification. With this trend, research has shifted from engineering handcrafted features to engineering network architectures. NIN <re
mputer vision task requires "network surgery" to modify the ResNet to be more effective for that particular task. For example, some methods add a pyramid module [8,</ref>69]</ref> or introduce long-range connections [56]</ref> or use cross-channel feature-map attention [15,</r ta structure, which can be directly applied on many existing downstream models [22,</ref>41,</ref>46,</ref>69]</ref>. Our approach can also augment the search spaces for neural architecture search and potentially improve the overall performance, which can be studied in the fu iction logits are upsampled 8 times to calculate the per-pixel cross entropy loss against the ground truth labels. We use multi-scale evaluation with flipping [65,</ref>69,</ref>73]</ref>.</p><p>We first consider the Cityscapes [10]</ref> dataset, which consists of 5K highqual
nected layer to the networks with more than 200 layers. We also apply DropBlock layers to the convolutional layers at the last two stages of the network. As a structured variant of dropout, DropBlock [18]</ref> randomly masks out local block regions, and is more effective than dropout for specifically regularizing convolutional layers. Finally, we also apply weight d
signed for other applications, such as object detection [22,</ref>46]</ref>, semantic segmentation [6,</ref>43,</ref>73]</ref> and pose estimation [14,</ref>58]</ref>. Recent work has
cial code implementation (details in Section 5)</ref>. (Right-Top) Top-1 accuracy on ImageNet using ResNeSt. (Right-Bottom) Transfer learning results: object detection mAP on MS-COCO [42]</ref> and semantic segmentation mIoU on ADE20K [71]</ref>.</p><p>not even trainable on a GPU with an appropriate per-device batch-siz via neural architecture search.</p><p>6 Transfer Learning Results</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Object Detection</head><p>We report our detection result on MS-COCO [42]</ref>  2017 validation set with 5k images (aka. minival) using the standard COCO AP metric of single scale. We train all models with FPN <ref type="bibr" target="#b
by more than 1% mIoU. Additional results can be found in Sections 5 and 6.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Modern CNN Architectures. Since AlexNet [34]</ref>, deep convolutional neural networks [35]</ref> have dominated image classification. With this trend, research has shifted from oogleNet [52]</ref>, in which each network block consists of different convolutional kernels. ResNeXt [61]</ref> adopts group convolution [34]</ref> in the ResNet bottle block, which converts the multi-path structure into a unified operation. SE-Net [29]</ref> introduces a ch
multi-scale evaluation with flipping [65,</ref>69,</ref>73]</ref>.</p><p>We first consider the Cityscapes [10]</ref> dataset, which consists of 5K highquality labeled images. We train each model on 2,975 images from the training set and report its mIoU on 500 validation image
</div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Modern CNN Architectures. Since AlexNet [34]</ref>, deep convolutional neural networks [35]</ref> have dominated image classification. With this trend, research has shifted from engineering handcrafted features to engineering network architectures. NIN <re
n of each block, as has been suggested for large batch training [19]</ref>.</p><p>Label Smoothing Label smoothing was first used to improve the training of Inception-V2 [53]</ref>. Recall the cross entropy loss incurred by our network's predicted class probabilities q is computed against ground-truth p as:</p><formula xml:id="formula_5" 60]</ref> usually use a fixed training crop size of 224, while the Inception-Net family[51]</ref>[52]</ref>[53]</ref> uses a training crop size of 299. Recently, the EfficientNet method[55]</ref> has demonstrated that increasing the input image the final phase of training, the logits z j tend to be very small for j = c, while z c is being pushed to its optimal value ∞, and this can induce overfitting [26,</ref>53]</ref>. Rather than assigning hard labels as targets, label smoothing uses a smoothed ground truth probability:</p><formula xml:id="formula_7">p i = 1 − ε if i = c, ε

search. Networks trained for image classification often serve as the backbone of the neural networks designed for other applications, such as object detection [22,</ref>46]</ref>, semantic segmentation [6,</ref>43,</ref>73]</ref> and pose estimat . Instead, our model preserves ResNet meta structure, which can be directly applied on many existing downstream models [22,</ref>41,</ref>46,</ref>69]</ref>. Our approach can also augment the search spaces for neural architecture search and potentially improve the overall per

h with its reversed order sample [26]</ref>. Batch Normalization [32]</ref> is used after each convolutional layer before ReLU activation [44]</ref>. Network weights are initialized using Kaiming Initialization [24]</ref>. A drop layer is inserted before the final classificat
Top-1 accuracy on ImageNet using ResNeSt. (Right-Bottom) Transfer learning results: object detection mAP on MS-COCO [42]</ref> and semantic segmentation mIoU on ADE20K [71]</ref>.</p><p>not even trainable on a GPU with an appropriate per-device batch-size2</ref>  [55]</re
by more than 1% mIoU. Additional results can be found in Sections 5 and 6.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Modern CNN Architectures. Since AlexNet [34]</ref>, deep convolutional neural networks [35]</ref> have dominated image classification. With this trend, research has shifted from oogleNet [52]</ref>, in which each network block consists of different convolutional kernels. ResNeXt [61]</ref> adopts group convolution [34]</ref> in the ResNet bottle block, which converts the multi-path structure into a unified operation. SE-Net [29]</ref> introduces a ch

entation also predicts object masks, for which a more accurate dense image representation is desirable.</p><p>We evaluate the Mask-RCNN [22]</ref> and Cascade-Mask-RCNN [2]</ref> models with ResNeSt-50 and ResNeSt-101 as their backbones. All models are trained along with FPN [41]</ref> and synchronized batc
f type="bibr" target="#b56">[57]</ref>. For comparison, we simply replaced the vanilla ResNet backbones with our ResNeSt, while using the default settings for the hyper-parameters and detection heads [20,</ref>57]</ref>. Compared to the baselines using standard ResNet, Our backbone is able to boost mean average precision by around 3% on

f type="bibr" target="#b68">69]</ref> or introduce long-range connections [56]</ref> or use cross-channel feature-map attention [15,</ref>65]</ref>. While these approaches do improve the transfer learning performance for certain tasks, they raise the question: Can we create a versatile backbone with univer across multiple tasks at the same time? Cross-channel information has demonstrated success in downstream applications [56,</ref>64,</ref>65]</ref>, while recent image classification networks have focused more on group or depth-wise convolution [27,</ref><ref type="bibr" targ alidation set with 5k images (aka. minival) using the standard COCO AP metric of single scale. We train all models with FPN [41]</ref>, synchronized batch normalization [65]</ref> and image scale augmentation (short size of a image is picked randomly from 640 to 800). 1x learning rate schedule is used. We conduct Faster-RCNNs and Cascad ed network strategy [6,</ref>62]</ref> is applied to the backbone network, resulting in a stride-8 model. Synchronized Batch Normalization [65]</ref> is used during training, along with a polynomial-like learning rate schedule (with initial learning rate = 0.1). For evaluation, the network prediction logits = 0.1). For evaluation, the network prediction logits are upsampled 8 times to calculate the per-pixel cross entropy loss against the ground truth labels. We use multi-scale evaluation with flipping [65,</ref>69,</ref>73]</ref>.</p><p>We first consider the Cityscapes [10]</re
signed for other applications, such as object detection [22,</ref>46]</ref>, semantic segmentation [6,</ref>43,</ref>73]</ref> and pose estimation [14,</ref>58]</ref>. Recent work has


/ref>. To prevent this, dropout regularization randomly masks out some neurons during training (but not during inference) to form an implicit network ensemble [29,</ref>49,</ref>68]</ref>. A dropout layer with the dropout probability of 0.2 is applied before the final fully-connected layer to the networks

M (Long Short Term Memory) and GRU (Gated Recurrent Unit) networks practically only retain information from a limited number of time steps stored inside their hidden state (vanishing gradient problem (Hochreiter, 1998;</ref>Pascanu et al., 2013)</ref>), and thus the context used for representing each sequence element is inevitably local
lished: in fact, non-deep learning methods such as TS-CHIEF (Shifaz et al., 2020)</ref>, HIVE-COTE (Lines et al., 2018)</ref>, and ROCKET (Dempster et al., 2020</ref>) currently hold the record on time series regression and classification dataset benchmarks (Tan et al., 2020a;</ref><ref typ ries: Currently, non-deep learning methods such as TS-CHIEF (Shifaz et al., 2020)</ref>, HIVE-COTE (Lines et al., 2018)</ref>, and ROCKET (Dempster et al., 2020)</ref> constitute the state of the art for time series regression and classification based on evaluations on public benchmarks (Ta ROCKET and XGBoost. These have been shown to be orders of magnitude faster than methods such as TS-CHIEF, Proximity Forest, Elastic Ensembles, DTW and HIVE-COTE, but also deep learning based methods (Dempster et al., 2020)</ref>. As can be seen in Table 5</ref> in the Appendix, although XGBoost and ROCKET are on average must faster than the transfor
M (Long Short Term Memory) and GRU (Gated Recurrent Unit) networks practically only retain information from a limited number of time steps stored inside their hidden state (vanishing gradient problem (Hochreiter, 1998;</ref>Pascanu et al., 2013)</ref>), and thus the context used for representing each sequence element is inevitably local
ions between proximal segments and penalizes similarity between distal segments of the time series) for unsupervised representation learning of non-speech audio data. This idea is explored further by Franceschi et al. (2019)</ref>, who combine the triplet loss with a deep causal CNN with dilation, in order to make the method effective for very long time series. Altho length of time series samples, as well as the number of classes (see Appendix Table 4</ref>). As this archive is new, there have not been many reported model evaluations; we follow Franceschi et al. (2019)</ref> and use as a baseline the best performing method studied by the creators of the archive, DTW D (dimension-Dependent DTW), together with th seen that our models performed best on 7 out of the 11 datasets, achieving an average rank of 1.7, followed by ROCKET, which performed best on 3 datasets and on average ranked 2.3th. The dilation-CNN (Franceschi et al., 2019)</ref> and XGBoost, which performed best on the remaining 1 dataset, tied and on average ranked 3.7th and 3.8th respectively. Interestingly, we

s of time series regression and classification. Transformers are an important, recently developed class of deep learning models, which were first proposed for the task of natural language translation (Vaswani et al., 2017)</ref> but have since come to monopolize the state-of-the-art performance across virtually all NLP tasks (Raffel et HODOLOGY</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">BASE MODEL</head><p>At the core of our method lies a transformer encoder, as described in the original transformer work by Vaswani et al. (2017)</ref>; however, we do not use the decoder part of the architecture. A schematic diagram of the generic part of our model, common across all conside a xml:id="formula_3">W pos ? R w?d to the input vectors U ? R w?d = [u 1 , . . . , u w ]: U = U + W pos .</formula><p>Instead of deterministic, sinusoidal encodings, which were originally proposed by Vaswani et al. (2017)</ref>, we use fully learnable positional encodings, as we observed that they perform better for all datasets presented in this work. Interestingly, e layer normalization after computing self-attention and after the feedforward part of each encoder block, leading to significant performance gains over batch normalization, as originally proposed by Vaswani et al. (2017)</ref>. However, here we instead use batch normalization, because it can mitigate the effect of outlier values in time series, an issue that does no
NLP), the dominance of deep learning for time series is far from established: in fact, non-deep learning methods such as TS-CHIEF (Shifaz et al., 2020)</ref>, HIVE-COTE (Lines et al., 2018)</ref>, and ROCKET (Dempster et al., 2020</ref>) currently hold the record on time series regression and classification d n="2">RELATED WORK</head><p>Regression and classification of time series: Currently, non-deep learning methods such as TS-CHIEF (Shifaz et al., 2020)</ref>, HIVE-COTE (Lines et al., 2018)</ref>, and ROCKET (Dempster et al., 2020)</ref> constitute the state of the art for time series regression and classif
ries by directing learned representations to approximate a distance such as Dynamic Time Warping (DTW) between time series through a matrix factorization algorithm. A distinct approach is followed by Zhang et al. (2019)</ref>, who use a composite convolutional -LSTM network with attention and a loss which aims at reconstructing correlation matrices between the variab

of shifting sample topology with time. As an example of the lat-ter, Malhotra et al. (2017)</ref> presented a multi-layered RNN sequence-to-sequence autoencoder, while Lyu et al. (2018)</ref> developed a multi-layered LSTM with an attention mechanism and evaluated both an input reconstruction (autoencoding) as well as a forecasting los
ero values are represented by zeros, while the activation one is due to both low bitwdith and ReLU functions. To exploit the sparsity of DNNs to improve energy efficiency, many architectures, such as [25]</ref>, are proposed to detect and skip the multiplications associated with zeros. To locate the irregular appearance of zero elements in the matrices, an additional
fore, it is desired to investigate new communicationaware schemes for PIM architectures and chips. A systemlevel in-memory computing prototype, capable of speech recognition, was recently reported in [17]</ref>. It utilized multiple PIM macros. The precision issue was avoided through binary quantization on the network, while the communication issue was circumvented b y. Previous analogcomputing based PIM architectures are not effective in performing complicated dataflow optimization to reduce unnecessary data movement. Only output-stationary designs were reported [17]</ref>. Because analog signals' replication, storage, and accumulation all require power and area hungry amplifiers.</p><p>To take advantage of these tensorization t
rmation: DOI</ref>   TNAM [31]</ref> Twin-8T [32]</ref> Sandwich-RAM [8]</ref> Wang et al. [33]</ref> Thinker [14]</ref> iFPNA [28]</ref> This Work  power consuming part is the clock tree. The clock
he ImageNet classification dataset. The framework uses pre-trained ResNet models from the Model Zoo as a basis of the training procedure. The network architecture follows the model in the torchvision [30]</ref>. We refactor the convolution functions in it. The LSQ quantizers of weights and activations are inserted before the built-in convolution function call. Note t
been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI</ref>   TNAM [31]</ref> Twin-8T [32]</ref> Sandwich-RAM [8]</ref> Wang et al. [33]</ref> T
emory actually means replacing traditional digital computing circuits with regular placed analog ones, closely coupling to memory cells and likely occupying the same layout area but different devices [9]</ref>.</p><p>Though featuring high efficiency, state-of-the-art PIM chips suffer from two issues. The first is the accuracy issue for complicated vision tasks, such a
gy efficiency improvement compared with CPU architectures or reconfigurable DNN accelerators. Capacitor array-based charge sharing techniques were reported for always-on image classification tasks in [6]</ref>. CMOS-inverter based resistive ladders were adopted in [7]</ref> to perform signed accumulation. In addition to the voltage domain
he ImageNet classification dataset. The framework uses pre-trained ResNet models from the Model Zoo as a basis of the training procedure. The network architecture follows the model in the torchvision [30]</ref>. We refactor the convolution functions in it. The LSQ quantizers of weights and activations are inserted before the built-in convolution function call. Note t
f this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI</ref>   TNAM [31]</ref> Twin-8T [32]</ref> Sandwich-RAM [8]</ref> Wang et al. [33]</ref> Thinker [14]</ref> i
ems that fabricated processors in DRAM chips, dating back to 1990s [2,</ref>3]</ref>. Furthermore, processing-in-memory (PIM) architectures [4]</ref> and silicon prototypes [5]</ref> stand out recently due to their ultra good energy efficiency.</p><p>Utilizing analog/mixed-signal
been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI</ref>   TNAM [31]</ref> Twin-8T [32]</ref> Sandwich-RAM [8]</ref> Wang et al. [33]</ref> T

posed with pointwise non-linearities, building on the result that group equivariant linear maps (with mild assumptions) are necessarily convolutions (Kondor &amp; Trivedi, 2018;</ref>Cohen et al., 2019;</ref>Bekkers, 2020)</ref>. However there has been little work on non-linear group equivariant building blocks. In this p block of their equivariant module, drawing from the result that bounded linear operators are group equivariant if and only if they are convolutions (Kondor &amp; Trivedi, 2018;</ref>Cohen et al., 2019;</ref>Bekkers, 2020)</ref>  2020</ref>) describe group equivariant self-attention also using lifting
v> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">QM9: Molecular Property Regression from Molecular Geometry</head><p>We apply the LieTransformer to the QM9 molecule property prediction task (Wu et al., 2018)</ref>. This dataset consists of 133,885 small inorganic molecules described by the location and charge of each atom in the molecule, along with the bon
ural-language processing (Vaswani et al., 2017;</ref>Brown et al., 2020</ref>), computer vision (Zhang et al., 2019;</ref>Parmar et al., 2019b)</ref>, reinforcement learning (Parisotto et al., 2020)</ref>, and audio generation (H
s work, including Pytorch (Paszke et al., 2017)</ref>, NumPy (Oliphant, 2006;</ref>Walt et al., 2011;</ref>Harris et al., 2020)</ref>, SciPy (Jones et al., 2001)</ref>, and Matplotlib (Hunter, 2007)</ref>.</p></div

study efficient variants of self-attention (Wang et al., 2020;</ref>Kitaev et al., 2020;</ref>Zaheer et al., 2020;</ref>Katharopoulos et al., 2020)</ref>. An alternative approach is to incorporate information about pairs of inputs (such as bonding information for the QM9 task) as masking

about Hamiltonian dynamics is that symmetries of the Hamiltonian function play an important role in the physical properties of the modelled system. Indeed, a famous result known as Noether's theorem (Noether, 1971)</ref> states that if the Hamiltonian function has a symmetry, the resulting physical system modelled by the Hamiltonian will have a conserved quantity. F
>Brown et al., 2020</ref>), computer vision (Zhang et al., 2019;</ref>Parmar et al., 2019b)</ref>, reinforcement learning (Parisotto et al., 2020)</ref>, and audio generation (Huang et al., 2019)</ref>. (2) While convolutions are inherently translation equivar
t="#b6">(Cohen &amp; Welling, 2016b;</ref>Worrall et al., 2017;</ref>Thomas et al., 2018;</ref>Kondor et al., 2018;</ref>Weiler et al., 2018b;</ref>a;</ref>Weiler &amp; Cesa, 2019;</ref>Esteves et al., 2020;</re
ibr" target="#b26">27]</ref>. While these attacks have gained significant attention in research, they are unfortunately not the only weak spot in machine learning systems.</p><p>Recently, Xiao et al. [35]</ref> have demonstrated that data preprocessing used in machine learning can also suffer from vulnerabilities. In particular, they present a novel type of attack th OpenCV. As a consequence, we focus our analysis on these major imaging libraries.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image-Scaling Attacks</head><p>Recently, Xiao et al. [35]</ref> have shown that scaling algorithms are vulnerable to attacks and can be misused to fool machine learning systems. The proposed attack carefully manipulates an n×n and D ∈ R m ×n . The matrices L and R contain fixed coefficients that depend on the selected scaling algorithm. Both matrices can be computed in advance and are reusable. We refer to Xiao et al. [35]</ref> for a description how to calculate L and R.</p><p>Based on this matrix multiplication, the attack can also be decomposed into a horizontal and vertical manipu along the vertical and horizontal direction for each image, we consider the minimum of both for this assignment.</p><p>We implement image-scaling attacks in the strong variant proposed by Xiao et al. [35]</ref>. We make a slight improvement to the original attacks: Instead of using a fixed ε value, we increase its value gradually from 1 up to 50 if the quadratic prog caling stands out from the other algorithms as it employs a uniform weighting of pixels and operates on rectangular blocks instead of columns and rows. As a result, the original attack by Xiao et al. [35]</ref> is not applicable to this scaling algorithm. To attack area scaling, we thus propose two novel attack strategies. The first strategy aims at slightly changing

ing scenario. Moreover, we note that image-scaling attacks further bridge the gap between adversarial learning and multimedia security where the latter also considers adversarial signal manipulations [1,</ref>22]</ref>. Finally, image-scaling attacks differ from prior work in two important properties: (a) The attacks affect all further s ls with indices in [1, k/2] by a value smaller than m, the median is not changed. Likewise, replacing pixels larger than x (l) by a value larger than m does not change the median. Two methods remain: (1)</ref> We can replace pixels with indices in [1, (k + 1)/2] by a value larger than m. (2) We can set all pixels with index [(k + 1)/2, l] to p. While both methods can


age-scaling attacks further bridge the gap between adversarial learning and multimedia security where the latter also considers adversarial signal manipulations [1,</ref>22]</ref>. Finally, image-scaling attacks differ from prior work in two important properties: (a) The attacks affect all further steps of a machine learning system. They


ested in investigating different scaling ratios, we sample the images such that we obtain 120 images for each of the following five intervals of ratios: [2, 3), [3,</ref>4)</ref>, [4,</ref>5)</ref>, [5, 7.5</ref>), [7.5, 10)</ref>. Since we have ratios, we sample the images such that we obtain 120 images for each of the following five intervals of ratios: [2, 3), [3,</ref>4)</ref>, [4,</ref>5)</ref>, [5, 7.5</ref>), [7.5, 10)</ref>. Since we have two ratios along the vertical and horizo he successful attacks against OpenCV and TensorFlow, we allow 2 pixels to be freely changed in the optimization from Eq. ( 4</ref>) while using images with β ∈ [4,</ref>5)</ref>. The goal is to find a modification for these pixels, such that the convolution over the whole kernel yields the target va
in image processing, and there exist several methods that provide excellent performance in practice, such as techniques based on wavelets and shearlets [e.g., 26,</ref>30]</ref>. These involved approaches, however, are difficult to analyze from a security perspective, and their robustness is hard to assess. Hence, we propose two simple
consider the attack unsuccessful if the PSNR value is below 15 dB. We also experimented with more advanced methods for comparing the quality of images, such as feature matching based on SIFT analysis [16]</ref>. This technique, however, shows the same trends as the simple PSNR measurement, and thus we omit these measurements.</p></div> <div xmlns="http://www.tei-c.or
">50,</ref>30]</ref>. In fact, selfsupervised visual representation learning has been closing the gap with, and in some cases even surpassing its supervised counterpart [9,</ref>22,</ref>11,</ref>10]</ref>. Notably, most state-of-theart self-super fur (positive pair), but is repelled from similar fur of another dog image on the right (negative pair), creating contradicting objectives.</p><p>While recent efforts focus on improved architectures [9,</ref>10,</ref>22]</ref> and data augmentation [9,</ref><ref type="bibr" tar /p><p>While recent efforts focus on improved architectures [9,</ref>10,</ref>22]</ref> and data augmentation [9,</ref>43]</ref>, relatively little work considers the effects of negative samples, especially that of false negatives. Most existing met 23,</ref>24,</ref>42,</ref>34,</ref>22,</ref>9]</ref>.</p><p>In contrastive learning, the embedding space is governed by two opposing forces, the attraction of positive pairs and repellence of negative pairs, effect efined as different views of the same image, while negative pairs are formed by sampling views from different images, regardless of their semantic information [22,</ref>9,</ref>34]</ref>. Figure 1</ref> illustrates this process. Positive pairs generated from different view of all images, which limits scalability. MoCo v1 [22]</ref> addresses this problem by maintaining a momentum encoder and a limited queue of previous samples. SimCLR v1 [9]</ref> eschews a momentum encoder in favor of a large batch size, and proposes updates to the projection head and data augmentation.</p><p>Realizing the important role ontrastive learning</head><p>MoCo v1 [22]</ref> 60.6 -PIRL [34]</ref> 63.6 -PCL [32]</ref> 65.9 -SimCLR v1 [9]</ref> 69.3 89.0 MoCo v2 [11]</ref> 71.1 -SimCLR v2 [10]</ref> 71.7 90.4 InfoMin <ref type="bibr" target="
osing the gap with, and in some cases even surpassing its supervised counterpart [9,</ref>22,</ref>11,</ref>10]</ref>. Notably, most state-of-theart self-supervised visual representation learning methods are converging around, and fueled by, the central concept of contrastive l rom similar fur of another dog image on the right (negative pair), creating contradicting objectives.</p><p>While recent efforts focus on improved architectures [9,</ref>10,</ref>22]</ref> and data augmentation [9,</ref>43]</ref>, relatively little b33">[34]</ref> 63.6 -PCL [32]</ref> 65.9 -SimCLR v1 [9]</ref> 69.3 89.0 MoCo v2 [11]</ref> 71.1 -SimCLR v2 [10]</ref> 71.7 90.4 InfoMin [43]</ref> 73.0 91.  Method AP50 Supervised 81.3 MoCo v2 [11]</ref> 82.5 SwAV <
esentations have proven essential to improving performance on downstream tasks [16,</ref>20,</ref>49,</ref>27]</ref>. While conventional approaches use labeled data to pretrain visual representations, there has been a recent surge in self-supervised representation learning <r
clustering-based methods for selfsupervised representation learning [1,</ref>3,</ref>47]</ref>. Caron et al. [6]</ref> iteratively improve the learned representations by clustering samples (e.g., k-means) and using these clusters as pseudo-labels. They then train the network to
ref type="bibr" target="#b18">[19,</ref>15,</ref>36,</ref>45,</ref>38,</ref>8,</ref>50,</ref>30]</ref>. In fact, selfsupervised visual representation learning has been closing the gap >. Other proxy tasks include recovering an image from a corrupted version [45]</ref>, predicting part of the image from context [38,</ref>8]</ref> or generating one view of an image from another, e.g., split-brain auto-encoder [50]</ref> or colorization <ref type="bibr" target
ref type="bibr" target="#b4">[5]</ref>, CIFAR10 [29]</ref>, CIFAR100 [29]</ref>, Birdsnap [4]</ref>, SUN397 [46]</ref>, Cars [28]</ref>, Aircraft [33]</ref>, VOC2007 [17]</ref>, DTD <r
converging around, and fueled by, the central concept of contrastive learning [44,</ref>23,</ref>24,</ref>42,</ref>34,</ref>22,</ref>9]</ref>.</p><p>In contrastive learning, the embed "bibr" target="#b43">[44,</ref>23]</ref>, Deep InfoMax [24,</ref>2]</ref>, and contrastive multiview coding [42]</ref>. Recognizing that contrastive loss requires a large set of negative samples, PIRL [34]</ref> maintains a memory bank of previou
most state-of-theart self-supervised visual representation learning methods are converging around, and fueled by, the central concept of contrastive learning [44,</ref>23,</ref>24,</ref>42,</ref>34,</ref>22,</ref> ion and context differs.</p><p>We take a contrastive learning-based approach to selfsupervised representation learning. Earlier work in this area includes CPC [44,</ref>23]</ref>, Deep InfoMax [24,</ref>2]</ref>, and contrastive multiview coding 
neural networks, representation learning has become the backbone of most modern AI agents, in which good pretrained representations have proven essential to improving performance on downstream tasks [16,</ref>20,</ref>49,</ref>27]</ref>. While conventional approaches use lab
div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Transferring Features</head><p>Image Classification Following SimCLR, we perform the same evaluations on 12 classification datasets: Food [5]</ref>, CIFAR10 [29]</ref>, CIFAR100 [29]</ref>, Birdsnap [4]</ref>, SUN397
sual representation learning methods are converging around, and fueled by, the central concept of contrastive learning [44,</ref>23,</ref>24,</ref>42,</ref>34,</ref>22,</ref>9]</ref>.< arning-based approach to selfsupervised representation learning. Earlier work in this area includes CPC [44,</ref>23]</ref>, Deep InfoMax [24,</ref>2]</ref>, and contrastive multiview coding [42]</ref>. Recognizing that contrastive loss requires
rning frameworks, and (ii) generating an optimized implementation for deployment in production. Typical works include XLA [9]</ref> (applicable to training as well), TVM [10]</ref>, Glow [11]</ref>, Tensor Comprehensions [12]</ref>, nGraph [13]</r tly can be applied to optimize PyTorch models as well. XLA lowers operators into primitive linear algebra operations and calls into backend-specific libraries for execution on different backends. TVM [10]</ref> is an end-to-end compiler framework with Halide at the core, which first optimizes a computational graph, then converts the optimized graph into intermediate r
er another is actually unable to reduce data movement overhead between operator calls, making operator fusion ineffective at all. Taking GPU as an example, one effective approach is to write one CUDA [23]</ref> kernel function for the fused operator and complete the whole computation within only one kernel launch to eliminate the intermediate data movement overhead m spectrum of processors including x86/ARM CPUs and GPUs, WPK naturally supports these architectures as well. Nonetheless, our paper will merely investigate optimization techniques on CUDA-enabled GPUs [23]</ref>.</p><p>Halide compiler Halide is a DSL compiler based on the concept of functional programming. A Halide program is actually C++ code written using the functi
omputational graph, then converts the optimized graph into intermediate representations and finally compiles to executable codes on a specific target device. This work was further enhanced by AutoTVM [31]</ref> to enable automatic optimization of tensor operators. Compared to TVM, WPK provides broader capability by enabling system-level exploration as described befor
by enabling system-level exploration as described before, i.e. we aim to achieve fastest speed by singling out operator implementations not only from ours but also from third-party libraries. NeoCPU [32]</ref> is built upon TVM and aims to optimize CNN inference on CPUs by taking advantage of wide SIMD instructions. nGraph [13]</ref> a
in CNN model training and inference, owing to its high compute power exposed by massive parallelism. Popular deep learning frameworks such as Caffe [5]</ref>, TensorFlow [6]</ref>, Mxnet [7]</ref> and PyTorch [8]</ref> all provide built-in support for GPUs. However, these framewo
ificantly distinguishes WPK from all existing compiler frameworks including XLA, TVM and nGraph. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We used ResNet-18 [30]</ref> to evaluate WPK and its counterparts on a Tesla P100 GPU. ResNet-18 is an image classification model trained with Caffe and accepts inputs with NCHW data layo
s/1.0"><head n="1">Introduction</head><p>Convolutional neural network (CNN) models [1]</ref>[2]</ref>[3]</ref>[4]</ref> usually have high computational cost subject to batch size, number of weight parameters and image size. Hence, graphics processing units (GPUs) have been playin
er another is actually unable to reduce data movement overhead between operator calls, making operator fusion ineffective at all. Taking GPU as an example, one effective approach is to write one CUDA [23]</ref> kernel function for the fused operator and complete the whole computation within only one kernel launch to eliminate the intermediate data movement overhead m spectrum of processors including x86/ARM CPUs and GPUs, WPK naturally supports these architectures as well. Nonetheless, our paper will merely investigate optimization techniques on CUDA-enabled GPUs [23]</ref>.</p><p>Halide compiler Halide is a DSL compiler based on the concept of functional programming. A Halide program is actually C++ code written using the functi
g advantage of wide SIMD instructions. nGraph [13]</ref> adopts a similar workflow to TVM, but was further extended to support encypted data with homomorphic encryption [33]</ref>. Some other compiling frameworks (e.g. Tensor Comprehensions [12]</ref>, and Glow [11]</ref>) we
omputational graph, then converts the optimized graph into intermediate representations and finally compiles to executable codes on a specific target device. This work was further enhanced by AutoTVM [31]</ref> to enable automatic optimization of tensor operators. Compared to TVM, WPK provides broader capability by enabling system-level exploration as described befor
/div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Convolutional neural network (CNN) models [1]</ref>[2]</ref>[3]</ref>[4]</ref> usually have high computational cost subjec
/p><p>Here we address the above problems and rethink what is a "good" representation for graph-structured data. In particular, the Information Bottleneck (IB) [18,</ref>19]</ref> provides a critical principle for representation learning: an optimal representation should contain the minimal sufficient information for the downstream predi
lso other alternative formalizations of the GIB principle, especially when modeling P(Z</p><p>A |Z (l−1) X , A). Generally speaking, any node-pair representations, such as messages over edges in MPNN [29]</ref>, can be leveraged to sample structures. Applying the GIB principle to other architectures is a promising direction for future investigation.</p></div> <div xm d n="4">Related Work</head><p>GNNs learn node-level representations through message passing and aggregation from neighbors [1,</ref>3,</ref>[29]</ref>[30]</ref>[31]</ref>. Several previous works further incorporate the attention mechanism to adapt
different channels to obtain new Z (l) X . Moreover, when training the model, we adopt reparameterization trick for Steps 3 and 7: Step 3 uses Gumbel-softmax [24,</ref>25]</ref> while Step 7 uses</p><formula xml:id="formula_17">Ẑ(l) X,v = µ (l) v + σ (l) v</formula><p>z where z ∼ Gaussian(0, I), z ∈ R 1×f and is element-wise product.</ l−1) X,v ⊕ Z(l−1) X,u )a T } u∈Vvt ) 3. Z (l+1) A,v ← ∪ T t=1 {u ∈ V vt |u iid ∼ Bernoulli(φ<label>(</label></formula><p>A ) is a non-informative distribution [24,</ref>25]</ref>. Specifically, we use the uniform distribution for the categorical version:</p><formula xml:id="formula_21">Z A ∼ Q(Z A ), Z A,v = ∪ T t=1 {u ∈ V vt |u iid ∼ C exible variational marginal allows it to flexibly approximate the true marginal distribution P(Z X ). For the reparameterization in AIB, we use Gumbel-softmax [24,</ref>25]</ref> with temperature τ . For GIB-Cat, the number of neighbors k to be sampled is a hyperparameter. For GIB-Bern, we use Bernoulli(α) as the non-informative prior,
er, at present GNNs still suffer from a few problems. For example, the features of a neighborhood node can contain non-useful information that may negatively impact the prediction of the current node [14]</ref>. Also, GNN's reliance on message passing over the edges of the graph also makes it prone to noise and adversarial attacks that target at the graph structure <
different channels to obtain new Z (l) X . Moreover, when training the model, we adopt reparameterization trick for Steps 3 and 7: Step 3 uses Gumbel-softmax [24,</ref>25]</ref> while Step 7 uses</p><formula xml:id="formula_17">Ẑ(l) X,v = µ (l) v + σ (l) v</formula><p>z where z ∼ Gaussian(0, I), z ∈ R 1×f and is element-wise product.</ l−1) X,v ⊕ Z(l−1) X,u )a T } u∈Vvt ) 3. Z (l+1) A,v ← ∪ T t=1 {u ∈ V vt |u iid ∼ Bernoulli(φ<label>(</label></formula><p>A ) is a non-informative distribution [24,</ref>25]</ref>. Specifically, we use the uniform distribution for the categorical version:</p><formula xml:id="formula_21">Z A ∼ Q(Z A ), Z A,v = ∪ T t=1 {u ∈ V vt |u iid ∼ C exible variational marginal allows it to flexibly approximate the true marginal distribution P(Z X ). For the reparameterization in AIB, we use Gumbel-softmax [24,</ref>25]</ref> with temperature τ . For GIB-Cat, the number of neighbors k to be sampled is a hyperparameter. For GIB-Bern, we use Bernoulli(α) as the non-informative prior,
[14]</ref>. Also, GNN's reliance on message passing over the edges of the graph also makes it prone to noise and adversarial attacks that target at the graph structure [15,</ref>16]</ref>.</p><p>Here we address the above problems and rethink what is a "good" representation for graph-structured data. In pa ntial neighbors for each node, and we perform message passing based on Z A . This property renders our models extremely robust to structural perturbations/attacks where traditional GNNs are sensitive [15,</ref>16]</ref>. Both our models also keep robustness to the feature perturbation that is similar to other IB-based DNN models <ref ty e="bibr" target="#b31">32]</ref>. Recent literature shows that representations learned by GNNs are far from robust and can be easily attacked by malicious manipulation on either features or structure [15,</ref>16]</ref>. Accordingly, several defense models are proposed to increase the robustness by injecting random noise in the represen ttp://www.tei-c.org/ns/1.0"><head n="5.1">Robustness Against Adversarial Attacks</head><p>In this experiment, we compare the robustness of different models against adversarial attacks. We use Nettack [15]</ref>, a strong targeted attack technique on graphs that attacks a target node by flipping the edge or node features. We evaluate the models on both evasive and poi the edge or node features. We evaluate the models on both evasive and poisoning settings, i.e. the attack happens after or before the model is trained, respectively. We follow the setting of Nettack [15]</ref>: for each dataset, select (i) 10 nodes with highest margin of classification, i.e. they are clearly correctly classified, (ii) 10 nodes with lowest margin but t (AIB-Bern) only underperforms GIB-Cat (GIB-Bern) by 0.9% (0.4%). The performance gain is due to the attacking style of Nettack, as the most effective attack is typically via structural perturbation [15]</ref>, as is also confirmed in Appendix J. Therefore, next we further investigate the case that only perturbation on node features is available.</p></div> <div xmln e" target="#tab_7">9</ref>, 10 and 11. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>G.4 Additional Details for Adversarial Attack Experiment</head><p>We use the implementation of Nettack [15]</ref> in the repository https://github.com/DSE-MSU/ DeepRobust with default settings. As stated in the main text, for each dataset we select 40 nodes in the test se classified), and 20 random nodes. For each target node, we independently train a different model and evaluate its performance on the target node in both evasive and poisoning setting. Different from [15]</ref> that only keeps the largest connected component of the graph and uses random split, to keep consistent settings across experiments, we still use the full grap onnected component of the graph and uses random split, to keep consistent settings across experiments, we still use the full graph and standard split, which makes the defense even harder than that in [15]</ref>. For each dataset and each number of perturbations (1, 2, 3, 4), we repeat the above experiment 5 times with random seeds 0, 1, 2, 3, 4, and report the averag
/div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Who may benefit from this research: Graphs have been used to represent a vast amount of realworld data from social science [44]</ref>, biology [45]</ref>, geographical mapping [46]</ref>, finances [4
e="bibr" target="#b14">[15,</ref>16]</ref>. Accordingly, several defense models are proposed to increase the robustness by injecting random noise in the representations [33]</ref>, removing suspicious and uninformative edges [34]</ref>, low-rank approximation of the adjacency matrix <ref type="bibr" target d against adversarial attacks: GCNJaccard [34]</ref> that pre-processes the graph by deleting the edges between nodes with low feature similarity, and Robust GCN (RGCN) [33]</ref> that uses Gaussian reparameterization for node features and variance-based attention. Note that RGCN essentially includes the term XIB (Eq. ( <ref type="formu
[8]</ref>[9]</ref>[10]</ref>[11]</ref>[12]</ref>[13]</ref>, in a sense that they can fit more complex graph-structured data. However, at present GNNs still suffer from a few problems. For example, the features of a ne de rep- resentations Z (L)</formula><p>X,Π and ΠZ (L)</p><p>X share the same distribution (proof in Appendix E). Permutation invariance is known to be important for structural representation learning [13]</ref>. X ) as in Eq. ( 2</ref>), and further compute the bound of the GIB objective in Eq. (1). To characterize AIB (l) in Eq. (3), we assume Q(
/div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Who may benefit from this research: Graphs have been used to represent a vast amount of realworld data from social science [44]</ref>, biology [45]</ref>, geographical mapping [46]</ref>, finances [4
4]</ref>, biology [45]</ref>, geographical mapping [46]</ref>, finances [47]</ref> and recommender systems [48]</ref>, because of their flexibility in modeling both the relation among the data (structures) and the content of the data (features). Graph neural networks (GNN), n
on, how to effectively integrate network and text remains a major challenge. We leverage motif patterns in our framework to extract useful features from the heterogeneous textrich network. Meta-paths [31]</ref> and motif patterns [5,</ref>18]</ref> have been widely adopted to extract useful structural infor ontext of heterogeneous information networks, network motifs, sometimes also referred to as meta-graphs, can offer more flexibility and capture richer network semantics than the widely used meta-path [31]</ref> patterns. Recent studies have shown that incorporating motifs for node embedding leads to superior performance [24,</ref><ref t and "information cascade" are the same. Both motif instances can be represented by the combination of two authors (i.e., "Jure Leskovec" and "Jon Kleinberg").</p><p>It is worth noting that meta-path [31]</ref> can be viewed as a special case of motif patterns when they degenerate to lines. For example, the meta-path describing the shared venue relation between two t
ajor challenge. We leverage motif patterns in our framework to extract useful features from the heterogeneous textrich network. Meta-paths [31]</ref> and motif patterns [5,</ref>18]</ref> have been widely adopted to extract useful structural information from networks. As illustrated in Figure <ref type="fig critical in complex networks across various domains, such as neuroscience [30]</ref>, bioinformatics [18]</ref>, and information networks [5]</ref>. In the context of heterogeneous information networks, network motifs, sometimes also referred to as meta-graphs, can offer more flexibility and capture richer
rns in our framework to extract useful features from the heterogeneous textrich network. Meta-paths [31]</ref> and motif patterns [5,</ref>18]</ref> have been widely adopted to extract useful structural information from networks. As illustrated in Figure 2</ref>, motifs ar otifs. Network motifs are higher-order subgraph structures that are critical in complex networks across various domains, such as neuroscience [30]</ref>, bioinformatics [18]</ref>, and information networks [5]</ref>. In the context of heterogeneous information networks, network motifs, sometimes also referr
the corpus using some supervision or seeds [1,</ref>6,</ref>15,</ref>20,</ref>28,</ref>47]</ref>. Such patterns have demonstrated their effectiveness at finding hyponymy relations, however, they are not suitable for
a</head><p>In NetTaxo framework, term embedding is the key to discover subtopic clusters at every taxonomy node.</p><p>Term embedding learning is typically conducted on the entire document collection [17,</ref>22]</ref>. However, such learning paradigm faces a major drawback in topic taxonomy construction: the discriminative power of le its own associated (weighted) documents. Its effectiveness has been verified in [44]</ref> through ablation tests.</p><p>We use skip-gram with negative sampling (SGNS) [17]</ref> as our base embedding model. At each taxonomy node, we use local documents D c instead of D for training. Similar to the original SGNS model, the objective is       (2)</formula><p>where Mc (t) is the associated motif instances of term t. We will describe how to select Mc in section 4.5.</p><p>The probabilities are approximated with negative sampling [17]</ref>.</p><formula xml:id="formula_2">log P(m | t) = log σ (r T m u t ) − E m∼P neg (m) log σ (−r T j u t )<label>(3)</label></formula><p>where r and u are embeddin ren nodes. In principle, our method is flexible in the choice of clustering method. Consider that cosine similarity between term embedding has demonstrated its effectiveness in term similarity search [17]</ref>, we apply vMF mixture clustering [3]</ref> in NetTaxo. It is a classical, effective soft clustering method on the unit hyper-sph ext and network data. It is a straightforward solution to combine the term embedding technique with the network structure. Specifically, we first learn term embedding vectors from text using word2vec [17]</ref> and network using LINE [34]</ref> separately, where every embedding vector has a dimension of 300. And then, we concatenate the
ds [1,</ref>6,</ref>15,</ref>20,</ref>28,</ref>47]</ref>. Such patterns have demonstrated their effectiveness at finding hyponymy relations, however, they are not suitable for constructing a topic taxonomy as (1) eac
a tree-structured hierarchy, where each taxonomy node contains a set of semantically similar terms. A high-quality topic taxonomy benefits various downstream applications, such as search and indexing [43]</ref>, personalized content recommendation [46]</ref>, and question answering [42]</ref>. For example,
method. Consider that cosine similarity between term embedding has demonstrated its effectiveness in term similarity search [17]</ref>, we apply vMF mixture clustering [3]</ref> in NetTaxo. It is a classical, effective soft clustering method on the unit hyper-sphere. Since the constructed topic taxonomy rarely changes, we leave the choi mlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Parameter Setting</head><p>The number of mixtures k for vMF mixture clustering is manually selected by incrementally increasing k by 1 in the range of [3,</ref>6]</ref> until coherent clusters are observed. We set k = 5 for the top level and k = 4 for the second level of the taxonomy in bot
type="bibr" target="#b13">12,</ref>19,</ref>37,</ref>38]</ref> and bottom-up agglomerative clusteringbased [8]</ref> methods are arguably the most popular and effective frameworks, before word embedding techniques become mature.</p><p>Among unsupervised frameworks using term e
ext data, yielding unsatisfactory results in our experiments.</p><p>Another related thread is the clustering algorithms on heterogeneous information networks (i.e., networks of typed nodes and edges) [32,</ref>33]</ref>. For example, NetClus [33]</ref> starts with user-provided seed nodes and applies autho one or a small number of sub-topics under the current taxonomy node, thereby including it will help us better separate sub-topics.</p><p>We realize these two principles by applying authority ranking [32]</ref> upon the motif context graph.</p><p>The motif context graph at a taxonomy node c is a bipartite graph G M c = (T c , M c ,W ), where T c is the terms under th
) is a boolean indicator function about whether the term t appears in the document d.</p><p>Combined Anchor Score. As an unsupervised ranking problem, we follow the previous comparative analysis work [36]</ref> and use a geometric mean to combine these three signals.</p><formula xml:id="formula_6">anchor_score(c, t) = pop(c, t) • discriminative(c, t) • idf(c, t)</for
, users, and reviews.</p><p>While most existing methods solely rely on text data [2,</ref>11,</ref>16,</ref>44]</ref>, incorporating network structures can bring additional, valuable information to text. Let's use the computer science paper collection to convey our intuition. frameworks, before word embedding techniques become mature.</p><p>Among unsupervised frameworks using term embedding, topdown hierarchical clustering methods [16,</ref>44]</ref> achieve the state-ofthe-art. For example, TaxoGen [44]</ref> learns local term embedding from the documents associated with a ta ciated with each paper node. The edges describe author-paper, venue-paper, year-paper, year range-paper, and term-paper relations. Note that, previous methods [38,</ref>44]</ref> choose five areas from this dataset too, for example in [44]</ref>, information retrieval, computer vision, robotics, security & matic evaluation of the constructed topic taxonomy has long been a very challenging task. Inspired by the state-of-the-art work on topic taxonomy construction [38,</ref>44]</ref> and recent work on topic modeling [39,</ref>40]</ref>, we design a set of tasks for human evaluat clusive Siblings. Besides the coherence, each taxonomy node should be distinguishable from its sibling nodes. Following previous taxonomy construction methods [38,</ref>44]</ref>, we perform the term intrusion test. Specifically, for each node, we collect its top-5 terms, and then randomly mix in an intruder term from the top-5 terms of works using term embedding, topdown hierarchical clustering methods [16,</ref>44]</ref> achieve the state-ofthe-art. For example, TaxoGen [44]</ref> learns local term embedding from the documents associated with a taxonomy node, and then clusters terms at a deeper level. Most of these methods, including Ta nts into its children accordingly. The key contribution of NetTaxo is our designed effective way of leveraging both text data and network structures.</p><p>Based on our observations and previous work [44]</ref>, using term embedding learned from textual contexts alone can cluster subtopics roughly, although not necessarily perfect. Therefore, we decide to leverage su gh not necessarily perfect. Therefore, we decide to leverage such clustering results as the initialization to our subsequent motif instance selection step. Specifically, we first follow previous work [44]</ref> to learn local term embedding and obtain initial term clusters. To be more accurate, we conduct a comparative analysis between clusters to select the most rep ther. This problem will only get worse as we drill down further. Therefore, it is a necessity to condition the term embeddings to the current taxonomy node.</p><p>To this end, we follow previous work [44]</ref> and adopt the idea of local embedding [13]</ref> to learn term embedding from text data. The basic idea of local embedding is t rm embedding from text data. The basic idea of local embedding is to fine-tune term embedding at each node according to its own associated (weighted) documents. Its effectiveness has been verified in [44]</ref> through ablation tests.</p><p>We use skip-gram with negative sampling (SGNS) [17]</ref> as our base embedding model. At each ta he multinomial distribution P D (D c ) parameterized by the document weights {w c,d } under the current taxonomy node. Therefore, our loss function slightly differs from the ones in the previous work [44]</ref> as well as the original local embedding work [13]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Motif terms to children clusters.</p><p>For documents in D c , we estimate their clustering probability by aggregating clustering probability from their connected terms. This process is the same as that in [44]</ref>. The aggregated probabilities of a document, multiplied by its current weight, will be the weights of the document on the next level.</p></div> <div xmlns="ht -paper, and term-paper relations. Note that, previous methods [38,</ref>44]</ref> choose five areas from this dataset too, for example in [44]</ref>, information retrieval, computer vision, robotics, security &amp; network, and machine learning. In contrast, our chosen five areas are more closely related t cal Latent Dirichlet Allocation (HLDA) model [12]</ref> and its performance is quite similar to HPAM++. Therefore, we only present the results of HPAM++ here. • TaxoGen [44]</ref> is the state-of-the-art topic taxonomy construction method using text data. As demonstrated in its paper, it beats many strong baselines, such as hierarchical ref type="bibr" target="#b7">6]</ref> until coherent clusters are observed. We set k = 5 for the top level and k = 4 for the second level of the taxonomy in both the DBLP and Yelp dataset. In TaxoGen [44]</ref>, this number is set to 5 for all levels, which is not far from our observation. Note that this parameter will only need to set once for a given dataset, so th
he-art work on topic taxonomy construction [38,</ref>44]</ref> and recent work on topic modeling [39,</ref>40]</ref>, we design a set of tasks for human evaluation.</p><p>For each dataset, we recruited 10 in-domain human experts. In their annotation process, they were encoura ><p>• Coherence. Within each node in the taxonomy, the terms should be able to form a semantically coherent topic. Similar to previous topic model evaluations [39,</ref>40]</ref>, we present the top-5 terms to human annotators from the same taxonomy node. Annotators are asked to first judge whether these terms form an interpretable topi
r studies, hierarchical topic modeling [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref> and bottom-up agglomerative clusteringbased [8]</ref> methods are arguably the most popular and effective frameworks, before word nes, such as hierarchical topic models [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref>. It utilizes the same local embedding idea as our model, but ignores network structures. • CATHYHIN++ is a method enhanced by us from the original CATHYHIN <re rk, we follow the top-down, local embedding approach but go beyond and leverage network structures to significantly improve the quality of clustering.</p><p>Network Clustering-based Methods. CATHYHIN [38]</ref> is arguably the state-of-the-art method solely based on network structures for automatic topic taxonomy construction. Specifically, with unigram words as a pa ef>38]</ref>. It utilizes the same local embedding idea as our model, but ignores network structures. • CATHYHIN++ is a method enhanced by us from the original CATHYHIN [38]</ref> method. CATHYHIN [38]</ref> is a topic taxonomy construction method using network data. It treats unigrams as nodes and attempt e same local embedding idea as our model, but ignores network structures. • CATHYHIN++ is a method enhanced by us from the original CATHYHIN [38]</ref> method. CATHYHIN [38]</ref> is a topic taxonomy construction method using network data. It treats unigrams as nodes and attempted to mine terms (i.e., phrases) and clusters simultaneousl t data, i.e., title and abstract, is associated with each paper node. The edges describe author-paper, venue-paper, year-paper, year range-paper, and term-paper relations. Note that, previous methods [38,</ref>44]</ref> choose five areas from this dataset too, for example in [44]</ref>, information retriev uation Tasks &amp; Metrics</head><p>Systematic evaluation of the constructed topic taxonomy has long been a very challenging task. Inspired by the state-of-the-art work on topic taxonomy construction [38,</ref>44]</ref> and recent work on topic modeling [39,</ref>40]</ref>, w the total number of presented terms. • Exclusive Siblings. Besides the coherence, each taxonomy node should be distinguishable from its sibling nodes. Following previous taxonomy construction methods [38,</ref>44]</ref>, we perform the term intrusion test. Specifically, for each node, we collect its top-5 terms, and then randomly mix in
, users, and reviews.</p><p>While most existing methods solely rely on text data [2,</ref>11,</ref>16,</ref>44]</ref>, incorporating network structures can bring additional, valuable information to text. Let's use the computer science paper collection to convey our intuition. frameworks, before word embedding techniques become mature.</p><p>Among unsupervised frameworks using term embedding, topdown hierarchical clustering methods [16,</ref>44]</ref> achieve the state-ofthe-art. For example, TaxoGen [44]</ref> learns local term embedding from the documents associated with a ta ciated with each paper node. The edges describe author-paper, venue-paper, year-paper, year range-paper, and term-paper relations. Note that, previous methods [38,</ref>44]</ref> choose five areas from this dataset too, for example in [44]</ref>, information retrieval, computer vision, robotics, security & matic evaluation of the constructed topic taxonomy has long been a very challenging task. Inspired by the state-of-the-art work on topic taxonomy construction [38,</ref>44]</ref> and recent work on topic modeling [39,</ref>40]</ref>, we design a set of tasks for human evaluat clusive Siblings. Besides the coherence, each taxonomy node should be distinguishable from its sibling nodes. Following previous taxonomy construction methods [38,</ref>44]</ref>, we perform the term intrusion test. Specifically, for each node, we collect its top-5 terms, and then randomly mix in an intruder term from the top-5 terms of works using term embedding, topdown hierarchical clustering methods [16,</ref>44]</ref> achieve the state-ofthe-art. For example, TaxoGen [44]</ref> learns local term embedding from the documents associated with a taxonomy node, and then clusters terms at a deeper level. Most of these methods, including Ta nts into its children accordingly. The key contribution of NetTaxo is our designed effective way of leveraging both text data and network structures.</p><p>Based on our observations and previous work [44]</ref>, using term embedding learned from textual contexts alone can cluster subtopics roughly, although not necessarily perfect. Therefore, we decide to leverage su gh not necessarily perfect. Therefore, we decide to leverage such clustering results as the initialization to our subsequent motif instance selection step. Specifically, we first follow previous work [44]</ref> to learn local term embedding and obtain initial term clusters. To be more accurate, we conduct a comparative analysis between clusters to select the most rep ther. This problem will only get worse as we drill down further. Therefore, it is a necessity to condition the term embeddings to the current taxonomy node.</p><p>To this end, we follow previous work [44]</ref> and adopt the idea of local embedding [13]</ref> to learn term embedding from text data. The basic idea of local embedding is t rm embedding from text data. The basic idea of local embedding is to fine-tune term embedding at each node according to its own associated (weighted) documents. Its effectiveness has been verified in [44]</ref> through ablation tests.</p><p>We use skip-gram with negative sampling (SGNS) [17]</ref> as our base embedding model. At each ta he multinomial distribution P D (D c ) parameterized by the document weights {w c,d } under the current taxonomy node. Therefore, our loss function slightly differs from the ones in the previous work [44]</ref> as well as the original local embedding work [13]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Motif terms to children clusters.</p><p>For documents in D c , we estimate their clustering probability by aggregating clustering probability from their connected terms. This process is the same as that in [44]</ref>. The aggregated probabilities of a document, multiplied by its current weight, will be the weights of the document on the next level.</p></div> <div xmlns="ht -paper, and term-paper relations. Note that, previous methods [38,</ref>44]</ref> choose five areas from this dataset too, for example in [44]</ref>, information retrieval, computer vision, robotics, security &amp; network, and machine learning. In contrast, our chosen five areas are more closely related t cal Latent Dirichlet Allocation (HLDA) model [12]</ref> and its performance is quite similar to HPAM++. Therefore, we only present the results of HPAM++ here. • TaxoGen [44]</ref> is the state-of-the-art topic taxonomy construction method using text data. As demonstrated in its paper, it beats many strong baselines, such as hierarchical ref type="bibr" target="#b7">6]</ref> until coherent clusters are observed. We set k = 5 for the top level and k = 4 for the second level of the taxonomy in both the DBLP and Yelp dataset. In TaxoGen [44]</ref>, this number is set to 5 for all levels, which is not far from our observation. Note that this parameter will only need to set once for a given dataset, so th
edding is the key to discover subtopic clusters at every taxonomy node.</p><p>Term embedding learning is typically conducted on the entire document collection [17,</ref>22]</ref>. However, such learning paradigm faces a major drawback in topic taxonomy construction: the discriminative power of learned term embedding becomes limited at d
r studies, hierarchical topic modeling [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref> and bottom-up agglomerative clusteringbased [8]</ref> methods are arguably the most popular and effective frameworks, before word nes, such as hierarchical topic models [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref>. It utilizes the same local embedding idea as our model, but ignores network structures. • CATHYHIN++ is a method enhanced by us from the original CATHYHIN <re rk, we follow the top-down, local embedding approach but go beyond and leverage network structures to significantly improve the quality of clustering.</p><p>Network Clustering-based Methods. CATHYHIN [38]</ref> is arguably the state-of-the-art method solely based on network structures for automatic topic taxonomy construction. Specifically, with unigram words as a pa ef>38]</ref>. It utilizes the same local embedding idea as our model, but ignores network structures. • CATHYHIN++ is a method enhanced by us from the original CATHYHIN [38]</ref> method. CATHYHIN [38]</ref> is a topic taxonomy construction method using network data. It treats unigrams as nodes and attempt e same local embedding idea as our model, but ignores network structures. • CATHYHIN++ is a method enhanced by us from the original CATHYHIN [38]</ref> method. CATHYHIN [38]</ref> is a topic taxonomy construction method using network data. It treats unigrams as nodes and attempted to mine terms (i.e., phrases) and clusters simultaneousl t data, i.e., title and abstract, is associated with each paper node. The edges describe author-paper, venue-paper, year-paper, year range-paper, and term-paper relations. Note that, previous methods [38,</ref>44]</ref> choose five areas from this dataset too, for example in [44]</ref>, information retriev uation Tasks &amp; Metrics</head><p>Systematic evaluation of the constructed topic taxonomy has long been a very challenging task. Inspired by the state-of-the-art work on topic taxonomy construction [38,</ref>44]</ref> and recent work on topic modeling [39,</ref>40]</ref>, w the total number of presented terms. • Exclusive Siblings. Besides the coherence, each taxonomy node should be distinguishable from its sibling nodes. Following previous taxonomy construction methods [38,</ref>44]</ref>, we perform the term intrusion test. Specifically, for each node, we collect its top-5 terms, and then randomly mix in
in our experiments.</p><p>Another related thread is the clustering algorithms on heterogeneous information networks (i.e., networks of typed nodes and edges) [32,</ref>33]</ref>. For example, NetClus [33]</ref> starts with user-provided seed nodes and applies authority ranking together with node clusterin ring algorithms on heterogeneous information networks (i.e., networks of typed nodes and edges) [32,</ref>33]</ref>. For example, NetClus [33]</ref> starts with user-provided seed nodes and applies authority ranking together with node clustering to cluster nodes. We adopt a similar authority ranking proces
s into a taxonomy by applying algorithms like maximum spanning tree. The lexical patterns are either manually designed [14,</ref>21,</ref>23,</ref>25]</ref> or derived from the corpus using some supervision or seeds [1,</ref><ref type="bibr" targ
/p><p>Term Clustering-based Methods. A number of clustering methods have been proposed towards automatic topic taxonomy construction from text corpora. In pioneer studies, hierarchical topic modeling [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref r" target="#b45">[44]</ref> is the state-of-the-art topic taxonomy construction method using text data. As demonstrated in its paper, it beats many strong baselines, such as hierarchical topic models [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref
like maximum spanning tree. The lexical patterns are either manually designed [14,</ref>21,</ref>23,</ref>25]</ref> or derived from the corpus using some supervision or seeds [1,</ref>6,</ref><ref type="bibr" target
ludes terms in D, which can be either specified by users or extracted from the corpus. In our experiments, we form the term set T by extracting high-quality phrases from the corpus D using AutoPhrase [26]</ref>.</p><p>• Network Structure: A heterogeneous information network G = (V , E, ϕ,ψ ), where V is the node set and E is the edge set. Type mapping ϕ and ψ map eac treats unigrams as nodes and attempted to mine terms (i.e., phrases) and clusters simultaneously. Its performance is limited due to (1) the poor phrase quality compared to the state-of-the-art method [26]</ref> and</p><p>(2) the poor term clustering results compared to methods that use the term embedding technique. To make the comparison more fair, we improve the CAT in order to conduct a fair comparison, the same set of terms are used across different methods. They are the extracted from raw texts by the state-of-the-art distantly supervised phrase mining method [26]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Parameter Setting</head><p>The number of mixtures k for vMF mixture clustering is manually s
twork semantics than the widely used meta-path [31]</ref> patterns. Recent studies have shown that incorporating motifs for node embedding leads to superior performance [24,</ref>41,</ref>45]</ref> compared to conventional path-based methods [9,
xt-rich network with nodes of businesses, users, and reviews.</p><p>While most existing methods solely rely on text data [2,</ref>11,</ref>16,</ref>44]</ref>, incorporating network structures can bring additional, valuable information to text. Let's use the computer science pa e arguably the most popular and effective frameworks, before word embedding techniques become mature.</p><p>Among unsupervised frameworks using term embedding, topdown hierarchical clustering methods [16,</ref>44]</ref> achieve the state-ofthe-art. For example, TaxoGen [44]</ref> learns local term embeddin
pAdvisor2</ref> can be seen as a part of a text-rich network with nodes of businesses, users, and reviews.</p><p>While most existing methods solely rely on text data [2,</ref>11,</ref>16,</ref>44]</ref>, incorporating network structures can br between terms and clusters can be identified through supervised models, for example, semantic projection in the embedding space [11]</ref> and neural network classifier [2]</ref>. In our setting, there are no hyponymy labels.</p><p>Term Clustering-based Methods. A number of clustering methods have been proposed towards automatic topic ta
term at taxonomy node c.</p><p>Informativeness Score. Inverse document frequency (IDF) has been widely adopted in information retrieval to measure the informativeness of a term within a given corpus [29]</ref>. At each taxonomy node c, we calculate the weighted inverse document frequency as follows.</p><p>idf</p><formula xml:id="formula_5">(c, t) = log d ∈D w c,d d
edding is the key to discover subtopic clusters at every taxonomy node.</p><p>Term embedding learning is typically conducted on the entire document collection [17,</ref>22]</ref>. However, such learning paradigm faces a major drawback in topic taxonomy construction: the discriminative power of learned term embedding becomes limited at d
]</ref> patterns. Recent studies have shown that incorporating motifs for node embedding leads to superior performance [24,</ref>41,</ref>45]</ref> compared to conventional path-based methods [9,</ref>27]</ref>. In this work, the quality of term
sing lexical patterns (e.g., "A such as B"), and then organize the extracted pairs into a taxonomy by applying algorithms like maximum spanning tree. The lexical patterns are either manually designed [14,</ref>21,</ref>23,</ref>25]</ref> or derived from the corpus using some
ly adopted in automatic topic taxonomy construction. A common practice is to first learn term embedding from text data and then organize them into a structure based on their representation similarity [4]</ref> and cluster separation measures [7]</ref>. Utilizing pairwise hyponymy relation labels, taxonomic relations between terms and clus
cally similar terms. A high-quality topic taxonomy benefits various downstream applications, such as search and indexing [43]</ref>, personalized content recommendation [46]</ref>, and question answering [42]</ref>. For example, organizing copious scientific papers into a well-structured taxonomy gives res
/p><p>Term Clustering-based Methods. A number of clustering methods have been proposed towards automatic topic taxonomy construction from text corpora. In pioneer studies, hierarchical topic modeling [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref r" target="#b45">[44]</ref> is the state-of-the-art topic taxonomy construction method using text data. As demonstrated in its paper, it beats many strong baselines, such as hierarchical topic models [10,</ref>12,</ref>19,</ref>37,</ref>38]</ref
edding is the key to discover subtopic clusters at every taxonomy node.</p><p>Term embedding learning is typically conducted on the entire document collection [17,</ref>22]</ref>. However, such learning paradigm faces a major drawback in topic taxonomy construction: the discriminative power of learned term embedding becomes limited at d
hese systems to compromise between the model design and batch sizes.</p><p>This paper presents Group Normalization (GN) as a simple alternative to BN. We notice that many classical features like SIFT [14]</ref> and HOG [15]</ref> are group-wise features and involve group-wise normalization. For example, a HOG vector is the outcome of se >[3]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Group Normalization</head><p>The channels of visual representations are not entirely independent. Classical features of SIFT [14]</ref>, HOG [15]</ref>, and GIST [41]</ref> are group-wise representations by design, where each group orresponding channels of these filters can be normalized together.</p><p>The higher-level layers are more abstract and their behaviors are not as intuitive. However, in addition to orientations (SIFT [14]</ref>, HOG [15]</ref>, or [44,</ref>45]</ref>), there are many factors
target="#b0">[1]</ref>, often by running average; consequently, there is no normalization performed when testing. The pre-computed statistics may also change when the target data distribution changes [32]</ref>. These issues lead to inconsistency at training, transferring, and testing time. In addition, as aforementioned, reducing the batch size can have dramatic imp
rget="#b17">[18]</ref> (Figure 2</ref>), that also avoid normalizing along the batch dimension. These methods are effective for training sequential models (RNN/LSTM [22,</ref>23]</ref>) or generative models (GANs [24,</ref>25]</ref>). But as
would be limited by memory. The restriction on batch sizes is more demanding in computer vision tasks including detection [8,</ref>9,</ref>10]</ref>, segmentation [11,</ref>10]</ref>, video recognition [12,</ref><ref n tasks including detection [8,</ref>9,</ref>10]</ref>, segmentation [11,</ref>10]</ref>, video recognition [12,</ref>13]</ref>, and other high-level systems built on them. E.g., the Fast pe="bibr" target="#b12">13]</ref>, and other high-level systems built on them. E.g., the Fast/er and Mask R-CNN frameworks [8,</ref>9,</ref>10]</ref> use a batch size of 1 or 2 images because of higher resolution, where BN is "frozen" by transforming to a linear layer [3]</ref>; in general benefit from higherresolution input, so the batch size tends to be small in common practice (1 or 2 images/GPU [8,</ref>9,</ref>10,</ref>58]</ref>). As a result, BN is turned into a linear layer y = γ σ (x−µ)+β where µ and σ are pre-computed from the pre-trained mode fine-tunes BN (normalization is performed and not frozen) and found it works poorly (reducing ∼6 AP with a batch size of 2), so we ignore this variant.</p><p>We experiment on the Mask R-CNN baselines [10]</ref>, implemented in the publicly available codebase of Detectron [59]</ref>. We use the end-to-end variant with the same hyper-param x ) and instance segmentation (AP mask ).</p><p>Results of C4 backbone. Table 4</ref> shows the comparison of GN vs. BN * on Mask R-CNN using a conv 4 backbone ("C4" [10]</ref>). This C4 variant uses ResNet's layers of up to conv 4 to extract feature maps, and ResNet's conv 5 layers as the Region-of-Interest (RoI) heads for classifica
tablished as a very effective component in deep learning, largely helping push the frontier in computer vision [2,</ref>3]</ref> and beyond [4]</ref>. BN normalizes the features by the mean and variance computed within a (mini-)batch. This has been shown by many practices to ease optimization and enable very
error (by 10%) than BN with a batch size of 2.</p><p>As a result, many recent models [2,</ref>3,</ref>5,</ref>6,</ref>7]</ref> are trained with non-trivial batch sizes that are memory-consuming. The heavy reliance on BN's effectiveness to train model
h a regular batch size, GN is comparably good as BN (with a gap of ∼0.5%) and outperforms other normalization variants [17,</ref>18,</ref>19]</ref>. Moreover, although the batch size may change, GN can naturally transfer from pre-training to fine-tuning. GN shows improved results vs. its BN counterpart on educing the batch size can have dramatic impact on the estimated batch statistics.</p><p>Several normalization methods [17,</ref>18,</ref>19,</ref>33,</ref>34]</ref> have been proposed to avoid exploiting the batch dimension. Layer Normalization ="bibr" target="#b17">[18]</ref> performs BN-like computation but only for each sample (Figure 2</ref>). Instead of operating on features, Weight Normalization (WN) [19]</ref> proposes to normalize the filter weights. These methods do not suffer from the issues caused by the batch dimension, but they have not been able to approach B
"figure" target="#fig_1">2</ref>), that also avoid normalizing along the batch dimension. These methods are effective for training sequential models (RNN/LSTM [22,</ref>23]</ref>) or generative models (GANs [24,</ref>25]</ref>). But as we will show by experiments, both LN and
ion, textures. Their coefficients can be interdependent. In fact, a wellaccepted computational model in neuroscience is to normalize across the cell responses [46,</ref>47,</ref>48,</ref>49]</ref>, "with various receptive-field centers (covering the visual field) and with var
t misses the opportunity of exploiting the channel dependence.  Implementation. GN can be easily implemented by a few lines of code in PyTorch [50]</ref> and TensorFlow [51]</ref> where automatic differentiation is supported. Figure 3</ref> shows the code based on TensorFlow. In fact, we only need to s
computational model in neuroscience is to normalize across the cell responses [46,</ref>47,</ref>48,</ref>49]</ref>, "with various receptive-field centers (covering the visual field) and with various spatiotemporal frequency tunings" (p183, [46 d) and with various spatiotemporal frequency tunings" (p183, [46]</ref>); this can happen not only in the primary visual cortex, but also "throughout the visual system" [49]</ref>. Motivated by these works, we propose new generic group-wise normalization for deep neural networks.</p><p>Formulation. We first describe a general formulatio
ted statistics including latency, energy, the number of buffer accesses, buffer size requirement, etc. We validated the performance statistics of MAESTRO against cycle-accurate RTL simulation results 5</ref> and reported performance in a previous work 6</ref> with the accuracy of 96.1% on average. MAESTRO provides fast cost-benefit estima We present implementation details in our web page and open-source repository. ? We validated MAESTRO's performance model against RTL simulation and reported processing delay of two accelerators-MAERI 5</ref> and Eyeriss 6 when running VGG16 and AlexNet, respectively. The latency estimated by MAESTRO are within 3.9% absolute error of the cycle-accurate RTL simulation a ploying the adaptive approach, we could observe a potential 37% latency and 10% energy reduction. Such an optimization opportunity can be exploited by flexible accelerators like Flexflow 15 and MAERI 5</ref> or via heterogeneous accelerators that employ multiple subaccelerators with various mapping styles in a single DNN accelerator chip.</p></div> <div xmlns="http://
ze requirement, etc. We validated the performance statistics of MAESTRO against cycle-accurate RTL simulation results 5</ref> and reported performance in a previous work 6</ref> with the accuracy of 96.1% on average. MAESTRO provides fast cost-benefit estimation based on an analytical model, which took 493 ms to analyze the entire Resent5 sing the DSE tool, we explore the design space of KC-P and YR-P mapping accelerators. We set the area and power constraint as 16 mm 2 and 450 mW, which is the reported chip area and power of Eyeriss. 6</ref> We plot the entire design space we explored in Figure 4(c)</ref>. Whether an accelerator can achieve peak throughput depends on






reds of processing elements (PEs) and high energy efficiency by maximizing data reuse within PEs and on-chip scratchpads. [1]</ref>[2]</ref>[3]</ref>[4]</ref> The efficiency (performance and energy efficiency) of a DNN accelerator depends on three factors depicted in Figure <ref

d energy, respectively. We apply 256 PEs and 32 GBps NoC bandwidth. We use five different DNN models; Resnet50, 7 VGG16, 9 ResNeXt50, 10 MobileNetV2, 11</ref> and UNet. 12</ref> The right-most column presents the average results across models for each DNN operator type and the adaptive mapping case. We compare the number of input channe and energy, respectively. We apply 256 PEs and 32 GBps NoC bandwidth. We use five different DNN models; Resnet50, 7 VGG16, 9 ResNeXt50, 10 MobileNetV2,11</ref> and UNet.12</ref> The right-most column presents the average results across models for each DNN operator type and the adaptive mapping case. We compare the number of input channe
ck of effective metrics to measure structural perturbations. Following the progress in graph adversarial attacks, designing defense mechanisms or building robust variants of GNNs have become critical (Zhu et al. 2019)</ref>.</p><p>In this paper, we propose a new approach UM-GNN aimed at improving the robustness of GNN models, particularly against challenging poisonin opposed to deterministic vectors in GCN and GAT models. It employs a variance-based attention mechanism to attenuate the influence of neighbors with large variance (potentially corrupted). Following (Zhu et al. 2019)</ref>, we set hidden dimensions at 16 and assume a diagonal covariance for each node. For all baselines, we set the number of layers (2 layers) and oth fer strategy for achieving robustness to structural perturbations;</p><p>• Across a suite of global poisoning attacks, UM-GNN consistently outperforms existing methods including the recent Robust GCN (Zhu et al. 2019</ref>);</p><p>• UM-GNN achieves significantly lower misclassification rate (&gt; 50% improvement) against targeted attacks.</p></div> <div xmlns="http:/ NN), and provide details on the model training process.</p><p>While there exist very few GNN formulations for specifically defending against adversarial attacks, the recent robust GCN (RGCN) approach (Zhu et al. 2019</ref>) has been the most effective, when compared to standard GCN and GAT models. At its core, RGCN relies on using the aleatoric uncertainties in the g model uses a multi-head attention mechanism to learn the hidden representations for each node through a weighted aggregation of features in a closed neighborhood where the weights are trainable. RGCN (Zhu et al. 2019</ref>): This is a recently proposed ap-proach that explicitly enhances the robustness of GCNs. RGCN models node features as distributions as opposed to nce in performance compared to the baselines. In comparison, GAT appears to be the most sensitive to random structural perturbations and its low performance strongly corroborates with the findings in (Zhu et al. 2019</ref>).</p><p>(ii) DICE Attack: In this challenging attack, where the attacker can both delete and add edges, all baseline methods suffer from severe pe proximation of the given graph and showed that it can defend against specific types of graph attack (Zügner, Akbarnejad, and Günnemann 2018)</ref>. Recently, Zhu et al. (Zhu et al. 2019</ref>) introduced a robust variant of GCN based on a variance-weighted attention mechanism, and showed it to be effective against different types of att
learning, have produced state-of-the-art results in image analysis, language modeling and more recently with graph-structured data (Torng and Altman 2019). In particular, graph neural networks (GNNs) (Kipf and Welling 2017;</ref>Hamilton, Ying, and Leskovec 2017)</ref> have gained prominence due to their ability to effectively leverage "#b14">(Sen et al. 2008)</ref>. The documents are represented by nodes, and citations among the documents are encoded as undirected edges. We follow the typical transductive node classification setup (Kipf and Welling 2017;</ref>Veličković et al. 2018)</ref>, while using the standard train, test, and validation splits for our experiment /p><formula xml:id="formula_3">h i = ψ   j∈Ni α ij h j W   .<label>(2)</label></formula><p>Here, the message computation is parameterized by α ij , which can be a symmetric normalization constant (Kipf and Welling 2017)</ref> or a learnable attention weight (Veličković et al. 2018</ref>). The update function U is parameterized using 20)</ref>. While GNNs based on spectral convolutional approaches (Bruna et al. 2013;</ref>Defferrard, Bresson, and Vandergheynst 2016;</ref>Kipf and Welling 2017)</ref> have been widely adopted, there also exists models that implement convolutions directly using spatial neighborhoods <ref type="bibr" target=
tious edges to the graph before the model is trained. Though there exists a vast literature on adversarial attacks on images (Goodfellow, Shlens, and Szegedy 2014;</ref>Szegedy et al. 2013)</ref> and their countermeasures (Ren et al. 2020;</ref>Chakraborty et al. 2018)</ref>,
learning, have produced state-of-the-art results in image analysis, language modeling and more recently with graph-structured data (Torng and Altman 2019). In particular, graph neural networks (GNNs) (Kipf and Welling 2017;</ref>Hamilton, Ying, and Leskovec 2017)</ref> have gained prominence due to their ability to effectively leverage "#b14">(Sen et al. 2008)</ref>. The documents are represented by nodes, and citations among the documents are encoded as undirected edges. We follow the typical transductive node classification setup (Kipf and Welling 2017;</ref>Veličković et al. 2018)</ref>, while using the standard train, test, and validation splits for our experiment /p><formula xml:id="formula_3">h i = ψ   j∈Ni α ij h j W   .<label>(2)</label></formula><p>Here, the message computation is parameterized by α ij , which can be a symmetric normalization constant (Kipf and Welling 2017)</ref> or a learnable attention weight (Veličković et al. 2018</ref>). The update function U is parameterized using 20)</ref>. While GNNs based on spectral convolutional approaches (Bruna et al. 2013;</ref>Defferrard, Bresson, and Vandergheynst 2016;</ref>Kipf and Welling 2017)</ref> have been widely adopted, there also exists models that implement convolutions directly using spatial neighborhoods <ref type="bibr" target=
p>Here, the message computation is parameterized by α ij , which can be a symmetric normalization constant (Kipf and Welling 2017)</ref> or a learnable attention weight (Veličković et al. 2018</ref>). The update function U is parameterized using the learnable weights W and applies a non-linearity ψ.</p><p>As discussed earlier, our goal or Pubmed.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>GCN:</head><p>We use the GCN model, proposed by Kipf &amp; Welling, based on the message passing formulation in eqn. (2).</p><p>GAT (Veličković et al. 2018</ref>): This model uses a multi-head attention mechanism to learn the hidden representations for each node through a weighted aggregation of feat nly the features X as input. While we implement M using graph convolution layers as defined in eqn.</p><p>(2), it can be replaced using any other message passing strategy, e.g, graph attention layers (Veličković et al. 2018)</ref>. Given that all datasets we consider in our study contain vector-values defined at the nodes, we implement F as a fully connected network. d by nodes, and citations among the documents are encoded as undirected edges. We follow the typical transductive node classification setup (Kipf and Welling 2017;</ref>Veličković et al. 2018)</ref>, while using the standard train, test, and validation splits for our experiments (see Table 1</ref>).</p>
andergheynst 2016;</ref>Kipf and Welling 2017)</ref> have been widely adopted, there also exists models that implement convolutions directly using spatial neighborhoods (Duvenaud et al. 2015;</ref>Atwood and Towsley 2016;</ref>Hamilton, Ying, and Leskovec 2017)</ref>. The vulne
, Feng et al. adapted the conventional adversarial training approach to the case of graphs in order to make GNNs more robust (Goodfellow, Shlens, and Szegedy 2014;</ref>Feng et al. 2019</ref>). On the other hand, methods that rely on graph preprocessing have also been proposed -for example, in (Wu et al. 20
lows: A deep network is trained with dropout and even at test time the dropout is used to generate samples from the approximate posterior through Monte Carlo sampling. Interestingly, it was showed in (Gal and Ghahramani 2016)</ref> that the dropout inference minimizes the KL divergence between the approximated distribution and the posterior of a deep Gaussian process.
n their gradients. We choose FGA to show the superior performance of UM-GNN even against targeted attacks. The implementations for Mettack, PGD and FGA were based on the publicly available DeepRobust (Jin et al. 2020)</ref> library. Due to the lack of computationally efficient implementations, we could not generate these attacks on largescale graphs such as Pubmed.</ ity of GNNs to adversarial attacks was first studied in (Zügner, Akbarnejad, and Günnemann 2018)</ref>. Since then, several graph adversarial attacks have been proposed (Jin et al. 2020;</ref>Sun et al. 2018)</ref>. Adversarial attacks on graphs can be broadly categorized as follows:</p><p>(i) Attacker kno en proposed -for example, in (Wu et al. 2019)</ref>, edges with low Jaccard similarity between the constituent nodes were removed prior to training a GNN. Similarly, in (Jin et al. 2019)</ref>, explicit graph smoothing was performed by training on a family of graphs to defend against evasion attacks. Entezari et al. obtained a low rank
GCN and GAT baselines. In addition, we set the number of attention heads to 8 for GAT. We implemented all the baselines and the proposed approach using the Pytorch Deep Graph Library (version 0.5.1) (Wang et al. 2019</ref>). In our implementation of UM-GNN, the GNN model M was designed as a 2−layer GCN similar to the baseline and the surrogate F was a 3−layer FCN wi
GCN and GAT baselines. In addition, we set the number of attention heads to 8 for GAT. We implemented all the baselines and the proposed approach using the Pytorch Deep Graph Library (version 0.5.1) (Wang et al. 2019</ref>). In our implementation of UM-GNN, the GNN model M was designed as a 2−layer GCN similar to the baseline and the surrogate F was a 3−layer FCN wi
d as the "information intersection" across all the modalities, i.e., the amount of agreement shared by all the modalities.</p><p>Inspired by such an assumption and the fact that the Total Correlation [29]</ref> can measure the amount of information shared by M (M ≥ 2) variables, in this paper, we propose Total Correlation Gain (TCG), which is a function of classifier r method can avoid the trivial solution and can learn the optimal, i.e., the Bayesian Posterior classifiers of each modality.</p><p>Total Correlation/Mutual information maximization Total Correlation [29]</ref>, as an extension of Mutual Information, measures the amount of information shared by M (M ≥ 2) variables. There are several works in the literature that have
ettings.</p><p>The second branch of work [26,</ref>28,</ref>9,</ref>31,</ref>10,</ref>18]</ref> centers on learning joint representations that project unimodal representations all together into a multi-modal space in
[6]</ref>. [17,</ref>3,</ref>12,</ref>21,</ref>11]</ref> use weak classifiers trained by the labeled data from each modality to bootstrap each other by generating labels for the unlabeled data. However, the underlying
>9</ref> . We evaluate TCGM and the baseline methods on 3 datasets from Newsgroup: News-M2, News-M5, News-M10. They contain 500, 500, 1000 data points with 2, 5, 10 categories respectively. Following [33]</ref>, we use 60% for training, 20% for validation and 20% for testing for all of these three datasets.</p><p>Implementation details We synthesize two different lab for all of these three datasets.</p><p>Implementation details We synthesize two different label rates (the percentage of labeled data points in each modality): {10%, 30%} for each dataset. We follow [33]</ref> for classifiers. Adam with default parameters and learning rate γ u = 0.0001, γ l = 0.01 is used as the optimizer during training. Batch size is set to 32. We during training. Batch size is set to 32. We further compare with two additional baselines: VAT [24]</ref> uses adversarial training for semi-supervised learning; PVCC [33]</ref> that considers the consistency of data points under different modalities. As shown in Fig. 4</ref>, TCGM achieves the best
wo branches: (i) co-training strategy [6]</ref>; and (ii) learning joint representation across modalities in an unsupervised way [26,</ref>28]</ref>. These methods suffer from either too strong assumptions or loss of information during fusing. Specifically, the co-training strategy relies largely on the "co sumes the same conditional distributions for data point labels in each modality, may not be consistent with the real settings.</p><p>The second branch of work [26,</ref>28,</ref>9,</ref>31,</ref>10,</ref>18]</ref> ce
ised learning of representations [14]</ref>, learning node representations within graph-structured data [30]</ref>). Kong and Schoenebeck [19]</ref> provide another mutual information estimator in the co-training framework for the peer prediction mechanism, which has been combined with deep neural networks f type="figure">.</ref> 2. To the best of our knowledge, we are the first to theoretically prove the identification of ground truth classifiers on semi-supervised multi-modality data, by generalizing [19,</ref>8]</ref> that can only handle two views in multi-view scenario. The high-level spirit is designing TC-induced loss over classifie
[6]</ref>. [17,</ref>3,</ref>12,</ref>21,</ref>11]</ref> use weak classifiers trained by the labeled data from each modality to bootstrap each other by generating labels for the unlabeled data. However, the underlying
k [26,</ref>28,</ref>9,</ref>31,</ref>10,</ref>18]</ref> centers on learning joint representations that project unimodal representations all together into a multi-modal space in an unsupervised way and then using the
ised learning of representations [14]</ref>, learning node representations within graph-structured data [30]</ref>). Kong and Schoenebeck [19]</ref> provide another mutual information estimator in the co-training framework for the peer prediction mechanism, which has been combined with deep neural networks f type="figure">.</ref> 2. To the best of our knowledge, we are the first to theoretically prove the identification of ground truth classifiers on semi-supervised multi-modality data, by generalizing [19,</ref>8]</ref> that can only handle two views in multi-view scenario. The high-level spirit is designing TC-induced loss over classifie
gure" target="#fig_3">3</ref>, our method TCGM has competitive performance compared to well established clustering algorithms K-means++ [2]</ref> and spectral clustering [25]</ref>. Based on the promising unsupervised learning result, as shown by the light blue line (the top line) in Figure 3</ref>, our
div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">News Classification</head><p>Dataset Newsgroup [5]8</ref> is a group of news classification datasets. Following [16]</ref>, each data point has three modalities, PAM, SMI and UMI, collected from three different preprocessing steps 9</ref> . We eva
implementations approximate the loss by reducing the number of comparisons to random subsets of images during training [10,</ref>24,</ref>56]</ref>. An alternative to approximate the loss is to approximate the task-that is to relax the instance discrimination problem. For example, clustering-based methods d><p>Instance and contrastive learning. Instance-level classification considers each image in a dataset as its own class [5,</ref>16,</ref>56]</ref>. Dosovitskiy et al. [16]</ref> assign a class explicitly to each image and learn a linear classifier with as many classes as ima and the codes are learned online, allowing our method to scale to potentially unlimited amounts of data. In addition, SwAV works with small and large batch sizes and does not need a large memory bank [56]</ref> or a momentum encoder [24]</ref>.</p><p>Besides our online clustering-based method, we also propose an improvement to the image " target="#b15">[16]</ref> assign a class explicitly to each image and learn a linear classifier with as many classes as images in the dataset. As this approach becomes quickly intractable, Wu et al. [56]</ref> mitigate this issue by replacing the classifier with a memory bank that stores previously-computed representations. They rely on noise contrastive estimation /p><p>In this section, we describe an alternative where we enforce consistency between codes from different augmentations of the same image. This solution is inspired by contrastive instance learning [56]</ref> as we do not consider the codes as a target, but only enforce consistent mapping between views of the same image. Our method can be interpreted as a way of co two features capture the same information, it should be possible to predict the code from the other feature. A similar comparison appears in contrastive learning where features are compared directly [56]</ref>. In Fig. 1</ref>, we illustrate the relation between contrastive learning and our method.</p></div> <div xmlns="http://www. rmula><p>t , where p</p><formula xml:id="formula_2">(k) t = exp 1 τ z t c k k exp 1 τ z t c k . (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where τ is a temperature parameter [56]</ref>. Taking this loss over all the images and pairs of data augmentations leads to the following loss function for the swapped prediction problem:</p><formula xml speed up training, we choose to use the features computed during the previous epoch instead of dedicating pass forwards to the assignments. This is similar to the memory bank introduced by Wu et al. [56]</ref>, without momentum.</p><p>Assignment phase in DeepCluster-v2. DeepCluster-v2 uses spherical k-means to get pseudolabels. In particular, pseudo-labels q are obt rmance compared to training from scratch.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Image classification with KNN classifiers on ImageNet</head><p>Following previous work protocols [56,</ref>66]</ref>, we evaluate the quality of our unsupervised features with K-nearest neighbor (KNN) classifiers on ImageNet. We get fe
ur method to scale gracefully to any dataset size.</p><p>Handcrafted pretext tasks. Many self-supervised methods manipulate the input data to extract a supervised signal in the form of a pretext task [1,</ref>14,</ref>30,</ref>32,</ref>34,</ref><
"#b41">42]</ref>. Many recent state-of-the-art methods build upon the instance discrimination task that considers each image of the dataset (or "instance") and its transformations as a separate class [16]</ref>. This task yields representations that are able to discriminate between different images, while achieving some invariance to image transformations. Recent sel fication considers each image in a dataset as its own class [5,</ref>16,</ref>56]</ref>. Dosovitskiy et al. [16]</ref> assign a class explicitly to each image and learn a linear classifier with as many classes as images in the dataset. As this approach becomes quickly intracta rg/ns/1.0"><head n="2">Related Work</head><p>Instance and contrastive learning. Instance-level classification considers each image in a dataset as its own class [5,</ref>16,</ref>56]</ref>. Dosovitskiy et al. [16]</ref> assign a class explicitly to each image and learn a linea
23">24]</ref>. In Fig. 4</ref> (right), we explore the limits of pretraining as we increase the model capacity. We consider the variants of the ResNeXt architecture [59]</ref> as in Mahajan et al. [39]</ref>. We compare SwAV with supervised models trained from scratch on ImageNet. For all models, SwAV
31]</ref> for an exhaustive and detailed review of this literature. Of particular interest, Misra and van der Maaten [42]</ref> propose to encode the jigsaw puzzle task [44]</ref> as an invariant for contrastive learning. Jigsaw tiles are non-overlapping crops with small resolution that cover only part (∼20%) of the entire image area. I
ike SimCLR, we see that SwAV reduces the difference with supervised models even further. Indeed, for large architectures, our method shrinks the gap with supervised training to 0.6%. on the Places205 [65]</ref>, VOC07 [17]</ref>, and iNaturalist2018 [52]</ref> datasets. Our method outperforms supervised fe
o surpass ImageNet supervised features on these datasets. Second, we report network finetuning on object detection on VOC07+12 using Faster R-CNN [48]</ref> and on COCO [36]</ref> with DETR [6]</ref>. DETR is a recent object detection framework that reaches competitive performance with Faster R-CNN while be ed over 5 independant runs.</p><p>Object Detection on COCO. We test the generalization of our ResNet-50 features trained on ImageNet with SwAV by transferring them to object detection on COCO dataset [36]</ref> with DETR framework [6]</ref>. DETR is a recent object detection framework that relies on a transformer encoderdecoder architect by replacing the ImageNet supervised network with our model. (2) Object detection with finetuned features on VOC07+12 trainval using Faster R-CNN [48]</ref> and on COCO [36]</ref> using DETR [6]</ref>. In this </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 More detection metrics for object de p-1 accuracy on all datasets except VOC07 where we report mAP. (2) Object detection with finetuned features on VOC07+12 trainval using Faster R-CNN[48]</ref> and on COCO[36]</ref> using DETR[6]</ref>. We report the most standard detection metrics for these datasets: AP 50 on VOC07+12 and AP on COCO.</figDes
. Note that SwAV is the first self-supervised method to surpass ImageNet supervised features on these datasets. Second, we report network finetuning on object detection on VOC07+12 using Faster R-CNN [48]</ref> and on COCO [36]</ref> with DETR [6]</ref>. DETR is a recent object detection framework that reac odels for 28 epochs and on iNat18 for 84 epochs. We report the top-1 accuracy computed using the 224 × 224 center crop on the validation set.</p><p>Object Detection on VOC07+12. We use a Faster R-CNN [48]</ref> model as implemented in Detec-tron2 [55]</ref> and follow the finetuning protocol from He et al. <ref type="bibr" target="#b23" r training a linear classifier on top of frozen representations on different datasets while on the right panel we evaluate the features by finetuning a ResNet-50 on object detection with Faster R-CNN [48]</ref> and DETR [6]</ref>. Overall, we observe on Table 6</ref> that SwAV is the first self-supervise se this model so other researchers might also benefit by replacing the ImageNet supervised network with our model. (2) Object detection with finetuned features on VOC07+12 trainval using Faster R-CNN [48]</ref> and on COCO [36]</ref> using DETR [6]</ref>. In this </p></div> <div xmlns="http://www.tei-c.org/ ad><p>In Table 7</ref> and Table 8</ref>, we evaluate the features by finetuning a ResNet-50 on object detection with Faster R-CNN [48]</ref> and DETR [6]</ref> and report more detection metrics compared to Table 6</ref>. We observe in lassification on top of frozen features. We report top-1 accuracy on all datasets except VOC07 where we report mAP. (2) Object detection with finetuned features on VOC07+12 trainval using Faster R-CNN[48]</ref> and on COCO[36]</ref> using DETR[6]</ref>. We report the most standard detection metrics for thes tp://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>More detection metrics for object detection on VOC07+12 with finetuned features using Faster R-CNN[48]</ref>.</figDesc><table><row><cell>Method</cell><cell cols="3">AP all AP 50 AP 75</cell></row><row><cell>Supervised</cell><cell>53.5</cell><cell>81.3</cell><cell>58.
proximate the task-that is to relax the instance discrimination problem. For example, clustering-based methods discriminate between groups of images with similar features instead of individual images [7]</ref>. The objective in clustering is tractable, but it does not scale well with the dataset as it requires a pass over the entire dataset to form image "codes" (i.e. der model. We also show that our multi-crop strategy is general, and improves the performance of different self-supervised methods, namely SimCLR [10]</ref>, DeepCluster [7]</ref>, and SeLa [2]</ref>, between 2% and 4% top-1 accuracy on ImageNet. Overall, we make the following contributions:</p><p>• We propos " target="#b28">29,</ref>57,</ref>60,</ref>61,</ref>66]</ref>. Caron et al. [7]</ref> show that k-means assignments can be used as pseudo-labels to learn visual representations. This method scales to large uncurated dataset and can be used for pr ods. Besides SwAV, we consider supervised learning, SimCLR and two clustering-based models, DeepCluster-v2 and SeLa-v2. The last two are obtained by applying the improvements of SimCLR to DeepCluster [7]</ref> and SeLa [2]</ref> (see details in the Appendix). We see that the multi-crop strategy consistently improves the performance for al ur framework learns from a different signal from "offline" approaches that attribute a pseudo-label to each instance while considering the full dataset and then predict these labels (like DeepCluster [7]</ref> for example). Indeed, the prototypes in SwAV are not strongly encouraged to be categorical and random fixed prototypes work almost as well. Rather, they help co backpropragation.</p><p>Clustering for deep representation learning. Our work is also related to clustering-based methods [2,</ref>4,</ref>7,</ref>8,</ref>19,</ref>29,</ref>57,</ref><ref ]</ref> we keep the soft assignment produced by the Sinkhorn-Knopp algorithm [13]</ref> instead of approximating it into a hard assignment. Besides, unlike Caron et al. [7,</ref>8]</ref> and Asano et al. [2]</ref>, we obtain online assignments which allows our method to scale gr eatures in an online fashion without supervision. To that effect, we propose an online clustering-based self-supervised method. Typical clustering-based methods [2,</ref>7]</ref> are offline in the sense that they alternate between a cluster assignment step where image features of the entire dataset are clustered, and a training step wher e provide details on our improved implementation of clustering-based approaches DeepCluster-v2 and SeLa-v2 compared to their corresponding original publications [2,</ref>7]</ref>. These two methods follow the same pipeline: they alternate between pseudo-labels generation ("assignment 0 100 200 300 400 epochs   phase") and training the net nments q for each instance of the dataset. For both methods, this implies having access to feature representations z for the entire dataset. Both original works [2,</ref>7]</ref> perform regularly a pass forward on the whole dataset to get these features. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1
o surpass ImageNet supervised features on these datasets. Second, we report network finetuning on object detection on VOC07+12 using Faster R-CNN [48]</ref> and on COCO [36]</ref> with DETR [6]</ref>. DETR is a recent object detection framework that reaches competitive performance with Faster R-CNN while be ed over 5 independant runs.</p><p>Object Detection on COCO. We test the generalization of our ResNet-50 features trained on ImageNet with SwAV by transferring them to object detection on COCO dataset [36]</ref> with DETR framework [6]</ref>. DETR is a recent object detection framework that relies on a transformer encoderdecoder architect by replacing the ImageNet supervised network with our model. (2) Object detection with finetuned features on VOC07+12 trainval using Faster R-CNN [48]</ref> and on COCO [36]</ref> using DETR [6]</ref>. In this </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 More detection metrics for object de p-1 accuracy on all datasets except VOC07 where we report mAP. (2) Object detection with finetuned features on VOC07+12 trainval using Faster R-CNN[48]</ref> and on COCO[36]</ref> using DETR[6]</ref>. We report the most standard detection metrics for these datasets: AP 50 on VOC07+12 and AP on COCO.</figDes

approaches, existing work uses embedding pre-computing, either for documents [23,</ref>29]</ref> or for member profiles (personalization) [10]</ref>. It requires a huge amount of hard disk space to store the embedding, as well as a sophisticated system design to refresh the embeddings when there are any doc
the greatest extent, as the query word embeddings can incorporate many matching signals in documents. This approach, in the category of interaction based models [7,</ref>11,</ref>28]</ref>, comes with a significant challenge in online serving: a) the heavy BERT computation on the fly is not affordable in a nsional vector, cannot summarize all the information in the original text.</p><p>To overcome the issue, interaction based models compare each part of the query with each part of the document. In DRMM [11]</ref>, a cosine similarity is computed for each word embedding in the query and each word embedding in the document. The final document score is computed based on t
defined in Table 3</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Baseline Models.</head><p>The production models are trained with XGBoost [5]</ref>. The hyper-parameters (pairwise vs listwise, number of trees, etc) are optimized by both manual tuning and auto hyper-parameter tuning, which are proven effecti
ext-MLP (DeText with only MLP and LTR layers on traditional features). Since DeText-MLP does not use any text embedding, it has comparable results as XGBoost, which is also observed in previous works [17]</ref>. For DeText-CNN, it consistently outperforms the strong production baseline model by a large margin. DeText-LiBERT is able to further improve the NDCG scores.
and the deep semantics of natural language data through embedding representation [13]</ref>. Moreover, to enhance contextual modeling, contextual embedding such as BERT [8]</ref> has been proposed and extensively evaluated on various NLP tasks with significant improvements over existing techniques.</p><p>However, promoting the power of B gram. K-NRM [28]</ref> and Conv-KNRM [7]</ref> extended DRMM by kernel pooling and pairwise ngram similarity, respectively. Recently, BERT [8]</ref> has shown superior performance [6,</ref>18,</ref>22]</ref> in rankin formance.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">DeText-BERT for Ranking</head><p>To use BERT in ranking model, we follow the approach of finetuning on pretrained BERT model [8]</ref>: The BERT model is firstly pretrained on unsupervised data, and then fine-tuned in ranking framework with supervised clickthrough data. To extract the text embe ain specific data, and then fine tuned the parameters during DeText-LiBERT training.</p><p>In order to reduce model serving latency, we use a smaller architecture compared to Google's BERT base model [8]</ref>: (6 layers, 512 hidden, 8 heads). The resulting model has 34 million parameters, 1/3 of Google's BERT BASE model. We also use less data (around 1/5) than BERT B
ext-MLP (DeText with only MLP and LTR layers on traditional features). Since DeText-MLP does not use any text embedding, it has comparable results as XGBoost, which is also observed in previous works [17]</ref>. For DeText-CNN, it consistently outperforms the strong production baseline model by a large margin. DeText-LiBERT is able to further improve the NDCG scores.
ower of contextual modeling in BERT to the greatest extent, as the query word embeddings can incorporate many matching signals in documents. This approach, in the category of interaction based models [7,</ref>11,</ref>28]</ref>, comes with a significant challenge in online serving: a) the heavy BERT computa uery and each word embedding in the document. The final document score is computed based on the pairwise word similarity score histogram. K-NRM [28]</ref> and Conv-KNRM [7]</ref> extended DRMM by kernel pooling and pairwise ngram similarity, respectively. Recently, BERT [8]</ref> has shown superior performan
sed approaches are generally used for production.</p><p>With representation based approaches, existing work uses embedding pre-computing, either for documents [23,</ref>29]</ref> or for member profiles (personalization) [10]</ref>. It requires a huge amount of hard disk space to store the embedding, as well
ext-MLP (DeText with only MLP and LTR layers on traditional features). Since DeText-MLP does not use any text embedding, it has comparable results as XGBoost, which is also observed in previous works [17]</ref>. For DeText-CNN, it consistently outperforms the strong production baseline model by a large margin. DeText-LiBERT is able to further improve the NDCG scores.
ower of contextual modeling in BERT to the greatest extent, as the query word embeddings can incorporate many matching signals in documents. This approach, in the category of interaction based models [7,</ref>11,</ref>28]</ref>, comes with a significant challenge in online serving: a) the heavy BERT computa uery and each word embedding in the document. The final document score is computed based on the pairwise word similarity score histogram. K-NRM [28]</ref> and Conv-KNRM [7]</ref> extended DRMM by kernel pooling and pairwise ngram similarity, respectively. Recently, BERT [8]</ref> has shown superior performan
defined in Table 3</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Baseline Models.</head><p>The production models are trained with XGBoost [5]</ref>. The hyper-parameters (pairwise vs listwise, number of trees, etc) are optimized by both manual tuning and auto hyper-parameter tuning, which are proven effecti
ore, researchers have incorporated rich contextual information (such as item attributes) to neural sequential recommenders [4,</ref>6,</ref>29]</ref>. It has been demonstrated that contextual information is important to consider for improving the performance of sequential recommender systems.</p><p>Although S 3 -Rec, the L AAP loss and L M AP loss aim to fuse attribute with items or sequential contexts, which is able to achieve the same effect as previous methods [16,</ref>29]</ref>. Besides, the pre-trained data representations can be also applied to improve existing methods.  1</ref>.</p><p>(1) Meituan<r s are used as attributes.</p><p>For all datasets, we group the interaction records by users and sort them by the interaction timestamps ascendingly. Following [21,</ref>29]</ref>, we only keep the 5-core datasets, and filter unpopular items and inactive users with fewer than five interaction records.</p></div> <div xmlns="http://www.tei HR@k), topk Normalized Discounted Cumulative Gain (NDCG@k), and Mean Reciprocal Rank (MRR) to evaluate the performance, which are widely used in related works [21,</ref>29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works [8,</ref><ref t items. To tackle this problem, TransFM [16]</ref> utilized Factorization Machines to incorporate arbitrary real-valued features to the sequential recommendation. FDSA [29]</ref> employed a feature-level self-attention block to leverage the attribute information about items in user history. Despite the remarkable success of these seque arget="#b20">21]</ref> except that it can also utilize bidirectional sequential information.</p><p>Attribute-aware sequential models such as TransFM [16]</ref> and FDSA [29]</ref> leverage the contextual features to improve the sequential recommender models, in which these features are treated as auxiliary information to enhance the rep ance.</p><p>(10) SASRec F is our extension of SASRec, which concatenates the representations of item and attribute as the input to the model. ( 11</ref>) FDSA [29]</ref> constructs a feature sequence and uses a featurelevel self-attention block to model the feature transition patterns. This is the state-of-the-art model in seq
br" target="#b17">[18]</ref> and reinforcement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref>24]</ref> for sequential recommendation. However, these approaches neglect the rich attribute information about items. To tackle context-aware representation of each item in an item sequence. It is beneficial to incorporate context from both directions for sequence representation learning [1,</ref>23]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Prediction Layer.</head><p>In the final layer of S 3 -Rec, we calculate the user's preferen ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works [8,</ref>19,</ref>23]</ref>, we apply the leave-oneout strategy for evaluation. Concretely, for each user interaction sequence, the last item is used as the test data, the item before the SASRec [8]</ref> is a self-attention based sequential recommendation model, which uses the multi-head attention mechanism to recommend the next item.</p><p>(7) BERT4Rec [23]</ref> uses a Cloze objective loss for sequential recommendation by the bidirectional self-attention mechanism.</p><p>(8) HGN [13]</re
e the final performance, while the association or fusion between context data and sequence data has not been well captured in data representations. As shown in increasing evidence from various fields [1,</ref>5,</ref>10]</ref>, effective data representation (e.g., pre-trained contextualized embedding) has bee elop more effective sequential recommender systems.</p><p>To address the above issues, we borrow the idea of self-supervised learning for improving sequential recommendation. Self-supervised learning [1,</ref>15]</ref> is a newly emerging paradigm, which aims to let the model learn from the intrinsic structure of the raw data. A general ribute, item, and sequence are still not utilized and modeled sufficiently.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Self-supervised Learning</head><p>Self-supervised learning [1,</ref>5,</ref>15]</ref> aims at training a network on an auxiliary objective where the ground-truth sample pervised objectives have been introduced to use non-visual but intrinsically correlated features to guide the visual feature learning [5]</ref>. As for language modeling [1,</ref>15]</ref>, it is a popular self-supervised objective for natural language processing, where the model learns to predict the next w mechanism to acquire the bidirectional context-aware representation of each item in an item sequence. It is beneficial to incorporate context from both directions for sequence representation learning [1,</ref>23]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Prediction Layer.</head><p>In the final layer of S 3 predict the next word or sentence given the previous sequences. The learned representations of words or sequences can improve the performance of downstream tasks such as machine reading comprehension [1]</ref> and natural language understanding [10]</ref>.</p><p>Mutual information maximization [5,</ref><ref t ered as different views of the input. By capturing the multi-view correlation, we unify these self-supervised learning objectives with the recently proposed pretraining framework in language modeling [1]</ref>.</p><p>The overview of S 3 -Rec is presented in Fig. 1</ref>. In the following sections, we first introduce the base model of efore the current time step can be utilized, thus we apply the mask operation for the output of the multi-head self-attention function to remove all connections between Q i and K i . Inspired by BERT [1]</ref>, at the pre-training stage, we remove the mask mechanism to acquire the bidirectional context-aware representation of each item in an item sequence. It is benef in an item sequence from left to right. While it is noted that the entire interaction sequence is indeed observed by the model in the training process. Inspired by the masked language model like BERT [1]</ref>, we propose to model the bidirectional information in item sequence by a Cloze task. For our task, the Cloze setting is described as below: at each training ste
accurately characterize user interests and provide high-quality recommendations, the task of sequential recommendation has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendati ibr" target="#b19">20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivat bility matrix and utilized it to predict the next item given the last interaction of a user. A series of works follow this line and extend it for high-order MCs [4,</ref>8,</ref>24]</ref>. With the development of the neural networks, Hidasi et al. [3]</ref> firstly introduced Ga t contains.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPROACH 4.1 Overview</head><p>Existing studies [3,</ref>4,</ref>8,</ref>24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspire rmula_21">f (C i t , a) = σ F ⊤ t • W MAP • e a ,<label>(15)</label></formula><p>where W MAP ∈ R d ×d is a parameter matrix to learn. Note that existing methods [4,</ref>8,</ref>24]</ref> seldom directly model the correlation between the sequential context and attribute information. While, we would like to e s methods using recurrent neural networks (RNNs) [3]</ref>, convolutional neural networks (CNNs) [24]</ref>, and self-attention mechanisms [8]</ref> have been proposed to learn good representations of user preference and characterize sequential user-item interactions.</p><p>Furthermore, researchers have inco is end, in this paper, we propose a novel Self-Supervised learning approach to improve Sequential Recommendation with MIM, which is called S 3 -Rec. Based on a self-attentive recommender architecture [8]</ref>, we propose to first pre-train the sequential recommender with self-supervised signals and then fine-tune the model parameters according to the recommendation t s presented in Fig. 1</ref>. In the following sections, we first introduce the base model of our proposed approach that is developed on the Transformer architecture [8]</ref>. Then, we will describe how we utilize the correlation signals among attributes, items, segments, and sequences to enhance the data representations based on the teraction as additional supervision signals to enhance data representations instead of making predictions.</p><p>Sequential models such as GRU4Rec [21]</ref> and SASRec [8]</ref> mainly focus on modeling the sequential dependencies between contextual items and the target item in a left-to-right order. S 3 -Rec additionally incorporates a e="bibr" target="#b23">[24]</ref> is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.</p><p>(6) SASRec [8]</ref> is a self-attention based sequential recommendation model, which uses the multi-head attention mechanism to recommend the next item.</p><p>(7) BERT4Rec <ref typ s.</p><p>For our proposed S 3 -Rec, we set the number of the self-attention blocks and the attention heads as 2. The dimension of the embedding is 64, and the maximum sequence length is 50 (following [8]</ref>). Note that our training phase contains two stages (i.e., pre-training and fine-tuning stage), the learned parameters in the pre-training stage are used to init 17]</ref>, copy mechanism [18]</ref> and reinforcement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref>24]</ref> for sequential recommendation. However, these approaches neglect the rich attrib of self-supervised learning signals for enhancing data representations. In particular, the masked item prediction loss L M I P in Eq. 12 has a similar effect to capture sequential dependencies as in [8,</ref>21]</ref> except that it can also utilize bidirectional sequential information.</p><p>Attribute-aware sequential models such as Tr s [21,</ref>29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works [8,</ref>19,</ref>23]</ref>, we apply the leave-oneout strategy for evaluation. Concretely, for each user in remaining data is used for training. Since the item set is large, it is time-consuming to use all items as candidates for testing. Following the common strategy [7,</ref>8]</ref>, we pair the ground-truth item with 99 randomly sampled negative items that the user has not interacted with. We calculate all metrics according to the ranking o
arget="#b3">[4]</ref>, memory networks [6,</ref>7]</ref>, hierarchical structures [17]</ref>, copy mechanism [18]</ref> and reinforcement learning [27]</ref>, etc. There are also studies that leverage other architectures <ref type="bibr" target="#
contributions are summarized as follows: (1) To the best of our knowledge, it is the first time that self-supervised learning with MIM has been applied to improve the sequential recommendation task; (2)</ref> We propose four self-supervised optimization objectives to maximize the mutual information of context information in different forms or granularities; (3) Exten l in practice is InfoNCE [10,</ref>12,</ref>25]</ref>, which is based on Noise Contrastive Estimation (NCE) [2]</ref>. InfoNCE is defined as:</p><formula xml:id="formula_2">E p(X,Y ) [f θ (x, y) − E q( Ỹ ) [log ỹ ∈ Ỹ exp f θ (x, ỹ)]] + log | Ỹ |, (2)</formula><p>where x and y a
user-item interactions.</p><p>Furthermore, researchers have incorporated rich contextual information (such as item attributes) to neural sequential recommenders [4,</ref>6,</ref>29]</ref>. It has been demonstrated that contextual information is important to consider for improving the performance of sequentia Units (GRU) to the session-based recommendation and a surge of following variants modified this model by introducing pair-wise loss functions [4]</ref>, memory networks [6,</ref>7]</ref>, hierarchical structures [17]</ref>, copy mechanism [18]</re
mend the next item.</p><p>(7) BERT4Rec [23]</ref> uses a Cloze objective loss for sequential recommendation by the bidirectional self-attention mechanism.</p><p>(8) HGN [13]</ref> is recently proposed and adopts hierarchical gating networks to capture long-term and short-term user interests.</p><p>(9) GRU4Rec F <ref type="bibr" target="
has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref><ref type="bibr" target="#b20" "bibr" target="#b23">24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivation has been extensively explored with deep learning. Various methods using re ct the next item given the last interaction of a user. A series of works follow this line and extend it for high-order MCs [4,</ref>8,</ref>24]</ref>. With the development of the neural networks, Hidasi et al. [3]</ref> firstly introduced Gated Recurrent Units (GRU) to the sessi cement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref>24]</ref> for sequential recommendation. However, these approaches neglect the rich attribute information about items. To tackle this problem, TransFM <ref type="bibr" t ://www.tei-c.org/ns/1.0"><head n="4">APPROACH 4.1 Overview</head><p>Existing studies [3,</ref>4,</ref>8,</ref>24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspired by recent progress with MIM <ref typ MAP • e a ,<label>(15)</label></formula><p>where W MAP ∈ R d ×d is a parameter matrix to learn. Note that existing methods [4,</ref>8,</ref>24]</ref> seldom directly model the correlation between the sequential context and attribute information. While, we would like to explicitly model the correlation to der Such motivation has been extensively explored with deep learning. Various methods using recurrent neural networks (RNNs) [3]</ref>, convolutional neural networks (CNNs) [24]</ref>, and self-attention mechanisms [8]</ref> have been proposed to learn good representations of user preference and characterize se pe="bibr" target="#b2">[3]</ref> applies GRU to model user click sequence for session-based recommendation. We represent the items using embedding vectors rather than one-hot vectors.</p><p>(5) Caser [24]</ref> is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.</p><p>(6)
ref>29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works [8,</ref>19,</ref>23]</ref>, we apply the leave-oneout strategy for evaluation. Concretely, for each user interaction sequence, the last item is us
and provide high-quality recommendations, the task of sequential recommendation has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods <ref type="bibr" target="#b xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Sequential Recommendation</head><p>Early works on sequential recommendation are based on the Markov Chain assumption. MC-based methods [20]</ref> estimated an item-item transition probability matrix and utilized it to predict the next item given the last interaction of a user. A series of works follow t models. This approach is quite general so that many existing methods can be included in this framework. We make a brief discussion below.</p><p>Feature-based approaches such as Factorization Machine [20]</ref> and AutoInt [22]</ref> mainly learn data representations through the interaction of context features. The final prediction is m oposed approach with the following eleven baseline methods:</p><p>(1) PopRec is a non-personalized method that ranks items according to popularity measured by the number of interactions.</p><p>(2) FM [20]</ref> characterizes the pairwise interactions between variables using factorized model.</p><p>(3) AutoInt [22]</ref> utilizes the mul
contributions are summarized as follows: (1) To the best of our knowledge, it is the first time that self-supervised learning with MIM has been applied to improve the sequential recommendation task; (2)</ref> We propose four self-supervised optimization objectives to maximize the mutual information of context information in different forms or granularities; (3) Exten l in practice is InfoNCE [10,</ref>12,</ref>25]</ref>, which is based on Noise Contrastive Estimation (NCE) [2]</ref>. InfoNCE is defined as:</p><formula xml:id="formula_2">E p(X,Y ) [f θ (x, y) − E q( Ỹ ) [log ỹ ∈ Ỹ exp f θ (x, ỹ)]] + log | Ỹ |, (2)</formula><p>where x and y a
s, the task of sequential recommendation has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref><ref type="bibr" target="#b7 "bibr" target="#b20">21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivation has been extensively explored with is incorporated, the involved parameters are also learned through the only optimization objective. It has been found that such an optimization way is easy to suffer from issues such as data sparsity [21,</ref>22]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2008.07873v1 [cs.IR] 18 Aug 2020</head><p>Second, they the tags of the artists given by the users are used as attributes.</p><p>For all datasets, we group the interaction records by users and sort them by the interaction timestamps ascendingly. Following [21,</ref>29]</ref>, we only keep the 5-core datasets, and filter unpopular items and inactive users with fewer than five interaction reco ics.</head><p>We employ top-k Hit Ratio (HR@k), topk Normalized Discounted Cumulative Gain (NDCG@k), and Mean Reciprocal Rank (MRR) to evaluate the performance, which are widely used in related works [21,</ref>29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works <r major difference in our work is to utilize feature interaction as additional supervision signals to enhance data representations instead of making predictions.</p><p>Sequential models such as GRU4Rec [21]</ref> and SASRec [8]</ref> mainly focus on modeling the sequential dependencies between contextual items and the target item in a left r enhancing data representations. In particular, the masked item prediction loss L M I P in Eq. 12 has a similar effect to capture sequential dependencies as in [8,</ref>21]</ref> except that it can also utilize bidirectional sequential information.</p><p>Attribute-aware sequential models such as TransFM [1
are also learned through the only optimization objective. It has been found that such an optimization way is easy to suffer from issues such as data sparsity [21,</ref>22]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2008.07873v1 [cs.IR] 18 Aug 2020</head><p>Second, they overemphasize the final performance, whi xisting methods can be included in this framework. We make a brief discussion below.</p><p>Feature-based approaches such as Factorization Machine [20]</ref> and AutoInt [22]</ref> mainly learn data representations through the interaction of context features. The final prediction is made according to the actual interaction results betwee rity measured by the number of interactions.</p><p>(2) FM [20]</ref> characterizes the pairwise interactions between variables using factorized model.</p><p>(3) AutoInt [22]</ref> utilizes the multi-head self-attentive neural network to learn the feature interaction.</p><p>(4) GRU4Rec [3]</ref> applies GRU
has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref><ref type="bibr" target="#b20" "bibr" target="#b23">24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivation has been extensively explored with deep learning. Various methods using re ct the next item given the last interaction of a user. A series of works follow this line and extend it for high-order MCs [4,</ref>8,</ref>24]</ref>. With the development of the neural networks, Hidasi et al. [3]</ref> firstly introduced Gated Recurrent Units (GRU) to the sessi cement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref>24]</ref> for sequential recommendation. However, these approaches neglect the rich attribute information about items. To tackle this problem, TransFM <ref type="bibr" t ://www.tei-c.org/ns/1.0"><head n="4">APPROACH 4.1 Overview</head><p>Existing studies [3,</ref>4,</ref>8,</ref>24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspired by recent progress with MIM <ref typ MAP • e a ,<label>(15)</label></formula><p>where W MAP ∈ R d ×d is a parameter matrix to learn. Note that existing methods [4,</ref>8,</ref>24]</ref> seldom directly model the correlation between the sequential context and attribute information. While, we would like to explicitly model the correlation to der Such motivation has been extensively explored with deep learning. Various methods using recurrent neural networks (RNNs) [3]</ref>, convolutional neural networks (CNNs) [24]</ref>, and self-attention mechanisms [8]</ref> have been proposed to learn good representations of user preference and characterize se pe="bibr" target="#b2">[3]</ref> applies GRU to model user click sequence for session-based recommendation. We represent the items using embedding vectors rather than one-hot vectors.</p><p>(5) Caser [24]</ref> is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.</p><p>(6)
mend the next item.</p><p>(7) BERT4Rec [23]</ref> uses a Cloze objective loss for sequential recommendation by the bidirectional self-attention mechanism.</p><p>(8) HGN [13]</ref> is recently proposed and adopts hierarchical gating networks to capture long-term and short-term user interests.</p><p>(9) GRU4Rec F <ref type="bibr" target="
24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspired by recent progress with MIM [5,</ref>28]</ref>, we take a different perspective to develop neural sequential recommenders by maximizing the mutual information among different views of the raw data.</p><p>Th
has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref><ref type="bibr" target="#b20" "bibr" target="#b23">24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivation has been extensively explored with deep learning. Various methods using re ct the next item given the last interaction of a user. A series of works follow this line and extend it for high-order MCs [4,</ref>8,</ref>24]</ref>. With the development of the neural networks, Hidasi et al. [3]</ref> firstly introduced Gated Recurrent Units (GRU) to the sessi cement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref>24]</ref> for sequential recommendation. However, these approaches neglect the rich attribute information about items. To tackle this problem, TransFM <ref type="bibr" t ://www.tei-c.org/ns/1.0"><head n="4">APPROACH 4.1 Overview</head><p>Existing studies [3,</ref>4,</ref>8,</ref>24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspired by recent progress with MIM <ref typ MAP • e a ,<label>(15)</label></formula><p>where W MAP ∈ R d ×d is a parameter matrix to learn. Note that existing methods [4,</ref>8,</ref>24]</ref> seldom directly model the correlation between the sequential context and attribute information. While, we would like to explicitly model the correlation to der Such motivation has been extensively explored with deep learning. Various methods using recurrent neural networks (RNNs) [3]</ref>, convolutional neural networks (CNNs) [24]</ref>, and self-attention mechanisms [8]</ref> have been proposed to learn good representations of user preference and characterize se pe="bibr" target="#b2">[3]</ref> applies GRU to model user click sequence for session-based recommendation. We represent the items using embedding vectors rather than one-hot vectors.</p><p>(5) Caser [24]</ref> is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.</p><p>(6)
s, the task of sequential recommendation has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref><ref type="bibr" target="#b7 "bibr" target="#b20">21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivation has been extensively explored with is incorporated, the involved parameters are also learned through the only optimization objective. It has been found that such an optimization way is easy to suffer from issues such as data sparsity [21,</ref>22]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2008.07873v1 [cs.IR] 18 Aug 2020</head><p>Second, they the tags of the artists given by the users are used as attributes.</p><p>For all datasets, we group the interaction records by users and sort them by the interaction timestamps ascendingly. Following [21,</ref>29]</ref>, we only keep the 5-core datasets, and filter unpopular items and inactive users with fewer than five interaction reco ics.</head><p>We employ top-k Hit Ratio (HR@k), topk Normalized Discounted Cumulative Gain (NDCG@k), and Mean Reciprocal Rank (MRR) to evaluate the performance, which are widely used in related works [21,</ref>29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works <r major difference in our work is to utilize feature interaction as additional supervision signals to enhance data representations instead of making predictions.</p><p>Sequential models such as GRU4Rec [21]</ref> and SASRec [8]</ref> mainly focus on modeling the sequential dependencies between contextual items and the target item in a left r enhancing data representations. In particular, the masked item prediction loss L M I P in Eq. 12 has a similar effect to capture sequential dependencies as in [8,</ref>21]</ref> except that it can also utilize bidirectional sequential information.</p><p>Attribute-aware sequential models such as TransFM [1
[6,</ref>7]</ref>, hierarchical structures [17]</ref>, copy mechanism [18]</ref> and reinforcement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref><ref type="bibr"
accurately characterize user interests and provide high-quality recommendations, the task of sequential recommendation has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendati ibr" target="#b19">20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivat bility matrix and utilized it to predict the next item given the last interaction of a user. A series of works follow this line and extend it for high-order MCs [4,</ref>8,</ref>24]</ref>. With the development of the neural networks, Hidasi et al. [3]</ref> firstly introduced Ga t contains.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPROACH 4.1 Overview</head><p>Existing studies [3,</ref>4,</ref>8,</ref>24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspire rmula_21">f (C i t , a) = σ F ⊤ t • W MAP • e a ,<label>(15)</label></formula><p>where W MAP ∈ R d ×d is a parameter matrix to learn. Note that existing methods [4,</ref>8,</ref>24]</ref> seldom directly model the correlation between the sequential context and attribute information. While, we would like to e s methods using recurrent neural networks (RNNs) [3]</ref>, convolutional neural networks (CNNs) [24]</ref>, and self-attention mechanisms [8]</ref> have been proposed to learn good representations of user preference and characterize sequential user-item interactions.</p><p>Furthermore, researchers have inco is end, in this paper, we propose a novel Self-Supervised learning approach to improve Sequential Recommendation with MIM, which is called S 3 -Rec. Based on a self-attentive recommender architecture [8]</ref>, we propose to first pre-train the sequential recommender with self-supervised signals and then fine-tune the model parameters according to the recommendation t s presented in Fig. 1</ref>. In the following sections, we first introduce the base model of our proposed approach that is developed on the Transformer architecture [8]</ref>. Then, we will describe how we utilize the correlation signals among attributes, items, segments, and sequences to enhance the data representations based on the teraction as additional supervision signals to enhance data representations instead of making predictions.</p><p>Sequential models such as GRU4Rec [21]</ref> and SASRec [8]</ref> mainly focus on modeling the sequential dependencies between contextual items and the target item in a left-to-right order. S 3 -Rec additionally incorporates a e="bibr" target="#b23">[24]</ref> is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.</p><p>(6) SASRec [8]</ref> is a self-attention based sequential recommendation model, which uses the multi-head attention mechanism to recommend the next item.</p><p>(7) BERT4Rec <ref typ s.</p><p>For our proposed S 3 -Rec, we set the number of the self-attention blocks and the attention heads as 2. The dimension of the embedding is 64, and the maximum sequence length is 50 (following [8]</ref>). Note that our training phase contains two stages (i.e., pre-training and fine-tuning stage), the learned parameters in the pre-training stage are used to init 17]</ref>, copy mechanism [18]</ref> and reinforcement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref>24]</ref> for sequential recommendation. However, these approaches neglect the rich attrib of self-supervised learning signals for enhancing data representations. In particular, the masked item prediction loss L M I P in Eq. 12 has a similar effect to capture sequential dependencies as in [8,</ref>21]</ref> except that it can also utilize bidirectional sequential information.</p><p>Attribute-aware sequential models such as Tr s [21,</ref>29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works [8,</ref>19,</ref>23]</ref>, we apply the leave-oneout strategy for evaluation. Concretely, for each user in remaining data is used for training. Since the item set is large, it is time-consuming to use all items as candidates for testing. Following the common strategy [7,</ref>8]</ref>, we pair the ground-truth item with 99 randomly sampled negative items that the user has not interacted with. We calculate all metrics according to the ranking o
accurately characterize user interests and provide high-quality recommendations, the task of sequential recommendation has been widely studied in the literature [3,</ref>8,</ref>20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendati ibr" target="#b19">20,</ref>21,</ref>24]</ref>.</p><p>Typically, sequential recommendation methods [3,</ref>8,</ref>21,</ref>24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivat bility matrix and utilized it to predict the next item given the last interaction of a user. A series of works follow this line and extend it for high-order MCs [4,</ref>8,</ref>24]</ref>. With the development of the neural networks, Hidasi et al. [3]</ref> firstly introduced Ga t contains.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPROACH 4.1 Overview</head><p>Existing studies [3,</ref>4,</ref>8,</ref>24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspire rmula_21">f (C i t , a) = σ F ⊤ t • W MAP • e a ,<label>(15)</label></formula><p>where W MAP ∈ R d ×d is a parameter matrix to learn. Note that existing methods [4,</ref>8,</ref>24]</ref> seldom directly model the correlation between the sequential context and attribute information. While, we would like to e s methods using recurrent neural networks (RNNs) [3]</ref>, convolutional neural networks (CNNs) [24]</ref>, and self-attention mechanisms [8]</ref> have been proposed to learn good representations of user preference and characterize sequential user-item interactions.</p><p>Furthermore, researchers have inco is end, in this paper, we propose a novel Self-Supervised learning approach to improve Sequential Recommendation with MIM, which is called S 3 -Rec. Based on a self-attentive recommender architecture [8]</ref>, we propose to first pre-train the sequential recommender with self-supervised signals and then fine-tune the model parameters according to the recommendation t s presented in Fig. 1</ref>. In the following sections, we first introduce the base model of our proposed approach that is developed on the Transformer architecture [8]</ref>. Then, we will describe how we utilize the correlation signals among attributes, items, segments, and sequences to enhance the data representations based on the teraction as additional supervision signals to enhance data representations instead of making predictions.</p><p>Sequential models such as GRU4Rec [21]</ref> and SASRec [8]</ref> mainly focus on modeling the sequential dependencies between contextual items and the target item in a left-to-right order. S 3 -Rec additionally incorporates a e="bibr" target="#b23">[24]</ref> is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.</p><p>(6) SASRec [8]</ref> is a self-attention based sequential recommendation model, which uses the multi-head attention mechanism to recommend the next item.</p><p>(7) BERT4Rec <ref typ s.</p><p>For our proposed S 3 -Rec, we set the number of the self-attention blocks and the attention heads as 2. The dimension of the embedding is 64, and the maximum sequence length is 50 (following [8]</ref>). Note that our training phase contains two stages (i.e., pre-training and fine-tuning stage), the learned parameters in the pre-training stage are used to init 17]</ref>, copy mechanism [18]</ref> and reinforcement learning [27]</ref>, etc. There are also studies that leverage other architectures [8,</ref>23,</ref>24]</ref> for sequential recommendation. However, these approaches neglect the rich attrib of self-supervised learning signals for enhancing data representations. In particular, the masked item prediction loss L M I P in Eq. 12 has a similar effect to capture sequential dependencies as in [8,</ref>21]</ref> except that it can also utilize bidirectional sequential information.</p><p>Attribute-aware sequential models such as Tr s [21,</ref>29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works [8,</ref>19,</ref>23]</ref>, we apply the leave-oneout strategy for evaluation. Concretely, for each user in remaining data is used for training. Since the item set is large, it is time-consuming to use all items as candidates for testing. Following the common strategy [7,</ref>8]</ref>, we pair the ground-truth item with 99 randomly sampled negative items that the user has not interacted with. We calculate all metrics according to the ranking o
, feature maps generated by the encoder comprise low-level and fine-grained detailed information, while feature maps generated by the decoder contain high-level and coarse-gained semantic information [15]</ref>. And skip connections, which combine the low-level and high-level feature maps, are an effective method to boost the semantic extraction ability of encoder-de </ref>. And skip connections, which combine the low-level and high-level feature maps, are an effective method to boost the semantic extraction ability of encoder-decoder frameworks.</p><p>In U-Net++ [15]</ref>, plain skip connections are substituted by nested and dense skip connections, which enhance the ability of skip connections and narrow the semantic gap betwee #b13">[14]</ref>, FC-DenseNet57 [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [15]</ref>. The major C. Duan is with the State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan 430079, Chin /ref>, FC-DenseNet57 (tiramisu) [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [15]</ref>. Excluding SegNet, DeepLab V3 and DeepLab V3+, the remaining methods are all improved version of U-Net.</p><p>All of the models are implemented with PyTorch,
with square, horizontal and vertical kernels, could capture refined features by summing up the outputs of three convolutions, which just cause finite increasing in additional computational complexity [17]</ref>. The effectiveness of ACB has been verified in the fields including image classification [17]</ref>, image denoising <ref type= just cause finite increasing in additional computational complexity [17]</ref>. The effectiveness of ACB has been verified in the fields including image classification [17]</ref>, image denoising [18]</ref>, and medical image segmentation [19]</ref>. In <ref type="bibr" targ on. In order to extract available information contained in remote sensing images, the neural network should be robust to rotation and renders consistent results in different rotations. As reported in [17]</ref>, different asymmetric convolutions are robust with different rotation objects. As can be seen from Fig. 2</ref>, 3×1 kernel ng. Hence, asymmetric convolutions are viable schemes to boost the rotation robustness of the neural network.</p><p>Based on above-mentioned insight, we modify the asymmetric convolutions proposed in [17]</ref> and design an asymmetric convolution block (ACB) to capture features from different receptive fields, which can be seen from Fig. <ref type="figure" target="#
hance the ability of skip connections and narrow the semantic gap between the encoder and decoder. To make utmost of the multi-scale features, the full-scale skip connections are designed in U-Net 3+ [16]</ref>. However, the design philosophy of full-scale skip connections impliedly indicates that all channels of feature maps generated by different layers share equal
</ref>[5]</ref>. Hitherto the remote sensing community has tried to design assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</re
target="#b1">2]</ref>, plays a critical role in wide range of application scenarios such as land resource management, yield estimation, and economic assessment [3]</ref>[4]</ref>[5]</ref>. Hitherto the remote sensing community has tried to design assorted classifiers from diverse perspectives, from orthodox
" target="#b10">[11]</ref>, U-Net [12]</ref>, DeepLab V3 [13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [ b10">[11]</ref>, U-Net [12]</ref>, DeepLab V3 [13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 (tiramisu) [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [
rmance between different frameworks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>The effectiveness of MACU-Net is verified using Wuhan Dense Labeling Dataset (WHDLD) [24,</ref>25]</ref> and Gaofen Image Dataset (GID) [30]</ref>. WHDLD contains 4940 RGB images in the size of 256 × 256 ca
target="#b1">2]</ref>, plays a critical role in wide range of application scenarios such as land resource management, yield estimation, and economic assessment [3]</ref>[4]</ref>[5]</ref>. Hitherto the remote sensing community has tried to design assorted classifiers from diverse perspectives, from orthodox
ACB has been verified in the fields including image classification [17]</ref>, image denoising [18]</ref>, and medical image segmentation [19]</ref>. In [19]</ref>, only the convolutional layers of encoder are replaced by ACB. Aiming at the task of high-resolution remote sens image classification [17]</ref>, image denoising [18]</ref>, and medical image segmentation [19]</ref>. In [19]</ref>, only the convolutional layers of encoder are replaced by ACB. Aiming at the task of high-resolution remote sensing image segmentation, we thoroughly incorpor
et="#b8">[9]</ref> have demonstrated its powerful capacity of automatically capture nonlinear and hierarchical features from images, and have dramatically influenced the field of computer vision (CV) [10]</ref>. For semantic segmentation, the encoder-decoder frameworks such as SegNet [11]</ref>, U-Net [12]<
</ref>[5]</ref>. Hitherto the remote sensing community has tried to design assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</re
RODUCTION</head><p>emantic segmentation using remote sensing images, i.e., the assignment of assigning the precise category to every pixel contained in an image [1,</ref>2]</ref>, plays a critical role in wide range of application scenarios such as land resource management, yield estimation, and economic assessment <ref type="bibr" target
omplexity [17]</ref>. The effectiveness of ACB has been verified in the fields including image classification [17]</ref>, image denoising [18]</ref>, and medical image segmentation [19]</ref>. In [19]</ref>, only the convolutional layers of enco
sign assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</ref>. However, the high dependency on hand-crafted visual features or mid-level semantic features rest
target="#b0">[1,</ref>2]</ref>, plays a critical role in wide range of application scenarios such as land resource management, yield estimation, and economic assessment [3]</ref>[4]</ref>[5]</ref>. Hitherto the remote sensing community has tried to design assorted classifiers fr
rmance between different frameworks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>The effectiveness of MACU-Net is verified using Wuhan Dense Labeling Dataset (WHDLD) [24,</ref>25]</ref> and Gaofen Image Dataset (GID) [30]</ref>. WHDLD contains 4940 RGB images in the size of 256 × 256 ca
rmance between different frameworks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>The effectiveness of MACU-Net is verified using Wuhan Dense Labeling Dataset (WHDLD) [24,</ref>25]</ref> and Gaofen Image Dataset (GID) [30]</ref>. WHDLD contains 4940 RGB images in the size of 256 × 256 ca
sign assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</ref>. However, the high dependency on hand-crafted visual features or mid-level semantic features rest
sign assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</ref>. However, the high dependency on hand-crafted visual features or mid-level semantic features rest
dox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</ref>. However, the high dependency on hand-crafted visual features or mid-level semantic features restricts the flexibility and adaptability of these methods.</p><p>
dentical size and resolution in hand, we need to further decrease the prodigious number of channels, as well as realign channel-wise features. Motivated by Convolutional Block Attention Module (CBAM) [23]</ref>, we design the channel attention block (CAB) to reweighting the channel-wise features, which can be seen from the right of Fig. <ref type="figure" target="#fi
et="#b8">[9]</ref> have demonstrated its powerful capacity of automatically capture nonlinear and hierarchical features from images, and have dramatically influenced the field of computer vision (CV) [10]</ref>. For semantic segmentation, the encoder-decoder frameworks such as SegNet [11]</ref>, U-Net [12]<
</ref>[5]</ref>. Hitherto the remote sensing community has tried to design assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</re
arget="#b12">[13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [15]</ref>. The major C. Duan is with the State Key Laboratory of Information Engineering in Surveying, Map ">[13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 (tiramisu) [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [15]</ref>. Excluding SegNet, DeepLab V3 and DeepLab V3+, the remaining methods are all improved version of
" target="#b10">[11]</ref>, U-Net [12]</ref>, DeepLab V3 [13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [ b10">[11]</ref>, U-Net [12]</ref>, DeepLab V3 [13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 (tiramisu) [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [
tp://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>emantic segmentation using remote sensing images, i.e., the assignment of assigning the precise category to every pixel contained in an image [1,</ref>2]</ref>, plays a critical role in wide range of application scenarios such as land resource management, yield estimation, and econ
d the field of computer vision (CV) [10]</ref>. For semantic segmentation, the encoder-decoder frameworks such as SegNet [11]</ref>, U-Net [12]</ref>, and DeepLab [13,</ref>14]</ref> have become the frequently-used schemes. Generally, feature map rk, MACU-Net with asymmetric convolution blocks. To verify the effectiveness of MACU-Net, we compare the performance of proposed algorithm with SegNet [11]</ref>, U-Net [12]</ref>, DeepLab V3 [13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 [20 code 1   </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Setting</head><p>To evaluate the effectiveness of MACU-Net, SegNet [11]</ref>, U-Net [12]</ref>, DeepLab V3 [13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 (tiramisu) <ref type="bibr" target
</ref>[5]</ref>. Hitherto the remote sensing community has tried to design assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</re
et="#b8">[9]</ref> have demonstrated its powerful capacity of automatically capture nonlinear and hierarchical features from images, and have dramatically influenced the field of computer vision (CV) [10]</ref>. For semantic segmentation, the encoder-decoder frameworks such as SegNet [11]</ref>, U-Net [12]<
arget="#b12">[13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [15]</ref>. The major C. Duan is with the State Key Laboratory of Information Engineering in Surveying, Map ">[13]</ref>, DeepLab V3+ [14]</ref>, FC-DenseNet57 (tiramisu) [20]</ref>, Attention U-Net [21]</ref>, FGC [22]</ref>, MSFCN, and U-Net++ [15]</ref>. Excluding SegNet, DeepLab V3 and DeepLab V3+, the remaining methods are all improved version of
et="#b8">[9]</ref> have demonstrated its powerful capacity of automatically capture nonlinear and hierarchical features from images, and have dramatically influenced the field of computer vision (CV) [10]</ref>. For semantic segmentation, the encoder-decoder frameworks such as SegNet [11]</ref>, U-Net [12]<
dentical size and resolution in hand, we need to further decrease the prodigious number of channels, as well as realign channel-wise features. Motivated by Convolutional Block Attention Module (CBAM) [23]</ref>, we design the channel attention block (CAB) to reweighting the channel-wise features, which can be seen from the right of Fig. <ref type="figure" target="#fi
sign assorted classifiers from diverse perspectives, from orthodox methods such as distance measure [6]</ref>, to advanced methods including support vector machine (SVM) [7]</ref> and random forest (RF) [8]</ref>. However, the high dependency on hand-crafted visual features or mid-level semantic features rest
generalized well to much larger systems and longer time scales than those on which it was trained. While previous learning simulation approaches (Li et al., 2018;</ref>Ummenhofer et al., 2020)</ref> have been highly specialized for particular tasks, we found our single GNS model performed well across dozens of experiments and was gener type="bibr" target="#b19">(Macklin et al., 2014)</ref>.</p><p>We also created WATER-3D, a high-resolution 3D water scenario with randomized water position, initial velocity and volume, comparable to Ummenhofer et al. (2020)</ref>'s containers of water. We used SPlisHSPlasH (Bender &amp; Koschier, 2015)</ref>, a SPH-based fluid simulator ored to modeling fluid dynamics (e.g., an SPH-like local kernel, different sub-networks for fluid and boundary particles, a loss function that weights slow particles with few neighbors more heavily). Ummenhofer et al. (2020)</ref> reported CConv outperformed DPI, so we quantitatively compared our GNS model to CConv. We implemented CConv as described in its paper, plu iled in Section C.</p><p>Another way to address differences in training and test input distributions is to, during training, provide the model with its own predictions by rolling out short sequences. Ummenhofer et al. (2020)</ref>, for example, train with two-step predictions. However computing additional model predictions are more expensive, and in our experience ma update function, CNNs and CConv are very similar to how graph convolutional networks (GCN) (Kipf &amp; Welling, 2016)</ref> work. The full CConv update as described in Ummenhofer et al. (2020)</ref> is,</p><formula xml:id="formula_19">f i = 1 ψ(xi)</formula><p>j∈N (xi,R) a (x j , x i ) f j g (Λ (x j − x i )). In particular, it indexes hborhood size, they set it to 1.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance comparisons.</head><p>We implemented the CConv model, loss and training procedure as described by Ummenhofer et al. (2020)</ref>. For simplicity, we only tested the CConv model on datasets with flat walls, rather than those with irregular geometry. This way we could ve than boundary particles for square containers. Also, for environments with multiple materials, we appended a particle type learned embedding to the input node features.</p><p>To be consistent with Ummenhofer et al. (2020)</ref>, we used their batch size of 16, learning rate decay of 10 −3 to 10 −5 for 50k iterations, and connectivity radius of 4.5x the particle ra d more exposure to fall versus sticking phenomena.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Supplementary baseline comparisons D.1. Continuous convolution (CConv)</head><p>Recently Ummenhofer et al. (2020)</ref> presented Continuous Convolution (CConv) as a method for particle-based fluid simulation. We show that CConv can also be understood in our We show that CConv can also be understood in our framework, and compare CConv to our approach on several tasks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Interpretation.</head><p>While Ummenhofer et al. (2020)</ref> state that "Unlike previous approaches, we do not build an explicit graph structure to connect the particles but use spatial convolutions
mal transport (OT) (Villani, 2003)</ref> (approximated by the Sinkhorn Algorithm (Cuturi, 2013)</ref>), and Maximum Mean Discrepancy (MMD) (Gretton et al., 2012)</ref>. For the generalization experiments we also evaluate our models on a number of initial conditions drawn from distributions different than tho rget="#b35">(Villani, 2003)</ref> using 2D or 3D Wasserstein distance and approximated by the Sinkhorn Algorithm (Cuturi, 2013)</ref>, and maximum mean discrepancy (MMD) (Gretton et al., 2012)</ref> with a Gaussian kernel bandwidth of σ = 0.1. These distributional metrics may be more appropriate when the goal is to predict what regions of
iewel et al., 2019)</ref> learn parts of a fluid simulator for faster prediction.</p><p>Graph networks (GN) (Battaglia et al., 2018</ref>)-a type of graph neural network (Scarselli et al., 2008)</ref>-have recently proven effective at learning forward dynamics in various settings that involve interactions between many entities. A GN maps
particles' velocities and positions accordingly. Other techniques, such as "position-based dynamics" (PBD) (Müller et al., 2007)</ref> and "material point method" (MPM) (Sulsky et al., 1995)</ref>, are more suitable for interacting, deformable materials. In PBD, incompressibility and collision dynamics involve resolving pairwise distanc
ace. Dynamics are computed on the basis of particles' interactions within their local neighborhoods. One popular particle-based method for simulating fluids is "smoothed particle hydrodynamics" (SPH) (Monaghan, 1992)</ref>, which evaluates pressure and viscosity forces around each particle, and updates particles' velocities and positions accordingly. Other techniques
iewel et al., 2019)</ref> learn parts of a fluid simulator for faster prediction.</p><p>Graph networks (GN) (Battaglia et al., 2018</ref>)-a type of graph neural network (Scarselli et al., 2008)</ref>-have recently proven effective at learning forward dynamics in various settings that involve interactions between many entities. A GN maps
omain, we use Li et al. (2018)</ref>'s BOXBATH, which simulates a container of water and a cube floating inside, all represented as particles, using the PBD engine FleX (Macklin et al., 2014)</ref>.</p><p>We also created WATER-3D, a high-resolution 3D water scenario with randomized water position, initial velocity and volume, comparable
particles' velocities and positions accordingly. Other techniques, such as "position-based dynamics" (PBD) (Müller et al., 2007)</ref> and "material point method" (MPM) (Sulsky et al., 1995)</ref>, are more suitable for interacting, deformable materials. In PBD, incompressibility and collision dynamics involve resolving pairwise distanc
particles' velocities and positions accordingly. Other techniques, such as "position-based dynamics" (PBD) (Müller et al., 2007)</ref> and "material point method" (MPM) (Sulsky et al., 1995)</ref>, are more suitable for interacting, deformable materials. In PBD, incompressibility and collision dynamics involve resolving pairwise distanc

ny entities. A GN maps an input graph to an output graph with the same structure but potentially different node, edge, and graph-level attributes, and can be trained to learn a form of messagepassing (Gilmer et al., 2017)</ref>, where latent information is propagated between nodes via the edges. GNs and their variants, e.g., "interaction networks", can learn to simula
ttack models. Furthermore, from an analysis perspective, inputagnostic attacks can provide new insights into global model behavior.</p><p>Triggers are a new form of universal adversarial perturbation (Moosavi-Dezfooli et al., 2017)</ref> adapted to discrete textual inputs. To find them, we design a gradient-guided search over tokens. The search iteratively updates th astically lower the barrier of entry for an adversary: trigger sequences can be widely distributed for anyone to fool machine learning models. Moreover, universal attacks often transfer across models (Moosavi-Dezfooli et al., 2017)</ref>, which further decreases attack requirements: the adversary does not need white-box (gradient) access to the target model. Instead, or characters) to the front or end of an input to cause a target prediction.</p><p>Why Universal? The adversarial threat is higher if an attack is universal: using the exact same attack for any input (Moosavi-Dezfooli et al., 2017;</ref>Brown et al., 2017)</ref>. Universal attacks are advantageous as (1) no access to the target model is
(Szegedy et al., 2014)</ref>. From an attack perspective, they expose system vulnerabilities, e.g., a spammer may use adversarial attacks to bypass a spam email filter (Biggio et al., 2013)</ref>. These security concerns grow as natural language processing (NLP) models are deployed in production systems such as fake news detectors and h
d show that triggers align with known dataset biases in Section 6.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Attacking Reading Comprehension</head><p>We create triggers for SQuAD (Rajpurkar et al., 2016)</ref>. We use an intentionally simple baseline model and test the trigger's transferability to more advanced models (with different embeddings,
l at flipping neutral and contradiction predictions to entailment. We suspect that this arises from a bias towards entailment when there is high lexical overlap between the premise and the hypothesis (McCoy et al., 2019)</ref>. Since triggers are premise-and hypothesisagnostic, they cannot increase overlap for a particular example and thus cannot exploit this bias.</



"#b6">Cheng et al. (2018)</ref> do the same for text generation. Other attack methods are based on generative (Iyyer et al., 2018)</ref> or human-in-the-loop approaches (Wallace et al., 2019)</ref>. We turn the reader to Zhang et al. (2019)</ref> for a recent survey. Triggers differ from most previous atta
l at flipping neutral and contradiction predictions to entailment. We suspect that this arises from a bias towards entailment when there is high lexical overlap between the premise and the hypothesis (McCoy et al., 2019)</ref>. Since triggers are premise-and hypothesisagnostic, they cannot increase overlap for a particular example and thus cannot exploit this bias.</

linkov and Bisk, 2018)</ref>. Adversarial attacks also facilitate interpretation, e.g., by analyzing a model's sensitivity to local perturbations (Li et al., 2016;</ref>Feng et al., 2018)</ref>.</p><p>These attacks are typically generated for a specific input; are there attacks that work for any input? We search for universal adversarial
ing scale-free and hierarchical graphs. However, current hyperbolic embedding techniques only account for the graph structure and do not leverage rich node features. For instance, Poincar? embeddings [29]</ref> capture the hyperbolic properties of real graphs by learning shallow embeddings with hyperbolic distance metric and Riemannian optimization. Compared to As cu population of the country where the airport belongs to as the label for node classification.</p><p>Baselines. For shallow methods, we consider Euclidean embeddings (EUC) and Poincar? embeddings (HYP) [29]</ref>. We conjecture that HYP will outperform EUC on hierarchical graphs. For a fair comparison with HGCN which leverages node features, we also consider EUC-MIXED t="#b23">24]</ref> and random walk methods [12,</ref>31]</ref>. Shallow embedding methods have also been developed in hyperbolic geometry [29,</ref>30]</ref> for reconstructing trees [35]</ref> and graphs [5,</ref>< olic embeddings (x L,H ) i?V at the last layer can then be used to predict node attributes or links.</p><p>For link prediction, we use the Fermi-Dirac decoder [23,</ref>29]</ref>, a generalization of sigmoid, to compute probability scores for edges:</p><formula xml:id="formula_21">p((i, j) ? E|x L,H i , x L,H j ) = e (d K L L (x L,H i ,
"#b40">41,</ref>45]</ref>. However, many real-world graphs, such as protein interaction networks and social networks, often exhibit scale-free or hierarchical structure [7,</ref>50]</ref> and Euclidean embeddings, used by existing GCNs, have a high distortion when embedding such graphs <ref type="bibr" targ
="#b44">45]</ref>. However, many real-world graphs, such as protein interaction networks and social networks, often exhibit scale-free or hierarchical structure [7,</ref>50]</ref> and Euclidean embeddings, used by existing GCNs, have a high distortion when embedding such graphs [6,</ref><ref type="bibr" targ
f>30]</ref> for reconstructing trees [35]</ref> and graphs [5,</ref>13,</ref>22]</ref>, or embedding text [39]</ref>. However, shallow (Euclidean and hyperbolic) embedding methods have three major downsides:</p><p>(
resentation learning models that combines the expressiveness of GCNs and hyperbolic geometry to learn improved representations for real-world hierarchical and scale-free graphs in inductive settings: (1)</ref> We derive the core operations of GCNs in the hyperboloid model of hyperbolic space to transform input features which lie in Euclidean space into hyperbolic embe 0"><head n="5.1">Experimental setup</head><p>Datasets. We use a variety of open transductive and inductive datasets that we detail below (more details in Appendix). We compute Gromovs ?-hyperbolicity [1,</ref>28,</ref>17]</ref>, a notion from group theory that measures how tree-like a graph is. The lower ?,
ad><p>Datasets. We use a variety of open transductive and inductive datasets that we detail below (more details in Appendix). We compute Gromovs ?-hyperbolicity [1,</ref>28,</ref>17]</ref>, a notion from group theory that measures how tree-like a graph is. The lower ?, the more hyperbolic is the graph datas
/10% for training, validation and test sets. For transductive NC, we use 70/15/15% splits for AIRPORT, 30/10/60% splits for DISEASE, and we use standard splits[21,</ref>46]</ref> with 20 train examples per class for CORA and PUBMED. One of the main advantages of HGCN over related hyperbolic graph embedding is its inductive capability. F
ntroduction</head><p>Graph Convolutional Neural Networks (GCNs) are state-of-the-art models for representation learning in graphs, where nodes of the graph are embedded into points in Euclidean space [15,</ref>21,</ref>41,</ref>45]</ref>. However, many real-world graphs, such ral Networks. Instead of learning shallow embeddings, an alternative approach is to learn a mapping from input graph structure as well as node features to embeddings, parameterized by neural networks [15,</ref>21,</ref>25,</ref>41,</ref>45,</ref ><formula xml:id="formula_2">,E i = ?(h ,E i + j?N (i) w ij h ,E j ) (neighborhood aggregation)<label>(2)</label></formula><p>where aggregation weights w ij can be computed using different mechanisms [15,</ref>21,</ref>41]</ref>. Message passing is then performed for multiple layers to propagate messages o mbeddings with node features, followed by a MLP to predict node labels or links. For state-of-the-art Euclidean GNN models, we consider GCN [21]</ref>, GraphSAGE (SAGE) [15]</ref>, Graph Attention Networks (GAT) [41]</ref> and Simplified Graph Convolution (SGC) [44]</ref> <re
Neural Networks (GCNs) are state-of-the-art models for representation learning in graphs, where nodes of the graph are embedded into points in Euclidean space [15,</ref>21,</ref>41,</ref>45]</ref>. However, many real-world graphs, such as protein interaction networks and soci embeddings, an alternative approach is to learn a mapping from input graph structure as well as node features to embeddings, parameterized by neural networks [15,</ref>21,</ref>25,</ref>41,</ref>45,</ref>47]</ref> E i + j?N (i) w ij h ,E j ) (neighborhood aggregation)<label>(2)</label></formula><p>where aggregation weights w ij can be computed using different mechanisms [15,</ref>21,</ref>41]</ref>. Message passing is then performed for multiple layers to propagate messages over network neighborhoods. Unlike shallow baselines, where we concatenate the corresponding shallow embeddings with node features, followed by a MLP to predict node labels or links. For state-of-the-art Euclidean GNN models, we consider GCN [21]</ref>, GraphSAGE (SAGE) [15]</ref>, Graph Attention Networks (GAT) [41]</ref> and Simplified Graph Con tasks, we randomly split edges into 85/5/10% for training, validation and test sets. For transductive NC, we use 70/15/15% splits for AIRPORT, 30/10/60% splits for DISEASE, and we use standard splits[21,</ref>46]</ref> with 20 train examples per class for CORA and PUBMED. One of the main advantages of HGCN over related hyperbolic graph
Neural Networks (GCNs) are state-of-the-art models for representation learning in graphs, where nodes of the graph are embedded into points in Euclidean space [15,</ref>21,</ref>41,</ref>45]</ref>. However, many real-world graphs, such as protein interaction networks and soci embeddings, an alternative approach is to learn a mapping from input graph structure as well as node features to embeddings, parameterized by neural networks [15,</ref>21,</ref>25,</ref>41,</ref>45,</ref>47]</ref> E i + j?N (i) w ij h ,E j ) (neighborhood aggregation)<label>(2)</label></formula><p>where aggregation weights w ij can be computed using different mechanisms [15,</ref>21,</ref>41]</ref>. Message passing is then performed for multiple layers to propagate messages over network neighborhoods. Unlike shallow baselines, where we concatenate the corresponding shallow embeddings with node features, followed by a MLP to predict node labels or links. For state-of-the-art Euclidean GNN models, we consider GCN [21]</ref>, GraphSAGE (SAGE) [15]</ref>, Graph Attention Networks (GAT) [41]</ref> and Simplified Graph Con tasks, we randomly split edges into 85/5/10% for training, validation and test sets. For transductive NC, we use 70/15/15% splits for AIRPORT, 30/10/60% splits for DISEASE, and we use standard splits[21,</ref>46]</ref> with 20 train examples per class for CORA and PUBMED. One of the main advantages of HGCN over related hyperbolic graph
="#b44">45]</ref>. However, many real-world graphs, such as protein interaction networks and social networks, often exhibit scale-free or hierarchical structure [7,</ref>50]</ref> and Euclidean embeddings, used by existing GCNs, have a high distortion when embedding such graphs [6,</ref><ref type="bibr" targ
</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pre-training models (Radford et al., 2018;</ref>Devlin et al., 2019;</ref>Radford et al., 2019b;</ref>Song et al., 2019;</ref>Yang et al., 0"><head n="2">MPNet</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Background</head><p>The key of pre-training methods (Radford et al., 2018;</ref>Devlin et al., 2019;</ref>Song et al., 2019;</ref>Yang et al., 2019;</ref>Clar ibute equally to this work. Correspondence to Tao Qin: taoqin@microsoft.com 1 https://github.com/microsoft/MPNet the accuracy of NLP tasks in the past years. One of the most successful models is BERT (Devlin et al., 2019)</ref>, which mainly adopts masked language modeling (MLM) for pre-training2</ref> . MLM leverages bidirectional co of self-supervised tasks/objectives for model training to exploit large language corpora for language understanding and generation. For language understanding, masked language modeling (MLM) in BERT (Devlin et al., 2019)</ref> and permuted language modeling (PLM) in XLNet (Yang et al., 2019)</ref> are two representative objectives. In t Net (Yang et al., 2019)</ref> are two representative objectives. In this section, we briefly review MLM and PLM, and discuss their pros and cons.</p><p>MLM in BERT BERT (Devlin et al., 2019)</ref> is one of the most successful pre-training models for natural language understanding. It adopts Transformer (Va ], [M ], [M ]) are taken as the nonpredicted part, and x z&gt;c = (x 4 , x 6 , x 2 ) are taken as the predicted part. For the non-predicted part (x z&lt;=c , M z&gt;c ), we use bidirectional modeling (Devlin et al., 2019)</ref>  Modeling Output Dependency with Two-Stream Self-Attention For the predicted part x z&gt;c , since the tokens are in permuted order, the next is used on average to predict a masked token in each pre-training objective. We assume all the three objectives mask and predict the same amount of tokens (15%), following the common practice in BERT (Devlin et al., 2019)</ref> and XLNet (Yang et al., 2019)</ref> 5</ref> . As can be seen, MLM conditions .0"><head n="3">Experiments and Results</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>We conduct experiments under the BERT base setting (BERT BASE ) (Devlin et al., 2019)</ref>, where the model consists of 12 transformer layers, with 768 hidden size, 12 attention heads as 12, and 110M model parameters in total. For th et al., 2019)</ref>  7</ref> , choose the rightmost 15% tokens as the predicted tokens, and prepare mask tokens following the same 8:1:1 replacement strategy in BERT (Devlin et al., 2019)</ref>. Additionally, we also apply whole word mask (Cui et al., 2019)</ref> and relative positional embedding <ref typ ref>, CC-News (Liu et al., 2019b)</ref> and Stories (Trinh and Le, 2018)</ref>, with 160GB data size in total. We use a subword dictionary with 30K BPE codes in BERT (Devlin et al., 2019)</ref> to tokenize the sentences. We limit the length of sentences in each mini-batch up to 512 tokens following the previous practice <ref type="bib baselines in Table 3</ref>. All of the listed results are reported in BERT BASE setting and from MNLI QNLI QQP RTE SST MRPC CoLA STS Avg Single model on dev set BERT (Devlin et al., 2019)</ref> 84.5 91.7 91.3 68.6 93.2 87.3 58.9 89.5 83.1 XLNet (Yang et al., 2019)</ref> 86.8 91.7 91.4 74.0 94.7 88.2 60.2 2019)</ref> 86.8 91.7 91.4 74.0 94.7 88.2 60.2 89.5 84.5 RoBERTa (Liu et al., 2019a)</ref> 87 </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>SQuAD v1.1 EM F1</head><p>BERT (Devlin et al., 2019)</ref> 80.8 88.5 RoBERTa (Liu et al., 2019a)</ref>  single model without any data augmentation for fair comparisons. On the dev set et al., 2019)</ref> 80.8 88.5 RoBERTa (Liu et al., 2019a)</ref>  single model without any data augmentation for fair comparisons. On the dev set of GLUE tasks, MPNet outperforms BERT (Devlin et al., 2019)</ref>, XLNet (Yang et al., 2019)</ref> and RoBERTa (Liu et al., 2019a)</ref> by 4.6, 3.2, 1.3 points
" target="#b14">(Radford et al., 2018;</ref>Devlin et al., 2019;</ref>Radford et al., 2019b;</ref>Song et al., 2019;</ref>Yang et al., 2019;</ref>Dong et al., 2019;</ref>Liu et al., 2019a;</ref>Raffel et al., 2019a)</ref> have e key of pre-training methods (Radford et al., 2018;</ref>Devlin et al., 2019;</ref>Song et al., 2019;</ref>Yang et al., 2019;</ref>Clark et al., 2020)</ref> is the design of self-supervised tasks/objectives for model training to exploit large lan for pre-training2</ref> . MLM leverages bidirectional context of masked tokens efficiently, but ignores the dependency among the masked (and to be predicted) tokens (Yang et al., 2019)</ref>.</p><p>To improve BERT, XLNet (Yang et al., 2019</ref>) introduces permuted language modeling (PLM) for pre-trai nderstanding and generation. For language understanding, masked language modeling (MLM) in BERT (Devlin et al., 2019)</ref> and permuted language modeling (PLM) in XLNet (Yang et al., 2019)</ref> are two representative objectives. In this section, we briefly review MLM and PLM, and discuss their pros and cons.</p><p>MLM in BERT BERT <ref by maximizing the following objective</p><formula xml:id="formula_2">log P (x K |x \K ; ?) ? k?K log P (x k |x \K ; ?). (1)</formula><p>PLM in XLNet Permuted language model (PLM) is proposed in XLNet (Yang et al., 2019)</ref> to retain the benefits of autoregressive modeling and also allow models to capture bidirectional context. For a given sentence x = (x 1 , x 2 , x z&lt;=c . In practice, only a part of last tokens x z&gt;c (usually c = 85% * n) are chosen to predict and the remaining tokens are used as condition in order to reduce the optimization difficulty (Yang et al., 2019)</ref>.</p><p>Pros and Cons of MLM and PLM We compare MLM and PLM from two perspectives: the dependency in the predicted (output) tokens and the discr ="formula">1</ref>, MLM assumes the masked tokens are independent with each other and predicts them separately, which is not sufficient to model the complicated context dependency in natural language (Yang et al., 2019)</ref>. In contrast, PLM factorizes the predicted tokens with the product rule in any permuted order, as shown in Equation 2</ref> e in permuted order, the next predicted token could occur in any position, which makes it difficult for normal autoregressive prediction. To this end, we follow PLM to adopt two-stream self-attention (Yang et al., 2019)</ref> to autoregressively predict the tokens, which is illustrated in Figure 3</ref>. In two-stream self-attention lways see n tokens, where n is the length of original sequence (in the above example, n = 6) 4 . For example, when predicting token x z 5 = x 6 , the query stream in the original two-stream attention (Yang et al., 2019)</ref> takes mask token M z 5 = [M ] and position p z 5 = p 6 as the attention query, and can only see previous tokens x z &lt;5 = (x 1 , x 3 , x 5 , jective. We assume all the three objectives mask and predict the same amount of tokens (15%), following the common practice in BERT (Devlin et al., 2019)</ref> and XLNet (Yang et al., 2019)</ref> 5</ref> . As can be seen, MLM conditions on 85% tokens and 100% positions since masked tokens contains positi ts of 12 transformer layers, with 768 hidden size, 12 attention heads as 12, and 110M model parameters in total. For the pretraining objective of MPNet, we randomly permute the sentence following PLM (Yang et al., 2019)</ref>  7</ref> , choose the rightmost 15% tokens as the predicted tokens, and prepare mask tokens following the sam batch size of 8192 sentences. We use Adam (Kingma and Ba, 2014) with ? 1 = 0.9, ? 2 = 0.98 and = 1e -6. We pre-train our model for 500K steps to be comparable with state-of-the-art models like XLNet (Yang et al., 2019)</ref>, RoBERTa (Liu et al., 2019a)</ref> and ELECTRA (Clark et al., 2020)</ref>. We use 32 NVIDIA Tesl BASE setting and from MNLI QNLI QQP RTE SST MRPC CoLA STS Avg Single model on dev set BERT (Devlin et al., 2019)</ref> 84.5 91.7 91.3 68.6 93.2 87.3 58.9 89.5 83.1 XLNet (Yang et al., 2019)</ref> 86.8 91.7 91.4 74.0 94.7 88.2 60.2 89.5 84.5 RoBERTa (Liu et al., 2019a)</ref> 87 </p></div> <div xmlns="http://www.tei-c.org/ ., 2019a)</ref>  single model without any data augmentation for fair comparisons. On the dev set of GLUE tasks, MPNet outperforms BERT (Devlin et al., 2019)</ref>, XLNet (Yang et al., 2019)</ref> and RoBERTa (Liu et al., 2019a)</ref> by 4.6, 3.2, 1.3 points on average. On the test set of GLEU tasks, MPNet outperforms ELE el><figDesc>Results on the RACE and IMDB test set under BERT BASE setting. For RACE, the results of BERT are from the RACE leaderboard 10 and the results of XL-Net are obtained from the original paper(Yang et al., 2019)</ref>. "Middle" and "High" denote the accuracy on the middle school set and high school set in RACE. For IMDB, the result of BERT is from<ref type="b . For IMDB, the result of BERT is fromSun et al. (2019)</ref> and the result of XLNet is ran by ourselves with only PLM pre-training objective but no long context memory(Yang et al., 2019)</ref>. "*" represents pre-training only on Wikipedia and BooksCorpus (16GB size).</figDesc><table /></figure> 			<note xmlns="http://www.tei-c.org/ns l context of masked tokens efficiently, but ignores the dependency among the masked (and to be predicted) tokens (Yang et al., 2019)</ref>.</p><p>To improve BERT, XLNet (Yang et al., 2019</ref>) introduces permuted language modeling (PLM) for pre-training to capture the dependency among the predicted tokens. However, PLM has its own lim information of all the tokens in the sentence and thus alleviates the position discrepancy of XLNet.</p><p>We pre-train MPNet on a large-scale text corpora (over 160GB data) following the practice in Yang et al. (2019)</ref>; Liu et al. (2019a)</ref>, and fine-tune on a variety of down-streaming benchmark tasks, including GLUE, SQuAD, RACE and IMDB. ent stream can see all the previous and current tokens and positions, as shown in Figure 2a</ref>. For more details about two-stream self-attention, please refer to Yang et al. (2019)</ref>. One drawback of two-stream self-attention in PLM is that it can only see the the previous Table 1</ref>: An example sentence 9</ref> .</p><p>During fine-tuning, we do not use query stream in two-stream self-attention and use the original hiddens to extract context representations following Yang et al. (2019)</ref>. The fine-tuning experiments on each downstream tasks are conducted 5 times and the median value is chosen as the final result. For experimental dding (Shaw et al., 2018)</ref> 8</ref> in our model pretraining since these tricks have been successfully validated in previous works (Yang et al., 2019;</ref>Raffel et al., 2019b)</ref>.</p><p>For pre-training corpus, we follow the data used in RoBERTa (Liu et al., 20 Corpus (16GB size).</figDesc><table /></figure> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We do not consider next sentence prediction here since previous works(Yang et al., 2019;</ref> Liu et al., 2019a;Joshi et al., 2019)</ref> have achieved good results without next sentence prediction.</p></not

nts gain (72.0 vs. 70.4) can be further achieved.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results on IMDB</head><p>We further study MPNet on the IMDB text classification task (Maas et al., 2011)</ref>, which contains over 50,000 movie reviews for binary sentiment classification. The results are reported in Table <ref type="table" target="#tab
ingle-sentence tasks (CoLA (Warstadt et al., 2018)</ref>, SST-2 (Socher et al., 2013)</ref>), three similarity and paraphrase tasks (MRPC (Dolan and Brockett, 2005)</ref>, STS-B (Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams
="#b0">(Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et al., 2016)</ref>, RTE (Dagan et al., 2006)</ref>, WNLI (Levesque et al., 2012)</ref>). We follow RoBERTa hyper-parameters for single-task finetuning, where RTE,
troduction</head><p>Pre-training models (Radford et al., 2018;</ref>Devlin et al., 2019;</ref>Radford et al., 2019b;</ref>Song et al., 2019;</ref>Yang et al., 2019;</ref>Dong et al., 2019;</ref>Liu et al., 2019a;< .tei-c.org/ns/1.0"><head n="2.1">Background</head><p>The key of pre-training methods (Radford et al., 2018;</ref>Devlin et al., 2019;</ref>Song et al., 2019;</ref>Yang et al., 2019;</ref>Clark et al., 2020)</ref> is the design of self-supervised t
al., 2018)</ref>, SST-2 (Socher et al., 2013)</ref>), three similarity and paraphrase tasks (MRPC (Dolan and Brockett, 2005)</ref>, STS-B (Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et
="#b0">(Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et al., 2016)</ref>, RTE (Dagan et al., 2006)</ref>, WNLI (Levesque et al., 2012)</ref>). We follow RoBERTa hyper-parameters for single-task finetuning, where RTE,
in BERT (Devlin et al., 2019)</ref>. Additionally, we also apply whole word mask (Cui et al., 2019)</ref> and relative positional embedding (Shaw et al., 2018)</ref> 8</ref> in our model pretraining since these tricks have been successfully validated in previous works <ref t
ingle-sentence tasks (CoLA (Warstadt et al., 2018)</ref>, SST-2 (Socher et al., 2013)</ref>), three similarity and paraphrase tasks (MRPC (Dolan and Brockett, 2005)</ref>, STS-B (Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams
ee similarity and paraphrase tasks (MRPC (Dolan and Brockett, 2005)</ref>, STS-B (Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et al., 2016)</ref>, RTE (Dagan et al., 2006)</ref>, WNLI <re
ults on GLUE tasks, demonstrating the advantages of MPNet.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results on RACE</head><p>The ReAding Comprehension from Examinations (RACE) (Lai et al., 2017)</ref>  four choices. The task is to select the correct choice based on the given options. The results on RACE task are listed in Table <ref type="table
bibr" target="#b4">Devlin et al., 2019;</ref>Radford et al., 2019b;</ref>Song et al., 2019;</ref>Yang et al., 2019;</ref>Dong et al., 2019;</ref>Liu et al., 2019a;</ref>Raffel et al., 2019a)</ref> have greatly boosted * Authors contribute equally to this wo
nts gain (72.0 vs. 70.4) can be further achieved.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results on IMDB</head><p>We further study MPNet on the IMDB text classification task (Maas et al., 2011)</ref>, which contains over 50,000 movie reviews for binary sentiment classification. The results are reported in Table <ref type="table" target="#tab
="#b0">(Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et al., 2016)</ref>, RTE (Dagan et al., 2006)</ref>, WNLI (Levesque et al., 2012)</ref>). We follow RoBERTa hyper-parameters for single-task finetuning, where RTE,
and cons.</p><p>MLM in BERT BERT (Devlin et al., 2019)</ref> is one of the most successful pre-training models for natural language understanding. It adopts Transformer (Vaswani et al., 2017)</ref> as the feature extractor and introduces masked language model (MLM) and next sentence prediction as training objectives to learn bidirection iew of MLM and PLM</head><p>To address the issues and inherit the advantages of MLM and PLM, in this section, we provide a unified view to understand MLM and PLM. Both BERT and XLNet take Transformer (Vaswani et al., 2017)</ref> as their backbone. Transformer takes tokens and their positions in a sentence as input, and is not sensitive to the absolute input order of
b5">(Dolan and Brockett, 2005)</ref>, STS-B (Cer et al., 2017)</ref>, QQP), four inference tasks (MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et al., 2016)</ref>, RTE (Dagan et al., 2006)</ref>, WNLI (Levesque et al., 2012)</ref>). We foll nswering (SQuAD)</head><p>The Stanford Question Answering Dataset (SQuAD) task requires to extract the answer span from the provided context based on the question. We evaluate our model on SQuAD v1.1 (Rajpurkar et al., 2016)</ref> and SQuAD v2.0 (Rajpurkar et al., 2018)</ref>. SQuAD v1.1 always exists the corresponding answer for each q
ain MPNet in BERT LARGE setting in the future.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results on GLUE Benchmark</head><p>The General Language Understanding Evaluation (GLUE) (Wang et al., 2019)</ref> is a collection of 9 natural language understanding tasks, which include two single-sentence tasks (CoLA (Warsta
and cons.</p><p>MLM in BERT BERT (Devlin et al., 2019)</ref> is one of the most successful pre-training models for natural language understanding. It adopts Transformer (Vaswani et al., 2017)</ref> as the feature extractor and introduces masked language model (MLM) and next sentence prediction as training objectives to learn bidirection iew of MLM and PLM</head><p>To address the issues and inherit the advantages of MLM and PLM, in this section, we provide a unified view to understand MLM and PLM. Both BERT and XLNet take Transformer (Vaswani et al., 2017)</ref> as their backbone. Transformer takes tokens and their positions in a sentence as input, and is not sensitive to the absolute input order of
bibr" target="#b4">Devlin et al., 2019;</ref>Radford et al., 2019b;</ref>Song et al., 2019;</ref>Yang et al., 2019;</ref>Dong et al., 2019;</ref>Liu et al., 2019a;</ref>Raffel et al., 2019a)</ref> have greatly boosted * Authors contribute equally to this wo
nts gain (72.0 vs. 70.4) can be further achieved.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results on IMDB</head><p>We further study MPNet on the IMDB text classification task (Maas et al., 2011)</ref>, which contains over 50,000 movie reviews for binary sentiment classification. The results are reported in Table <ref type="table" target="#tab
nt train-ing and inference. Recently, GCNs attract substantial efforts from both the industrial and academic communities [3,</ref>14,</ref>18,</ref>20,</ref>28,</ref>43,</ref>44]</ref> on.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Need for a GCN Accelerator</head><p>GCNs are showing great potential in various tasks [16,</ref>18,</ref>19,</ref>38,</ref>43,</ref>46]</ref> d><p>GCNs follow a neighborhood aggregation scheme, where the feature vector of each vertex is computed by recursively aggregating and transforming the representation vectors of its neighbor vertices [18,</ref>39,</ref>47]</ref>. Fig. 1</ref> illustrates the execution pha the computational complexity, the Sample function is usually applied before the Aggregate function to sample a subset from the neighbor vertices of each vertex [6,</ref>18]</ref> as the new neighbors, specifically,</p><formula xml:id="formula_1">S(v) = Sample k N(v) .</formula><p>(2) Sometimes, the Pool function <ref type="bibr" target= ReLU(W k a k v + b k ).<label>(4)</label></formula><p>GraphSage further adopts uniform neighbor sampling to alleviate receptive field expansion that effectively trades off accuracy and execution time [18]</ref>. It is formulated as</p><formula xml:id="formula_4">a k v = Mean {h (k−1) v } ∪ {h (k−1) u , ∀u ∈ S(v)} , h k v = ReLU(W k a k v + b k ).<label>(5)</label></f layer or multiple layers). Sampling is used to sample a subset from neighbors, which can be done during preprocessing [20]</ref> or with random selection during runtime [18]</ref>. Aggregation aggregates the features from its 1-hop neighbors. Pooling acts like the pooling layer in CNNs to realize graph transformation by reducing the num software framework PyTorch Geometric [15]</ref> on Intel Xeon CPU. The execution time breakdown of GCN (GCN) [25]</ref>, GraphSage (GSC) [18]</ref>, and GINConv (GIN) [39]</ref> on several datasets [23]</ref> is illustrated in Fig. <ref type="f
aling factors to convert them to 12 nm technology as shown in [33,</ref>36]</ref>. The energy of HBM 1.0 is estimated with 7 pJ/bit as in [32,</ref>41]</ref>. Benchmark Graph Datasets and GCN Models. Table 4</ref> and Table <ref type="table"
ms. GCNs demand specialized architecture design. With the emergence of graph analytics and neural networks workloads, a lot of hardware architecture designs are proposed to accelerate these workloads [7,</ref>8,</ref>17,</ref>22,</ref>33]</ref>. F
et="#b25">[25]</ref>, link prediction [14,</ref>16]</ref>, graph clustering [44]</ref>, and recommendation [12]</ref>. As a result, GCNs gradually become a new workload family member in data-centers, such as in Google [13]</ref>, Facebook <ref t
aph analytics and neural networks have been presented to release the programming efforts while achieving high performance on modern generalpurpose architectures [5,</ref>34,</ref>35,</ref>37]</ref>. However, all of them only work well for the single-pattern workloads. Therefor
type="bibr" target="#b11">[11]</ref>, they fail to address the abundant dynamic and irregular data accesses in the Aggregation phase since the irregularity harms the predictability of memory accesses [10]</ref>. Besides, it is difficult to efficiently implement the reuse of the highly reusable parameter data between computing units in CPUs as like TPU <ref type="bibr
using Cacti 6.5 [1]</ref>. Since Cacti only supports down to 32 nm technologies, we apply four different scaling factors to convert them to 12 nm technology as shown in [33,</ref>36]</ref>. The energy of HBM 1.0 is estimated with 7 pJ/bit as in [32,</ref><ref type="bibr" targ are proposed to accelerate these workloads [7,</ref>8,</ref>17,</ref>22,</ref>33]</ref>. For example, Graphicionado [17]</ref> is tailored for graph analtyics; while TPU [22]</ref> focu
[3,</ref>14,</ref>18,</ref>20,</ref>28,</ref>43,</ref>44]</ref> to solve problems including node classification [25]</ref>, link prediction <ref type="b owing great potential in various tasks [16,</ref>18,</ref>19,</ref>38,</ref>43,</ref>46]</ref>. Many companies, such as Google [13]</ref>, Facebook [28] arge number of software frameworks for hybrid-pattern GCNs are proposed recently [2,</ref>15,</ref>28,</ref>43,</ref>47]</ref>. For instance, Py-Torch Geometric [15]</ref> leverages message-passing framework to enha
aph analytics and neural networks have been presented to release the programming efforts while achieving high performance on modern generalpurpose architectures [5,</ref>34,</ref>35,</ref>37]</ref>. However, all of them only work well for the single-pattern workloads. Therefor
struct a neural network for the consequent train-ing and inference. Recently, GCNs attract substantial efforts from both the industrial and academic communities [3,</ref>14,</ref>18,</ref>20,</ref>28,</ref>43,</ref> 8">28,</ref>43,</ref>44]</ref> to solve problems including node classification [25]</ref>, link prediction [14,</ref>16]</ref>, graph clustering [44]</ref>, and recommendation [12]</r
"#b0">[1]</ref>. Since Cacti only supports down to 32 nm technologies, we apply four different scaling factors to convert them to 12 nm technology as shown in [33,</ref>36]</ref>. The energy of HBM 1.0 is estimated with 7 pJ/bit as in [32,</ref>41]</ref>. Benchmark Graph Data
cost and the resulting low throughput and high elapsed time for compression intense workloads. In the past, IBM z13 and many other systems have used FPGA based PCIe attached compression accelerators [2]</ref>- [5]</ref>. However, the FPGA cost and limited number of PCIe slots restrict their usage to high-end servers <ref type="bibr" targ ression accelerators [2]</ref>- [5]</ref>. However, the FPGA cost and limited number of PCIe slots restrict their usage to high-end servers [2]</ref> and specialized applications such as storage controllers.</p><p>IBM POWER9 (launched in 2017), and IBM z15 (launched in 2019) overcome the shortcomings of exist the largest z15 system topology with 20 processor chips, 20 NXU units provide 280 GB/s total throughput [6]</ref>. We would need 68 PCIe based compression cards such as [2]</ref>, with 4GB/s peak throughput to match the NXU performance. Besides substantial improvements in performance, the compression function on IBM z15 features a novel g in a tradeoff between area (or memory), performance, and compression ratio. We describe an area efficient LZ77 encoding hardware that improves state of the art in Section IV, where the related work [2]</ref>- [4]</ref>, [14]</ref>- [19]</ref> are also discussed.</p><p>Deflate es the compression ratio. In contrast, we implemented a true "Dynamic Huffman" mode in both POWER9 and z15 to achieve highest possible compression ratio, as described in Section V, where related work [2]</ref>- [4]</ref>, [7]</ref>, [14]</ref>, [20 - [32]</ref>.</p><p>IBM has been employing compression hardware and software extensively in its products. IBM z13 and POWER systems used PCIe based Deflate accelerators [2]</ref>, [5]</ref>, [15]</ref>, [28]</ref>. POWER7+ processor implemented a ER9. Prior art, mostly FPGA based, often replicate logic to meet throughput and compression ratio objectives which is not suitable for an on-chip design. In [4]</ref> In [2]</ref>, [15]</ref>, the 32KB sliding window data is replicated M times stored directly in M SRAMs organized as hash tables (M = 16). Eac ww.tei-c.org/ns/1.0"><head>D. Discussion on Design Trade-offs</head><p>Many hardware designs implement a static table with an assumed LZ symbol distribution which typically degrades compression ratio [2]</ref>- [4]</ref>, [14]</ref>. For example, Fig. 5</ref> shows the comp tio difference between static and dynamic tables. IBM z13 adapter uses a "pseudo-dynamic" approach where one of 15 different static Huffman tables yielding the smallest output is selected at run time [2]</ref>. We implemented in contrast, a true "Dynamic Huffman" mode for both POWER9 and z15 to achieve highest possible compression ratio.</p><p>On POWER9, software must
for Parquet, by default, define the page size as 1 MB and Snappy as the default compression codec.  Each dataset in Spark is represented as a data structure called resilient distributed dataset (RDD) [65]</ref>, which is a fault-tolerant collection of partitions that can be operated on in parallel. Spark partitions RDDs into multiple partitions. A partition in Spark o compress internal data such as in-memory data partitions, broadcast variables, and shuffle outputs.Each dataset in Spark is represented as a data structure called resilient distributed dataset (RDD)[65]</ref>, which is a fault-tolerant collection of partitions that can be operated on in parallel. Spark partitions RDDs into multiple partitions. A partition in Spark
000 and Storewize SAN storage systems, and TS7700 tape storage systems [16]</ref>- [18]</ref>, [36]</ref>, [37]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>III. HIGH-LEVEL ACCELERATOR OVERVIEW</head><p>The z15 and POWER9 processor chips use 14nm process. N
ref>- [19]</ref> are also discussed.</p><p>Deflate uses variable length prefix-free codes produced by the Huffman algorithm to compress an LZ77 stream by another 10-20% [20]</ref>. Frequent symbols are encoded with fewer bits. For example, the most frequent character 'e' in English may be encoded with 6-bits vs. the usual 8-bits. Deflat in Section V, where related work [2]</ref>- [4]</ref>, [7]</ref>, [14]</ref>, [20]</ref>, [22]</ref>- [26]</ref> and hardware issues are also discussed.</p><p>The prefix-free property a amic Huffman Tables</head><p>The basic Huffman algorithm runs in O(n log n) time where n is the number of symbols in the table; n = 286 for the literal and length symbols and n = 30 for the distances [20]</ref>. The algorithm is sequential and a basic hardware implementation would have a relatively long execution time negatively impacting overall throughput.</p><p>We ed Encoding</head><p>Maximum code length permitted in the Deflate format is 15-bits. The Huffman algorithm builds a binary tree with LZ symbols at the leaves arranged according to their probabilities [20]</ref>. The path from the tree root is the binary code of the LZ symbol assigned to the leaf. In the unlimited case, the tree depth may excessively grow as much as n
choice for providing accelerated compression functionality in highly interconnected enterprise and cloud environments.</p><p>Deflate uses the LZ77 variant of the Lempel-Ziv (LZ) compression algorithm [9]</ref>, followed by an entropy coding algorithm [7]</ref>. Few other compressed data formats and software exist making various trade-offs good compression ratio. We compare our work to previous work in Sections VIII-IX.</p><p>LZ77 replaces duplicate strings with references to earlier copies in the most recent 32KB of the source stream [9]</ref>, called the sliding window or dynamic dictionary (called "History" in this paper). An LZ reference is a distance/length pair, a copy instruction from an earlier

ve that with a single thread, POWER9 NXU and z15 NXU compression throughputs are low for small data sizes, then reach their peak at about 256 KB data size. Although a detailed accelerator model LogCA [50]</ref> exists, we used a simpler model to estimate the data granularity   we get T = 2T 0 which means that half the time is spent in the setup and the other half in

>IX. RESULTS: END TO END APPLICATION PERFORMANCE</head><p>Data compression is a vital component in large scale big data applications for improving storage space efficiency and application performance [52]</ref>.</p><p>In this section, we first describe the integration of NXU into two components of the Hadoop ecosystem: Apache Spark [53] (NoSQL database) and many other applications.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. TPC-DS Benchmark on Apache Spark</head><p>TPC-DS is a de-facto standard benchmark in academia [52]</ref>, [56]</ref>- [58]</ref> and industry [59]</ref>- <ref type="bibr"
.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Power and Energy Efficiency</head><p>Figure 15</ref> shows active power measurement of a POWER9 system [51]</ref> with the accelerator and with cores-only. One or 80 independent copies of the zlib/zpipe.c utility running on a single POWER9 chip are used. Active power is d

t self-supervised techniques which often function by considering each image as its own class and dissimilar from every other image in the dataset (Wu et al., 2018;</ref>Chen et al., 2020)</ref>. We propose to train feature representations on the novel target domain to replicate this induced grouping. This approach produces a feature repr arning is contrastive learning (Wu et al., 2018;</ref>Misra &amp; Maaten, 2020;</ref>He et al., 2020;</ref>Chen et al., 2020)</ref> which aims to learn representations by considering each image together with its augmentations as a separate class. While self supervision has bee eled , is intended to help the learner extract additional useful knowledge specific to the target domain. We use a state-of-the-art self-supervised loss function based on contrastive learning: SimCLR (Chen et al., 2020)</ref>. The SimCLR loss encourages two augmentations of the same image to be closer in feature space to each other than to other images in the batch. W ks. These techniques do not use the novel domain unlabeled data.</p><p>We also compare to another baseline, SimCLR that uses the novel domain unlabeled data D u to train a representation using SimCLR (Chen et al., 2020)</ref>, and then uses the resulting representation to learn linear classifiers for few-shot tasks. This builds upon state-of-the-art self-supervised te

e to each other than to other images in the batch. We refer the reader to the paper for the detailed loss formulation.</p><p>The first two terms are similar to those in prior self-training literature (Xie et al., 2020)</ref>. However, while in prior self-training work, the second term (l KL ) is thought to mainly introduce noise during training, we posit that l KL ha pe="bibr" target="#b12">Guo et al. (2020)</ref>, we freeze the representation φ after performing STARTUP and train a linear classifier on the support set and evaluate the classifier on the query set. Xie et al. (2020)</ref> found that training the student from scratch sometimes yields better results for Im-ageNet classification. To investigate, we focused on a varian isingly good representation.</note></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>STARTUP ADDS NOISE WHICH INCREASES ROBUSTNESS.Xie et al. (2020)</ref> posit that self-training introduces noise when training the student and thus yielding a more robust student. More robust students may be learning


with unlabeled data. This paper uses unlabeled data from the target domain to bridge the domain gap. Semi-supervised few-shot learning (SS-FSL) (Ren et al., 2018;</ref>Li et al., 2019;</ref>Yu et al., 2020;</ref>Rodríguez et al., 2020;</ref>Wan
ecent work (Guo et al., 2020;</ref>Chen et al., 2019a)</ref> has shown that existing stateof-the-art few-shot learners fail to generalize. Tseng et al. (2020)</ref> attempt to address this problem by simulating cross-domain transfer during training. However, their approach assumes access to an equally diver Baselines. We compare to the techniques reported in Guo et al. (2020)</ref>, which includes most stateof-the-art approaches as well as a cross-domain few-shot technique Tseng et al. (2020)</ref>. The top performing among these is naive Transfer which simply trains a convolutional network to classify the base dataset, and uses the result otoNet: (Snell et al., 2017)</ref>, MAML: (Finn et al., 2017)</ref>, MetaOpt: (Lee et al., 2019)</ref> FWT: (Tseng et al., 2020)</ref>. * Numbers reported in (Guo et al., 2020)</ref> We conjecture that the base embedding is not a good starting po otoNet: (Snell et al., 2017)</ref>, MAML: (Finn et al., 2017)</ref>, MetaOpt: (Lee et al., 2019)</ref> FWT: (Tseng et al., 2020)</ref>. * Numbers reported in (Guo et al., 2020)</ref> ), from teacher model (STARTUP-T (no SS)). We repeated the expe
time than the usual FSL setup.</p><p>Few-shot learning with unlabeled data. This paper uses unlabeled data from the target domain to bridge the domain gap. Semi-supervised few-shot learning (SS-FSL) (Ren et al., 2018;</ref>Li et al., 2019;</ref>Yu et al., 2020;</ref>Rodrígue get is smaller? To answer this, we tested STARTUP on two popular within-domain few-shot learning benchmark: miniImageNet (Vinyals et al., 2016)</ref> and tieredImageNet (Ren et al., 2018)</ref>. For miniImageNet, we use 20% of the and tieredImageNet-more that uses 50% of the novel set as unlabeled data. We follow the same evaluation pro
time than the usual FSL setup.</p><p>Few-shot learning with unlabeled data. This paper uses unlabeled data from the target domain to bridge the domain gap. Semi-supervised few-shot learning (SS-FSL) (Ren et al., 2018;</ref>Li et al., 2019;</ref>Yu et al., 2020;</ref>Rodrígue get is smaller? To answer this, we tested STARTUP on two popular within-domain few-shot learning benchmark: miniImageNet (Vinyals et al., 2016)</ref> and tieredImageNet (Ren et al., 2018)</ref>. For miniImageNet, we use 20% of the and tieredImageNet-more that uses 50% of the novel set as unlabeled data. We follow the same evaluation pro
time than the usual FSL setup.</p><p>Few-shot learning with unlabeled data. This paper uses unlabeled data from the target domain to bridge the domain gap. Semi-supervised few-shot learning (SS-FSL) (Ren et al., 2018;</ref>Li et al., 2019;</ref>Yu et al., 2020;</ref>Rodrígue get is smaller? To answer this, we tested STARTUP on two popular within-domain few-shot learning benchmark: miniImageNet (Vinyals et al., 2016)</ref> and tieredImageNet (Ren et al., 2018)</ref>. For miniImageNet, we use 20% of the and tieredImageNet-more that uses 50% of the novel set as unlabeled data. We follow the same evaluation pro
ecent work (Guo et al., 2020;</ref>Chen et al., 2019a)</ref> has shown that existing stateof-the-art few-shot learners fail to generalize. Tseng et al. (2020)</ref> attempt to address this problem by simulating cross-domain transfer during training. However, their approach assumes access to an equally diver Baselines. We compare to the techniques reported in Guo et al. (2020)</ref>, which includes most stateof-the-art approaches as well as a cross-domain few-shot technique Tseng et al. (2020)</ref>. The top performing among these is naive Transfer which simply trains a convolutional network to classify the base dataset, and uses the result otoNet: (Snell et al., 2017)</ref>, MAML: (Finn et al., 2017)</ref>, MetaOpt: (Lee et al., 2019)</ref> FWT: (Tseng et al., 2020)</ref>. * Numbers reported in (Guo et al., 2020)</ref> We conjecture that the base embedding is not a good starting po otoNet: (Snell et al., 2017)</ref>, MAML: (Finn et al., 2017)</ref>, MetaOpt: (Lee et al., 2019)</ref> FWT: (Tseng et al., 2020)</ref>. * Numbers reported in (Guo et al., 2020)</ref> ), from teacher model (STARTUP-T (no SS)). We repeated the expe
="bibr" target="#b36">[37,</ref>8,</ref>12]</ref>.</p><p>Our approach has some similarities with Predictions of Bootstrapped Latents (PBL, [49]</ref>), a selfsupervised representation learning technique for reinforcement learning (RL). PBL jointly trains the agent's history representation and an encoding of
"bibr" target="#b1">2,</ref>3]</ref> as it allows for efficient training on downstream tasks [4,</ref>5,</ref>6,</ref>7]</ref>. Many different training approaches have been proposed to learn such representations, usually relying on visual pretext tas
-IN baseline (+1.9 mIoU) and SimCLR (+1.1 mIoU).</p><p>Similarly, we evaluate on object detection by reproducing the setup in [9]</ref> using a Faster R-CNN architecture [82]</ref>, as detailed in Appendix E.5. We fine-tune on trainval2007 and report results on test2007 using the standard AP 50 metric; BYOL is significantly better than t
entation of different views of the same image closer ('positive pairs'), and spreading representations of views from different images ('negative pairs') apart [39,</ref>40]</ref>. Contrastive methods often require comparing each example with many other examples to work well [9,</ref><ref type="bibr" target= d methods are not contrastive but rely on using auxiliary handcrafted prediction tasks to learn their representation. In particular, relative patch prediction [23,</ref>40]</ref>, colorizing grayscale images [41,</ref>42]</ref>, image inpainting <ref type="bibr" target="#b42" here the depth map of a scene is estimated given a single RGB image. Depth prediction measures how well a network represents geometry, and how well that information can be localized to pixel accuracy [40]</ref>. The setup is based on [83]</ref> and detailed in Appendix E.6. We evaluate on the commonly used test subset of 654 images and mean squared (rms) error, and the percent of pixels (pct) where the error, max(d gt /d p , d p /d gt ), is below 1.25 n thresholds where d p is the predicted depth and d gt is the ground truth depth [40]</ref>. BYOL is better or on par with other methods for each metric. For instance, the challenging pct.&lt;1. 25</ref>   </p></div> <d
type="bibr" target="#b15">[16]</ref>, cluster indices [17]</ref> or a handful of labels [18,</ref>19,</ref>20]</ref>, we propose to directly bootstrap the representations. In particular, BYOL uses two neural networks, referred to as online and target networks, that interact a 55,</ref>56]</ref>, an unsupervised loss is combined with a classification loss over a handful of labels to ground the training [19,</ref>20,</ref>57,</ref>58,</ref>59,</ref>60,</ref> ref type="bibr" target="#b58">59,</ref>60,</ref>61,</ref>62]</ref>. Among these methods, mean teacher (MT) [20]</ref> also uses a slow-moving average network, called teacher, to produce targets for an online network, called student. An 2 consistency loss between the softmax p lled teacher, to produce targets for an online network, called student. An 2 consistency loss between the softmax predictions of the teacher and the student is added to the classification loss. While [20]</ref> demonstrates the effectiveness of MT in the semi-supervised learning case, in Section 5 we show that a similar approach collapses when removing the classifica e that modifying the architecture of S θ to include a predictor only mildly affects the performance of SimCLR.</p><p>Relationship with Mean Teacher Another semi-supervised approach, Mean Teacher (MT) [20]</ref>, complements a supervised loss on few labels with an additional consistency loss. In [20]</ref>, this consistency loss is the 2 ip with Mean Teacher Another semi-supervised approach, Mean Teacher (MT) [20]</ref>, complements a supervised loss on few labels with an additional consistency loss. In [20]</ref>, this consistency loss is the 2 distance between the logits from a student network, and those of a temporally averaged version of the student network, called

orks (as in [54]</ref>) in order to provide smoother changes in the target representation.</p><p>In the semi-supervised setting [55,</ref>56]</ref>, an unsupervised loss is combined with a classification loss over a handful of labels to ground the training [19,</ref><ref type
of using a slow-moving average target network to produce stable targets for the online network was inspired by deep RL [50,</ref>51,</ref>52,</ref>53]</ref>. Target networks stabilize the bootstrapping updates provided by the Bellman equation, making them appealing to stabili
Net</head><p>We first evaluate BYOL's representation by training a linear classifier on top of the frozen representation, following the procedure described in [48,</ref>74,</ref>41,</ref>10,</ref>8]</ref>, and appendix D.1; we report top-1 and top mance obtained when finetuning BYOL's representation on a classification task with a small subset of ImageNet's train set, this time using label information. We follow the semi-supervised protocol of [74,</ref>76,</ref>8,</ref>32]</ref> detailed in Appendix D.1, and use the sa thus useful across image domains, or if they are ImageNet-specific. We perform linear evaluation and fine-tuning on the same set of classification tasks used in [8,</ref>74]</ref>, and carefully follow their evaluation protocol, as detailed in Appendix E. Performance is reported using standard metrics for each benchmark, and results are
ned with a classification loss over a handful of labels to ground the training [19,</ref>20,</ref>57,</ref>58,</ref>59,</ref>60,</ref>61,</ref>62]</ref>
-IN baseline (+1.9 mIoU) and SimCLR (+1.1 mIoU).</p><p>Similarly, we evaluate on object detection by reproducing the setup in [9]</ref> using a Faster R-CNN architecture [82]</ref>, as detailed in Appendix E.5. We fine-tune on trainval2007 and report results on test2007 using the standard AP 50 metric; BYOL is significantly better than t
attribute information while retaining high utility for users.</p><p>Recommendation while countering private-attribute inference attack can be naturally formulated as a problem of adversarial learning [19]</ref>. In our proposed RAP, there are two components: a Bayesian personalized ranking recommender and a private-attribute inference attacker (illustrated in Figure
r publicly available information. These attacks could be categorized into three groups.A group of these attacks leverages a target user's friends' information [18,</ref>21,</ref>31]</ref> and community membership information [34,</ref>44]</ref>
.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>Explosive growth of the Web has raised numerous challenges for online users including disinformation spread [1]</ref>[2]</ref>[3]</ref>[4]</ref> and threats to users' privacy [7,</ref><ref type="bi
eb has raised numerous challenges for online users including disinformation spread [1]</ref>[2]</ref>[3]</ref>[4]</ref> and threats to users' privacy [7,</ref>9]</ref>. Addressing user privacy issues has been studied fro
urbation based [32,</ref>38,</ref>41]</ref> approaches. Some methods utilize differential privacy strategy [14]</ref> to modify the answers of the recommendation algorithm so the the presence of a user's data (either a single user-item rating or entire user's history) is mask
such that the adversary cannot deduce the user's actual ratings and preferences (i.e., perturbation based techniques) [32,</ref>38,</ref>41]</ref>.</p><p>Another privacy issue is the disclosure of user private-attribute information through leaked users' interactions history  #b25">26,</ref>33,</ref>45]</ref> and perturbation based [32,</ref>38,</ref>41]</ref> approaches. Some methods utilize differential privacy strategy [14]</ref> to modify the answers of the recommendation algorithm f> makes items list differentially private and then sends it to recommender. Perturbation based techniques obfuscate user's interactions history by adding fake items and ratings to it. Rebollo et al. [41]</ref> propose an information theoretic based privacy metric and then find the obfuscation rate for generating forged user profiles so that the privacy risk is minim
WORK</head><p>Explosive growth of the Web has raised numerous challenges for online users including disinformation spread [1]</ref>[2]</ref>[3]</ref>[4]</ref> and threats to users' privacy [7,</ref>9]</ref>. Addressing u
e accurate assessment. Lower AUC demonstrates higher privacy in terms of obscuring private attributes. • Recommendation Evaluation: We use standard metrics that are widely used in other related works [46]</ref>, i.e., P@K and R@K. P@K: P@K represents the ratio of test cases which has been successfully recommended in a top-K position in a ranking list to value of K. F
target="#b40">[41]</ref> propose an information theoretic based privacy metric and then find the obfuscation rate for generating forged user profiles so that the privacy risk is minimized. Similarly, [37]</ref> proposes to add or remove items and ratings from user profiles minimize privacy risk. Polat et al. [38]</ref> use a randomized
usted.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>Explosive growth of the Web has raised numerous challenges for online users including disinformation spread [1]</ref>[2]</ref>[3]</ref>[4]</ref> and threats to users' privacy <ref type="bi
eb has raised numerous challenges for online users including disinformation spread [1]</ref>[2]</ref>[3]</ref>[4]</ref> and threats to users' privacy [7,</ref>9]</ref>. Addressing user privacy issues has been studied fro
. § 3.1), Graph Diffusion Convolution [18]</ref> replaces the adjacency matrix with a sparsified version of a diffusion matrix (e.g., heat kernel or PageRank). Geom-GCN [26]</ref> precomputes unsupervised node embeddings and uses neighborhoods defined by geometric relationships in the resulting latent space to define graph convolution. (and their employed designs among D1-D3) under heterophily (benchmarks with h ≤ 0.3), homophily (h ≥ 0.7), and across the full spectrum ("Overall"). The "*" denotes ranks based on results reported in [26]</ref>. Real datasets &amp; setup We now evaluate the performance of our model and existing GNNs on a variety of real-world datasets [ rks (except Cora-Full), we use the feature vectors, class labels, and 10 random splits (48%/32%/20% of nodes per class for train/validation/test2</ref> ) provided by [26]</ref>.</p><p>For Cora-Full, we generate 3 random splits, with 25%/25%/50% of nodes per class for train/validation/test.</p><p>Effectiveness of design choices Table /1.0"><head>Additional model comparison</head><p>In Table 4</ref>, we also report the best results among the three recentlyproposed GEOM-GCN variants ( § 4), directly from the paper [26]</ref>: other models (including ours) outperform this method significantly under heterophily. We note that MLP is a competitive baseline under heterophily (ranked 6. <p>• Texas, Wisconsin and Cornell are graphs representing links between web pages of the corresponding universities, originally collected by the CMU WebKB project. We used the preprocessed version in [26]</ref>. In these networks, nodes are web pages, which are classified into 5 categories: course, faculty, student, project, staff. • Squirrel and Chameleon are subgra subgraphs of web pages in Wikipedia discussing the corresponding topics, collected by [29]</ref>. For the classification task, we utilize the class labels generated by [26]</ref>, where the nodes are categorized into 5 classes based on the amount of their average traffic. • Actor is a graph representing actor co-occurrence in Wikipedia et="#b25">[26]</ref>, where the nodes are categorized into 5 classes based on the amount of their average traffic. • Actor is a graph representing actor co-occurrence in Wikipedia pages, processed by [26]</ref> based on the film-director-actor-writer network in [35]</ref>. We also use the class labels generated by <ref type="bibr" targe a pages, processed by [26]</ref> based on the film-director-actor-writer network in [35]</ref>. We also use the class labels generated by [26]</ref>. • Cora, Pubmed and Citeseer are citation graphs originally introduced in [30,</ref>22]</ref>, w l:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Real data: mean accuracy ± stdev over different data splits. Best model per benchmark highlighted in gray. The "*" results are obtained from[26]</ref> and "N/A" denotes non-reported results.</figDesc><table><row><cell></cell><cell>Texas</cell><cell>Wisconsin</cell><cell>Actor</cell><cell cols="6">Squirrel Ch " place="foot" n="2" xml:id="foot_1">(A + I) D−1  2  , where I is the identity and D the degree matrix of A + I.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">[26]</ref> claims that the ratios are 60%/20%/20%, which is different from the actual data splits shared on GitHub.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" p ervised node embeddings and uses neighborhoods defined by geometric relationships in the resulting latent space to define graph convolution. Some of these works [1,</ref>26,</ref>12]</ref> acknowledge the challenges of learning from graphs with heterophily. Others have noted that node labels may have comple
esentations. While these designs have been utilized separately in some prior works [11,</ref>7,</ref>1,</ref>38]</ref>, we are the first to discuss their importance under heterophily by providing novel theoretical justifications and an extensive empirical analysis on a variety . . . , r (K) v<label>(4)</label></formula><p>to explicitly capture local and global information via COMBINE functions that leverage each representation separately-e.g., concatenation, LSTM-attention [38]</ref>. This design is introduced in jumping knowledge networks [38]</ref> and shown to increase the representation power of GCNs unde a COMBINE functions that leverage each representation separately-e.g., concatenation, LSTM-attention [38]</ref>. This design is introduced in jumping knowledge networks [38]</ref> and shown to increase the representation power of GCNs under homophily.</p><p>Intuition. Intuitively, each round collects information with different locality- ssiveness in the general setting.</p><p>Observations. By concatenating the intermediate representations from two rounds with the embedded ego-representation (following the jumping knowledge framework [38]</ref>), GCN's accuracy increases to 58.93%±3.17 for h = 0.1, a 20% improvement over its counterpart without design D3 (Table 1</re ations:</p><formula xml:id="formula_10">r (final) v = COMBINE r (0) v , r (1) v , . . . , r (K) v ,<label>(7)</label></formula><p>where we empirically find concatenation works better than max-pooling [38]</ref> as the COMBINE function.</p><p>In the classification stage (S3), the node is classified based on its final embedding r</p><formula xml:id="formula_11">(final) portance of D2, especially in heterophily.</p><p>(D3) Combination of Intermediate Representations. We compare GraphSAGE, GCN-Cheby and GCN to their corresponding variants enhanced with JK connections [38]</ref>. GCN and GCN-Cheby benefit significantly from D3 in heterophily: their average ranks improve (9.8 vs. 7.2 and 7 vs 3.7, respectively) and their mean accuracie inal benefit of D3 when combined with D1, which GraphSAGE employs. Under homophily, the performance with and without JK connections is similar (gaps mostly less than 2%), matching the observations in [38]</ref>.</p><p>While other design choices and implementation details may confound a comparative evaluation of D1-D3 in different models (motivating our introduction o 4 -early_stopping: {40, 100, 200} -weight_decay: {5e-5, 1e- For GCN+JK, GCN-Cheby+JK and GraphSAGE+JK, we enhanced the corresponding base model with jumping knowledge (JK) connections using JK-Concat [38]</ref> without changing the number of layers or other hyperparameters for the base method.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>G Synthetic Datas rity Function σ: {ReLU, None} -Dropout Rate: {0, 0.5}</p><p>For GCN+JK, GCN-Cheby+JK and GraphSAGE+JK, we enhanced the corresponding base model with jumping knowledge (JK) connections using JK-Concat [38]</ref> without changing the number of layers or other hyperparameters for the base method.</p><p>Cora Full Benchmark Tuning The number of class labels in Cora-Full a
model the homophily principle by propagating features and aggregating them within various graph neighborhoods via different mechanisms (e.g., averaging, LSTM) [17,</ref>11,</ref>36]</ref>. However, in the real world, there are also settings where "opposites attract", leading to networks with heterophily: l sing an attention mechanism, GAT [36]</ref> models the influence of different neighbors more precisely as a weighted average of the ego-and neighbor-features. GraphSAGE [11]</ref> generalizes the aggregation beyond averaging, and models the ego-features distinctly from the neighbor-features in its subsampled neighborhood.</p><p>Homophil n of COMBINE (akin to 'skip connection' between layers) is critical: a simple way to combine the ego-and the aggregated neighbor-embeddings without 'mixing' them is with concatenation as in GraphSAGE [11]</ref>-rather than averaging all of them as in the GCN model by Kipf and Welling [17]</ref>.</p><p>Intuition. In heterophily settings, type="bibr" target="#b9">[10]</ref> into GNNs. GCN [17]</ref> GAT [36]</ref> GCN-Cheby [7]</ref> GraphSAGE [11]</ref> MixHop [1]</ref> H2GCN (proposed)</p><p>Comparison of H 2 GCN to existing GNN models As shown in Table <ref type="table" target= to represent the high-frequency components that are critical in heterophily.</p><p>Non-linear embedding transformations per round in H 2 GCN? GCN [17]</ref>, GraphSAGE [11]</ref> and other GNN models embed the intermediate representations per round of feature propagation and aggregation. However, as we show in the ablation study in App "http://www.tei-c.org/ns/1.0"><head>F Experimental Setup &amp; Hyperparameter Tuning</head><p>• GCN &amp; GCN-Cheby [17]</ref>: https://github.com/tkipf/gcn • GraphSAGE [11]</ref>: https://github.com/williamleif/graphsage-simple (PyTorch implementation) • MixHop [1]</ref>: https://github.com/samihaija/mixho ly_stopping: 40 -Set 2: * hidden1: a ∈ {16, 32, 64} * dropout: 0.5 * weight_decay: 5e-4 * max_degree: 3 * early_stopping: 40 We report the best performance, for Set 1 with a = 64, b = 5e-4.• GraphSAGE[11]</ref>:-hid_units: a ∈ {64, 128} lr: b ∈ {0.1, 0.7} epochs: 500</note> 		</body> 		<back>  			<div type="acknowledgement"> <div xmlns="http://www.tei-c.org/ns/1.0">< ="#b16">[17]</ref>:</p><p>-hidden1: 64 -max_degree: 2 -early_stopping: 40 epochs: 2000 We also disabled the default feature normalization in the official implementation for this baseline. • GraphSAGE [11]</ref>:</p><p>-hid_units: a ∈ {64, 128} lr: b ∈ {0.1, 0.7} epochs: 500 We report the performance with a = 128, b = 0.1.</p></div> <div xmlns="http://www.tei-c.org/ns th a = 192. • GAT [36]</ref>:</p><p>-hid_units: 8</p><p>We also disabled the default feature normalization in the official implementation for this baseline. • GraphSAGE [11]</ref>:</p><p>-hid_units: 64 lr: {0.1, 0.7} epochs: 500</p><p>• MixHop [1]</ref>:</p><p>-hidden_dims_csv: {64, 192} -adj_pows: 0, 1, 2< D1) ego-and neighbor-embedding separation; (D2) higher-order neighborhoods; and (D3) combination of intermediate representations. While these designs have been utilized separately in some prior works [11,</ref>7,</ref>1,</ref>38]</ref>, we are the first to discuss their importa δ 1 (d + 1)(|Y| − 1 + (|Y|h − 1)d) &lt; − ((|Y| − 1) + (|Y| − 2 + h)d)δ 1 (d + 1)(|Y| − 1 + (|Y|h − 1)d)</formula><p>Solving the above inequality for δ 1 , we get the amount of perturbation needed as (11)</ref> and the least absolute amount of perturbation needed is |δ</p><formula xml:id="formula_25">δ 1 &gt; −h|Y|d−|Y|+d+1 |Y|−1 , when 0 ≤ h &lt; −|Y|+d+1 |Y|d δ 1 &
Besides the models mentioned above, there are various comprehensive reviews describing previously proposed architectures [42,</ref>5,</ref>41]</ref>. Recent work has investigated GNN's ability to capture graph information, proposing diagnostic measurements based on feature smoothness and label smoothness <r
correlations between the node labels and their attributes [30]</ref>. Since exact inference is NP-hard, approximate inference algorithms (e.g., iterative classification [14,</ref>20]</ref>, loopy belief propagation) are used to solve the problem. Belief propagation (BP) [40]<
(D3) combination of intermediate representations. While these designs have been utilized separately in some prior works [11,</ref>7,</ref>1,</ref>38]</ref>, we are the first to discuss their importance under heterophily by providing novel theoretical justifications and an exte v at exactly i hops away, and the AGGR functions applied to different neighborhoods can be the same or different. This design-employed in GCN-Cheby [7]</ref> and MixHop [1]</ref>-augments the implicit aggregation over higher-order neighborhoods that most GNN models achieve through multiple rounds of first-order propagation based on varia t="#b11">[12]</ref> that may guide the learning process. To capture more graph information, other works generalize graph convolution outside of immediate neighborhoods. For example, apart from MixHop [1]</ref> (cf. § 3.1), Graph Diffusion Convolution [18]</ref> replaces the adjacency matrix with a sparsified version of a diffusion matrix CN [17]</ref> GAT [36]</ref> GCN-Cheby [7]</ref> GraphSAGE [11]</ref> MixHop [1]</ref> H2GCN (proposed)</p><p>Comparison of H 2 GCN to existing GNN models As shown in Table 2</ref>, H 2 GCN differs from existing G differs from H 2 GCN in the same ways that are described in (1) and ( 3</ref>)-(4) above. It explicitly considers higher-order neighborhoods up to N 2 , though [1]</ref> defines the 2-hop neighborhoods as that including neighbors up to 2-hop away neighbors. In our framework, we define the i-hop neighborhood as the set of neighbo ="bibr" target="#b16">[17]</ref>: https://github.com/tkipf/gcn • GraphSAGE [11]</ref>: https://github.com/williamleif/graphsage-simple (PyTorch implementation) • MixHop [1]</ref>: https://github.com/samihaija/mixhop • GAT [36]</ref>: https://github.com/PetarV-/GAT. (For large datasets, we make use of the sp e default feature normalization in the official implementation for this baseline. • GraphSAGE [11]</ref>:</p><p>-hid_units: 64 lr: {0.1, 0.7} epochs: 500</p><p>• MixHop [1]</ref>:</p><p>-hidden_dims_csv: {64, 192} -adj_pows: 0, 1, 2</p><p>• GAT [36]</ref>:</p><p>-hid_units: 8</p><p>• MLP -Dimension of Featu get="#b25">[26]</ref> precomputes unsupervised node embeddings and uses neighborhoods defined by geometric relationships in the resulting latent space to define graph convolution. Some of these works [1,</ref>26,</ref>12]</ref> acknowledge the challenges of learning from graphs with heterophily. Others have Synthetic Datasets: Details G.1 Data Generation Process &amp; Setup</head><p>Synthetic graph generation We generate synthetic graphs with various heterophily levels by adopting an approach similar to [1,</ref>16]</ref>. In general, the synthetic graphs are generated by a modified preferential attachment process <ref type="bibr" target="# f designs D1-D3. Here we give some additional conceptual and mechanism differences.</p><p>As we have mentioned, H 2 GCN differs from GCN [17]</ref> in a number of ways: (1)</ref> In each round of propagation/aggregation, GCN "mixes" the ego-and neighbor-representations by repeatedly averaging them to obtain the new node representations,
agation (BP) [40]</ref> is a classic messagepassing algorithm for graph-based semi-supervised learning, which can be used for graphs exhibiting homophily or heterophily [19]</ref> and has fast linearized versions [10,</ref>8]</ref>. Different from the setup where GNNs are emplo
ks based on results reported in [26]</ref>. Real datasets &amp; setup We now evaluate the performance of our model and existing GNNs on a variety of real-world datasets [35,</ref>29,</ref>30,</ref>22,</ref>4,</ref>< heir average traffic. • Actor is a graph representing actor co-occurrence in Wikipedia pages, processed by [26]</ref> based on the film-director-actor-writer network in [35]</ref>. We also use the class labels generated by [26]</ref>. • Cora, Pubmed and Citeseer are citation graphs originally introduced in
wledge the challenges of learning from graphs with heterophily. Others have noted that node labels may have complex relationships that should be modeled directly. For instance, Graph Agreement Models [33]</ref> augment the classification task with an agreement task, co-training a model to predict whether pairs of nodes share the same label; Graph Markov Neural Networ
wledge the challenges of learning from graphs with heterophily. Others have noted that node labels may have complex relationships that should be modeled directly. For instance, Graph Agreement Models [33]</ref> augment the classification task with an agreement task, co-training a model to predict whether pairs of nodes share the same label; Graph Markov Neural Networ
agation (BP) [40]</ref> is a classic messagepassing algorithm for graph-based semi-supervised learning, which can be used for graphs exhibiting homophily or heterophily [19]</ref> and has fast linearized versions [10,</ref>8]</ref>. Different from the setup where GNNs are emplo
formation, other works generalize graph convolution outside of immediate neighborhoods. For example, apart from MixHop [1]</ref> (cf. § 3.1), Graph Diffusion Convolution [18]</ref> replaces the adjacency matrix with a sparsified version of a diffusion matrix (e.g., heat kernel or PageRank). Geom-GCN [26]</r
ting networks, different amino acid types are more likely to connect in protein structures, fraudsters are more likely to connect to accomplices than to other fraudsters in online purchasing networks [24]</ref>. Since many existing GNNs assume strong homophily, they fail to generalize to networks with heterophily (or low/medium level of homophily). In such cases, we actual level of homophily may vary within different pairs of node classes, i.e., there is different tendency of connection between each pair of classes. For instance, in an online purchasing network [24]</ref> with three classes-fraudsters, accomplices, and honest users-, fraudsters connect with higher probability to accomplices and honest users. Moreover, within th
D − A, where A ∈ {0, 1} |V|×|V| is the adjacency matrix and D is the diagonal matrix with [D] i,i = j [A] i,j . Without loss of generality, since the eigenvalues {λ i } of L are real and nonnegative [32]</ref>, we assume the following order for the eigenvalues of L:</p><formula xml:id="formula_41">0 = λ 0 &lt; λ 1 ≤ λ 2 ≤ • • • ≤ λ |V|−1 = λ max .</formula><p>Furthe values, λ i which are closer to 0 would correspond to lower-frequency components, and λ i which are closer to λ max would correspond to higher-frequency components. Interested readers are referred to [32]</ref> for further details regarding signal processing on graphs.</p><p>The smoothness score of a signal s on graph G, which measures the amount of changes of signal
Besides the models mentioned above, there are various comprehensive reviews describing previously proposed architectures [42,</ref>5,</ref>41]</ref>. Recent work has investigated GNN's ability to capture graph information, proposing diagnostic measurements based on feature smoothness and label smoothness <r
pe="bibr" target="#b22">[23]</ref>. GNNs model the homophily principle by propagating features and aggregating them within various graph neighborhoods via different mechanisms (e.g., averaging, LSTM) [17,</ref>11,</ref>36]</ref>. However, in the real world, there are also settings where "opposites attract" in their definitions of neighborhoods N (v) and embedding function f . A typical definition of neighborhood is N 1 (v)-i.e., the 1-hop neighbors of v. As for f , in graph convolutional networks (GCN) [17]</ref> each node repeatedly averages its own features and those of its neighbors to update its own feature representation. Using an attention mechanism, GAT <ref typ (MLP) with 1 hidden layer, a graph-agnostic baseline that relies solely on the node features for classification (differences in accuracy of MLP for different h are due to randomness). Especially, GCN [17]</ref> and GAT [36]</ref> show up to 42% worse performance than MLP, highlighting that methods that work well under high homophily (h ted neighbor-embeddings without 'mixing' them is with concatenation as in GraphSAGE [11]</ref>-rather than averaging all of them as in the GCN model by Kipf and Welling [17]</ref>.</p><p>Intuition. In heterophily settings, by definition (Dfn. 2), the class label y v and original features x v of a node and those of its neighboring nodes a node and those of its neighboring nodes {(y u , x u ) : u ∈ N (v)} (esp. the direct neighbors N1 (v)) may be different. However, the typical GCN design that mixes the embeddings through an average [17]</ref> or weighted average [36]</ref> as the COMBINE function results in final embeddings that are similar across neighboring nodes (e " target="#b42">[43]</ref> method models more complex label correlations by integrating the compatibility matrix notion from belief propagation [10]</ref> into GNNs. GCN [17]</ref> GAT [36]</ref> GCN-Cheby [7]</ref> GraphSAGE [11]</ref> MixHop <re that we consider in this work, including the inclusion or not of designs D1-D3. Here we give some additional conceptual and mechanism differences.</p><p>As we have mentioned, H 2 GCN differs from GCN [17]</ref> in a number of ways: (1)</ref> In each round of propagation/aggregation, GCN "mixes" the ego-and neighbor-representations by rep CN uses concatenationbased jumping knowledge in order to represent the high-frequency components that are critical in heterophily.</p><p>Non-linear embedding transformations per round in H 2 GCN? GCN [17]</ref>, GraphSAGE [11]</ref> and other GNN models embed the intermediate representations per round of feature propagation and aggregat the official implementation released by the authors on GitHub.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F Experimental Setup &amp; Hyperparameter Tuning</head><p>• GCN &amp; GCN-Cheby [17]</ref>: https://github.com/tkipf/gcn • GraphSAGE [11]</ref>: https://github.com/williamleif/graphsage-simple (PyTorch implementation) ula_61">H 2 GCN-1 &amp; H 2 GCN-2:</formula><p>-Dimension of Feature Embedding p: 64 -Non-linearity Function σ: ReLU -Dropout Rate: a ∈ {0, 0.5}</p><p>We report the best performance, for a = 0. • GCN [17]</ref>:</p><p>-hidden1: a ∈ {16, 32, 64} -early_stopping: b ∈ {40, 100, 200} epochs: 2000</p><p>We report the best performance, for a = 32, b = 40. • GCN-Cheby <ref GCN [17]</ref>:</p><p>-hidden1: a ∈ {16, 32, 64} -early_stopping: b ∈ {40, 100, 200} epochs: 2000</p><p>We report the best performance, for a = 32, b = 40. • GCN-Cheby [17]</ref>:</p><p>-Set 1:</p><p>-hidden1: 64 -early_stopping: {40, 100, 200} -weight_decay: {5e-5, 1e- For GCN+JK, GCN-Cheby+JK and GraphSAGE+JK, we enhanced the corresp ture vectors in this benchmark have already been normalized, and we found the default normalization method hurts the performance significantly. We report the best performance, for a = 40. • GCN-Cheby [17]</ref>:</p><p>-hidden1: 64 -max_degree: 2 -early_stopping: 40 epochs: 2000 We also disabled the default feature normalization in the official implementation for this ments for each baseline method:</p><p>•</p><p>-Dimension of Feature Embedding p: 64 -Non-linearity Function σ: {ReLU, None} -Dropout Rate: {0, 0.5} -L2 Regularization Weight: {1e-5, 1e-6}</p><p>• GCN [17]</ref>: </p></div>			</div> 			<div type="references">  				<listBibl>  <biblStruct xml:id="b0"> 	<analytic> 		<title level="a" type="main">MixHop: Higher-Order Grap
performance of our model and existing GNNs on a variety of real-world datasets [35,</ref>29,</ref>30,</ref>22,</ref>4,</ref>31]</ref> with edge homophily ratio h ranging from strong heterophily to strong homophily, We also use the class labels generated by [26]</ref>. • Cora, Pubmed and Citeseer are citation graphs originally introduced in [30,</ref>22]</ref>, which are among the most widely used benchmarks for semi-supervised node classification [31,</ref><ref type="bibr" target="#b12
; (D2) higher-order neighborhoods; and (D3) combination of intermediate representations. While these designs have been utilized separately in some prior works [11,</ref>7,</ref>1,</ref>38]</ref>, we are the first to discuss their importance under heterophily by providing novel </formula><p>where N i (v) denotes the neighbors of v at exactly i hops away, and the AGGR functions applied to different neighborhoods can be the same or different. This design-employed in GCN-Cheby [7]</ref> and MixHop [1]</ref>-augments the implicit aggregation over higher-order neighborhoods that most GNN models achieve through multip ectation.</p><p>Observations. Under heterophily (h = 0.1), GCN-Cheby, which models different neighborhoods by combining Chebyshev polynomials to approximate a higher-order graph convolution operation [7]</ref>, outperforms GCN and GAT, which aggregate over only the immediate neighbors N 1 , by up to +31% (Table 1</ref>). MixHop, which ibility matrix notion from belief propagation [10]</ref> into GNNs. GCN [17]</ref> GAT [36]</ref> GCN-Cheby [7]</ref> GraphSAGE [11]</ref> MixHop [1]</ref> H2GCN (proposed)</p><p>Comparison of H 2 GCN to existing GNN
er probability to accomplices and honest users. Moreover, within the same network, it is possible that some pairs of classes exhibit homophily, while others exhibit heterophily. In belief propagation [40]</ref>, a message-passing algorithm used for inference on graphical models, the different levels of homophily or affinity between classes are captured via the class hms (e.g., iterative classification [14,</ref>20]</ref>, loopy belief propagation) are used to solve the problem. Belief propagation (BP) [40]</ref> is a classic messagepassing algorithm for graph-based semi-supervised learning, which can be used for graphs exhibiting homophily or heterophily <ref type="bi
><p>Under this definition, we can prove Theorem 3 for one-hot encoding of class label vectors Y s , Y t as before, with the modification that in this case we have for signal Y s (similarly for Y t ): (20)</ref>. The rest of the proof is similar to Proof 3.</p><formula xml:id="formula_57">h s = 1 4|E| u∈V   2d u − v∈N (v) φ j=1 ([Y s ] u,j − [Y t ] v,j ) 2   inste their attributes [30]</ref>. Since exact inference is NP-hard, approximate inference algorithms (e.g., iterative classification [14,</ref>20]</ref>, loopy belief propagation) are used to solve the problem. Belief propagation (BP) [40]</ref> is a classic messagepassing algorit
D − A, where A ∈ {0, 1} |V|×|V| is the adjacency matrix and D is the diagonal matrix with [D] i,i = j [A] i,j . Without loss of generality, since the eigenvalues {λ i } of L are real and nonnegative [32]</ref>, we assume the following order for the eigenvalues of L:</p><formula xml:id="formula_41">0 = λ 0 &lt; λ 1 ≤ λ 2 ≤ • • • ≤ λ |V|−1 = λ max .</formula><p>Furthe values, λ i which are closer to 0 would correspond to lower-frequency components, and λ i which are closer to λ max would correspond to higher-frequency components. Interested readers are referred to [32]</ref> for further details regarding signal processing on graphs.</p><p>The smoothness score of a signal s on graph G, which measures the amount of changes of signal
nary class labels); and the recent CPGNN [43]</ref> method models more complex label correlations by integrating the compatibility matrix notion from belief propagation [10]</ref> into GNNs. GCN [17]</ref> GAT [36]</ref> GCN-Cheby [7]</ref> GraphS passing algorithm for graph-based semi-supervised learning, which can be used for graphs exhibiting homophily or heterophily [19]</ref> and has fast linearized versions [10,</ref>8]</ref>. Different from the setup where GNNs are employed, BP does not by itself leverage node features, and usually assumes a pr
atasets &amp; setup We now evaluate the performance of our model and existing GNNs on a variety of real-world datasets [35,</ref>29,</ref>30,</ref>22,</ref>4,</ref>31]</ref> with edge homophily ratio h ranging from ification.</p><p>Collective classification in statistical relational learning focuses on the problem of node classification by leveraging the correlations between the node labels and their attributes [30]</ref>. Since exact inference is NP-hard, approximate inference algorithms (e.g., iterative classification [14,</ref><ref type="bibr" h generation. Then, in each synthetic graph, the feature vectors of nodes in each class are generated by sampling feature vectors of nodes from the corresponding class in a real benchmark (e.g., Cora [30,</ref>39]</ref> or ogbn-products [13]</ref>): We first establish a class mapping ψ : Y s → Y b between ref type="bibr" target="#b34">[35]</ref>. We also use the class labels generated by [26]</ref>. • Cora, Pubmed and Citeseer are citation graphs originally introduced in [30,</ref>22]</ref>, which are among the most widely used benchmarks for semi-supervised node classification <ref type="bibr" target="#b30
formation, other works generalize graph convolution outside of immediate neighborhoods. For example, apart from MixHop [1]</ref> (cf. § 3.1), Graph Diffusion Convolution [18]</ref> replaces the adjacency matrix with a sparsified version of a diffusion matrix (e.g., heat kernel or PageRank). Geom-GCN [26]</r
mmediate neighborhoods may be heterophily-dominant, the higher-order neighborhoods may be homophily-dominant and thus provide more relevant context. This observation is also confirmed by recent works [2,</ref>6]</ref> in the context of binary attribute prediction.</p><p>Theoretical Justification. Below we formalize the above observation f
><p>Under this definition, we can prove Theorem 3 for one-hot encoding of class label vectors Y s , Y t as before, with the modification that in this case we have for signal Y s (similarly for Y t ): (20)</ref>. The rest of the proof is similar to Proof 3.</p><formula xml:id="formula_57">h s = 1 4|E| u∈V   2d u − v∈N (v) φ j=1 ([Y s ] u,j − [Y t ] v,j ) 2   inste their attributes [30]</ref>. Since exact inference is NP-hard, approximate inference algorithms (e.g., iterative classification [14,</ref>20]</ref>, loopy belief propagation) are used to solve the problem. Belief propagation (BP) [40]</ref> is a classic messagepassing algorit
ly-dominant, the higher-order neighborhoods may be homophily-dominant and thus provide more relevant context. This observation is also confirmed by recent works [2,</ref>6]</ref> in the context of binary attribute prediction.</p><p>Theoretical Justification. Below we formalize the above observation for 2-hop neighborhoods under non-binary t="#b24">[25]</ref> transforms the original graph into either a similarity graph by measuring similarity between node neighborhoods or a new graph connecting nodes that are two hops away; Chin et al. [6]</ref> decouple graph smoothing where the notion of "identity" and "preference" for each node are considered separately. However, like BP, these approaches do not by t
rom the spectral perspective. Assuming a GCN-style layer-where propagation can be viewed as spectral filtering-, the higher order polynomials of the normalized adjacency matrix A is a low-pass filter [37]</ref>, so intermediate outputs from earlier rounds contain higher-frequency components than outputs from later rounds. At the same time, the following theorem holds formula" target="#formula_1">2</ref>), here we do not combine the ego-embedding of node v with the neighbor-embeddings. We found that removing the usual nonlinear transformations per round, as in SGC [37]</ref>, works better (App. D.2), in which case we only need to include the ego-embedding in the final representation. By design D3, each node's final representation )} , (<label>21</label></formula><formula xml:id="formula_59">)</formula><p>where σ is RELU and W is a learnable matrix. Our design in Eq. 5 aggregates different neighborhoods in a similar way to SGC [37]</ref>, which has shown that removing non-linearities does not negatively impact performance in homophily settings. We actually find that removing non-linearities ev
formation, other works generalize graph convolution outside of immediate neighborhoods. For example, apart from MixHop [1]</ref> (cf. § 3.1), Graph Diffusion Convolution [18]</ref> replaces the adjacency matrix with a sparsified version of a diffusion matrix (e.g., heat kernel or PageRank). Geom-GCN [26]</r
performance of our model and existing GNNs on a variety of real-world datasets [35,</ref>29,</ref>30,</ref>22,</ref>4,</ref>31]</ref> with edge homophily ratio h ranging from strong heterophily to strong homophily, We also use the class labels generated by [26]</ref>. • Cora, Pubmed and Citeseer are citation graphs originally introduced in [30,</ref>22]</ref>, which are among the most widely used benchmarks for semi-supervised node classification [31,</ref><ref type="bibr" target="#b12
Besides the models mentioned above, there are various comprehensive reviews describing previously proposed architectures [42,</ref>5,</ref>41]</ref>. Recent work has investigated GNN's ability to capture graph information, proposing diagnostic measurements based on feature smoothness and label smoothness <r
tworks [27]</ref> model the joint label distribution with a conditional random field, trained with expectation maximization using GNNs; Correlated Graph Neural Networks [15]</ref> model the correlation structure in the residuals of a regression task with a multivariate Gaussian, and can learn negative label correlations for neighbors in
f>41]</ref>. Recent work has investigated GNN's ability to capture graph information, proposing diagnostic measurements based on feature smoothness and label smoothness [12]</ref> that may guide the learning process. To capture more graph information, other works generalize graph convolution outside of immediate neighborhoods. For examp rhoods defined by geometric relationships in the resulting latent space to define graph convolution. Some of these works [1,</ref>26,</ref>12]</ref> acknowledge the challenges of learning from graphs with heterophily. Others have noted that node labels may have complex relationships that should be modeled d
htning location data become readily available. These data contain valuable information for predicting future lightning occurrences. However, although extrapolationbased methods for weather nowcasting [1]</ref>- [3]</ref> can be migrated to lightning forecast tasks, they encounter rapid decline in forecasting accuracy beyond two to three h b29">[30]</ref>, a series of 3D convolution [31]</ref> filters that are sensitive to different dimensions are assembled to predict mobile events in the city. Shi et al. [1]</ref> proposed convolutional LSTM (ConvLSTM) for precipitation nowcasting. As a landmark structure, ConvLSTM is used as a base module in many subsequent works. In MCn ula_4">)</formula><p>where * is the convolution operation </p><formula xml:id="formula_5">H t−1 , C t−1 .</formula><p>The ConvLSTM in this paper does not include peephole connections, as mentioned in [1]</ref>. The data first enters the CNN modules, where sequentially arranged 2D convolutional layers expand the receptive field and enhance the presentation capabilities
while the convolutional neural network (CNN) extracts spatial features. The encoder-decoder structure facilitates sequence-to-sequence (Seq2Seq) conversion between data series with different lengths [9]</ref>- [11]</ref>. Since both recent lightning observations and numerical simulations can be organized in the form of spatiotemporal da

ore complicated fact is that the contribution of a certain parameter to the lightning also varies with conditions such as season, terrain, stage of thunderstorm development and type of weather system [14]</ref>, [16]</ref>- [20]</ref>. The naive deep learning models are short of specialized means to deal w
while the convolutional neural network (CNN) extracts spatial features. The encoder-decoder structure facilitates sequence-to-sequence (Seq2Seq) conversion between data series with different lengths [9]</ref>- [11]</ref>. Since both recent lightning observations and numerical simulations can be organized in the form of spatiotemporal da
rnable weights. The bias terms are omitted in (10)</ref>. • is Hadamard product and refers specifically here to the summation of all elements of the vector. According to [37]</ref>, we scale the weights before normalizing them to avoid getting values into the saturation region of the softmax function, as shown in <ref type="bibr" target=
limited to the early stage of the forecast. Second, although lightning is the result of multiple factors, it tends to be more closely related to some of them [5]</ref>, [7]</ref>, [12]</ref>, [13]</ref>. The more complicated fact is that the contribution of a certain parameter height of the charging bands, Wang et al. [8]</ref> improved the above scheme by replacing the radar reflectivity from height levels to temperature levels. Lynn and Yair [7]</ref> proposed Lightning Potential Index (LPI) that calculated from the max mixing ratio of snow, cloud ice, and graupel. But they did not provide a direct way to acq ical results. Finally, we verify the validity of each module of our model.</p><p>1 https://keras.io We choose parameters that are closely related to lightning [5]</ref>, [7]</ref>, [8]</ref>, [15]</ref>, [16]</ref>: the mixing ratio of ice, snow an
rnable weights. The bias terms are omitted in (10)</ref>. • is Hadamard product and refers specifically here to the summation of all elements of the vector. According to [37]</ref>, we scale the weights before normalizing them to avoid getting values into the saturation region of the softmax function, as shown in <ref type="bibr" target=

RICS</head><p>Our evaluation metrics include four types of commonly used skill-scores in meteorological forecasts [18]</ref>, [39]</ref>, [40]</ref>: probability of detection (POD), false alarm ratio (FAR), threat score (TS) and equitable threat score (ETS). Among them, TS and ETS are comprehensive scores,

</ref>. The deliberation model has been used in state-of-the-art machine translation [17]</ref>, or generating intermediate representation in speech-to-text translation [18]</ref>. Our deliberation model has a similar structure as [16]</ref>: An RNN-T model generates the first-pass hypotheses, and delibera
el attends to acoustics alone for second-pass processing.</p><p>In this work, we propose to combine acoustics and first-pass text hypotheses for second-pass decoding based on the deliberation network [16]</ref>. The deliberation model has been used in state-of-the-art machine translation [17]</ref>, or generating intermediate representa e="bibr" target="#b16">[17]</ref>, or generating intermediate representation in speech-to-text translation [18]</ref>. Our deliberation model has a similar structure as [16]</ref>: An RNN-T model generates the first-pass hypotheses, and deliberation attends to both acoustics and first-pass hypotheses for a second-pass decoding. We encod ional Encoder Layers</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Training</head><p>A deliberation model is typically trained from scratch by jointly optimizing all components [16]</ref>. However, we find training a two-pass model from scratch tends to be unstable in practice [10]</ref>, and thus use a two-step tr network consists of three major components: A shared encoder, an RNN-T decoder [1]</ref>, and a deliberation decoder, similar to [10,</ref>16]</ref>. The shared encoder takes log-mel filterbank energies, x = (x1, ..., xT ), where T denotes the number of frames, and generates an encoding e. The encoder outpu
#b7">[8]</ref>.</p><p>A class of neural correction models post-process hypotheses using only the text information, and can be considered as second-pass models [11,</ref>12,</ref>13]</ref>. The models typically use beam search to generate new hypotheses, compared to rescoring where one leverages external la first-pass text hypotheses and generates new sequences to improve numeric utterance recognition [15]</ref>. A transformer-based spelling correction model is proposed in [12]</ref> to correct the outputs of a connectionist temporal classification model in Mandarin ASR. In addition, [13]</ref> leverages text
pronunciation, and language models), and directly outputs subword (or word) symbols [1,</ref>2,</ref>3,</ref>4,</ref>5]</ref>. In large scale training, E2E models perform competitively compared to more sophisticated conventional systems on Google tr
d are usually short in VS, and thus the encoding should have limited impact on latency.</p><p>Our experiments are conducted using the same training data as in [20,</ref>21]</ref>, which is from multiple domains such as Voice Search, YouTube, Farfield and Telephony. We first analyze the behavior of the deliberation model, including perfo RIMENTAL SETUP</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>For training, we use the same multidomain datasets as in [20,</ref>21]</ref> which include anonymized and hand-transcribed English utterances from general Google traffic, far-field environments, telephony conversations, and YouTube. We
and directly outputs subword (or word) symbols [1,</ref>2,</ref>3,</ref>4,</ref>5]</ref>. In large scale training, E2E models perform competitively compared to more sophisticated conventional systems on Google traffic [6
a conventional model (i.e., acoustic, pronunciation, and language models), and directly outputs subword (or word) symbols [1,</ref>2,</ref>3,</ref>4,</ref>5]</ref>. In large scale training, E2E models perform competitively compared to more sophistic
pe="bibr" target="#b4">5]</ref>. In large scale training, E2E models perform competitively compared to more sophisticated conventional systems on Google traffic [6,</ref>7]</ref>. Given its all-neural nature, an E2E model can be reasonably downsized to fit on mobile devices [6]</ref>.</p><p>Despite the rapid two-step training process: Train the RNN-T as in [6]</ref>, and then fix the RNN-T parameters and only train the deliberation decoder and additional encoder layers as in [7,</ref>10]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">MWER Loss</head><p>We apply the MWER loss <ref type=
pe="bibr" target="#b4">5]</ref>. In large scale training, E2E models perform competitively compared to more sophisticated conventional systems on Google traffic [6,</ref>7]</ref>. Given its all-neural nature, an E2E model can be reasonably downsized to fit on mobile devices [6]</ref>.</p><p>Despite the rapid two-step training process: Train the RNN-T as in [6]</ref>, and then fix the RNN-T parameters and only train the deliberation decoder and additional encoder layers as in [7,</ref>10]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">MWER Loss</head><p>We apply the MWER loss <ref type=
ized to fit on mobile devices [6]</ref>.</p><p>Despite the rapid progress made by E2E models, they still face challenges compared to state-of-the-art conventional models [8,</ref>9]</ref>. To bridge the quality gap between a streaming recurrent neural network transducer (RNN-T) [ ref type="bibr" target="#b8">9]</ref>. To bridge the quality gap between a streaming recurrent neural network transducer (RNN-T) [6]</ref> and a large conventional model [8]</ref>, a two-pass framework has been proposed in [10]</ref>, which uses a non-streaming LAS decoder to rescore the RNN-T hypotheses. The first-pass hypotheses. The two-pass model achieves 17%-22% relative WER reduction (WERR) compared to RNN-T [6]</ref> and has a similar WER to a large conventional model [8]</ref>.</p><p>A class of neural correction models post-process hypotheses using only the text information, and can be considered as second-pass models <ref type="bibr" slightly (2%) but significantly for a proper noun test set: 9%. As a result, our best deliberation model achieves a WER of 5.0% on VS, which is 21% relatively better than the large conventional model [8]</ref> (6.3% VS WER). Lastly, we analyze the computational complexity of the deliberation model, and show some decoding examples to understand its strength.</p></div> f type="bibr" target="#b5">[6]</ref>. The SxS set contains utterances where the LAS rescoring model [10]</ref> performs inferior to a state-of-the-art conventional model [8]</ref>, and one reason is due to proper nouns. The voice command test sets include 3 TTS test sets created using parallel-wavenet [25]</
pe="bibr" target="#b4">5]</ref>. In large scale training, E2E models perform competitively compared to more sophisticated conventional systems on Google traffic [6,</ref>7]</ref>. Given its all-neural nature, an E2E model can be reasonably downsized to fit on mobile devices [6]</ref>.</p><p>Despite the rapid two-step training process: Train the RNN-T as in [6]</ref>, and then fix the RNN-T parameters and only train the deliberation decoder and additional encoder layers as in [7,</ref>10]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">MWER Loss</head><p>We apply the MWER loss <ref type=
ed to individually train components of a conventional model (i.e., acoustic, pronunciation, and language models), and directly outputs subword (or word) symbols [1,</ref>2,</ref>3,</ref>4,</ref>5]</ref>. In large scale training, E2E models perform co
ed to individually train components of a conventional model (i.e., acoustic, pronunciation, and language models), and directly outputs subword (or word) symbols [1,</ref>2,</ref>3,</ref>4,</ref>5]</ref>. In large scale training, E2E models perform co
ss hypotheses for a second-pass decoding. We encode first-pass hypotheses bidirectionally to leverage context information for decoding. Note that the first-pass hypotheses are sequences of wordpieces [19]</ref> and are usually short in VS, and thus the encoding should have limited impact on latency.</p><p>Our experiments are conducted using the same training data as and fed to a 2-layer LAS decoder (2,048 hidden units followed by 640-dimensional projection per layer). The LAS decoder has a 4,096-dimensional softmax layer to predict the same mixed-case wordpieces [19]</ref> as the RNN-T.</p><p>For feature extraction, we use 128-dimensional log-Mel features from 32-ms windows at a rate of 10 ms. Each feature is stacked with three
and then encoded by a 2-layer bidirectional LSTM encoder, where each layer has 2,048 hidden units followed by 320-dimensional projection. Each of the two attention models is a multi-headed attention [27]</ref> with four attention heads. The two output context vectors are concatenated and fed to a 2-layer LAS decoder (2,048 hidden units followed by 640-dimensional pr
">[14]</ref>. For example, a neural correction model in [11]</ref> takes first-pass text hypotheses and generates new sequences to improve numeric utterance recognition [15]</ref>. A transformer-based spelling correction model is proposed in [12]</ref> to correct the outputs of a connectionist temporal cla
d are usually short in VS, and thus the encoding should have limited impact on latency.</p><p>Our experiments are conducted using the same training data as in [20,</ref>21]</ref>, which is from multiple domains such as Voice Search, YouTube, Farfield and Telephony. We first analyze the behavior of the deliberation model, including perfo RIMENTAL SETUP</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>For training, we use the same multidomain datasets as in [20,</ref>21]</ref> which include anonymized and hand-transcribed English utterances from general Google traffic, far-field environments, telephony conversations, and YouTube. We
the clean training utterances by artificially corrupting them by using a room simulator, varying degrees of noise, and reverberation such that the signal-to-noise ratio (SNR) is between 0dB and 30dB [23]</ref>. We also use mixed-bandwidth utterances at 8kHz or 16 kHz for training [24]</ref>.</p><p>Our main test set includes ~14K anonym
32-ms windows at a rate of 10 ms. Each feature is stacked with three previous frames to form a 512-dimensional vector, and then downsampled to a 30-ms frame rate. Our models are trained in Tensorflow [28]</ref> using the Lingvo framework [29]</ref> on 8×8 Tensor Processing Units (TPU) slices with a global batch size of 4,096.</p></div>
ype="bibr" target="#b12">13]</ref>. The models typically use beam search to generate new hypotheses, compared to rescoring where one leverages external language models trained with large text corpora [14]</ref>. For example, a neural correction model in [11]</ref> takes first-pass text hypotheses and generates new sequences to improve n
the clean training utterances by artificially corrupting them by using a room simulator, varying degrees of noise, and reverberation such that the signal-to-noise ratio (SNR) is between 0dB and 30dB [23]</ref>. We also use mixed-bandwidth utterances at 8kHz or 16 kHz for training [24]</ref>.</p><p>Our main test set includes ~14K anonym
correction models post-process hypotheses using only the text information, and can be considered as second-pass models [11,</ref>12,</ref>13]</ref>. The models typically use beam search to generate new hypotheses, compared to rescoring where one leverages external language models trained with large text co nsformer-based spelling correction model is proposed in [12]</ref> to correct the outputs of a connectionist temporal classification model in Mandarin ASR. In addition, [13]</ref> leverages text-to-speech (TTS) audio to train an attention-based neural spelling corrector to improve LAS decoding. These neural correction models typically u
odel, particularly by learning model weights from the sample distribution.</p><p>Representative methods include AdaBoost (Freund and Schapire, 1997)</ref> and RankBoost (Freund et al., 2004)</ref>, which target at classification and ranking respectively. AdaBoost starts with a pool of weak classifiers and iteratively selects the best one bination, which aims at reinforcing correct beliefs and compensating for alignment error. An embedding model that makes more accurate predictions should receive a higher weight. Inspired by RankBoost (Freund et al., 2004)</ref>, we reduce the ranking combination problem to a classifier ensemble problem. KEnS b therefore learns model weights in a similar manner as AdaB ry, Japan) (The Tale of Genji, genre, Monogatari) (The Tale of Genji, genre, Love Story)} Queries: Q = {q1 = (The Tale of Genji, country, ?t) q2 = (The Tale of Genji, genre, ?t)} Similar to RankBoost (Freund et al., 2004)</ref> Ranking loss. The overall objective of KEnS b is to minimize the sum of ranks of all correct answers in the combined ranking list q e∈Ω(q) r(e tive is minimizing the number of mis-ordered critical entity pairs in the combined ranking list.</p><p>Let the set of all the critical entity pairs from all the validation queries of an entity as P . Freund et al. (2004)</ref> have proved that, when using RankBoost, this ranking loss is bounded as follows:</p><formula xml:id="formula_10">|{p : p ∈ P, p is mis-ordered}
oss different embeddings is hindered by the lack of reliable alignment information that bridges different KGs. Recent works on multilingual KG embeddings provide support for automated entity matching (Chen et al., 2017</ref>(Chen et al., , 2018b;;</ref>Sun et al., 2018</ref>Sun ">Ji et al., 2020)</ref> for more information.</p><p>Multilingual KG Embeddings. Recent studies have extended embedding models to bridge multiple KGs, typically for KGs of multiple languages. MTransE (Chen et al., 2017)</ref> jointly learns a transformation across two separate translational embedding spaces along with the KG structures. BootEA <ref type="bibr" target= ounts.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Embedding Learning</head><p>The embedding learning process jointly trains the knowledge model and the alignment model following Chen et al. (2017)</ref>, while self-learning is added to improve the alignment learning. The details are described below. Knowledge model. A knowledge model seeks to enc ed in Eq (1),</p><formula xml:id="formula_6">J G i ↔G j A</formula><p>is the alignment loss between G i and G j . λ is a positive hyperparameter that weights the two model components.</p><p>Following Chen et al. (2017)</ref>, instead of directly optimizing J in Eq. ( 5</ref>), our implementation optimizes each J G K and each λJ</p><formula xml:id="
of Bilinear models such as RESCAL (Nickel et al., 2011)</ref> and DistMult (Yang et al., 2015)</ref>, as well as neural models like HolE (Nickel et al., 2016)</ref> and ConvE (Dettmers et al., 2018)</ref>. Due to the large body of work in this line of research, we only provid br" target="#b30">(Sun et al., 2019b)</ref>, we also include DistMult (Yang et al., 2015)</ref>, TransD (Ji et al., 2015)</ref>, and HolE (Nickel et al., 2016)</ref>. After extensive hyperparameter tuning, the baselines are set to their best configurations. We also include a baseline named RotatE+PARIS, wh
of Bilinear models such as RESCAL (Nickel et al., 2011)</ref> and DistMult (Yang et al., 2015)</ref>, as well as neural models like HolE (Nickel et al., 2016)</ref> and ConvE (Dettmers et al., 2018)</ref>. Due to the large body of work in this line of research, we only provid br" target="#b30">(Sun et al., 2019b)</ref>, we also include DistMult (Yang et al., 2015)</ref>, TransD (Ji et al., 2015)</ref>, and HolE (Nickel et al., 2016)</ref>. After extensive hyperparameter tuning, the baselines are set to their best configurations. We also include a baseline named RotatE+PARIS, wh
tionable knowledge that is crucial to various knowledge-driven applications (Koncel-Kedziorski et al., 2019;</ref>Chen et al., 2018a;</ref>Bordes et al., 2014)</ref>. Recently, extensive efforts have been invested in KG embedding models, which encode entities as low-dimensional vectors and capture relations
These models provide a beneficial tool to complete KGs by discovering previously unknown knowledge from latent representations of observed facts. Representative models including translational models (Bordes et al., 2013;</ref>Wang et al., 2014)</ref> and bilinear models (Yang et al., 2015;</ref><ref type=" otherwise 0. When there is a tie, we order by the MRR given by the models on the validation set. MRR weighting (KEnS m ): MRR is a widely-used metric for evaluating the ranking performance of a model (Bordes et al., 2013;</ref>Yang et al., 2015;</ref>Trouillon et al., 2016)</ref>, which may also serve as a els assess the plausibility of a triple (h, r, t) by the distance between two entity vectors h and t, after applying a relation-specific translation vector r. The representative models include TransE (Bordes et al., 2013)</ref> and its extensions TransD (Ji et al., 2015)</ref>. Despite their simplicity, translational models achieve satis nd (h , r, t ) is a negative sampled triple obtained by randomly corrupting either head or tail of a true triple (h, r, t).</p><p>We here consider two representative triple scoring techniques: TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>. TransE models relations as translations between head entities and tail en metrics with K as 1, 3, 10. Hits@1 is equivalent to accuracy. All three metrics are preferred to be higher. Although another common metric, Mean Reciprocal Rank (MRR), has been used in previous works (Bordes et al., 2013)</ref>, it is not applicable to the evaluation of our framework because our ensemble framework combines the top entity candidates from multiple knowl x variants of KEnS, which are generated by combining two knowledge models and three ensemble inference techniques introduced in in Section 3. For baseline methods, besides the single-embedding TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>, we also include DistMult (Yang et al., 201
te their simplicity, translational models achieve satisfactory performance on KG completion and are robust against the sparsity of data (Hao et al., 2019)</ref>. RotatE (Sun et al., 2019b)</ref> employs a complex embedding space and models the relation r as the rotation instead of translation of the complex vector h toward t, which lead upting either head or tail of a true triple (h, r, t).</p><p>We here consider two representative triple scoring techniques: TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>. TransE models relations as translations between head entities and tail entities in a Euclidean space, while RotatE models relations as rotatio dels and three ensemble inference techniques introduced in in Section 3. For baseline methods, besides the single-embedding TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>, we also include DistMult (Yang et al., 2015)</ref>, TransD (Ji et al., 2015)</re
;</ref>Yang et al., 2019)</ref>, neighborhood information (Wang et al., 2018;</ref>Yang et al., 2015;</ref>Li et al., 2019;</ref>Sun et al., 2019a</ref>Sun et al., , 2020a) )</ref> and degree centrality measures <r
er of influential knowledge bases, including DBpedia (Lehmann et al., 2015)</ref>, Wikidata (Vrandečić and Krötzsch, 2014)</ref> and YAGO (Rebele et al., 2016)</ref>. In contrast, KGs often consist of numerous entities that cannot be easily aligned, and entity alignment is available only in small amounts.<
/ref>), attributes (Trsedya et al., 2019;</ref>Sun et al., 2017;</ref>Yang et al., 2019)</ref>, neighborhood information (Wang et al., 2018;</ref>Yang et al., 2015;</ref>Li et al., 2019;</ref>Sun e
sD (Ji et al., 2015)</ref>. Despite their simplicity, translational models achieve satisfactory performance on KG completion and are robust against the sparsity of data (Hao et al., 2019)</ref>. RotatE (Sun et al., 2019b)</ref> employs a complex embedding space and models the relation r as the rotation ins
These models provide a beneficial tool to complete KGs by discovering previously unknown knowledge from latent representations of observed facts. Representative models including translational models (Bordes et al., 2013;</ref>Wang et al., 2014)</ref> and bilinear models (Yang et al., 2015;</ref><ref type=" otherwise 0. When there is a tie, we order by the MRR given by the models on the validation set. MRR weighting (KEnS m ): MRR is a widely-used metric for evaluating the ranking performance of a model (Bordes et al., 2013;</ref>Yang et al., 2015;</ref>Trouillon et al., 2016)</ref>, which may also serve as a els assess the plausibility of a triple (h, r, t) by the distance between two entity vectors h and t, after applying a relation-specific translation vector r. The representative models include TransE (Bordes et al., 2013)</ref> and its extensions TransD (Ji et al., 2015)</ref>. Despite their simplicity, translational models achieve satis nd (h , r, t ) is a negative sampled triple obtained by randomly corrupting either head or tail of a true triple (h, r, t).</p><p>We here consider two representative triple scoring techniques: TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>. TransE models relations as translations between head entities and tail en metrics with K as 1, 3, 10. Hits@1 is equivalent to accuracy. All three metrics are preferred to be higher. Although another common metric, Mean Reciprocal Rank (MRR), has been used in previous works (Bordes et al., 2013)</ref>, it is not applicable to the evaluation of our framework because our ensemble framework combines the top entity candidates from multiple knowl x variants of KEnS, which are generated by combining two knowledge models and three ensemble inference techniques introduced in in Section 3. For baseline methods, besides the single-embedding TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>, we also include DistMult (Yang et al., 201
tionable knowledge that is crucial to various knowledge-driven applications (Koncel-Kedziorski et al., 2019;</ref>Chen et al., 2018a;</ref>Bordes et al., 2014)</ref>. Recently, extensive efforts have been invested in KG embedding models, which encode entities as low-dimensional vectors and capture relations
="#b27">Sun et al., , 2020a) )</ref> and degree centrality measures (Pei et al., 2019)</ref>. A systematic summary of relevant approaches is given in a recent survey by Sun et al. (2020b)</ref>. Although these approaches focus on the KG alignment that is different from the problem we tackle here, such techniques can be leveraged to supp

te their simplicity, translational models achieve satisfactory performance on KG completion and are robust against the sparsity of data (Hao et al., 2019)</ref>. RotatE (Sun et al., 2019b)</ref> employs a complex embedding space and models the relation r as the rotation instead of translation of the complex vector h toward t, which lead upting either head or tail of a true triple (h, r, t).</p><p>We here consider two representative triple scoring techniques: TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>. TransE models relations as translations between head entities and tail entities in a Euclidean space, while RotatE models relations as rotatio dels and three ensemble inference techniques introduced in in Section 3. For baseline methods, besides the single-embedding TransE (Bordes et al., 2013)</ref> and RotatE (Sun et al., 2019b)</ref>, we also include DistMult (Yang et al., 2015)</ref>, TransD (Ji et al., 2015)</re
instead of translation of the complex vector h toward t, which leads to the SOTA performance on KG embedding. There are also various methods falling into the groups of Bilinear models such as RESCAL (Nickel et al., 2011)</ref> and DistMult (Yang et al., 2015)</ref>, as well as neural models like HolE (Nic
KGs, and the other is to extend the ensemble transfer mechanism to population sparse domain knowledge in biological (Hao et al., 2020)</ref> and medical knowledge bases (Zhang et al., 2020)</ref>. Pariticularly, we also seek to ensure the global logical consistency of predicted facts in the ensemble process by incorporating probabilisti
target="#b8">(Dettmers et al., 2018)</ref>. Due to the large body of work in this line of research, we only provide a highly selective summary here. Interested readers are referred to recent surveys (Wang et al., 2017;</ref>Ji et al., 2020)</ref> for more information.</p><p>Multilingual KG Embeddings. Recent studies have extended embed
ction</head><p>Knowledge graphs (KGs) store structured representations of real-world entities and relations, constituting actionable knowledge that is crucial to various knowledge-driven applications (Koncel-Kedziorski et al., 2019;</ref>Chen et al., 2018a;</ref>Bordes et al., 2014)</ref>. Recently, extensiv
s of real-world entities and relations, constituting actionable knowledge that is crucial to various knowledge-driven applications (Koncel-Kedziorski et al., 2019;</ref>Chen et al., 2018a;</ref>Bordes et al., 2014)</ref>. Recently, extensive efforts have been invested in KG embedding models, which encode ent
ckel et al., 2011)</ref> and DistMult (Yang et al., 2015)</ref>, as well as neural models like HolE (Nickel et al., 2016)</ref> and ConvE (Dettmers et al., 2018)</ref>. Due to the large body of work in this line of research, we only provide a highly selective summary here. Interested readers are referred to
he former component dynamically adjusts the relevance of nodes' local network neighborhoods, prunes likely fake edges, and assigns less weight to suspicious edges based on network theory of homophily [14]</ref>. The latter components stabilizes the evolution of graph structure by preserving, in part the memory from a previous layer in the GNN.</p><p>We compare GNNGUA ontrast to attention mechanisms (e.g., GAT [19,</ref>40]</ref>), GNNGUARD determines importance weights using theory of network homophily [14]</ref>, positing that similar nodes (i.e., nodes with similar features) are more likely to interact than dissimilar nodes. To this end, we quantify similarity s k uv
"5">Experiments</head><p>Datasets. We test GNNGUARD on four graphs. We use two citation networks with undirected edges and binary features: Cora [45]</ref> and Citeseer [46]</ref>. We also consider a directed graph with numeric node features, ogbn-arxiv [47]</ref>, representing a citation network of CS pap
/div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Datasets. We test GNNGUARD on four graphs. We use two citation networks with undirected edges and binary features: Cora [45]</ref> and Citeseer [46]</ref>. We also consider a directed graph with numeric node features, ogbn-arxiv <ref type="bibr" target="#b46
how relevant node u is to another node v in the sense that it allows for successful routing of GNN's messages. In contrast to attention mechanisms (e.g., GAT [19,</ref>40]</ref>), GNNGUARD determines importance weights using theory of network homophily [14]</ref>, positing that similar nodes (i.e., nodes
y restore state-of-the-art performance of even the strongest and most popular GNNs [3,</ref>19,</ref>7,</ref>20,</ref>21]</ref>, thereby demonstrating broad applicability and relevance of GNNGUARD for graph machine-learning.</p></div> <div xmlns=" r" target="#b2">[3]</ref>, Graph Attention Network (GAT) [19]</ref>, Graph Isomorphism Network (GIN) [7]</ref>, Jumping Knowledge (JK-Net) [20]</ref>, GraphSAINT [21]</ref>, GraphSAGE [36]</ref>, and SignedGCN [42]< GNNs. GNNs. GNNs. We integrate GNNGUARD with five GNNs (GCN [3]</ref>, GAT [19]</ref>, GIN [7]</ref>, JK-Net [20]</ref>, and GraphSAINT [21]</ref>) and present the defense performance against adversarial attacks. ( <ref type="formula" target="#for iginal authors' guidelines and relevant papers on GNNs (GCN [3]</ref>, GAT [19]</ref>, GIN [7]</ref>, JK-Net [20]</ref>, and Graph-SAINT [21]</ref>), baseline defense algorithms (GNN-Jaccard [15]</ref>, RobustGCN <re
designed to be unnoticeable. Modern studies have shown that machine leaning models, especially deep neural networks, are highly fragile to adversarial attacks [23,</ref>24,</ref>25]</ref>. The majority of existing works focus on grid data or independent samples [26]</ref> whi
l insights into robustness [12]</ref> and the development of effective defense techniques [9,</ref>11,</ref>13]</ref>, adversarial attacks and defense on graphs remain poorly understood.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Poisoned node</head></div> <div x
y restore state-of-the-art performance of even the strongest and most popular GNNs [3,</ref>19,</ref>7,</ref>20,</ref>21]</ref>, thereby demonstrating broad applicability and relevance of GNNGUARD for graph machine-learning.</p></div> <div xmlns=" r" target="#b2">[3]</ref>, Graph Attention Network (GAT) [19]</ref>, Graph Isomorphism Network (GIN) [7]</ref>, Jumping Knowledge (JK-Net) [20]</ref>, GraphSAINT [21]</ref>, GraphSAGE [36]</ref>, and SignedGCN [42]< GNNs. GNNs. GNNs. We integrate GNNGUARD with five GNNs (GCN [3]</ref>, GAT [19]</ref>, GIN [7]</ref>, JK-Net [20]</ref>, and GraphSAINT [21]</ref>) and present the defense performance against adversarial attacks. ( <ref type="formula" target="#for iginal authors' guidelines and relevant papers on GNNs (GCN [3]</ref>, GAT [19]</ref>, GIN [7]</ref>, JK-Net [20]</ref>, and Graph-SAINT [21]</ref>), baseline defense algorithms (GNN-Jaccard [15]</ref>, RobustGCN <re
up to 15.3% in defense performance. Importantly, unlike existing GNN defenders [15,</ref>16,</ref>17,</ref>18]</ref>, GNNGUARD is a general approach and can be effortlessly combined with any GNN architecture. To that end, we integrate GNNGUARD into five GNN models. Remarkably ect of an attack. Similarly, GNN-SVD [16]</ref> uses a low-rank approximation of adjacency matrix that drops noisy information through an SVD decomposition. Tang et al. [18]</ref> improve the robustness of GNNs against poisoning attack through transfer learning but has a limitation that requires several unperturbed graphs from the simil </ref>. The attacker carefully selects a small number of edges and manipulates them through perturbation and rewiring. In doing so, the attacker aims to fool the GNN into making incorrect predictions [18]</ref>. The attacker finds optimal perturbation A through optimization [26,</ref>8]</ref>:</p><formula x graph structure. Also, [16]</ref> is designed specifically for the Nettack attacker [8]</ref> and so is less versatile. Another technique [18]</ref> uses transfer learning to detect fake edges. While that is an interesting idea, it requires a large number of clean graphs from the same domain to successfull
up to 15.3% in defense performance. Importantly, unlike existing GNN defenders [15,</ref>16,</ref>17,</ref>18]</ref>, GNNGUARD is a general approach and can be effortlessly combined with any GNN architecture. To that end, we integrate GNNGUARD into five GNN models. Remarkably ect of an attack. Similarly, GNN-SVD [16]</ref> uses a low-rank approximation of adjacency matrix that drops noisy information through an SVD decomposition. Tang et al. [18]</ref> improve the robustness of GNNs against poisoning attack through transfer learning but has a limitation that requires several unperturbed graphs from the simil </ref>. The attacker carefully selects a small number of edges and manipulates them through perturbation and rewiring. In doing so, the attacker aims to fool the GNN into making incorrect predictions [18]</ref>. The attacker finds optimal perturbation A through optimization [26,</ref>8]</ref>:</p><formula x graph structure. Also, [16]</ref> is designed specifically for the Nettack attacker [8]</ref> and so is less versatile. Another technique [18]</ref> uses transfer learning to detect fake edges. While that is an interesting idea, it requires a large number of clean graphs from the same domain to successfull
ing results in a variety of applications [5,</ref>21,</ref>31,</ref>32,</ref>33]</ref>, little attention has been paid to the robustness of such models, in contrast to an abundance of research for image (e.g., [34]<
hese latent fields are continuous, unknown but learnable. Usually, the raw fields are not independent, thus it's effective to learn information from their interactions, such as low-order interactions [4,</ref>8]</ref> or high-order interactions [3,</ref>5]</ref>, as shown in Fig.
n Module (DRM). Our experimental results show that the proposed DRM module can catch extra useful information for CTR prediction and boost the performance of existing state-of-the-art methods such as [1,</ref>3]</ref>, especially when the size of embedding dimension is high.</p><p>The main contributions of this paper are concluded as foll ts of DRM with DNN network and Field Attention Network on the Criteo dataset in Table 1</ref>. We find that both architectures get improvements in AUC and decreases  [1]</ref> 0.8076 0.4436 0.7869 0.3755 0.6685 0.1432 AFM [11]</ref> 0.8038 0.4478 0.7817 0.3792 0.6618 0.1457 DeepFM <ref type="bibr" target
explicitly model such relations to improve CTR prediction. Specifically, we propose a novel module based on dimension recalibration and self-attention mechanism [2,</ref>9]</ref> to learn the relations among latent fields. Since each latent field corresponds to a specific dimension in the embedding feature space, we name our module Dimens
n Module (DRM). Our experimental results show that the proposed DRM module can catch extra useful information for CTR prediction and boost the performance of existing state-of-the-art methods such as [1,</ref>3]</ref>, especially when the size of embedding dimension is high.</p><p>The main contributions of this paper are concluded as foll ts of DRM with DNN network and Field Attention Network on the Criteo dataset in Table 1</ref>. We find that both architectures get improvements in AUC and decreases  [1]</ref> 0.8076 0.4436 0.7869 0.3755 0.6685 0.1432 AFM [11]</ref> 0.8038 0.4478 0.7817 0.3792 0.6618 0.1457 DeepFM <ref type="bibr" target
space.</p><p>In this paper, we aim to explicitly model such relations to improve CTR prediction. Specifically, we propose a novel module based on dimension recalibration and self-attention mechanism [2,</ref>9]</ref> to learn the relations among latent fields. Since each latent field corresponds to a specific dimension in the embedding f
n Module (DRM). Our experimental results show that the proposed DRM module can catch extra useful information for CTR prediction and boost the performance of existing state-of-the-art methods such as [1,</ref>3]</ref>, especially when the size of embedding dimension is high.</p><p>The main contributions of this paper are concluded as foll ts of DRM with DNN network and Field Attention Network on the Criteo dataset in Table 1</ref>. We find that both architectures get improvements in AUC and decreases  [1]</ref> 0.8076 0.4436 0.7869 0.3755 0.6685 0.1432 AFM [11]</ref> 0.8038 0.4478 0.7817 0.3792 0.6618 0.1457 DeepFM <ref type="bibr" target
own but learnable. Usually, the raw fields are not independent, thus it's effective to learn information from their interactions, such as low-order interactions [4,</ref>8]</ref> or high-order interactions [3,</ref>5]</ref>, as shown in Fig. 1</
space.</p><p>In this paper, we aim to explicitly model such relations to improve CTR prediction. Specifically, we propose a novel module based on dimension recalibration and self-attention mechanism [2,</ref>9]</ref> to learn the relations among latent fields. Since each latent field corresponds to a specific dimension in the embedding f
3755 0.6685 0.1432 AFM [11]</ref> 0.8038 0.4478 0.7817 0.3792 0.6618 0.1457 DeepFM [3]</ref> 0.8091 0.4423 0.7878 0.3753 0.6708 0.1372 DCN [10]</ref> 0.8093 0.4420 0.7875 0.3759 0.6702 0.1361 PNN [7]</ref> 0.8094 0.4414 0.7879 0.3752 0.6705 0.1360 xDeepFM <ref type="bibr" target s for CTR prediction. It should be explained that increase at 10 −3 level in Criteo dataset is already clear compared with recent works such as xDeepFM [5]</ref> and DCN [10]</ref>.</p><p>Since DRM learns the relations of dimensions in embedding features space, its performance is affected by the number of dimensions, i.e., the embedding s
space.</p><p>In this paper, we aim to explicitly model such relations to improve CTR prediction. Specifically, we propose a novel module based on dimension recalibration and self-attention mechanism [2,</ref>9]</ref> to learn the relations among latent fields. Since each latent field corresponds to a specific dimension in the embedding f
3755 0.6685 0.1432 AFM [11]</ref> 0.8038 0.4478 0.7817 0.3792 0.6618 0.1457 DeepFM [3]</ref> 0.8091 0.4423 0.7878 0.3753 0.6708 0.1372 DCN [10]</ref> 0.8093 0.4420 0.7875 0.3759 0.6702 0.1361 PNN [7]</ref> 0.8094 0.4414 0.7879 0.3752 0.6705 0.1360 xDeepFM <ref type="bibr" target s for CTR prediction. It should be explained that increase at 10 −3 level in Criteo dataset is already clear compared with recent works such as xDeepFM [5]</ref> and DCN [10]</ref>.</p><p>Since DRM learns the relations of dimensions in embedding features space, its performance is affected by the number of dimensions, i.e., the embedding s
sequence of 64K tokens can exhaust accelerator memory.</p><p>We introduce the Reformer model which solves these problems using the following techniques:</p><p>• Reversible layers, first introduced in Gomez et al. (2017)</ref>, enable storing only a single copy of activations in the whole model, so the N factor disappears. • Splitting activations inside feed-forward la marized in Table 3</ref>.</p><formula xml:id="formula_9">• n h • l term: the b • n h • l • d k ,</formula><p>RevNets. Reversible residual networks were introduced by Gomez et al. (2017)</ref> where it was shown that they can replace ResNets for image classification. The main idea is to allow the activations at any given layer to be re (Sohoni et al., 2019)</ref>, more efficient versions of the Transformer model's self-attention mechanism (Sukhbaatar et al., 2019a;</ref>b)</ref> have also recently been explored.</p><p>In particular, leveraging sparsity in the attention layers has proved fruitful. OpenAI introduced the sparse Transformer

et al. (2015)</ref>. The requirement that the memory be fixed before has been removed in Santoro et al. (2016)</ref> at the cost of memory size and later alleviated by Rae et al. (2016)</ref>. The last paper considered memory lookups with approximate nearest neighbors including both LSH and random kd-trees, but only for lookups in exte
et al. (2015)</ref>. The requirement that the memory be fixed before has been removed in Santoro et al. (2016)</ref> at the cost of memory size and later alleviated by Rae et al. (2016)</ref>. The last paper considered memory lookups with approximate nearest neighbors including both LSH and random kd-trees, but only for lookups in exte


example were processed in (Liu et al., 2018)</ref> and when processing other modalities, like music (Huang et al., 2018)</ref> and images (Parmar et al., 2018)</ref>, even longer sequences are commonplace. These large-scale long-sequence models yield great results but strain resources to the point where so et al., 2017)</ref> has been used widely in natural language tasks and further extended to model diverse data such as music scores (Huang et al., 2018)</ref>, and images (Parmar et al., 2018;</ref>Ramachandran et al., 2019)</ref>. Most notably, this model class has been applied successfully in the self-supe
et al. (2015)</ref>. The requirement that the memory be fixed before has been removed in Santoro et al. (2016)</ref> at the cost of memory size and later alleviated by Rae et al. (2016)</ref>. The last paper considered memory lookups with approximate nearest neighbors including both LSH and random kd-trees, but only for lookups in exte

et al. (2015)</ref>. The requirement that the memory be fixed before has been removed in Santoro et al. (2016)</ref> at the cost of memory size and later alleviated by Rae et al. (2016)</ref>. The last paper considered memory lookups with approximate nearest neighbors including both LSH and random kd-trees, but only for lookups in exte

y state-of-the-art models in various natural language understanding and generation tasks (Devlin et al., 2019;</ref>Liu et al., 2019;</ref>Lewis et al., 2020</ref>), yet they are far from perfect. In generation tasks, although models like GPT-2 (Radford et al., 2019)</ref> are s to different sentences and predicts their positions. Next, we propose a contentcontrolled text generation framework, built upon the pre-trained sequence-to-sequence (seq2seq) Transformer model BART (Lewis et al., 2020)</ref>. As shown in Figure 1</ref>, our generation model takes in a content plan consisting of keyphrase assignmen prove fluency of non-autoregressive generation outputs (Ghazvininejad et al., 2019;</ref>Lawrence et al., 2019)</ref>. Our work uses BART (Lewis et al., 2020)</ref>, a state-of-the-art seq2seq model that offers better generalizability and stronger capacity for long text generation. Our proposed strategy su f type="foot" target="#foot_2">5</ref> . For both training and decoding, we utilize the Titan RTX GPU card with 24 GB memory.</p><p>Model Sizes. Our generation model has the same architecture as BART (Lewis et al., 2020)</ref> with 406M parameters. The content planner is built on top of BERT base , which has 110M parameters.</p></div> <div xmlns="http://www.tei-c.org
ei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large pre-trained language models are the cornerstone of many state-of-the-art models in various natural language understanding and generation tasks (Devlin et al., 2019;</ref>Liu et al., 2019;</ref>Lewis et al., 2020</ref>), yet they are far from perfect. his work aims to bring new insights into how to effectively incorporate content plans into large models to generate more rele-vant and coherent text. We first study a planning model trained from BERT (Devlin et al., 2019)</ref> to produce the initial content plan, which assigns keyphrases to different sentences and predicts their positions. Next, we propose a contentc
ef>. However, most existing work relies on model engineering, limiting the generalizability to new domains and adaptability to large pre-trained Transformers. One exception is the Plug and Play model (Dathathri et al., 2020)</ref>, which directly modifies the key and value states of GPT-2 (Radford et al., 2019)</ref>. However, since the
r capacity for long text generation. Our proposed strategy substantially differs from prior solutions that rely on in-place word substitutions (Novak et al., 2016;</ref>Xia et al., 2017;</ref>Weston et al., 2018)</ref>, as we leverage the seq2seq architecture to offer more flexible edits.</p><p>3 Content-c
tegy substantially differs from prior solutions that rely on in-place word substitutions (Novak et al., 2016;</ref>Xia et al., 2017;</ref>Weston et al., 2018)</ref>, as we leverage the seq2seq architecture to offer more flexible edits.</p><p>3 Content-controlled Text Generation with PAIR Task Description.
syntax (Dušek and Jurčíček, 2016;</ref>Goyal and Durrett, 2020)</ref> and semantics (Wen et al., 2015;</ref>Chen et al., 2019)</ref> of the output. Specific applications encourage the model to cover a given topic (Wang et al., 2017;</ref><ref type
and suffers from disfluency. Since BART is trained to denoise the masked input with contextual understanding, it naturally benefits our method.</p><p>Decoding. We employ the nucleus sampling strategy (Holtzman et al., 2019)</ref>, which is shown to yield superior output quality in long text generation. In addition to the standard top-k sampling from tokens with the h
text generation models. This includes manipulating the syntax (Dušek and Jurčíček, 2016;</ref>Goyal and Durrett, 2020)</ref> and semantics (Wen et al., 2015;</ref>Chen et al., 2019)</ref> of the output. Specific applications encourage the model to cover a given topic <ref type=
ation. Our work is also in line with the study of controllability of neural text generation models. This includes manipulating the syntax (Dušek and Jurčíček, 2016;</ref>Goyal and Durrett, 2020)</ref> and semantics (Wen et al., 2015;</ref>Chen et al., 2019)</ref> of the output.
ces twice as many SNs than others on arguments.</p><p>if b e c a u s e g iv e n le s t u n t il le s t Can PAIR correctly generate discourse markers? Since discourse markers are crucial for coherence (Grote and Stede, 1998;</ref>Callaway, 2003)</ref> and have received dedicated research efforts in rulebased systems <ref type="bibr" targe
get="#b47">Stent et al., 2004)</ref>. Specially designed control codes and auxiliary planning modules have been integrated into neural models (Keskar et al., 2019;</ref>Moryossef et al., 2019;</ref>Hua and Wang, 2019)</ref>, yet those solutions require model architecture modification or retraining, making target="#b56">Xu et al., 2020)</ref>. Consequently, planning modules are designed and added into neural systems to enhance content relevance (Wiseman et al., 2018;</ref>Moryossef et al., 2019;</ref>Yao et al., 2019;</ref>Hua and Wang, 2019)</ref>. However, it is still an open question to i
eural systems are known to produce low-quality content (Wiseman et al., 2017;</ref>Rohrbach et al., 2018)</ref>, often with low relevance (Li et al., 2016)</ref> and poor discourse structure (Zhao et al., 2017;</ref>Xu et al., 2020)</ref>. Consequently, plann
19;</ref>Liu et al., 2019;</ref>Lewis et al., 2020</ref>), yet they are far from perfect. In generation tasks, although models like GPT-2 (Radford et al., 2019)</ref> are able to produce plausible text, their spontaneous nature limits their utility in actual applications, e.g., users cannot specify what co ity to large pre-trained Transformers. One exception is the Plug and Play model (Dathathri et al., 2020)</ref>, which directly modifies the key and value states of GPT-2 (Radford et al., 2019)</ref>. However, since the signal is derived from the whole generated text, it is too coarse to provide precise sentence-level content control. Her orce the decoder to copy the keyphrase unless it has already been generated in the previous five tokens. We sample three times to choose the one with the lowest perplexity, as estimated by GPT-2 base (Radford et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Iterative Refinement</head><p>Outputs generated in a single pass may suffe
and suffers from disfluency. Since BART is trained to denoise the masked input with contextual understanding, it naturally benefits our method.</p><p>Decoding. We employ the nucleus sampling strategy (Holtzman et al., 2019)</ref>, which is shown to yield superior output quality in long text generation. In addition to the standard top-k sampling from tokens with the h
r capacity for long text generation. Our proposed strategy substantially differs from prior solutions that rely on in-place word substitutions (Novak et al., 2016;</ref>Xia et al., 2017;</ref>Weston et al., 2018)</ref>, as we leverage the seq2seq architecture to offer more flexible edits.</p><p>3 Content-c
died in machine translation (Lee et al., 2018;</ref>Freitag et al., 2019;</ref>Mansimov et al., 2019;</ref>Kasai et al., 2020)</ref> to gradually improve translation quality. Refinement is also used with masked language models to improve fluency of non-autoregressive generati
c a u s e g iv e n le s t u n t il le s t Can PAIR correctly generate discourse markers? Since discourse markers are crucial for coherence (Grote and Stede, 1998;</ref>Callaway, 2003)</ref> and have received dedicated research efforts in rulebased systems (Reed et al., 2018;</ref><ref type="bibr" target="#
ugh keyphrase assignment and positioning per sentence, which can be adapted to any off-the-shelf pre-trained Transformer generators.</p><p>Iterative Refinement has been studied in machine translation (Lee et al., 2018;</ref>Freitag et al., 2019;</ref>Mansimov et al., 2019;</ref><ref type="bibr" target="#b2 the quality. In each pass, tokens with low generation confidence are masked (Algorithm 1). This is inspired by iterative decoding designed for inference acceleration in non-autoregressive generation (Lee et al., 2018;</ref>Lawrence et al., 2019)</ref>, though their refinement mostly focuses on word substitution and lacks the flexibilit
eural systems are known to produce low-quality content (Wiseman et al., 2017;</ref>Rohrbach et al., 2018)</ref>, often with low relevance (Li et al., 2016)</ref> and poor discourse structure (Zhao et al., 2017;</ref>Xu et al., 2020)</ref>. Consequently, plann
ad n="2">Related Work</head><p>Content Planning as a Generation Component.</p><p>Despite the impressive progress made in many generation tasks, neural systems are known to produce low-quality content (Wiseman et al., 2017;</ref>Rohrbach et al., 2018)</ref>, often with low relevance (Li et al., 2016)</ref>
satellite (S) elaborating on the first nucleus (N) node. DPLP achieves F1 scores of 81.6 for EDU detection and 71.0 for relation prediction on news articles from the annotated RST Discourse Treebank (Carlson et al., 2001)</ref>. We run this trained model on our data for both human references and model generations.</p><p>First, we analyze the depth of RST parse trees,
e translation quality. Refinement is also used with masked language models to improve fluency of non-autoregressive generation outputs (Ghazvininejad et al., 2019;</ref>Lawrence et al., 2019)</ref>. Our work uses BART (Lewis et al., 2020)</ref>, a state-of-the-art seq2seq model that offers better generaliz confidence are masked (Algorithm 1). This is inspired by iterative decoding designed for inference acceleration in non-autoregressive generation (Lee et al., 2018;</ref>Lawrence et al., 2019)</ref>, though their refinement mostly focuses on word substitution and lacks the flexibility for other operations. Moreover, our goal is to improv
bles and figures. We demonstrate that S2ORC can be used effectively for downstream NLP tasks in academic paper analysis.</p><p>The pipeline for creating S2ORC was used to construct the CORD-19 corpus (Wang et al., 2020)</ref>, which saw fervent adoption as the canonical resource for COVID-19 text mining. CORD-19 is aimed at assisting biomedical experts and policy make
ets for tasks like entity extraction, text classification, parsing, and discourse analysis. We focus on bibliometrically-enhanced derivations of these corpora, such as the ACL Anthology Network (AAN) (Radev et al., 2009)</ref> 6</ref> derived from the ACL Anthology, RefSeer (Huang et al., 2015)</ref> de to understand proof construction, or to assist in symbol co-reference resolution.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work</head><p>The ACL Anthology Network (AAN) (Radev et al., 2009</ref>) is a bibliometric-enhanced corpus covering papers in the field of computational linguistics. It is built from the ACL Anthology <ref type="bib
pread application in bibliometrics, science-of-science, information retrieval, and network analysis. Digital archives like arXiv, 2  PubMed Central,3</ref> CiteSeerX (Giles et al., 1998)</ref>, 4</ref>and the ACL Anthology (Bird et al., 2008)</ref>, <ref type="foot" targ tion. The PubMed Central Open Access corpus is a large corpus of 2.6M papers in the biomedical domain with citations linked to PubMed identifiers.17</ref> CiteSeerX (Giles et al., 1998)</ref>, consists of papers collected primarily via web crawl, without integrating metadata provided by sources outside of the PDF. Although citation
aining, we train BERT-Base (Devlin et al., 2019)</ref> on the parsed full text of S2ORC and show that the resulting model (S2ORC-SCIBERT) performs similarly to SCI-BERT (Beltagy et al., 2019)</ref> on a diverse suite of scientific NLP tasks and datasets.</p><p>While SCIBERT is a BERT-Base model also trained on multiple domains of scienti et al., 2016)</ref> vocabulary of size 31k using 15% of the S2ORC pretraining corpus. The Jaccard index between the S2ORC-SCIBERT and SCIBERT vocabularies is 0.536.</p><p>We follow a similar setup to Beltagy et al. (2019)</ref> for both pretraining and fine-tuning S2ORC-SCIBERT. Like SCIBERT, S2ORC-SCIBERT is pretrained from scratch using the original BERT code<ref ty e="bibr" target="#b26">(Kingma and Ba, 2014)</ref>, a linear learning rate decay with 10% warm-up, batch size of 32, and dropout of 0.1.</p><p>We search over an equal-sized grid of hyperparameters as Beltagy et al. (2019)</ref>. We fine-tune for 1 to 4 epochs with a maximum learning rate of 1e-5, 2e-5, 3e-5, or 5e-5. For each task, we select the optimal combination of rg/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>S2ORC-SCIBERT test results are comparable with reported SCIBERT test results on the set of tasks and datasets fromBeltagy et al. (2019)</ref>, to which we refer the reader for descriptions. Reported statistics are spanlevel F1 for NER, token-level F1 for PICO, dependency parsing (DEP DEP), and macro-F1 for relation (REL) and text (CLS) classification. We report micro-F1 for ChemProt. All S2ORC-SCIBERT results are the mean ± standard deviation of 5 runs with different random seeds.Beltagy et al. (2019)</ref> do not report standard deviation or number of runs.</figDesc><table><row><cell>Domain</cell><cell>Dataset</cell><cell>Reference</cell><cell>Ta
tion contexts available in S2ORC could be used to augment existing datasets for document-level tasks.</p><p>Citation contexts can also be used for the more general tasks of identifying similar papers (Kanakia et al., 2019;</ref>Eto, 2019;</ref>Haruna et al., 2018;</ref>Small,
Other tasks that leverage citation contexts in-clude classifying citation intent (Teufel et al., 2006;</ref>Jurgens et al., 2018;</ref>Cohan et al., 2019)</ref>, identifying citation sentiment (Athar and Teufel, 2012)</ref>, identifying meaningful citations <ref type="bibr" for training. S2ORC could potentially benefit task performance without additional annotation, for example, by pretraining language models on S2ORC citation contexts before fine-tuning to these tasks. Cohan et al. (2019)</ref> find that long citation contexts (beyond sentence boundary) are important for tasks like summarization; the wider citation contexts available i
er summarization (Teufel et al., 2006;</ref>Qazvinian and Radev, 2008;</ref>Cohan and Goharian, 2015;</ref>Mitrović and Müller, 2015)</ref>. The models in these papers require labeled citation contexts for training. S2ORC could potentially benefit task performance without add

tries, which are linked to papers in the Microsoft Academic Graph. The citation context they provide are extracted snippets and no bibliography parses are provided. An updated version of this dataset (Saier and Färber, 2020)</ref> released concurrently with this work now includes full text.</p><p>Compared with these resources, S2ORC represents a significantly larger
nces to these objects, footnotes, other papers, and more.</p><p>Different types of resources have been used to support research over academic papers. Citation graphs like AMiner's Open Academic Graph (Tang et al., 2008)</ref>, the Microsoft Academic Graph (MAG) (Shen et al., 2018)</ref>, and the Semantic Scholar literature graph <ref ty
">(Caragea et al., 2014)</ref>, and citation context-based paper summarization (Teufel et al., 2006;</ref>Qazvinian and Radev, 2008;</ref>Cohan and Goharian, 2015;</ref>Mitrović and Müller, 2015)</ref>. The models in these papers require labeled citation contexts for training
greatly when we apply multiple layers to leverage large receptive fields. Several recent works attribute this performance degradation to the oversmoothing issue [3,</ref>15,</ref>33]</ref>, which states that representations from different classes become inseparable due to repeated propagation. In this work, indistinguishable when depth goes infinity. This aligns with the over-smoothing issue. The previous descriptions of the over-smoothing issue simplify the assumption of non-linear activation function [15,</ref>33]</ref> or make approximations of different probabilities [33]</ref>. Our theoretical analysis layers are stacked. Several works reveal that stacking many layers can bring the oversmoothing issue, which means that representations of nodes converge to indistinguishable limits. To our knowledge, [15]</ref> is the first attempt to demystify the over-smoothing issue in the GCN model. The authors first demonstrate that the propagation process of the GCN model is a r peripheral nodes. Also, small receptive fields are not enough to propagate training signals to the whole graph when the number of training nodes is limited under a semi-supervised learning setting. [15]</ref> applies co-training and self-training to overcome the limitation of shallow architectures. A smoothness regularizer term and adaptive edge optimization are pr igure 2</ref>, the smoothness metric value of graph node representations has a slight downward trend as the number of propagation iterations increases. According to [15]</ref>, the node representations suffering from the oversmoothing issue will converge to the same value or be proportional to the square root of the node degree, whe to incorporate more information. In this section, we provide a theoretical analysis of the above observation when building very deep graph neural networks, which aligns with the over-smoothing issue. [15]</ref> and [33]</ref> study the over-smoothing issue from the perspective of Laplacian smoothing and nodes' influence distribution, wi GCN layers has the similar trend. The node representations generated by multiple GCN layers, like 6 layers, are very difficult to be separated.  Several studies [3,</ref>15]</ref> attribute this performance degradation phenomenon to the over-smoothing issue. However, we question this view for the following two reasons. First, we hold tha
neighbors and the performance degrades greatly when we apply multiple layers to leverage large receptive fields. Several recent works attribute this performance degradation to the oversmoothing issue [3,</ref>15,</ref>33]</ref>, which states that representations from different classes become inseparable due ations derived by different numbers of GCN layers has the similar trend. The node representations generated by multiple GCN layers, like 6 layers, are very difficult to be separated.  Several studies [3,</ref>15]</ref> attribute this performance degradation phenomenon to the over-smoothing issue. However, we question this view for the fo by reducing unnecessary complexity in GCN. The authors show that SGC corresponds to a low-pass-type filter on the spectral domain, thus deriving smoothing features across a graph. Another recent work [3]</ref> verify that smoothing is the nature of most typical graph convolutions. It is showed that reasonable smoothing makes graph convolutions work and over-smoothing "bibr" target="#b14">[15]</ref> applies co-training and self-training to overcome the limitation of shallow architectures. A smoothness regularizer term and adaptive edge optimization are proposed in [3]</ref> to relieve the over-smoothing problem. Jumping Knowledge Network [33]</ref> deploys a layer-aggregation mechanism to adaptively s
escription of these datasets are provided in Appendix A.7. We implemented our proposed DAGNN and some necessary baselines using Pytorch [24]</ref> and Pytorch Geometric [5]</ref>, a library for deep learning on irregularly structured data built upon Pytorch. We consider the following baselines: Logistic Regression (LogReg), Multilayer Pe luate performance by the community. Also, we conduct 100 runs for each model on randomly training/validation/test splits, where we additionally ensure uniform class distribution on the train split as [5]</ref>. We compute the average test accuracy of 100 runs.</p><p>As shown in Table 2</ref>, our DAGNN model performs better than the r
on [7,</ref>9,</ref>11,</ref>12,</ref>21,</ref>30,</ref>31,</ref>33]</ref>, graph classification [6,</ref><ref type="bibr" t de i at l-th layer and x (0) i is initialized as node feature x i . Most graph convolutions, like GCN [11]</ref>, GraphSAGE [9]</ref>, GAT [30]</ref>, and GIN [32]</ref>, can be obtained under this framework by deploying different propagation and transformation mechanisms.</p> L) [2]</ref>, Cheb-Net [4]</ref>, Graph Convolutional Network (GCN) [11]</ref>, Graph Attention Network(GAT) [30]</ref>, Mixture Model Network (MoNet) [21]</ref>, Graph-SAGE [9]</ref>, APPNP <ref type="bibr" target="#
on [6,</ref>8,</ref>14,</ref>18,</ref>32,</ref>34,</ref>35,</ref>38]</ref> and link prediction [1,</ref><ref type="bibr" tar
get="#b31">32,</ref>34,</ref>35,</ref>38]</ref> and link prediction [1,</ref>36,</ref>37]</ref>. Graph convolutions adopt a neighborhood aggregation (or message passing) scheme to learn node representations by consi
main steps in DAGNN: transformation, propagation and adaptive adjustment. We first utilize a shared MLP network for feature transformation. Theoretically, MLP can approximate any measurable function [10]</ref>. Obviously, Z only contains the information of individual nodes themselves with no structure information included. After transformation, a propagation mechanis
applications, such as node classification [7,</ref>9,</ref>11,</ref>12,</ref>21,</ref>30,</ref>31,</ref>33]</ref>, graph classification <ref type="bibr" get="#b3">[4]</ref>, Graph Convolutional Network (GCN) [11]</ref>, Graph Attention Network(GAT) [30]</ref>, Mixture Model Network (MoNet) [21]</ref>, Graph-SAGE [9]</ref>, APPNP [12]</ref>, and SGC [31]</ref>. We ai
get="#b29">30,</ref>31,</ref>33]</ref>, graph classification [6,</ref>8,</ref>14,</ref>18,</ref>32,</ref>34,</ref>35,</ref>
aph is connected can guarantee that for ∀i, j: ∃k s.     Co-purchase datasets. Amazon Computers and Amazon Photo [28]</ref> are segments of the Amazon co-purchase graph [20]</ref> where nodes are goods and edges denote that two goods are frequently bought together. Node features are derived from bag-of-words representations for product
rary for deep learning on irregularly structured data built upon Pytorch. We consider the following baselines: Logistic Regression (LogReg), Multilayer Perceptron (MLP), Label Propagation (LabelProp) [2]</ref>, Normalized Laplacian Label Propagation (LabelProp NL) [2]</ref>, Cheb-Net [4]</ref>, Graph Convolut wing baselines: Logistic Regression (LogReg), Multilayer Perceptron (MLP), Label Propagation (LabelProp) [2]</ref>, Normalized Laplacian Label Propagation (LabelProp NL) [2]</ref>, Cheb-Net [4]</ref>, Graph Convolutional Network (GCN) [11]</ref>, Graph Attention Network(GAT) <re
="#b11">12,</ref>21,</ref>30,</ref>31,</ref>33]</ref>, graph classification [6,</ref>8,</ref>14,</ref>18,</ref>32,</ref><re
d="formula_4">D (i,i) = j A (i, j) is the diagonal node degree matrix. W (ℓ) ∈ R d (ℓ−1) ×d (ℓ)</formula><p>is a layer-specific trainable weight matrix. σ is a nonlinear activation function like ReLU [22]</ref>. Intuitively, GCN learns representation for each node by propagating neighbors' representations and conducting non-linear transformation after that. GCN is or
data, leading to rapid development in the field of graph neural networks. Great successes have been achieved for many applications, such as node classification [7,</ref>9,</ref>11,</ref>12,</ref>21,</ref>30,</ref><r (ℓ)</formula><p>i is the representation of node i at l-th layer and x (0) i is initialized as node feature x i . Most graph convolutions, like GCN [11]</ref>, GraphSAGE [9]</ref>, GAT [30]</ref>, and GIN [32]</ref>, can be obtained under this framework by deploying different p be the over-smoothing issue for 2 typical propagation mechanisms. 2 , where A = A + I , are two frequently utilized propagation mechanisms. The row-averaging normalization A ⊕ is adopted in GraphSAGE [9]</ref> and DGCNN [38]</ref>. The symmetrical normalization scheme A ⊙ is applied in GCN [11]</ref>.</p><f [11]</ref>, Graph Attention Network(GAT) [30]</ref>, Mixture Model Network (MoNet) [21]</ref>, Graph-SAGE [9]</ref>, APPNP [12]</ref>, and SGC [31]</ref>. We aim to provide a rigorous and fair comparison between di
14,</ref>18,</ref>32,</ref>34,</ref>35,</ref>38]</ref> and link prediction [1,</ref>36,</ref>37]</ref>. Graph convolutions ion mechanisms. 2 , where A = A + I , are two frequently utilized propagation mechanisms. The row-averaging normalization A ⊕ is adopted in GraphSAGE [9]</ref> and DGCNN [38]</ref>. The symmetrical normalization scheme A ⊙ is applied in GCN [11]</ref>.</p><formula xml:id="formula_9">A ⊕ = D −1 A and A ⊙ = D
22">[23]</ref> to develop a propagation mechanism based on personalize PageRank, which can preserve the node's local information while gather information from a large neighborhood. Recently, Geom-GCN [25]</ref> and non-local GNNs [16]</ref> are proposed to capture longrange dependencies for disassortative graph by designing non-local ag
get="#b31">32,</ref>34,</ref>35,</ref>38]</ref> and link prediction [1,</ref>36,</ref>37]</ref>. Graph convolutions adopt a neighborhood aggregation (or message passing) scheme to learn node representations by consi
get="#b32">33]</ref>, graph classification [6,</ref>8,</ref>14,</ref>18,</ref>32,</ref>34,</ref>35,</ref>38]</ref> and link prediction <ref type="bibr" ta de feature x i . Most graph convolutions, like GCN [11]</ref>, GraphSAGE [9]</ref>, GAT [30]</ref>, and GIN [32]</ref>, can be obtained under this framework by deploying different propagation and transformation mechanisms.</p><p>Without losing generalization, we focus on the G
f>8,</ref>14,</ref>18,</ref>32,</ref>34,</ref>35,</ref>38]</ref> and link prediction [1,</ref>36,</ref><ref type="bibr" tar
at successes have been achieved for many applications, such as node classification [7,</ref>9,</ref>11,</ref>12,</ref>21,</ref>30,</ref>31,</ref>33]</ref> t="#b32">[33]</ref> deploys a layer-aggregation mechanism to adaptively select a nodeâĂŹs sub-graph features at different ranges rather than to capture equally smoothed representations for all nodes. [12]</ref> utilizes the relationship between GCN and PageRank [23]</ref> to develop a propagation mechanism based on personalize PageRank, tput feature matrix X out ∈ R n×c . A softmax classifier is applied to compute the classification probabilities. Notably, the separation of transformation and propagation processes is also adopted in [12]</ref> and [31]</ref> but for the sake of reducing complexity.</p><p>In this work, we analyze this scheme systematically and reveal th ph Attention Network(GAT) [30]</ref>, Mixture Model Network (MoNet) [21]</ref>, Graph-SAGE [9]</ref>, APPNP [12]</ref>, and SGC [31]</ref>. We aim to provide a rigorous and fair comparison between different models on each dataset by using the sam
f nodes from different classes indistinguishable. The same problem is studied in [33]</ref> by analyzing the connection of nodes' influence distribution and random walk [17]</ref>. Recently, SGC [31]</ref> is proposed by reducing unnecessary complexity in GCN. The authors show that SGC corresponds to a low
at successes have been achieved for many applications, such as node classification [7,</ref>9,</ref>11,</ref>12,</ref>21,</ref>30,</ref>31,</ref>33]</ref> t="#b32">[33]</ref> deploys a layer-aggregation mechanism to adaptively select a nodeâĂŹs sub-graph features at different ranges rather than to capture equally smoothed representations for all nodes. [12]</ref> utilizes the relationship between GCN and PageRank [23]</ref> to develop a propagation mechanism based on personalize PageRank, tput feature matrix X out ∈ R n×c . A softmax classifier is applied to compute the classification probabilities. Notably, the separation of transformation and propagation processes is also adopted in [12]</ref> and [31]</ref> but for the sake of reducing complexity.</p><p>In this work, we analyze this scheme systematically and reveal th ph Attention Network(GAT) [30]</ref>, Mixture Model Network (MoNet) [21]</ref>, Graph-SAGE [9]</ref>, APPNP [12]</ref>, and SGC [31]</ref>. We aim to provide a rigorous and fair comparison between different models on each dataset by using the sam
and scale feature values have proven to help the optimization of deep neural networks. Curiously, different domains require specialized normalization methods. In computer vision, batch normalization [16]</ref> is a standard component. While in natural language processing (NLP), layer normalization [4,</ref><ref type="bibr" target="#b35" x i − µ) 2 .</formula><p>The major difference among different existing normalization methods is which set of feature values the normalization is applied to. For example, in computer vision, BatchNorm [16]</ref> is the de facto method that normalizes the feature values in the same channel across different samples in the batch. In NLP, LayerNorm <ref type="bibr" target #b15">[16,</ref>23,</ref>32]</ref>. During testing, the estimated dataset-level statistics are used instead of the batch-level statistics [16]</ref>.</p><p>In GNNs, for each feature dimension, the BatchNorm normalizes the feature values of the dimension over all nodes across different graphs in the batch. her, our proposed GraphNorm normalizes the feature values further scaling to unit norm enjoys "scale-invariant" property [1,</ref>13,</ref>16]</ref>. In comparison, BatchNorm in the lower branch suffers from heavy batch noise. Overall, GraphNorm significantly surpasses BatchNorm in training speed (Figure <r g a learnable shift avoids the expressiveness degradation; further scaling to unit norm enjoys "scale-invariant" property[1,</ref>13,</ref>16]</ref>. In comparison, BatchNorm in the lower branch suffers from heavy batch noise. Overall, GraphNorm significantly surpasses BatchNorm in training speed (Figure4) mportant in optimizing deep neural networks, and different normalization techniques have been proposed to improve the training process in different applications [4,</ref>16,</ref>24,</ref>26,</ref>27,</ref>33,</ref> rget="#b19">[20]</ref> suggests that normalization decouples the optimization of direction and length of the parameters; [1,</ref>13,</ref>16,</ref>21]</ref> show that the normalization implicitly tunes the learning rate. [28]</ref> reveals that we conduct experiments to investigate the influence of the batch size. We visualize the statistics from BatchNorm layers under different settings of batch sizes [8,</ref>16,</ref>32</ref>, 64], as in Figure 9</ref>. We can see that the observations are consistent and the batch statistics arately, Q is an n×n matrix representing the neighbor aggregation, and W (k) is the weight/parameter matrix in layer k. We apply the normalization after the linear transformation as in previous works [16,</ref>36,</ref>37]</ref>. We can instantiate Eq. ( 6</ref>) as normalization (BatchNorm), the mean and standard deviation in a sampled batch are random variables which try to provide accurate estimations for the mean and standard deviation over the whole dataset [16,</ref>23,</ref>32]</ref>. During testing, the estimated dataset-level statistics are used instead of th
aining process in different applications [4,</ref>16,</ref>24,</ref>26,</ref>27,</ref>33,</ref>36]</ref>. The reason behind the effectiveness of normalization has been intensively stud
on in mean statistics to preserve. Together, our proposed GraphNorm normalizes the feature values further scaling to unit norm enjoys "scale-invariant" property [1,</ref>13,</ref>16]</ref>. In comparison, BatchNorm in the lower branch suffers from heavy batch noise. Overall, GraphNorm significantly surpasse Using this property, [20]</ref> suggests that normalization decouples the optimization of direction and length of the parameters; [1,</ref>13,</ref>16,</ref>21]</ref> show that the normalization implicitly tunes the learning rate. <ref type="bibr n has preconditioning effect; introducing a learnable shift avoids the expressiveness degradation; further scaling to unit norm enjoys "scale-invariant" property[1,</ref>13,</ref>16]</ref>. In comparison, BatchNorm in the lower branch suffers from heavy batch noise. Overall, GraphNorm significantly surpasse
rks, and different normalization techniques have been proposed to improve the training process in different applications [4,</ref>16,</ref>24,</ref>26,</ref>27,</ref>33,</ref>36]</ref>
et="#b18">19,</ref>34,</ref>38]</ref>. GNNs learn node and graph features by following a neighbor aggregation (or message passing) scheme [10]</ref>, where node features are recursively aggregated from their neighbours. One major theme of existing works is the design of GNN architecture variants, e.g., neig
perty: by using a normalization layer right after a linear (or convolutional) layer, the output values will not change when the weights of the parameters in the layer are scaled. Using this property, [20]</ref> suggests that normalization decouples the optimization of direction and length of the parameters; [1,</ref><ref type="bibr" targ
random variables which try to provide accurate estimations for the mean and standard deviation over the whole dataset [16,</ref>23,</ref>32]</ref>. During testing, the estimated dataset-level statistics are used instead of the batch-level statistics [16]</ref>.</p><p>In GNNs e influence of the batch size. We visualize the statistics from BatchNorm layers under different settings of batch sizes [8,</ref>16,</ref>32</ref>, 64], as in Figure 9</ref>. We can see that the observations are consistent and the batch statistics on graph data are noisy, as in Figure <r
random variables which try to provide accurate estimations for the mean and standard deviation over the whole dataset [16,</ref>23,</ref>32]</ref>. During testing, the estimated dataset-level statistics are used instead of the batch-level statistics [16]</ref>.</p><p>In GNNs e influence of the batch size. We visualize the statistics from BatchNorm layers under different settings of batch sizes [8,</ref>16,</ref>32</ref>, 64], as in Figure 9</ref>. We can see that the observations are consistent and the batch statistics on graph data are noisy, as in Figure <r
ns/1.0"><head n="1">Introduction</head><p>Recently, there has been a surge of interest in Graph Neural Networks (GNNs) for learning with graph-structured data [11,</ref>19,</ref>34,</ref>38]</ref>. GNNs learn node and graph features by following a neighbor aggregation (or mes works. GNNs use the graph structure and node features to learn the representations of nodes and graphs. Modern GNNs follow a neighborhood aggregation strategy [11,</ref>19,</ref>25,</ref>31,</ref>34]</ref>, where the representation of a node is des adjacent to v i . Different graph neural networks can be obtained by choosing different AGGREGATE functions. We introduce two popularly used networks in detail, Graph Convolutional Networks (GCN) [19]</ref> and Graph Isomorphism Network (GIN) [37]</ref>. In GCN, the AGGREGATE function is defined as:</p><formula xml:id="formula_1">h istics are summarized in Table 1</ref>. We evaluate our proposed GraphNorm on two typical graph neural networks GIN [37]</ref> and GCN [19]</ref> and compare it with BatchNorm2</ref> .. Specifically, we use a five-layer GCN/GIN. For GIN, the number of sub-layers in MLP aper [37]</ref>. For the large-scale ogbg-molhiv dataset, we use the baselines in [15]</ref>, including the Graph-agnostic MLP model, GCN [19]</ref> and GIN [37]</ref>. We also report the roc-auc values reported in the original paper [15]</ref>.
on in mean statistics to preserve. Together, our proposed GraphNorm normalizes the feature values further scaling to unit norm enjoys "scale-invariant" property [1,</ref>13,</ref>16]</ref>. In comparison, BatchNorm in the lower branch suffers from heavy batch noise. Overall, GraphNorm significantly surpasse Using this property, [20]</ref> suggests that normalization decouples the optimization of direction and length of the parameters; [1,</ref>13,</ref>16,</ref>21]</ref> show that the normalization implicitly tunes the learning rate. <ref type="bibr n has preconditioning effect; introducing a learnable shift avoids the expressiveness degradation; further scaling to unit norm enjoys "scale-invariant" property[1,</ref>13,</ref>16]</ref>. In comparison, BatchNorm in the lower branch suffers from heavy batch noise. Overall, GraphNorm significantly surpasse
terest in Graph Neural Networks (GNNs) for learning with graph-structured data [11,</ref>19,</ref>34,</ref>38]</ref>. GNNs learn node and graph features by following a neighbor aggregation (or message passing) scheme [10]</ref>, where node featur
ral Modularity Maximization</head><p>Maximizing the modularity is proven to be NP-hard [5]</ref>, however, a spectral relaxation of the problem can be solved efficiently [37]</ref>. Let C ∈ 0, 1 n×k be the cluster assignment matrix and d be the degree vector. Then, with modularity matrix B defined as B = A − dd 2m , the modularity Q can rmula_3">Bx = Ax − d xd 2m</formula><p>and optimized efficiently with iterative methods such as power iteration or Lanczos algorithm.</p><p>One can then obtain clusters by means of spectral bisection [37]</ref> with iterative refinement akin to Kernighan-Lin algorithm [28]</ref>. However, these formulations operate entirely on the graph
ds.</p><p>Graph Neural Networks (GNNs) [49,</ref>15,</ref>40,</ref>21,</ref>29]</ref> allow end-to-end differentable losses over data with arbitrary structure. They have been applied to an incredible range of applications, from social networks < tional chemistry [21]</ref>. While GNNs are flexible enough to allow for unsupervised losses, most work follows the semi-supervised setting for node classification from [29]</ref>. For a complete introductions to the vast topic we refer interested readers to detailed surveys [6,</ref><ref type="bibr" target onlinear feature aggregation with respect to graph structure. For the purposes of this work, we consider transductive GNNs that output a single embedding per node. Graph convolutional networks (GCNs) [29]</ref> are simple yet effective [51]</ref> message-passing networks that fit our criteria. Let X 0 ∈ R n×s be the initial node feature
es. This plain notion of cut degenerates on real-world graphs, as it does not require partitions to be balanced in terms of size. It is possible to get normalized partitions with the use of ratio cut [63]</ref>, which normalizes the cut by the product of the number of nodes in two partitions, or normalized cut [52]</ref>, which uses tot
hitectures for dealing with graph-structured data, such as social networks [47]</ref>, recommender graphs [68]</ref>, or molecular graphs [13,</ref>69]</ref>. GNNs leverage the structure of the data as computational graph, allowing the information to propagate across the edge able properties, such as relying on a multi-step optimization process which does not allow to optimize the objective via gradient descent end-to-end [46]</ref>. Graclus [13]</ref> DiffPool [69]</ref> Top-k [20]</ref> SAG [31]</ref> MinCut <ref t ons of graphs, which was first tackled in [36]</ref>.</p><p>Graph pooling aims to tackle the hierarchical nature of graphs via iterative coarsening. Early architectures [13]</ref> resorted to fixed axiomatic pooling, with no optimization of clustering while the network learns. DiffPool [69]</ref> suggests
learns its own positional representation [70]</ref>. The learning process in graph embeddings is often done in a similar way to DGI though noise contrastive estimation [24]</ref>. As far as we know, all pooling strategies for learning node embeddings without attributes have been axiomatic [10,</ref><ref ty
ainable. End-to-end training allows to capture both graph structure and node features.</p><p>• Unsupervised training is a desirable setting for clustering models. Works on supervised graph clustering [66,</ref>62]</ref> are outside of the scope of this work.</p><p>• Sparse. As graphs in the real-world vary in size and sparsity, methods
"bibr" target="#b68">[69]</ref> is not stable in terms of graph sparsity, while MinCutPool [4]</ref> can not deal with uneven degree distribution.</p><p>Graph embeddings [48,</ref>23,</ref>59</ref>] can be thought of as (very restricted) unsupervised GNNs with an identity feat
he algorithm performance. We review two families of clustering quality functions amenable to spectral optimization, and review some of their shortcomings.</p><p>Cut-based metrics. In his seminal work [18]</ref>, Fiedler suggested that the second (Fiedler) eigenvector of a graph Laplacian produces a graph cut minimal in terms of the weight of the edges. This plain not
way to DGI though noise contrastive estimation [24]</ref>. As far as we know, all pooling strategies for learning node embeddings without attributes have been axiomatic [10,</ref>33,</ref>14]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</
e to get normalized partitions with the use of ratio cut [63]</ref>, which normalizes the cut by the product of the number of nodes in two partitions, or normalized cut [52]</ref>, which uses total edge volume of the partition as normalization.</p><p>In real networks, however, there is evidence against existence of good cuts <ref type="
has been a surge of research interest in developing varieties of Graph Neural Networks (GNNs) -specialized deep learning architectures for dealing with graph-structured data, such as social networks [47]</ref>, recommender graphs [68]</ref>, or molecular graphs [13,</ref>69] >29]</ref> allow end-to-end differentable losses over data with arbitrary structure. They have been applied to an incredible range of applications, from social networks [47]</ref>, to recommender systems [68]</ref>, to computational chemistry [21]</ref>. While GNNs are flexib
way to DGI though noise contrastive estimation [24]</ref>. As far as we know, all pooling strategies for learning node embeddings without attributes have been axiomatic [10,</ref>33,</ref>14]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</
hitectures for dealing with graph-structured data, such as social networks [47]</ref>, recommender graphs [68]</ref>, or molecular graphs [13,</ref>69]</ref>. GNNs leverage the structure of the data as computational graph, allowing the information to propagate across the edge able properties, such as relying on a multi-step optimization process which does not allow to optimize the objective via gradient descent end-to-end [46]</ref>. Graclus [13]</ref> DiffPool [69]</ref> Top-k [20]</ref> SAG [31]</ref> MinCut <ref t ons of graphs, which was first tackled in [36]</ref>.</p><p>Graph pooling aims to tackle the hierarchical nature of graphs via iterative coarsening. Early architectures [13]</ref> resorted to fixed axiomatic pooling, with no optimization of clustering while the network learns. DiffPool [69]</ref> suggests
e two changes to the classic GCN architecture: first, we remove the self-loop creation and instead use an W skip ∈ R s×s trainable skip connection, and, second, we replace ReLU nonlinearity with SeLU [30]</ref> for better convergence.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>In this section, we present DMON, our method for attrib
neural networks and graph pooling methods.</p><p>Graph Neural Networks (GNNs) [49,</ref>15,</ref>40,</ref>21,</ref>29]</ref> allow end-to-end differentable losses over data with arbitrary structure. They have been applied to an incredible range ed to an incredible range of applications, from social networks [47]</ref>, to recommender systems [68]</ref>, to computational chemistry [21]</ref>. While GNNs are flexible enough to allow for unsupervised losses, most work follows the semi-supervised setting for node classification from <ref type="bibr"
elf -whether for data exploration [45]</ref>, visualization [11,</ref>12]</ref>, genomic feature discovery [7]</ref>, anomaly detection [44]</ref>, or for many other use-cases discussed e.g. in [19]</ref>. Additiona
learns its own positional representation [70]</ref>. The learning process in graph embeddings is often done in a similar way to DGI though noise contrastive estimation [24]</ref>. As far as we know, all pooling strategies for learning node embeddings without attributes have been axiomatic [10,</ref><ref ty
pture both graph structure and node features.</p><p>• Unsupervised training is a desirable setting for clustering models. Works on supervised graph clustering [66,</ref>62]</ref> are outside of the scope of this work.</p><p>• Sparse. As graphs in the real-world vary in size and sparsity, methods can not be limited by a O(n 2 ) link pred
[57]</ref> or employment [41]</ref> in social graphs. GNNs have been shown to benefit from leveraging higher-order structural information that could arise from clusters [9,</ref>69,</ref>31]</ref>, for example through pooling or trainable attention over edges <ref type="bibr"
he algorithm performance. We review two families of clustering quality functions amenable to spectral optimization, and review some of their shortcomings.</p><p>Cut-based metrics. In his seminal work [18]</ref>, Fiedler suggested that the second (Fiedler) eigenvector of a graph Laplacian produces a graph cut minimal in terms of the weight of the edges. This plain not
"bibr" target="#b68">[69]</ref> is not stable in terms of graph sparsity, while MinCutPool [4]</ref> can not deal with uneven degree distribution.</p><p>Graph embeddings [48,</ref>23,</ref>59</ref>] can be thought of as (very restricted) unsupervised GNNs with an identity feat
plore the robustness of our approach to variance in the graph and node features, we propose a study on synthetic graphs using an attributed, degree-corrected stochastic block model (ADC-SBM). The SBM [53]</ref> plants a partition of clusters ("blocks") in a graph, and generates edges via a distribution conditional on that partition. This model has been used extensive
aphs. Ehrlinger and W öß [7]</ref> analyzed several existing definitions and proposed Definition 1 which emphasizes the reasoning engine of knowledge graphs. Wang et al. [8]</ref> proposed a definition as a multi-relational graph in Definition 2. Following previous literature, we define a knowledge graph as G = {E, R, F}, where E, R and F ger and W öß [7]</ref>). A knowledge graph acquires and integrates information into an ontology and applies a reasoner to derive new knowledge. Definition 2 (Wang et al. [8]</ref>). A knowledge graph is a multirelational graph composed of entities and relations which are regarded as nodes and different types of edges, respectively. Specif earning [9]</ref>, knowledge graph refinement [6]</ref>, Chinese knowledge graph construction [10]</ref>, KGE [8]</ref> or KRL [11]</ref>. The latter two surveys are more related to our work. Lin et al. [11]</ref> pres The latter two surveys are more related to our work. Lin et al. [11]</ref> presented KRL in a linear manner, with a concentration on quantitative analysis. Wang et al. [8]</ref> categorized KRL according to scoring functions, and specifically focused on the type of information utilized in KRL. It provides a general view of current resea and image-based representations are in the same representation space. There still remains many kinds of auxiliary information for KRL such as attributes, relation path and logical rules. Wang et al. [8]</ref> gave a detailed review on these information. This paper discusses relation path and logical rules under the umbrella of KGC in Sec. 4.1.2 and 4.1.4, respectivel
ead><p>Most efforts have been made to give a definition by describing general semantic representation or essential characteristics. However, there is no such wide-accepted formal definition. Paulheim [6]</ref> defined four criteria for knowledge graphs. Ehrlinger and W öß [7]</ref> analyzed several existing definitions and proposed Defini "><head n="2.4">Related Surveys</head><p>Previous survey papers on knowledge graphs mainly focus on statistical relational learning [9]</ref>, knowledge graph refinement [6]</ref>, Chinese knowledge graph construction [10]</ref>, KGE [8]</ref> or KRL <ref type="bibr" target="#b10
dge Acquisition</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Related Surveys</head><p>Previous survey papers on knowledge graphs mainly focus on statistical relational learning [9]</ref>, knowledge graph refinement [6]</ref>, Chinese knowledge graph construction [10]</ref>, KGE <ref typ
ess is used to model the occurrence of facts, and a novel recurrent network is developed to learn the representation of non-linear temporal evolution. To capture the interaction between nodes, RE-NET [142]</ref> models event sequences via RNN-based event encoder and neighborhood aggregator. Specifically, RNN is used to capture the temporal entity interaction, and th
as threeway tensor X decomposition. A general principle of tensor factorization can be denoted as X hrt ≈ h M r t, with the composition function following the semantic matching pattern. Nickel et al. [42]</ref> proposed the three-way rank-r factorization RESCAL over each relational slice of knowledge graph tensor. For k-th relation of m relations, the k-th slice of X Linear and bilinear models use product-based functions over entities and relations, while factorization models regard knowledge graphs as three-way tensors. With the multiplicative operations, RESCAL [42]</ref>, ComplEx [18]</ref>, and SimplE [41]</ref> also belong to the bilinear models. DistMult <ref typ contrast, the OWA has a relaxed assumption that unobserved ones can be either missing or false. Generally, OWA has advantage over CWA because of the incompleteness nature of knowledge graphs. RESCAL [42]</ref> is a typical model trained under the CWA, while more models are formulated under the OWA.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Loss Fu
2">[13]</ref> then further introduces separated spaces for entities and relations. The authors projected entities (h, t ∈ R k ) into relation (r ∈ R d ) space by a projection matrix M r ∈ R k×d . NTN [14]</ref> models entities across multiple dimensions by a bilinear tensor neural layer. The relational interaction between head and tail h T Mt is captured as a tensor or example, SME [34]</ref>.</p><p>Representative neural models include multi-layer perceptron (MLP) [5]</ref>, neural tensor network (NTN) [14]</ref>, and neural association model (NAM) [46]</ref>. Generally, they take entities and/or relations into deep neural networks and co a triple as</p><formula xml:id="formula_37">fr(h, t) = σ(w σ(W[h, r, t])),<label>(27)</label></formula><p>where W ∈ R n×3d is the weight matrix and [h, r, t] is a concatenation of three vectors. NTN [14]</ref> takes entity embeddings as input associated with a relational tensor and outputs predictive score in as</p><formula xml:id="formula_38">fr(h, t) = r σ(h T Mt cluding translational distance-based methods like TransH [15]</ref> and TransR [13]</ref> and semantic matching-based methods such as NTN [14]</ref>, HolE [16]</ref> and ANALOGY [17]</ref>.</p><p>Vanilla vector-based embedding methods failed to target="#tab_7">5</ref>. The representation space has an impact on the expressiveness of KRL methods to some extent. By expanding point-wise Euclidean space [12]</ref>, [14]</ref>, [16]</ref>, manifold space [23]</ref>, complex space [18]</ref>, ns or compositional operators including linear matching in SME [34]</ref>, bilinear mapping in DistMult [26]</ref>, tensor product in NTN [14]</ref>, circular correlation in HolE [16]</ref> and ANALOGY [17]</ref>, Hadamard product in CrossE <ref edding dimensionality bounds. Neural network-based encoding models start from distributed representation of entities and relations, and some utilizes complex neural structures such as tensor networks [14]</ref>, graph convolution networks [38]</ref>, [53]</ref>, [55]</ref>, r
, and Akutan for knowledge graph store and query. The research community has also released codes to facilitate further research. Notably, there are three useful toolkits, namely scikit-kge and OpenKE [206]</ref> for knowledge graph embedding, and OpenNRE [207]</ref> for relation extraction. We  [190]</r
d knowledge injected into a unified semantic space. Recent knowledge-driven advances utilize explicit factual knowledge and implicit language representation, with many NLU tasks explored. Chen et al. [146]</ref> proposed doublegraph random walks over two knowledge graphs, i.e., a slotbased semantic knowledge graph and a word-based lexical knowledge graph, to conside
approaches have made efforts through representation learning of entities and mentions, for example, DSRM [95]</ref> for modeling entity semantic relatedness and EDKate [96]</ref> for the joint embedding of entity and text. Ganea and Hofmann [97]</ref> proposed an attentive neural model over local context
as a sequential optimization problem by maximizing the expected reward. It excludes the target answer entity and provides more capable inference. Instead of using a binary reward function, Multi-Hop [74]</ref> proposes a soft reward mechanism. To enable more effective path exploration, action dropout is also adopted to mask some outgoing edges during training. M-Wal id="formula_53">Diversity − 1 |F | |F | i=1 cos (p, pi)</formula><p>MINERVA [73]</ref> (et, es, rq, eq) {(et, r, v)} I {et = eq} ht = LST M (ht−1, [at−1; ot]) Multi-Hop [74]</ref> (et, (es, rq)) r , e | et, r , e ∈ G γ + (1 − γ) fr q (es, e T ) ht = LST M (ht−1, at−1) M-Walk [75]</ref> st−1 <ref type="bibr
p://www.tei-c.org/ns/1.0"><head n="4.3.5">Reinforcement Learning RL has been integrated into neural relation extraction recently</head><p>by training instance selector with policy network. Qin et al. [127]</ref> proposed to train policy-based RL agent of sentential relation classifier to redistribute false positive instances into negative samples to mitigate the eff ="bibr" target="#b124">[125]</ref> AT + PCNN/RNN + selective attention indicator encoding DSGAN [126]</ref> GAN + PCNN/CNN + attention position embedding RL Qin et al. [127]</ref> Policy gradient + CNN + performance change reward position embedding Zeng et al. [128]</ref> Policy gradient + CNN + +1/-1 b
over local context windows for entity embedding learning and differentiable message passing for inferring ambiguous entities. By regarding relations between entities as latent variables, Le and Titov [98]</ref> developed an end-toend neural architecture with relation-wise and mention-wise normalization.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.

in-specific, task-specific and temporal datasets.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1.1 General Datasets</head><p>Datasets with general ontological knowledge include Word-Net [189]</ref>, Cyc [190]</ref>, DBpedia [191]</ref>, YAGO [192]</ref>, Fre
ns.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.7">Graph Neural Networks</head><p>GNNs are introduced for learning connectivity structure under an encoder-decoder framework. R-GCN [53]</ref> proposes relation-specific transformation to model the directed nature of knowledge graphs. Its forward propagation is defined as</p><formula xml:id="formula_ ref type="bibr" target="#b11">[12]</ref>, TransH [15]</ref>, TransR [13]</ref>, HolE [16]</ref>, and R-GCN [53]</ref>) and joint learning methods like DKRL [57]</ref> with textual information can been used for KGC.</p><p>Unlike representing inpu ies and relations, and some utilizes complex neural structures such as tensor networks [14]</ref>, graph convolution networks [38]</ref>, [53]</ref>, [55]</ref>, recurrent networks [39]</ref> and transformers [51]<
structural information with R-GCN, and then takes the structural entity embedding for multi-step matching guided by long short-term memory (LSTM) networks to calculate the similarity scores. Meta-KGR [87]</ref>, an optimization-based meta learning approach, adopts model agnostic meta learning for fast adaption and reinforcement learning for entity searching and path
v> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Type Information</head><p>Entities are represented with hierarchical classes or types, and consequently, relations with semantic types. SSE [59]</ref> incorporates semantic categories of entities to embed entities belonging to the same category smoothly in semantic space. TKRL 
n entity pair. MIMLCNN [111]</ref> further extends it to multilabel learning with cross-sentence max pooling for feature selection. Side information such as class ties [112]</ref> and relation path [113]</ref> is also utilized. RNNs are also introduced, for example, SDP-LSTM <ref type="bibr" target="#b1 rget="#b109">[110]</ref> CNN + piecewise max pooling position embedding MIMLCNN [111]</ref> CNN + piecewise and cross-sentence max pooling position embedding Ye et al. [112]</ref> CNN/PCNN + pairwise ranking position embedding, class ties Zeng et al. [113]</ref> CNN + max pooling position embedding, rel
ooperative CORD [133]</ref> ensembles text corpus and knowledge graph with external logical rules by bidirectional knowledge distillation and adaptive imitation. TK-MF [134]</ref> enriches sentence representation learning by matching sentences and topic words. The existence of low-frequency relations in knowledge graphs requires few-s fer learning + sub-tree parse + attention position embedding CORD [133]</ref> BiGRU + hierarchical attention + cooperative module position embedding, logic rules TK-MF [134]</ref> Topic modeling + multi-head self attention position embedding, topic words HATT-Proto [135]</ref> Prototypical networks + CN
, providing supplementary semantic information. The challenge of KRL with textual description is to embed both structured knowledge and unstructured textual information in the same space. Wang et al. [56]</ref> proposed two alignment models for aligning entity space and word space by introducing entity names and Wikipedia anchors. DKRL  ong correlations between triples and textual descriptions by projecting them in a semantic subspace. Joint loss function is widely applied when incorporating KGE with textual description. Wang et al. [56]</ref> used a three-component loss</p><formula xml:id="formula_48">L = L K + L T + L A of knowledge model L K , text model L T</formula><p>and alignment model L A .
e dimensions by a bilinear tensor neural layer. The relational interaction between head and tail h T Mt is captured as a tensor denoted as M ∈ R d×d×k . Many other translational models such as TransH [15]</ref> also use similar representation space, while semantic matching models use plain vector space (e.g., HolE [16]</ref>) and relati mula_4">fr(h, t) = h + r − t L 1 /L 2 . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>Since that, many variants and extensions of TransE have been proposed. For example, TransH [15]</ref> projects entities and relations into a hyperplane as</p><formula xml:id="formula_6">fr(h, t) = − h − w r hwr + r − t − w r twr 2 2 ,<label>(5)</label></formul entity with each entity e ∈ E to calculate scores of all the candidate entities and rank the top k entities. Aforementioned KRL methods (e.g., TransE [12]</ref>, TransH [15]</ref>, TransR [13]</ref>, HolE [16]</ref>, and R-GCN [53]</ref>) and jo ule is based on the scoring function with a specific threshold. Aforementioned embedding methods could be applied for triple classification, including translational distance-based methods like TransH [15]</ref> and TransR [13]</ref> and semantic matching-based methods such as NTN [14]</ref>, HolE <ref type ds, especially the groundbreaking TransE [12]</ref>, borrowed the idea of distributed word representation learning and inspired many following approaches such as TransH [15]</ref> and TransR [13]</ref> which specify complex relations (1-to-N, N-to-1, and N-to-N) and the recent TransMS <ref type="bibr" targ re effective negative sampling strategies are required to learn semantic representation and improve the predictive performance.</p><p>Considering the mapping property of relations, Bernoulli sampling [15]</ref> introduces a heuristic of sampling distribution as tph tph+hpt , where tph and hpt denote the average number of tail entities per head entity and the average
Although deep learning techniques are intensively applied in KG-QA, they inevitably increase the model complexity. Through evaluation on simple KG-QA with and without neural networks, Mohammed et al. [159]</ref> found that sophisticated deep models such as LSTM and gated recurrent unit (GRU) with heuristics achieve the state of the art, and non-neural models also ga
"#b198">[199]</ref>, an analogical closure of Probase for opinion mining and sentiment analysis, is built by common knowledge base blending and multi-dimensional scaling. Recently, the FewRel dataset [200]</ref> was built to evaluate the emerging few-shot relation classification task. There are also more datasets for specific tasks such as cross-lingual DBP15K <ref
over multiple instances to alleviate the impact of noisy instances [118]</ref>. Other side information is also introduced for enriching semantic representation. APCNN [119]</ref> introduces entity description by PCNN and sentence-level attention, while HATT [120]</ref> proposes hierarchical selective a arget="#b117">[118]</ref> CNN/PCNN + selective attention + max pooling position embedding Att-BLSTM [121]</ref> Bi-LSTM + word-level attention position indicator APCNN [119]</ref> PCNN + sentence-level attention entity descriptions HATT [120]</ref> CNN/PCNN + hierarchical attention position embedding, r
ic research, covering complex domain and relations such as compounds, diseases and tissues. Examples of domainspecific knowledge graphs are ResearchSpace 6 , a cultural heritage knowledge graph; UMLS [197]</ref>, a unified medical language system; GeneOntology 7 , a gene ontology resource; SNOMED CT 8 , a commercial clinical terminology; and a medical knowledge grap
"#b44">[45]</ref> learns embedding by outputting a core tensor and embedding vectors of entities and relations. Its scoring function is defined as  [5]</ref> and (b) CNN [37]</ref> input triples into dense layer and convolution operation to learn semantic representation, (c) GCN [38]</ref> acts as encoder o he convolutional filters and vec is the vectorization operation reshaping a tensor into a vector. ConvE can express semantic information by non-linear feature learning through multiple layers. ConvKB [37]</ref> adopts CNNs for encoding the concatenation of entities and relations without reshaping (Fig. 5b</ref>). Its scoring functio ns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 :</head><label>5</label><figDesc>Fig.5: Illustrations of neural encoding models. (a) MLP[5]</ref> and (b) CNN[37]</ref> input triples into dense layer and convolution operation to learn semantic representation, (c) GCN[38]</ref> acts as encoder of
es heuristic matching to create training data by assuming that sentences containing the same entity mentions may express the same relation under the supervision of a relational database. Mintz et al. [106]</ref> adopted the distant supervision for relation classification with textual features including lexical and syntactic features, named entity tags, and conjuncti rvision for relation classification with textual features including lexical and syntactic features, named entity tags, and conjunctive features. Traditional methods rely highly on feature engineering [106]</ref>, with a recent approach exploring the inner correlation between features [107]</ref>. Deep neural networks is changing the r
n entity pair. MIMLCNN [111]</ref> further extends it to multilabel learning with cross-sentence max pooling for feature selection. Side information such as class ties [112]</ref> and relation path [113]</ref> is also utilized. RNNs are also introduced, for example, SDP-LSTM <ref type="bibr" target="#b1 rget="#b109">[110]</ref> CNN + piecewise max pooling position embedding MIMLCNN [111]</ref> CNN + piecewise and cross-sentence max pooling position embedding Ye et al. [112]</ref> CNN/PCNN + pairwise ranking position embedding, class ties Zeng et al. [113]</ref> CNN + max pooling position embedding, rel
entities and relations are denoted as [h], [r], [t] ∈ T n . Similar to TransE, it also learns embeddings following the relational translation in torus space, i.e., [h] + [r] ≈ [t]. Recently, DihEdral [25]</ref> proposes dihedral symmetry group preserving a 2-dimensional polygon.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scoring Function</head>< as:</p><formula xml:id="formula_28">min (x,y)∈([h]+[r])×[t]</formula><p>x − y i. (20)</ref> By modeling 2L relations as group elements, the scoring function of DihEdral [25]</ref> is defined as the summation of components:</p><formula xml:id="formula_29">fr(h, t) = h Rt = L l=1 h (l) R (l) t (l) ,<label>(21)</label></formula><p>where th nal space of entities and relations, and gains more expressive rotational capability than RotatE. Group theory remains less explored to capture rich information of relations. The very recent DihEdral [25]</ref> firstly introduces the finite non-Abelian group to preserve the relational properties of symmetry/skewsymmetry, inversion and composition effectively with the
, and conjunctive features. Traditional methods rely highly on feature engineering [106]</ref>, with a recent approach exploring the inner correlation between features [107]</ref>. Deep neural networks is changing the representation learning of knowledge graphs and texts. This section reviews recent advances of neural relation extract
embeddings with C kernels to be M (h, r) ∈ R C×d , its scoring function is defined as</p><formula xml:id="formula_47">fr(h, t) = g (vec (M (h, r)) W ) t.<label>(33)</label></formula><p>Nathani et al. [55]</ref> introduced graph attention networks with multi-head attention as encoder to capture multi-hop neighborhood features by inputing the concatenation of entity an x neural structures such as tensor networks [14]</ref>, graph convolution networks [38]</ref>, [53]</ref>, [55]</ref>, recurrent networks [39]</ref> and transformers [51]</ref>, [52]<
overs (NTP) [82]</ref> learns logical rules for multi-hop reasoning which utilizes radial basis function kernel for differentiable computation on vector space. NeuralLP [83]</ref> enables gradient-based optimization to be applicable in the inductive logic programming, where a neural controller system is proposed by integrating attention rget="#b83">[84]</ref> are generated by simple bruteforce search, making it insufficient on large-scale knowledge graphs. ExpressGNN [85]</ref> attempts to use NeuralLP [83]</ref> for efficient rule induction. But there still has a long way to go to deal with cumbersome deep architectures and the increasingly growing knowledge graphs.</
standing. Wang et al. [147]</ref> augmented short text representation learning with knowledge-based conceptualization by a weighted word-concept embedding. Peng et al. [148]</ref> integrated external knowledge base to build heterogeneous information graph for event categorization in short social text. Language modeling as a fundamenta
gorithms are black boxes and do not allow for high-level control of their generated content.</p><p>In this paper, we introduce TOAD-GAN as a solution to these problems. Our work is inspired by SinGAN (Shaham, Dekel, and Michaeli 2019)</ref>, a recent Generative Adversarial Network (GAN) (Goodfellow et al. 2014)</ref> architecture that learns a genera g/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Generation process of TOAD-GAN on Super Mario Bros. level 1-2. The architecture is adapted from SinGAN (cf. Fig. 4 of(Shaham, Dekel, and Michaeli 2019)</ref>). We use a downsampling method on a one-hot encoded version of the level that preserves small but important structures which wou els, this increases the number of parameters that have to be optimized, which further complicates the training process.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>SinGAN</head><p>SinGAN (Shaham, Dekel, and Michaeli 2019</ref>) is a novel GAN architecture that enables learning a generative model from a single image. This is achieved by using a cascade of volutional. This means that the size of the output is determined by the size of the initial noise map at the lowest scale. For a more in-depth explanation please refer to the original SinGAN paper by Shaham, Dekel, and Michaeli (2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>TOAD-GAN</head><p>Fig. 3</ref> show
to different heights in (l)). All this while the general structure of the generated levels is similar to a SMB level. We tested the validity of our generated content using the A* agent by Baumgarten (Togelius, Karakovskiy, and Baumgarten 2010)</ref>, who was able to win 65% of randomly sampled levels compared to the 52% of the original levels <ref type="bibr" target
bibr" target="#b9">(Hochreiter and Schmidhuber 1997)</ref> to predict the next token, given a context of previous tokens in the unrolled level.</p><p>Recently, GANs were used to create SMB levels. In (Volz et al. 2018)</ref> the authors train a GAN on slices of the original levels and use an EA to search the space of generated levels by scoring the fraction of enemy mple cut from (o) was trained on 4-2 and should therefore be more similar to an underground level. The closest to a convincing overworld level is (p) which was also created using a GAN-based approach (Volz et al. 2018)</ref>. However, this method relies on small samples that are stitched together and can result in repeating patterns.</p><p>Tile Pattern KL-Divergence n of new levels for SMB from very little training data. With TOAD-GAN, we take this problem to the extreme regime of learning from only one single training level. Similar to other recent publications (Volz et al. 2018;</ref>Torrado et al. 2019;</ref>Volz et al. 2020)</ref>, TOAD-GAN is based on the GAN arc
aining process, for example minimizing the Wasserstein distance (Arjovsky, Chintala, and Bottou 2017)</ref> and penalizing the norm of the gradients of the discriminator (Gulrajani et al. 2017)</ref>. The resulting Wasserstein GAN with Gradient Penalty (WGAN-GP) is able to model a variety of distributions, but it is still prone to failure
ntial to assist the designer by automating parts of the process. Early works in PCG used the co-occurrence of tokens (e.g. a single enemy or ground block) in existing game levels to identify patterns (Dahlskog and Togelius 2012</ref>) and combined them using simple statistical models (Snodgrass and Ontanón 2013)</ref>. The quality of the he vast amount of PCG approaches.</p><p>For a review of pattern-based level generators for SMB see Khalifa et al. (2019)</ref>.</p><p>Super Mario Bros. Level Generation Dahlskog and Togelius (2012)</ref> identified and analyzed patterns with different themes, such as enemies, gaps or stairs.</p><p>They assessed the difficulty of the patt enemies, gaps or stairs.</p><p>They assessed the difficulty of the patterns to human players and outlined how those patterns could be combined and varied to create new levels. In their continued work (Dahlskog and Togelius 2014)</ref>, they additionally defined micro-(vertical slices) and macro-patterns (sequences of patterns). Using an Evolutionary Algorithm (EA), th
bibr" target="#b9">(Hochreiter and Schmidhuber 1997)</ref> to predict the next token, given a context of previous tokens in the unrolled level.</p><p>Recently, GANs were used to create SMB levels. In (Volz et al. 2018)</ref> the authors train a GAN on slices of the original levels and use an EA to search the space of generated levels by scoring the fraction of enemy mple cut from (o) was trained on 4-2 and should therefore be more similar to an underground level. The closest to a convincing overworld level is (p) which was also created using a GAN-based approach (Volz et al. 2018)</ref>. However, this method relies on small samples that are stitched together and can result in repeating patterns.</p><p>Tile Pattern KL-Divergence n of new levels for SMB from very little training data. With TOAD-GAN, we take this problem to the extreme regime of learning from only one single training level. Similar to other recent publications (Volz et al. 2018;</ref>Torrado et al. 2019;</ref>Volz et al. 2020)</ref>, TOAD-GAN is based on the GAN arc
ed PCG (Togelius et al. 2011</ref>) was applied to SMB by Summerville, Philip, and Mateas (2015)</ref>. The authors used Monte Carlo Tree Search (MCTS) (Coulom 2006)</ref> to guide the sampling process from a Markov Chain model of tokens. The reward of the MCTS was computed based on the solvability, number of gaps, numbe

bibr" target="#b9">(Hochreiter and Schmidhuber 1997)</ref> to predict the next token, given a context of previous tokens in the unrolled level.</p><p>Recently, GANs were used to create SMB levels. In (Volz et al. 2018)</ref> the authors train a GAN on slices of the original levels and use an EA to search the space of generated levels by scoring the fraction of enemy mple cut from (o) was trained on 4-2 and should therefore be more similar to an underground level. The closest to a convincing overworld level is (p) which was also created using a GAN-based approach (Volz et al. 2018)</ref>. However, this method relies on small samples that are stitched together and can result in repeating patterns.</p><p>Tile Pattern KL-Divergence n of new levels for SMB from very little training data. With TOAD-GAN, we take this problem to the extreme regime of learning from only one single training level. Similar to other recent publications (Volz et al. 2018;</ref>Torrado et al. 2019;</ref>Volz et al. 2020)</ref>, TOAD-GAN is based on the GAN arc
ed PCG (Togelius et al. 2011</ref>) was applied to SMB by Summerville, Philip, and Mateas (2015)</ref>. The authors used Monte Carlo Tree Search (MCTS) (Coulom 2006)</ref> to guide the sampling process from a Markov Chain model of tokens. The reward of the MCTS was computed based on the solvability, number of gaps, numbe
div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Networks for PCG</head><p>Recent PCGML approaches that use Neural Networks have also been applied extensively to the SMB level generation problem. Hoover, Togelius, and Yannakis (2015)</ref> trained a neural network with an EA to generate new levels. The network predicts the height of a token in a level slice, give
target="#b35">[Monti et al., 2017b</ref>, Ying et al., 2018]</ref>, and efficiently segmenting large point clouds [Wang et al., 2018</ref>, Li et al., 2019b]</ref>. Recent works have looked at frameworks to train deeper GCN architectures [Li et al., 2019b,a]</ref>. These works demonstrate CNN-based networks [He et al., 2016a</ref>, Huang et al., 2017</ref>, Yu and Koltun, 2016]</ref>, DeepGCNs [Li et al., 2019b]</ref> propose to train very deep GCNs (56 layers) by adapting residual/dense connections (ResGCN/DenseGCN) and dilated convolutions to GCNs. DeepGCN v as 10 −7 . As the conditions are satisfied, we can choose the message aggregation function ζ (l) (•) to be either SoftMax_Agg β (•) or PowerMean_Agg p (•).</p><p>Better Residual Connections. DeepGCNs [Li et al., 2019b]</ref> show residual connections [He et al., 2016a]</ref> to be quite helpful in training very deep GCN architectures. T y Sum(•), Mean(•) or Max(•) aggregation. Layer normalization [Ba et al., 2016]</ref> is used in every layer before the activation function ReLU.</p><p>ResGCN. Similar to Li et al. [2019b]</ref>, we construct ResGCN by adding residual connections to PlainGCN following the ordering: GraphGonv → Normalization → ReLU → Addition.</p><p>ResGCN
s, aggregation functions must be permutation invariant. This invariance property guarantees the invariance/equivariance to isomorphic graphs [Battaglia et al., 2018</ref>, Xu et al., 2019b]</ref>. Popular choices for aggregation functions include mean [Kipf and Welling, 2016]</ref>, max <ref type="bibr" tar , and sum [Xu et al., 2019b]</ref>. Recent works suggest that different aggregations have different impact depending on the task. For et al., 2018</ref>, Xu et al., 2019b]</ref>. Specifically, Hamilton et al. [2017]</ref> examine mean, max, and LSTM aggregators, and they empirically find t n PyTorch, we are not able to use larger p. These results empirically validate the discussion in Section 4.1 regarding Proposition 4 and 5.  [Hamilton et al., 2017</ref>, Xu et al., 2019b]</ref>. Comparison with SOTA. We apply our GCN models to three other OGB datasets and compare all results with SOTA posted on OGB Learderboard at the </ref>. Popular choices for aggregation functions include mean [Kipf and Welling, 2016]</ref>, max [Hamilton et al., 2017]</ref>, and sum [Xu et al., 2019b]</ref>. Recent works suggest that different aggregations have different impact depending on the task. For et al., 2018</ref><ref type= pe="bibr" target="#b12">[Gilmer et al., 2017]</ref>, GraphSage [Hamilton et al., 2017]</ref>, GAT [Veličković et al., 2018]</ref> and GIN [Xu et al., 2019b]</ref>. In this work, we focus on the GCN family and its message passing framework [Gilmer et al., 2017</ref><ref type=" 8]</ref>. ζ (l) can be a simply symmetric function such as mean [Kipf and Welling, 2016]</ref>, max [Hamilton et al., 2017]</ref>, or sum [Xu et al., 2019b]</ref>. Vertex update function φ (l) combines the original vertex features h (l) v and the aggregated message m  G 1 ld tend to use simple permutation invariant functions like mean [Kipf and Welling, 2016]</ref>, max [Hamilton et al., 2017]</ref> and sum [Xu et al., 2019b]</ref>. Inspired by the Weisfeiler-Lehman (WL) graph isomorphism test [Weisfeiler and Lehman, 1968]</ref>, <ref type="bi propose a theoretical framework and analyze the representational power of GCNs with mean, max and sum aggregators. Although mean and max aggregators are proven to be less powerful than the WL test in [Xu et al., 2019b]</ref>, they are found to be effective on the tasks of node classification [Kipf and</ref>Welling, 2016 oard at the time of this submission. The methods include GCN [Kipf and Welling, 2016]</ref>, GraphSAGE [Hamilton et al., 2017]</ref>, GIN [Xu et al., 2019b]</ref>, GIN with virtual nodes, GaAN [Zhang et al., 2018]</ref>, and GatedGCN [Bresson and ble weights for neighbor nodes by learning the attention between their feature vectors and that of the central node. Thus, the aggregator in GATs operates like a learnable weighted mean. Furthermore, Xu et al. [2019b]</ref> propose a GCN architecture, denoted Graph Isomorphism Network (GIN), with a sum aggregation that is able to have as large discriminative power as ref> and sum [Xu et al., 2019b]</ref>. Inspired by the Weisfeiler-Lehman (WL) graph isomorphism test [Weisfeiler and Lehman, 1968]</ref>, Xu et al. [2019b]</ref> propose a theoretical framework and analyze the representational power of GCNs with mean, max and sum aggregators. Although mean and max aggregat
graph datasets. OGB provides graph datasets for tasks like node classification, link prediction, and graph classification.</p><p>Graph convolutions in GCNs are based on the notion of message passing [Gilmer et al., 2017]</ref>. At each GCN layer, node features are updated by passing information from its connected (neighbor) nodes. To compute a new node feature in me et="#b13">[Grover and Leskovec, 2016]</ref>, Chebyshev graph CNN [Defferrard et al., 2016]</ref>, GCN [Kipf and Welling, 2016]</ref>, MPNN [Gilmer et al., 2017]</ref>, GraphSage [Hamilton et al., 2017]</ref>, GAT [Veličković et al., 2018]</ref> a o the equivariant case. Maron et al. [2019a]</ref> compose networks by proposed invariant or equivariant linear layers and show their models are as powerful as any MPNN [Gilmer et al., 2017]</ref>. In this work, we study permutation invariant functions of GCNs, which enjoy these proven properties.</p></div> <div xmlns="http://www.tei-c. f type="bibr" target="#b43">[Veličković et al., 2018]</ref> and GIN [Xu et al., 2019b]</ref>. In this work, we focus on the GCN family and its message passing framework [Gilmer et al., 2017</ref>, Battaglia et al., 2018]</ref>. To be specific, message passing based on GCN operator F operating on vertex v ∈
l. [2019b]</ref> show the universality of invariant GNNs to any continuous invariant function. Keriven and Peyré [2019]</ref> further extend it to the equivariant case. Maron et al. [2019a]</ref> compose networks by proposed invariant or equivariant linear layers and show their models are as powerful as any MPNN <ref type="bibr" target=

are found to be effective on the tasks of node classification [Kipf and</ref>Welling, 2016, Hamilton et al., 2017]</ref> and 3D point cloud processing [Qi et al., 2017</ref>, Wang et al., 2019]</ref>. To further go beyond these simple aggregation functions and study their characteristics,
G 1 , F(G 2 ) = σ F(G 1 )</formula><p>, where denotes a permutation operator on graphs.</p><p>The invariance and equivariance properties on sets or GCNs/GNNs have been discussed in many recent works. Zaheer et al. [2017]</ref> propose DeepSets based on permutation invariance and equivariance to deal with sets as inputs. Maron et al. [20
"#b38">[Perozzi et al., 2014]</ref>, Planetoid [Yang et al., 2016]</ref>, Node2Vec [Grover and Leskovec, 2016]</ref>, Chebyshev graph CNN [Defferrard et al., 2016]</ref>, GCN [Kipf and Welling, 2016]</ref>, MPNN [Gilmer et al., 2017]</ref>, Graph
N performance would degrade. Inspired by the benefit of training deep CNN-based networks [He et al., 2016a</ref>, Huang et al., 2017</ref>, Yu and Koltun, 2016]</ref>, DeepGCNs [Li et al., 2019b]</ref> propose to train very deep GCNs (56 layers) by adapting residual/dense con
works are however limited to 10 layers of depth before GCN performance would degrade. Inspired by the benefit of training deep CNN-based networks [He et al., 2016a</ref>, Huang et al., 2017</ref>, Yu and Koltun, 2016]</ref>, DeepGCNs [Li et al., 2019b]</ref> propose to train
"#b38">[Perozzi et al., 2014]</ref>, Planetoid [Yang et al., 2016]</ref>, Node2Vec [Grover and Leskovec, 2016]</ref>, Chebyshev graph CNN [Defferrard et al., 2016]</ref>, GCN [Kipf and Welling, 2016]</ref>, MPNN [Gilmer et al., 2017]</ref>, Graph
1]</ref>, [24]</ref>, [45]</ref> which capitalize on FlowNet-s [59]</ref> to produce optical flow, PWC-Net [60]</ref> is particularly remould in our motion stream. Compared to a generic U-Net CNN built in FlowNets, the pyramid processing in PWC-Net is more flexible to the cal ch, with the input size of 448 2 in SSVD, the spatial scale of P3, P4, P5, and P6 is 56 2 , 28 2 , 14 2 , and 7 2 , respectively. Two-stream Feature Aggregation. For motion stream, we utilize PWC-Net [60]</ref> pre-trained on Flying Chairs dataset for optical flow estimation. For sampling stream, each conv layer in offset predictor consists of 3 × 3 kernel with 256 f g stream may suffer from robustness problem when object moves extremely fast. This is due to the fact that the receptive field in sampling stream for offset prediction is smaller than that in PWC-Net [60]</ref> for optical flow generation. As such, the range of estimated motion in sampling stream is shorter than that in motion stream, resulting in failure of motion c
extual content encoded across the sampling features from adjacent frames in sampling stream.</p><p>Formally, given the reference frame I t and each support frame I t+τ , Feature Pyramid Network (FPN) [56]</ref> is leveraged to extract multi-scale pyramidal feature maps of each frame for motion and sampling stream, separately. More precisely, by feeding each frame int training.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Model Architecture Design</head><p>Feature Pyramid Network. FPN is built at the top of ResNet-101 pre-trained on ImageNet. As in [56]</ref>, P3, P4, Algorithm 2 Inference Algorithm of our SSVD </p><formula xml:id="formula_7">f t+τ →t P i = W(f t+τ P i , m (t,t+τ ) P i</formula><p>), i ∈ {3, 4, 5,
ments on object detection in images [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>, <ref type="bibr" target="#b13 2">[3]</ref>, [4]</ref>, [5]</ref>, remarkable progresses have been witnessed for object detection [8]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>, <ref type="bibr" target="#b24
is featurelevel aggregation [19]</ref>, [20]</ref>, [21]</ref>, [22]</ref>, [23]</ref>, [24]</ref>. The former often applies a tracker to per-frame bounding box proposals over multiple frames to generate dense tube 76.3 LWDN [64]</ref> ResNet-101 76.3 PSLA [65]</ref> ResNet-101 77.1 MANet [21]</ref> ResNet-101 78.1 THP [23]</ref> ResNet-101+DCN 78.6 STSN [19]</ref> ResNet-101+DCN 78.9 in each frame unexploited. One possible way to address it is to enable eature aggregation, which achieves comparable performance with FGFA under the same backbone of Deformable Convolution Network [61]</ref> (DCN). Note that as reported in [23]</ref>, the performance of FGFA with DCN is 78.8%. For fair comparisons, our SSVD is evaluated based on three commonly adopted basic architectures, ResNet-101, Defor ame in 85 ms, which is even faster than the single-frame baseline of two-stage video object detectors, e.g., R-FCN and Faster R-CNN. Note that here we exclude several video object detection methods ( [23]</ref>, [45]</ref>) which are additionally equipped with the acceleration techniques (e.g., flow guided feature propagation and adapti
ibr" target="#b7">[8]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>, [25]</ref>, [26]</ref>, [27]</ref>, [28]</ref>, <ref type="bibr" target="#b2 two-stage solution, which firstly utilizes selective search to generate region proposals and then classifies each proposal. Later on, SPP-Net [33]</ref> and Fast R-CNN [25]</ref> extend [26]</ref> by devising SPP pooling or ROI pooling to enable the sharing of features across region proposals, which signi x subnets, which simultaneously classify anchor boxes with Focal Loss [11]</ref> (L FL ) and regress from anchor boxes to ground-truth object boxes with Smooth L 1 Loss [25]</ref> (L Loc ). Accordingly, the overall objective of our SSVD is computed as</p><formula xml:id="formula_5">L = 1 Nfg { j c LFL(p mo j,c , l * j ) + j c LFL(p sp j
" target="#b26">[27]</ref>, [28]</ref>, [29]</ref>, [30]</ref>, [31]</ref>, [32]</ref>. In particular, one common deep solution for object detection is based on a two-stage paradigm, i.e., first perform region proposal and then do classification
ype="bibr" target="#b5">[6]</ref>, [7]</ref>, [8]</ref>, [9]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>. Nevertheless, directly apply ">[4]</ref>, [5]</ref>, remarkable progresses have been witnessed for object detection [8]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>, [25]</ref>, <ref type="bibr" target="#b2 es and aspect ratios. Although methods with one-stage paradigm are potential to be faster and simpler, they trail in accuracy compared to two-stage ones. To match the performance of two-stage models, [11]</ref> presents an effective dense one-stage detector, RetinaNet, and equips it with Focal Loss to alleviate the foreground-background class imbalance and successful ature in each scale (i.e., { f mo P i } 6 i=3 and {ĝ sp P i } 6 i=3 ) in both motion and sampling stream is injected into class/box subnets, which simultaneously classify anchor boxes with Focal Loss [11]</ref> (L FL ) and regress from anchor boxes to ground-truth object boxes with Smooth L 1 Loss [25]</ref> (L Loc ). Accordingly, the o d the groundtruth box. To handle different scales and aspect ratios of objects, translation-invariant anchors are assigned to P3, P4, P5, P6 with anchor areas ranging from 32 2 to 256 2 . As in [56], [11]</ref>, each pyramid layer is associated with anchors at three aspect ratios of {1:2, 1:1, 2:1} and three size factors of {2 0 , 2 1/3 , 2 2/3 }. As such, there are
f type="bibr" target="#b3">[4]</ref>, [5]</ref> have successfully achieved remarkable improvements on object detection in images [6]</ref>, [7]</ref>, [8]</ref>, [9]</ref>, [10]</ref>, [11]
imbalance and successfully achieve comparable performance of state-of-the-art two-stage detectors. More recently, anchorfree one stage detectors proposed in [39]</ref>, [40]</ref> are superior in generalization ability since getting rid of limitation to the design of anchors.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. O
ates features via spatio-temporal sampling from the support frames, as shown in Figure 4</ref>. The philosophy is originated from the idea of deformable convolution [61]</ref> which performs non-rigid spatial sampling with self-learnt offsets. More precisely, deformable convolution upgrades standard convolution by adding 2D offsets here the 2D offsets are inferred by the input feature itself, without additional supervision. In our case, we extend the augmentation of spatial sampling locations in standard deformation convolution [61]</ref> which is only conditioned on one feature map to the measure of deformation across two feature maps of the reference frame and the support frame. In other word TSN leverages spatio-temporal sampling instead of motion calibration for feature aggregation, which achieves comparable performance with FGFA under the same backbone of Deformable Convolution Network [61]</ref> (DCN). Note that as reported in [23]</ref>, the performance of FGFA with DCN is 78.8%. For fair comparisons, our SSVD is evalua
ref type="bibr" target="#b12">[13]</ref> ResNet-101 75.4 D (&amp; T loss) [15]</ref> ResNet-101 75.8 FGFA [24]</ref> ResNet-101 76.3 LWDN [64]</ref> ResNet-101 76.3 PSLA [65]</ref> ResNet-101 77.1 MANet [21]</ref> ResNet-101 78.1 THP <ref type="
imbalance and successfully achieve comparable performance of state-of-the-art two-stage detectors. More recently, anchorfree one stage detectors proposed in [39]</ref>, [40]</ref> are superior in generalization ability since getting rid of limitation to the design of anchors.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. O
" target="#b48">[49]</ref>, [50]</ref>, [51]</ref>, [52]</ref>, [53]</ref>, [54]</ref>, [55]</ref>, we aim to detect the objects in the reference frame I t by additionally leveraging the spatio-temporal coherence d
"bibr" target="#b7">[8]</ref>, [9]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>. Nevertheless, directly applying these object detectors for still images to object detection in videos is very chal witnessed for object detection [8]</ref>, [10]</ref>, [11]</ref>, [12]</ref>, [13]</ref>, [25]</ref>, [26]</ref>, [27]</ref>, <ref type="bibr" target="#b2 e="bibr" target="#b25">[26]</ref> by devising SPP pooling or ROI pooling to enable the sharing of features across region proposals, which significantly speed up the process of detection. Faster R-CNN [13]</ref> further advances Fast R-CNN by leveraging Region Proposal Networks (RPN) instead of selective search at the first stage. Compared to the costly per-region cla leaves the relations between objects Methods Backbone mAP (%) R-FCN [8]</ref> ResNet-101 73.6 DorT [43]</ref> ResNet-101 73.9 Faster R-CNN [13]</ref> ResNet-101 75.4 D (&amp; T loss) [15]</ref> ResNet-101 75.8 FGFA [24]</ref> ResNet-101 76.3 LWDN ancing per-frame feature for detection in an end-to-end fashion without any postprocessing. Among them, the former two approaches (i.e., R-FCN [8]</ref> and Faster R-CNN [13]</ref>) are two representative twostage image object detectors only exploit single frame information. D (&amp;T loss) [15]</ref> exhib
. One common solution for video object detection is box-level tracking [15]</ref>, [16]</ref>, [17]</ref>, [18]</ref> and another branch is featurelevel aggregation [19]</ref>, [20]</ref>, <ref type="bibr" target="
task of video object detection, the ultimate goal is to localize and recognize objects from the reference frame. Taking the inspiration from the temporal coherence exploration in video understanding [48]</ref>, [49]</ref>, [50]</ref>, [51]</ref>, <ref type="bibr" target="#b5
" target="#b49">[50]</ref>, [51]</ref>, [52]</ref>, [53]</ref>, [54]</ref>, [55]</ref>, we aim to detect the objects in the reference frame I t by additionally leveraging the spatio-temporal coherence distilled from the support frames. Technical
arget="#b16">[17]</ref>, [18]</ref> and another branch is featurelevel aggregation [19]</ref>, [20]</ref>, [21]</ref>, [22]</ref>, [23]</ref>, [24]</ref>. The former often applies a t , [45]</ref> calibrate a sequence of per-frame feature maps with the guidance from optical flow and aggregate them along motion paths to enhance object detection. Next, [21]</ref> extends [24]</ref> by exploiting additional motion path with box-level calibration for feature aggregation. Instead of estimati h way of motion compensation has convincingly demonstrated high capability of modeling temporal correlation in video super-resolution [57]</ref>, video object detection [21]</ref>, [24]</ref>, and video translation [58]</ref>. As a result, we follow this elegant recipe and de tage video object detection.</p><p>Motion Estimation. Technically, with the input reference and support frames, we first estimate the motion between them in the form of optical flow. Unlike the works [21]</ref>, [24]</ref>, [45]</ref> which capitalize on FlowNet-s [59]</ref> ><p>Training. In our experiments, the whole architecture of our SSVD is trained over 4 GPUs by synchronized SGD with momentum of 0.9 and weight decay of 0.0001. The batch size is set as 16. Following [21]</ref>, [24]</ref>, the two-phase training strategy is adopted. In the first phase, we construct a still image detector by directly li 75.8 FGFA [24]</ref> ResNet-101 76.3 LWDN [64]</ref> ResNet-101 76.3 PSLA [65]</ref> ResNet-101 77.1 MANet [21]</ref> ResNet-101 78.1 THP [23]</ref> ResNet-101+DCN 78.6 STSN [19]</ref> ResNet-101+DCN 78.9 in each f the two image object detectors by exploiting temporal coherence among adjacent frames via RoI tracking module. The latter three baselines (i.e., FGFA [24]</ref>, MANet [21]</ref>, and STSN [19]</ref>) further boost the performance for video object detection by enhancing per-frame feature. Specifically, FG
" target="#b49">[50]</ref>, [51]</ref>, [52]</ref>, [53]</ref>, [54]</ref>, [55]</ref>, we aim to detect the objects in the reference frame I t by additionally leveraging the spatio-temporal coherence distilled from the support frames. Technical
tion in video understanding [48]</ref>, [49]</ref>, [50]</ref>, [51]</ref>, [52]</ref>, [53]</ref>, [54]</ref>, [55]</ref>, we aim to detect the objects
" target="#b12">[13]</ref>, [25]</ref>, [26]</ref>, [27]</ref>, [28]</ref>, [29]</ref>, [30]</ref>, [31]</ref>, [32]</ref>. In particular, one common de
motion-guided propagation to stabilize detection results and achieves 73.8% mAP. D&amp;T links detection boxes between each two adjacent frames by predicted tracking boxes and Viterbi Algorithm as in [67]</ref>, which boosts the performance from 75.8% to 79.8%. STMN firstly combines detection results of spatio-temporal memory module based sequence prediction with tha only evaluates the detection accuracy at frame level. Specifically, we exploit the Viterbi algorithm to link the per-frame detection boxes of our SSVD into tracklets. The mAP track of SSVD + Viterbi [67]</ref> is 60.2%, which is higher than 57.0% of DorT [43]</ref>. The results further demonstrate the effectiveness of our SSVD at track
first attempts that tackles object detection problem in a two-stage solution, which firstly utilizes selective search to generate region proposals and then classifies each proposal. Later on, SPP-Net [33]</ref> and Fast R-CNN [25]</ref> extend [26]</ref> by devising SPP pooling or ROI pooling to enable the
ates features via spatio-temporal sampling from the support frames, as shown in Figure 4</ref>. The philosophy is originated from the idea of deformable convolution [61]</ref> which performs non-rigid spatial sampling with self-learnt offsets. More precisely, deformable convolution upgrades standard convolution by adding 2D offsets here the 2D offsets are inferred by the input feature itself, without additional supervision. In our case, we extend the augmentation of spatial sampling locations in standard deformation convolution [61]</ref> which is only conditioned on one feature map to the measure of deformation across two feature maps of the reference frame and the support frame. In other word TSN leverages spatio-temporal sampling instead of motion calibration for feature aggregation, which achieves comparable performance with FGFA under the same backbone of Deformable Convolution Network [61]</ref> (DCN). Note that as reported in [23]</ref>, the performance of FGFA with DCN is 78.8%. For fair comparisons, our SSVD is evalua
from neighboring frames to the target one based on the motion. Such way of motion compensation has convincingly demonstrated high capability of modeling temporal correlation in video super-resolution [57]</ref>, video object detection [21]</ref>, [24]</ref>, and video translation <ref type="bibr" target="#
task of video object detection, the ultimate goal is to localize and recognize objects from the reference frame. Taking the inspiration from the temporal coherence exploration in video understanding [48]</ref>, [49]</ref>, [50]</ref>, [51]</ref>, <ref type="bibr" target="#b5
" target="#b12">[13]</ref>, [25]</ref>, [26]</ref>, [27]</ref>, [28]</ref>, [29]</ref>, [30]</ref>, [31]</ref>, [32]</ref>. In particular, one common de
p; T loss) [15]</ref> ResNet-101 75.8 FGFA [24]</ref> ResNet-101 76.3 LWDN [64]</ref> ResNet-101 76.3 PSLA [65]</ref> ResNet-101 77.1 MANet [21]</ref> ResNet-101 78.1 THP [23]</ref> ResNet-101+DCN 78.6 STSN <ref ty
on subnet in Faster R-CNN, R-FCN [8]</ref> capitalizes on the fully convolutional network with position-sensitive ROI pooling. In addition, inspired by domain adaptation [34]</ref>, [35]</ref> for recognition, [36]</ref>, [37]</ref> focus on lear
" target="#b25">[26]</ref>, [27]</ref>, [28]</ref>, [29]</ref>, [30]</ref>, [31]</ref>, [32]</ref>. In particular, one common deep solution for object detection is based on a two-stage paradigm, i.e., first perform
OI pooling. In addition, inspired by domain adaptation [34]</ref>, [35]</ref> for recognition, [36]</ref>, [37]</ref> focus on learning robust and domaininvariant detectors based on two-stage approaches.</p><p>Another direction mainly constructs one-stage detectors by omittin
olutional network with position-sensitive ROI pooling. In addition, inspired by domain adaptation [34]</ref>, [35]</ref> for recognition, [36]</ref>, [37]</ref> focus on learning robust and domaininvariant detectors based on two-stage approaches.</p><p>Another direction mainl
is featurelevel aggregation [19]</ref>, [20]</ref>, [21]</ref>, [22]</ref>, [23]</ref>, [24]</ref>. The former often applies a tracker to per-frame bounding box proposals over multiple frames to generate dense tube 76.3 LWDN [64]</ref> ResNet-101 76.3 PSLA [65]</ref> ResNet-101 77.1 MANet [21]</ref> ResNet-101 78.1 THP [23]</ref> ResNet-101+DCN 78.6 STSN [19]</ref> ResNet-101+DCN 78.9 in each frame unexploited. One possible way to address it is to enable eature aggregation, which achieves comparable performance with FGFA under the same backbone of Deformable Convolution Network [61]</ref> (DCN). Note that as reported in [23]</ref>, the performance of FGFA with DCN is 78.8%. For fair comparisons, our SSVD is evaluated based on three commonly adopted basic architectures, ResNet-101, Defor ame in 85 ms, which is even faster than the single-frame baseline of two-stage video object detectors, e.g., R-FCN and Faster R-CNN. Note that here we exclude several video object detection methods ( [23]</ref>, [45]</ref>) which are additionally equipped with the acceleration techniques (e.g., flow guided feature propagation and adapti
aining, for T i from D train , the model first learns from T support i and then evaluates on T query i to see how well the model performs on that task. The goal of Model-Agnostic Meta-Learning (MAML) [9]</ref> is to obtain a parameter initialization θ * that can adapt to unseen tasks quickly, such as D test , using gradients information learnt during meta-training. Hy e same procedure above is applied using the final meta-updated parameter θ * . θ * is learned from knowledge across meta-training tasks and is the optimal parameter to adapt to unseen tasks quickly.  [9]</ref> switches ProtoNet to MAML as the meta-learner. All experiments use the same number of query points per label. We use multi-class accuracy metric.</p></div> <div
:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph Neural Networks (GNNs) have achieved remarkable results on many tasks such as recommender systems [45]</ref>, molecular predictions [15]</ref>, and knowledge graphs [52]</ref>. Performance in such tasks is
ally designed for a particular graph meta-learning problem and a particular task [50,</ref>2,</ref>19,</ref>5,</ref>43]</ref>. While these methods provide a promising approach to meta-learning in GNNs, their specific strategy does not scale well a TA operates on label scarce settings. (4) For link prediction, the first dataset FirstMM-DB [21]</ref> is the standard 3D point cloud data, which consists of 41 graphs. (5)</ref> The second link prediction dataset is the Tree-of-Life dataset. This is a new dataset, which we constructed based on 1,840 protein interaction networks (PPIs),

type="bibr" target="#b45">[44,</ref>48]</ref>. Further, structural similarity enables G-META to form the much-needed inductive bias by using a metric-learning algorithm [29]</ref>. Moreover, local subgraphs also allow for effective feature propagation and label smoothing within a GNN.</p><p>(1) G-META is general. While previous meta gra are labeled, it is challenging to efficiently propagate the labels through the entire graph [51,</ref>18]</ref>. Metric-learning methods [29]</ref> learn a task-specific metric to classify query set data using the closest point from the support set. It has been proved as an effective inductive bias <ref t thods [29]</ref> learn a task-specific metric to classify query set data using the closest point from the support set. It has been proved as an effective inductive bias [29,</ref>34]</ref>. Equipped with subgraph representations that capture both structure and feature information, G-META uses metric-learni
type="bibr" target="#b45">[44,</ref>48]</ref>. Further, structural similarity enables G-META to form the much-needed inductive bias by using a metric-learning algorithm [29]</ref>. Moreover, local subgraphs also allow for effective feature propagation and label smoothing within a GNN.</p><p>(1) G-META is general. While previous meta gra are labeled, it is challenging to efficiently propagate the labels through the entire graph [51,</ref>18]</ref>. Metric-learning methods [29]</ref> learn a task-specific metric to classify query set data using the closest point from the support set. It has been proved as an effective inductive bias <ref t thods [29]</ref> learn a task-specific metric to classify query set data using the closest point from the support set. It has been proved as an effective inductive bias [29,</ref>34]</ref>. Equipped with subgraph representations that capture both structure and feature information, G-META uses metric-learni
many problems require rapid learning from only a few labeled nodes or edges in the graph. Such flexible adaptation, known as meta-learning, has been extensively studied for images and language, e.g., [31,</ref>41,</ref>20]</ref>. However, meta-learning on graphs has received considerably less research atte
ify nodes in a particular graph accurately. In the second level, this learning is guided by knowledge accumulated gradually across tasks that captures how task structure changes across target domains [27,</ref>3,</ref>26]</ref>. A powerful GNN trained to meta-learn can quickly learn never-before-seen labels
ify nodes in a particular graph accurately. In the second level, this learning is guided by knowledge accumulated gradually across tasks that captures how task structure changes across target domains [27,</ref>3,</ref>26]</ref>. A powerful GNN trained to meta-learn can quickly learn never-before-seen labels
[14]</ref>. (2) Tissue-PPI is 24 protein-protein interaction networks from different tissues, where features are gene signatures and labels are gene ontology functions [54,</ref>12]</ref>. Each label is a binary protein function classification task. We select the top 10 balanced tasks. (3) Fold-PPI is a n function classification task. We select the top 10 balanced tasks. (3) Fold-PPI is a novel dataset, which we constructed for the multiple graph and disjoint label setting. It has 144 tissue networks [54]</ref>, and the labels are classified using protein structures defined in SCOP database [1]</ref>. We screen fold groups that have more than 9 uniqu

6">[7,</ref>11,</ref>17,</ref>25,</ref>34]</ref>, with adversarial training [21]</ref> being one of the most effective methods. It formulates training as a game between adversarial attacks and the model: the stronger the adversarial examples gen type="bibr" target="#b20">21]</ref> (PGDk) has been widely adopted to generate adversarial examples. Typically, using more attack iterations (higher value of k) produces stronger adversarial examples [21]</ref>. However, each attack iteration needs to compute the gradient on the input, which causes a large computational overhead. As shown in Table 1 teration to generate adversarial examples, ATTA-1 can still achieve comparable robustness with respect to traditional PGD-40.</p><p>We apply our technique on Madry's Adversarial Training method (MAT) [21]</ref> and TRADES [39]</ref> and evaluate the performance on both MNIST and CIFAR10 dataset. Compared with traditional PGD attack, our f>26,</ref>38,</ref>39]</ref> focuse on analyzing and improving adversarial machine learning. Madry et al. [21]</ref> first formulate adversarial training as a min-max optimization problem:</p><formula xml:id="formula_0">min f ∈H E (x,y)∼D [max δ∈S L(f (x + δ), y)] (<label>1< ion function to project adversarial examples back to the allowed perturbation space S.</p><p>With a higher value of k (more attack iterations), PGDk can generate adversarial examples with higher loss [21]</ref> els. This property is named as transferability. This property is usually leveraged to perform a black-box attack [19,</ref><ref n−m+1 first. Then, for the following epochs, the attack is performed based on the accumulated perturbations from previous epochs. To compare the attack strength of two attacks, we use Madry's method [21]</ref> to adversarially train two models on MNIST and CIFAR10 and evaluate the loss value L(f n (x * n ), y) of adversarial examples generated by two attacks. Figure ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation</head><p>In this section, we integrate ATTA with two popular adversarial training methods: Madry's Adversarial Training (MAT) [21]</ref> and TRADES [39]</ref>. By evaluating the training time and robustness, we show that ATTA can provide a better trade-off than ot A under various attacks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Training efficiency</head><p>We select four state-of-the-art adversarial training methods as baselines: MAT [21]</ref>, TRADES [39]</ref>, YOPO [37]</ref> and Free [27]</ref>. For MNIS "http://www.tei-c.org/ns/1.0"><head n="6">Related work</head><p>Adversarial training is first proposed in [16]</ref> and is formulated as a min-max optimization problem [21]</ref>. As one of the most effective defense methods, lots of works [2,</ref>4,</ref><ref type="bibr" tar ibr" target="#b15">[16]</ref>, which use multiple attack iterations to generate adversarial examples, are widely adopted in various adversarial training methods [4,</ref>21,</ref>32,</ref>39]</ref>. Since adversarial perturbations are usually bounded by a constrained space S a h adversarial examples achieves considerable robustness. Recently, lots of works [2,</ref>12,</ref>14,</ref>21,</ref>26,</ref>38,</ref>39]</ref> focuse on analyzing and improving adver t effective defense methods, lots of works [2,</ref>4,</ref>12,</ref>18,</ref>21,</ref>27,</ref>28,</ref>32,</ref>37]</ref> tions are usually bounded by a constrained space S and attack perturbations outside S need to be projected back to S, k-step projected gradient descent method [16,</ref>21]</ref> (PGDk) has been widely adopted to generate adversarial examples. Typically, using more attack iterations (higher value of k) produces stronger adversarial exam arial perturbations are usually bounded by the allowed perturbation space S, PGD-k (k-step projected gradient descent [16]</ref>) is adopted to conduct iterative attack [21,</ref>27,</ref>37,</ref>39]</ref>. PGD-k adversarial attack is the multi To understand the contribution of each component to robustness, we conduct an ablation study.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Setup</head><p>Following the literature [21,</ref>37,</ref>39]</ref>, we use both MNIST [17]</ref> and CIFAR10 datas pe="bibr" target="#b14">[15]</ref> to evaluate ATTA.</p><p>For the MNIST dataset, the model has four convolutional layers followed by three full-connected layers which is same architecture as used in [21,</ref>39]</ref>. The adversarial perturbation is bounded by l ∞ ball with size = 0.3.</p><p>For the CIFAR10 dataset, we use the wide r ,</ref>39]</ref>. The adversarial perturbation is bounded by l ∞ ball with size = 0.3.</p><p>For the CIFAR10 dataset, we use the wide residual network  which is same as [21,</ref>39]</ref>. The perturbation is bounded by l ∞ ball with size = 0.031.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n ween epochs. We hope this finding can inspire other researchers to enhance adversarial training from a new perspective (e.g., improving transferability between epochs). which is same with other works [21,</ref>27,</ref>37,</ref>39]</ref>. We set the epoch period to reset pert ad>B Experiment setup</head><p>We provide additional details on the implementation, model architecture, and hyper-parameters used in this work.</p><p>MNIST. We use the same model architecture used in [21,</ref>37,</ref>39]</ref>, which has four convolutional layers followed by three fully-connected layers. type="bibr" target="#b7">[8]</ref> and CW [3]</ref> attack with a 0.01 step size and set decay factor as 1 for M-PGD (momentum PGD).</p><p>CIFAR10. Following other works [21,</ref>27,</ref>37,</ref>39]</ref>, we use Wide-Resnet- 
vulnerable to adversarial examples [31]</ref>. Even a small perturbation on the image can fool a well-trained model. Recent works [9,</ref>29,</ref>30]</ref> also show that adversarial examples can be physically realized, which can lead to serious safety issues. Design of robu
multiple attack iterations to generate adversarial examples, are widely adopted in various adversarial training methods [4,</ref>21,</ref>32,</ref>39]</ref>. Since adversarial perturbations are usually bounded by a constrained space S and attack perturbations outside S need t 12,</ref>18,</ref>21,</ref>27,</ref>28,</ref>32,</ref>37]</ref> focus on enhancing either the efficiency or effectiveness of adversarial training. YOPO 
dy> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>State-of-the-art deep learning models for computer vision tasks have been found to be vulnerable to adversarial examples [31]</ref>. Even a small perturbation on the image can fool a well-trained model. Recent works [9,</ref>29,< 38">[39]</ref>, TRADES improves the robustness of an adversarially trained model by adding a robustness regularizer in the loss function.</p><p>Transferability of adversarial examples. Szegedy et al. [31]</ref> first describes the transferability of adversarial examples. This property is usually used to perform black-box attack between models <ref type="bibr" target=
how that adversarial examples can be physically realized, which can lead to serious safety issues. Design of robust models, which correctly classifies adversarial examples, is an active research area [7,</ref>11,</ref>17,</ref>25,</ref>34]</ref>,
:</p><p>x * ← A(f θ , x nat,aug , y, x aug , ) 13:</p><formula xml:id="formula_7">θ ← θ − ∇ f θ ∂L(f θ ,x * ,y) ∂θ 14:</formula><p>x ← inverse aug(x, x * , T aug )</p><p>15:</p><p>end for 16: end for 5</ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation</head><p>In this section, we integrate ATTA with two popular adversarial training methods: Ma xamples. Szegedy et al. [31]</ref> first describes the transferability of adversarial examples. This property is usually used to perform black-box attack between models [5,</ref>19,</ref>20,</ref>24,</ref>35]</ref>.
he transferability between each of S i and T .</p><p>To measure transferability from the source model to the targeted model, we use two metrics. The first metric is error rate transferability used in [1,</ref>23]</ref>, which is the ratio of the number of adversarial examples misclassified by source model to that of the targeted model. T
dy> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>State-of-the-art deep learning models for computer vision tasks have been found to be vulnerable to adversarial examples [31]</ref>. Even a small perturbation on the image can fool a well-trained model. Recent works [9,</ref>29,< 38">[39]</ref>, TRADES improves the robustness of an adversarially trained model by adding a robustness regularizer in the loss function.</p><p>Transferability of adversarial examples. Szegedy et al. [31]</ref> first describes the transferability of adversarial examples. This property is usually used to perform black-box attack between models <ref type="bibr" target=
augmentation method, a model trained with adversarial examples achieves considerable robustness. Recently, lots of works [2,</ref>12,</ref>14,</ref>21,</ref>26,</ref>38,</ref>39]</ref>
f type="bibr" target="#b20">[21,</ref>37,</ref>39]</ref>, we use both MNIST [17]</ref> and CIFAR10 dataset [15]</ref> to evaluate ATTA.</p><p>For the MNIST dataset, the model has four convolutional layers followed by three full-connected layers which is same architecture as u
dy> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>State-of-the-art deep learning models for computer vision tasks have been found to be vulnerable to adversarial examples [31]</ref>. Even a small perturbation on the image can fool a well-trained model. Recent works [9,</ref>29,< 38">[39]</ref>, TRADES improves the robustness of an adversarially trained model by adding a robustness regularizer in the loss function.</p><p>Transferability of adversarial examples. Szegedy et al. [31]</ref> first describes the transferability of adversarial examples. This property is usually used to perform black-box attack between models <ref type="bibr" target=
during the search process; maintaining these data structures efficiently in a parallel program can be challenging. A number of GPM frameworks have been proposed to reduce the burden on the programmer [12,</ref>29,</ref>38,</ref>39,</ref>54,</ref ose patterns. These systems promote productivity, but they may not allow expressing more efficient algorithms. Low-level systems such as RStream [56]</ref> and Pangolin [12]</ref> provide low-level API functions for the user to control the details of mining process, and they can be used to implement solutions for a wider variety of GPM uation on a 56-core CPU demonstrates that applications written using Sandslash high-level API outperform the state-of-the-art GPM systems, AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref> by 7.7×, 6.2× and 3.9× on average, respectively. Applications using Sandslash low-level API outperfor r of length 𝑙 for vertices at level 𝑙 of the tree. We call this bit-vector the connectivity code (see an example in Appendix B.6). This technique is called Memoization of Embedding Connectivity (MEC) [12]</ref>. • For edge-induced extension, a set of edges instead of vertices is stored for each embedding. There is no need to store connectivity for embeddings since th ot need to understand Sandslash's implementation.</p><p>Fine-Grained Pruning (FP) and Customized Pattern Classification (CP): FP and CP are low-level optimizations enabled in a prior system, Pangolin [12]</ref>, so we describe them in Appendices B.4 and B.5. To support FP, Sandslash exposes API calls toExtend() and toAdd() (Listing 1), which allow the user to use alg -level and low-level optimizations. We compare Sandslash with the state-of-the-art GPM systems 3</ref> : AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref>. We use the five applications (also used in previous systems) listed in Table <ref type="table" targe sparse embedding (CSE) data structure to reduce memory consumption. G-Miner [11]</ref> is a distributed GPM system which incorporates task-parallel processing. Pangolin [12]</ref> is a shared-memory GPM system targeting both CPU and GPU. Instead of the BFS exploration used in the above systems, Fractal [19 patterns. For multiple explicit pattern problems, the connectivity check can be used to identify different patterns. For small implicit patterns, Sandslash uses customized pattern classification (CP) [12]</ref>. For example, in FSM, the labeled wedge patterns can be differentiated by hashing the labels of the three vertices (the two endpoints of the wedge are symmetr

y. Peregrine is the state-of-the-art high-level GPM system. It includes efficient matching strategies from well-established techniques [8,</ref>23,</ref>32]</ref> and improves performance compared to previous systems. Nevertheless, Sandslash outperforms Peregrine using only its high-level API. Furthermore, Sandslash prov om identical subgraphs. This technique is also known as symmetry breaking. A widely used approach is to apply partial orders between vertices in the embedding [29,</ref>32]</ref>. For special patterns, e.g., cliques, symmetry breaking can be done by constructing a DAG, which avoids runtime checks but requires preprocessing. Sandslash su number of triangles, so it is more efficient to find the triangle first.</p><p>In general, using the right matching order reduces computation and memory consumption. Sandslash uses a greedy approach [32]</ref> to choose a good matching order: at each step, (1) we choose a sub-pattern which has more internal partial orders; (2) If there is a tie, we choose a denser s
target="#b14">15,</ref>17,</ref>20]</ref>. One example is motif counting [6,</ref>23,</ref>41]</ref>, which counts the number of occurrences of certain structural patterns, such as those shown in Fig. 1</ref>, in a given graph. These numbers
ese data structures efficiently in a parallel program can be challenging. A number of GPM frameworks have been proposed to reduce the burden on the programmer [12,</ref>29,</ref>38,</ref>39,</ref>54,</ref>56,</ref> ng compared to hand-optimized code, but they make different tradeoffs and have different limitations.</p><p>High-level systems such as AutoMine [39]</ref> and Peregrine [29]</ref> take specifications of patterns as input and leverage static analysis techniques to automatically generate GPM programs for those patterns. These systems prom itten using Sandslash high-level API outperform the state-of-the-art GPM systems, AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref> by 7.7×, 6.2× and 3.9× on average, respectively. Applications using Sandslash low-level API outperform AutoMine, Pangolin, and Peregrine by 22.6×, 27.5× and 7 with the state-of-the-art GPM systems 3</ref> : AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref>. We use the five applications (also used in previous systems) listed in Table 2</ref>. We also evaluate the state-of-the-art ich selects a canonical representation from identical subgraphs. This technique is also known as symmetry breaking. A widely used approach is to apply partial orders between vertices in the embedding [29,</ref>32]</ref>. For special patterns, e.g., cliques, symmetry breaking can be done by constructing a DAG, which avoids runtime checks
ype="bibr" target="#b47">48,</ref>57,</ref>60]</ref>, distributed CPUs [22,</ref>44,</ref>51]</ref>, and GPUs [26,</ref>27,</ref>43]</ref>. kClist <ref type="bibr" ta
ese data structures efficiently in a parallel program can be challenging. A number of GPM frameworks have been proposed to reduce the burden on the programmer [12,</ref>29,</ref>38,</ref>39,</ref>54,</ref>56,</ref> ng compared to hand-optimized code, but they make different tradeoffs and have different limitations.</p><p>High-level systems such as AutoMine [39]</ref> and Peregrine [29]</ref> take specifications of patterns as input and leverage static analysis techniques to automatically generate GPM programs for those patterns. These systems prom itten using Sandslash high-level API outperform the state-of-the-art GPM systems, AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref> by 7.7×, 6.2× and 3.9× on average, respectively. Applications using Sandslash low-level API outperform AutoMine, Pangolin, and Peregrine by 22.6×, 27.5× and 7 with the state-of-the-art GPM systems 3</ref> : AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref>. We use the five applications (also used in previous systems) listed in Table 2</ref>. We also evaluate the state-of-the-art ich selects a canonical representation from identical subgraphs. This technique is also known as symmetry breaking. A widely used approach is to apply partial orders between vertices in the embedding [29,</ref>32]</ref>. For special patterns, e.g., cliques, symmetry breaking can be done by constructing a DAG, which avoids runtime checks
ists the input graphs. The first 3 graphs (Pa, Yo, pdb) are vertex-labeled graphs which can be used for FSM. We also include widely used large graphs (Lj, Or, Tw4, Fr, Uk), and a very large web-crawl [10]</ref> (Gsh). These graphs do not have labels and are only used for TC, 𝑘-CL, SL, 𝑘-MC.</p><p>Our experiments were conducted on a 4 socket machine with Intel Xeon Gol
ese data structures efficiently in a parallel program can be challenging. A number of GPM frameworks have been proposed to reduce the burden on the programmer [12,</ref>29,</ref>38,</ref>39,</ref>54,</ref>56,</ref> ng compared to hand-optimized code, but they make different tradeoffs and have different limitations.</p><p>High-level systems such as AutoMine [39]</ref> and Peregrine [29]</ref> take specifications of patterns as input and leverage static analysis techniques to automatically generate GPM programs for those patterns. These systems prom itten using Sandslash high-level API outperform the state-of-the-art GPM systems, AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref> by 7.7×, 6.2× and 3.9× on average, respectively. Applications using Sandslash low-level API outperform AutoMine, Pangolin, and Peregrine by 22.6×, 27.5× and 7 with the state-of-the-art GPM systems 3</ref> : AutoMine [39]</ref>, Pangolin [12]</ref>, and Peregrine [29]</ref>. We use the five applications (also used in previous systems) listed in Table 2</ref>. We also evaluate the state-of-the-art ich selects a canonical representation from identical subgraphs. This technique is also known as symmetry breaking. A widely used approach is to apply partial orders between vertices in the embedding [29,</ref>32]</ref>. For special patterns, e.g., cliques, symmetry breaking can be done by constructing a DAG, which avoids runtime checks
rous hand-optimized GPM applications targeting various platforms. For TC, there are parallel solvers on multicore CPUs [18,</ref>48,</ref>57,</ref>60]</ref>, distributed CPUs [22,</ref>44,</ref>51]
domains [4,</ref>15,</ref>17,</ref>20]</ref>. One example is motif counting [6,</ref>23,</ref>41]</ref>, which counts the number of occurrences of certain structural patterns, such as those shown in
ing to ease the training difficulty. Following these pioneering works, many CNN-based methods have been proposed and achieved state-of-the-art results in SISR [15,</ref>18,</ref>40,</ref>38,</ref>3,</ref>17,</ref><r R output at the end of the network. Thanks to the efficient sub-pixel layer, many very deep networks have been proposed for a better performance. Lim et al. proposed a very deep and wide network EDSR [18]</ref> by stacking modified residual blocks in which the batch normalization (BN) layers are removed. Ledig et al. introduced the SRResNet in <ref type="bibr" target classification problem. Recently, residual learning is also introduced in image SR to further boost the performance. Fig. 3</ref>(Left) depicts a basic residual module used in EDSR [18]</ref> and ESRGAN [31]</ref>. The residual modules are often stacked together to form the trunk part of the SR network (Fig. <ref type s="http://www.tei-c.org/ns/1.0"><head n="4.2.">Combination with Residual Block</head><p>In this section, we investigate the combination of our RFA framework with the basic residual block used in EDSR [18]</ref>. Different from the original residual block used in image classification, EDSR removes the Batch Normalization layers and achieved substantial improvements. T SRCNN [5]</ref>, VDSR [13]</ref>, LapSRN [15]</ref>, MemNet [25]</ref>, EDSR [18]</ref>, SRMD [36]</ref>, NLRN [19]</ref>, DBPN [6]</ref>, RDN <ref type=" ating the activation values. We can see that the activation ranges of the bottom row are smaller than the top row, which can ease the training difficulty to some extent (e.g. residual scaling in EDSR [18]</ref>).</p><p>(2) Feature maps after the attention mechanism tend to contain more negative values, showing a stronger effect of suppressing the smooth area of the i .1.">Basic Network Architecture for Image SR</head><p>Many recent SR networks have similar network architectures. Here we introduce one of the basic architecture used by some state-of-the-art methods [18,</ref>40,</ref>38,</ref>3]</ref>. As shown in Fig. <ref type="figure" tar
and wide network EDSR [18]</ref> by stacking modified residual blocks in which the batch normalization (BN) layers are removed. Ledig et al. introduced the SRResNet in [16]</ref> and are further improved in [31]</ref> by introducing the dense connections. Zhang et al. also used dense connections in RDN <r
: SPMSR [22]</ref>, SRCNN [4]</ref>, FSRCNN [5]</ref>, VDSR [13]</ref>, IRCNN [35]</ref>, SRMD [36]</ref>, RDN [40]</ref>, SRFBN [17]</ref>, RCAN <ref typ
i-c.org/ns/1.0"><head n="2.2.">Attention-based Networks</head><p>Attention mechanism are widely used in recent computer vision tasks, such as image captioning [32,</ref>2]</ref>, image and video classification [8,</ref>30]</ref>. It can be interpreted as a way to bias the alloc
e this inverse problem, including early interpolationbased [37]</ref>, reconstruction-based [34]</ref>, and recent learning based methods [27,</ref>28,</ref>22,</ref>4,</ref>12,</ref><
[27,</ref>28,</ref>22,</ref>4,</ref>12,</ref>13,</ref>36,</ref>3]</ref>. * Corresponding author. Recent deep convolutional neural network based methods h ef type="bibr" target="#b3">[4]</ref>, who proposed the three-layer SRCNN for SISR and achieved superior performance against conventional methods. Kim et al. further increased the depth to 20 in VDSR [13]</ref> and DRCN [14]</ref> by introducing residual learning to ease the training difficulty. Following these pioneering works, many CN sed a shallow three-layer convolutional neural network (SRCNN) for image SR and achieved superior performance against previous works. Inspired by this pioneering work, Kim et al. designed deeper VDSR [13]</ref> and DRCN [14]</ref> with 20 layers based on residual learning. Later, Tai et al. introduced recursive blocks in DRRN <ref type= dely used to simulate LR images with BI degradation model in image SR settings. To verify the effective-  [4]</ref>, FSRCNN [5]</ref>, VDSR [13]</ref>, LapSRN [15]</ref>, MemNet [25]</ref>, EDSR [18]</ref>, SRMD <ref mpare our RFANet with 10 state-of-the-art methods: SPMSR [22]</ref>, SRCNN [4]</ref>, FSRCNN [5]</ref>, VDSR [13]</ref>, IRCNN [35]</ref>, SRMD [36]</ref>, RDN [40]</ref>, SRFBN <ref ty ">9</ref> shows the comparisons about model size and performance with 11 stae-of-the-art SR methods:SRCNN [4]</ref>, FSRCNN [5]</ref>, VDSR [13]</ref>, LapSRN [15]</ref>, MemNet [25]</ref>, NLRN [19]</ref>, SRMD <ref
acking modified residual blocks in which the batch normalization (BN) layers are removed. Ledig et al. introduced the SRResNet in [16]</ref> and are further improved in [31]</ref> by introducing the dense connections. Zhang et al. also used dense connections in RDN [40]</ref> to utilize all the hierarchica s also introduced in image SR to further boost the performance. Fig. 3</ref>(Left) depicts a basic residual module used in EDSR [18]</ref> and ESRGAN [31]</ref>. The residual modules are often stacked together to form the trunk part of the SR network (Fig. 2</ref>). Each residual mod
which is a highly ill-posed procedure since multiple HR solutions can map to one LR input. Many image SR methods have been proposed to tackle this inverse problem, including early interpolationbased [37]</ref>, reconstruction-based [34]</ref>, and recent learning based methods [27,</ref><ref type="bibr" t
e this inverse problem, including early interpolationbased [37]</ref>, reconstruction-based [34]</ref>, and recent learning based methods [27,</ref>28,</ref>22,</ref>4,</ref>12,</ref><
[27,</ref>28,</ref>22,</ref>4,</ref>12,</ref>13,</ref>36,</ref>3]</ref>. * Corresponding author. Recent deep convolutional neural network based methods h ef type="bibr" target="#b3">[4]</ref>, who proposed the three-layer SRCNN for SISR and achieved superior performance against conventional methods. Kim et al. further increased the depth to 20 in VDSR [13]</ref> and DRCN [14]</ref> by introducing residual learning to ease the training difficulty. Following these pioneering works, many CN sed a shallow three-layer convolutional neural network (SRCNN) for image SR and achieved superior performance against previous works. Inspired by this pioneering work, Kim et al. designed deeper VDSR [13]</ref> and DRCN [14]</ref> with 20 layers based on residual learning. Later, Tai et al. introduced recursive blocks in DRRN <ref type= dely used to simulate LR images with BI degradation model in image SR settings. To verify the effective-  [4]</ref>, FSRCNN [5]</ref>, VDSR [13]</ref>, LapSRN [15]</ref>, MemNet [25]</ref>, EDSR [18]</ref>, SRMD <ref mpare our RFANet with 10 state-of-the-art methods: SPMSR [22]</ref>, SRCNN [4]</ref>, FSRCNN [5]</ref>, VDSR [13]</ref>, IRCNN [35]</ref>, SRMD [36]</ref>, RDN [40]</ref>, SRFBN <ref ty ">9</ref> shows the comparisons about model size and performance with 11 stae-of-the-art SR methods:SRCNN [4]</ref>, FSRCNN [5]</ref>, VDSR [13]</ref>, LapSRN [15]</ref>, MemNet [25]</ref>, NLRN [19]</ref>, SRMD <ref
f>22,</ref>4,</ref>12,</ref>13,</ref>36,</ref>3]</ref>. * Corresponding author. Recent deep convolutional neural network based methods have made great progress in reconstructing the HR images. The first successful at spatial attention in [10]</ref> lacks of a large receptive field which is essential for image SR and the Non-Local mechanisms in [19,</ref>3]</ref> consume a lot of computational resource. To solve this issue, we propose a lightweight and efficient enhanced spatial attention (ESA) block. The ESA block enable introduce one of the basic architecture used by some state-of-the-art methods [18,</ref>40,</ref>38,</ref>3]</ref>. As shown in Fig. 2</ref>, a basic image SR network usually consists of three parts: the head part, the trunk part and the rec ut aside the amount of calculation, a potentially better way to implement the spatial attention block is to use the Non-Local block. Actually, there are works [19,</ref>3]</ref> that have attempted to use the Non-Local block to model pixel-wise similarities in image SR. Though it brings performance boost, the huge computation overhead is iments</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Settings</head><p>Following previous works [40,</ref>38,</ref>3]</ref>, we use 800 highresolution training images from DIV2K [26]</ref> dataset as training set. During training, data augmentation is pe div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Results with Blur-downscale Degradation (BD)</head><p>Following [36,</ref>38,</ref>3]</ref>, we also provide the results with blur-downscale degradation (BD) model. We compare our RFANet with 10 state-of-the-art methods: SPMSR <ref type="bibr" target="# ieved state-of-the-art results in SISR [15,</ref>18,</ref>40,</ref>38,</ref>3,</ref>17,</ref>7,</ref>9,</ref>39]</ref>.</p>< ry deep network RFANet by combining the RFA framework with the ESA block. The RFANet achieves comparable or superior results compared with RCAN [38]</ref> (16M) and SAN [3]</ref> (15.7M) by using much fewer parameters (11M). In summary, the main contributions of this paper are as follows:</p><p>• We propose a general residual feature agg a modified residual block for image SR. The channel attention mechanism uses global average pooling to extract channel statistics which are called first-order statistics. On the contrary, Dai et al. [3]</ref> proposed the second-order attention network (SAN) to explore more powerful feature expression by using second-order feature statistics. RCAN and SAN are the two f>, NLRN [19]</ref>, DBPN [6]</ref>, RDN [40]</ref>, RCAN [38]</ref> and SAN [3]</ref>.  our RFANet behaves particularly well on Urban100 and Manga109 datasets. This is mainly because both datasets contain rich structured contents and our RFANet c SRMD [36]</ref>, RDN [40]</ref>, SRFBN [17]</ref>, RCAN [38]</ref>, and SAN [3]</ref>. As shown in Table 3</ref>, our RFANet outperforms other methods on all the datasets. Specifically, we achieve 0.06dB PSNR gai f>, SRMD [36]</ref>, DBPN [6]</ref>, RDN [40]</ref>, RCAN [38]</ref> and SAN [3]</ref>. Our RFANet has much fewer parameters than RDN, RCAN and SAN, but obtains better performance, which verifies the effectiveness of our method. Compared with DBPN
es with two models and rectifies the error propagation in theory.</p><p>Since it is hard to obtain a large-scale ST dataset, multitask learning (Weiss et al. 2017;</ref>Bérard et al. 2018</ref>) and pretraining techniques (Bansal et al. 2019)</ref> have been applied to end-to-end ST model to leverage large-s g, while it has to extract semantic and linguistic features additionally in fine-tuning, which significantly increases the learning difficulty.</p><p>• Non-pre-trained Attention Module: Previous work (Bérard et al. 2018)</ref> trains attention modules for ASR, MT and ST respectively, hence, the attention module of ST does not benefit from the pre-training.</p><p>To ad

>Introduction</head><p>Speech-to-Text translation (ST) is essential for a wide range of scenarios: for example in emergency calls, where agents have to respond emergent requests in a foreign language (Munro 2010)</ref>; or in online courses, where audiences and speakers use different languages (Jan et al. 2018)</ref>. To tackle this pro
>Introduction</head><p>Speech-to-Text translation (ST) is essential for a wide range of scenarios: for example in emergency calls, where agents have to respond emergent requests in a foreign language (Munro 2010)</ref>; or in online courses, where audiences and speakers use different languages (Jan et al. 2018)</ref>. To tackle this pro
g/ns/1.0"><head n="4.4">Discussion</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Early works conduct ST in a pipeline manner (Ney 1999; Matusov, Kanthak, and Ney 2005)</ref>, where the ASR output are fed into an MT system to generate target sentences. HMM (Juang and Rabiner 1991)</ref> </p></div
nt languages (Jan et al. 2018)</ref>. To tackle this problem, existing approaches can be categorized into cascaded method (Ney 1999;</ref>Ma et al. 2019)</ref>, where a machine translation (MT) model translates outputs of an automatic speech recognition (ASR) system into target language, and end-to-end met
vided in ST-TED test sets, we segment each audio with the LIUM SpkDiarization tool (Meignier and Merlin 2010)</ref> and then perform MWER segmentation with RWTH toolkit (Bender et al. 2004</ref>). Case-insensitive BLEU is used as evaluation metric.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental setups</head
works conduct ST in a pipeline manner (Ney 1999; Matusov, Kanthak, and Ney 2005)</ref>, where the ASR output are fed into an MT system to generate target sentences. HMM (Juang and Rabiner 1991)</ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper has investigated the end-to-end method for




r" target="#b14">[15]</ref>.</p><p>Motivated by recent advances in self-supervised learning of visual representations [16]</ref>[17]</ref>[18]</ref>[19]</ref>[20]</ref>1]</ref>, this paper first presents a thorough investigation ://www.tei-c.org/ns/1.0"><head>C The Correlation Between Linear Evaluation and Fine-tuning</head><p>Most existing work [17,</ref>19,</ref>18,</ref>40,</ref>20,</ref>1]</ref> on self-supervised learning leverages linear evaluatio
the teacher. Methods using unlabeled data in a task-specific way: Pseudo-label [11,</ref>30]</ref> ResNet-50 --51.6 82.4 VAT+Entropy Min. [37,</ref>38,</ref>30]</ref> ResNet-50 --47.0 83.4 UDA (w. RandAug) [14]</re
with depths of 50, 101, 152, width multiplier of 1×, 2× (w/o SK) are presented here. For supervised models on 1%/10% labels, AutoAugment [34]</ref> and label smoothing [35]</ref> are used. Increasing the size of SimCLRv2 models by 10×, from ResNet-50 to ResNet-152 (2×), improves label efficiency by 10×.   Figure 4</r
t="#b46">47]</ref>. There are other approaches to self-supervised learning that are based on handcrafted pretext tasks [48,</ref>31,</ref>49,</ref>50,</ref>27]</ref>. We also note a concurrent work on advancing self-supervised pretraining withou
on unlabeled data among different models [11,</ref>12,</ref>2]</ref> or under different data augmentations [13]</ref>[14]</ref>[15]</ref>.</p><p>Motivated by recent advances in self-supervised learning of visual re
ing effect": as the performance gets closer to the ceiling, the improvement becomes smaller. , Supervised learning with auto-augmentation [34]</ref> and label smoothing [67]</ref> are applied for 1%/10% label fractions, (c) semi-supervised learning by fine-tuning SimCLRv2.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B Param
rn representations in a discriminative fashion instead of a generative one as in [3,</ref>45,</ref>46,</ref>39,</ref>47]</ref>. There are other approaches to self-supervised learning that are based on handcrafted pretext tasks <ref type="bibr" ta
r" target="#b13">[14]</ref>[15]</ref>.</p><p>Motivated by recent advances in self-supervised learning of visual representations [16]</ref>[17]</ref>[18]</ref>[19]</ref>[20]</ref>1]</ref>, this pape us work, we also report performance when training a linear classifier on top of a fixed representation with all labels [31,</ref>16,</ref>17,</ref>1]</ref> to directly evaluate SimCLRv2 representations. We use the LARS optimizer [32]</ref> (with a momentum of arameter efficiency if group convolution is utilized. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>C The Correlation Between Linear Evaluation and Fine-tuning</head><p>Most existing work [17,</ref>19,</ref>18,</ref>40,</ref>20,</ref
g problem in machine learning. One approach to semi-supervised learning involves unsupervised or self-supervised pretraining, followed by supervised fine-tuning [3,</ref>4]</ref>. This Correspondence to: iamtingchen@google.com 1 Code and pretrained checkpoints are available at https://github.com/google-research/simclr.</p></div> <div xmln
representation learning paradigm, there is a large and diverse set of approaches for semi-supervised learning, we refer readers to [52]</ref>[53]</ref>[54]</ref> for surveys of classical approaches. Here we only review methods closely related to ours (especially within computer vision). One family of highly relevant me
completion inductive, Inductive Matrix Completion (IMC) has been proposed, which leverages content (side information) of users and items (Jain &amp; Dhillon, 2013;</ref>Xu et al., 2013)</ref>. In IMC, a rating is decomposed by r ij = x i Qy j , where x i and y j are content feature vectors of user i and item j, respectively, and Q is a

https://github.com/muhanzhang/IGMC.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">FLIXSTER, DOUBAN AND YAHOOMUSIC</head><p>For these three datasets, we compare our IGMC with GRALS (Rao et al., 2015)</ref>, sRGCNN (Monti et al., 2017)</ref>, GC-MC (Berg et al., 2017)</ref>, F-EAE <ref typ

">Bruna et al., 2013;</ref>Duvenaud et al., 2015;</ref>Li et al., 2015;</ref>Kipf &amp; Welling, 2016;</ref>Niepert et al., 2016;</ref>Dai et al., 2016)</ref>. There are two types of GNNs: Nodelevel GNNs use message passing layers to iteratively p


la><p>Next, we pool the node representations into a graph-level feature vector. There are many choices such as summing, averaging, SortPooling (Zhang et al., 2018)</ref>, DiffPooling (Ying et al., 2018b)</ref>, etc. In this work, however, we use a different pooling layer which concatenates the final representations of only the target user and item as
r node-based approaches, since there is no subgraph boundary, stacking multiple graph convolutions will only extend the convolution range to unrelated distant nodes and oversmooth the node embeddings (Li et al., 2018)</ref>. This is reflected in that previous node-based approaches mainly use only one or two message passing layers (Berg e
5">(Jamali &amp; Ester, 2010)</ref>, Douban (Ma et al., 2011)</ref>, YahooMusic (Dror et al., 2011)</ref>, MovieLens-100K and MovieLens-1M (Miller et al., 2003)</ref>. For ML-100K, we train and evaluate on the canonical u1.base/u1.test train/test split. For ML-1M, we randomly split it into 90% and 10% train
line of research from predicting link existence in simple graphs to predicting values of links in bipartite graphs (i.e., matrix completion). In (Chen et al., 2005;</ref>Zhou et al., 2007)</ref>, traditional link prediction heuristics are adapted to bipartite graphs which show promising performance for recommender systems. Our work diffe
</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Transformer models were originally introduced by Vaswani et al. (2017)</ref> in the context of neural machine translation (Sutskever et al., 2014;</ref>Bahda model that can perform sequence generation in linear time, similar to a recurrent neural network.</p><p>Initially, in § 3.1, we introduce a formulation for the transformer architecture introduced in (Vaswani et al., 2017)</ref>. Subsequently, in § 3.2 and § 3.3 we present our proposed linear transformer and finally, in § 3.4 we rewrite the transformer as a recurrent , we do not use the reversible layers, however, this does not affect the results as we only measure the memory consumption with respect to the self attention layer. In all experiments, we use softmax (Vaswani et al., 2017)</ref> to refer to the standard transformer architecture, linear for our proposed linear transformers and lsh-X for Reformer <ref type="bibr" targe

pendencies beyond a fixed length context without disrupting the temporal coherence. However, maintaining previous contexts in memory introduces significant additional computational cost. In contrast, Sukhbaatar et al. (2019)</ref> extended the context length significantly by learning the optimal attention span per attention head, while maintaining control over the me
</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Understanding Self-Attention</head><p>There have been few efforts to better understand selfattention from a theoretical perspective. Tsai et al. (2019)</ref> proposed a kernel-based formulation of attention in transformers which considers attention as applying a kernel smoother over the inputs with th nearized Attention</head><p>The definition of attention in equation 2 is generic and can be used to define several other attention implementations such as polynomial attention or RBF kernel attention (Tsai et al., 2019)</ref>. Note that the only constraint we need to impose to sim (•), in order for equation 3 to define an attention function, is to be non-negative. Th max attention infeasible. On the other hand, the polynomial kernel, for example, has an exact finite dimensional feature map and has been shown to work equally well with the exponential or RBF kernel (Tsai et al., 2019)</ref>. The computational cost for a linearized polynomial transformer of degree 2 is O N D 2 M . This makes the computational complexity favorable wh
and time complexity O N 2 . As a result, in practice transformers are slow to train and their context is limited. This disrupts temporal coherence and hinders the capturing of long-term dependencies. Dai et al. (2019)</ref> addressed the latter by attending to memories from previous contexts albeit at the expense of computational efficiency.</p><p>Lately, researchers § 4.1).</p><p>Another line of research aims at increasing the "context" of self-attention in transformers. Context refers to the maximum part of the sequence that is used for computing selfattention. Dai et al. (2019)</ref> introduced Transformer-XL which achieves state-of-the-art in language modeling by learning dependencies beyond a fixed length context without disr
lation. Clark et al. (2020)</ref> proposed a new pretraining objective called replaced token detection that is more sample efficient and reduces the overall computation. Lample et al. (2019)</ref> used product-key attention to increase the capacity of any layer with negligible computational overhead.</p><p>Reducing the memory or computat
target="#b0">Bahdanau et al., 2015)</ref> and have demonstrated impressive results on a variety of tasks dealing with natural language (Devlin et al., 2019)</ref>, audio (Sperber et al., 2018)</ref>, and images (Parmar et al., 2019)</ref>. Apart from tasks with ample supervision, transformers are also effec
ve results on a variety of tasks dealing with natural language (Devlin et al., 2019)</ref>, audio (Sperber et al., 2018)</ref>, and images (Parmar et al., 2019)</ref>. Apart from tasks with ample supervision, transformers are also effective in transferring knowledge to tasks with limited or no supervision w
., 2019)</ref>, weight factorization (Lan et al., 2020)</ref>, weight quantization (Zafrir et al., 2019)</ref> or knowledge distillation. Clark et al. (2020)</ref> proposed a new pretraining objective called replaced token detection that is more sample efficient and reduces the overall computation. <ref typ
pendencies beyond a fixed length context without disrupting the temporal coherence. However, maintaining previous contexts in memory introduces significant additional computational cost. In contrast, Sukhbaatar et al. (2019)</ref> extended the context length significantly by learning the optimal attention span per attention head, while maintaining control over the me
br" target="#b34">(Sutskever et al., 2014;</ref>Bahdanau et al., 2015)</ref> and have demonstrated impressive results on a variety of tasks dealing with natural language (Devlin et al., 2019)</ref>, audio (Sperber et al., 2018)</ref>, and images (Parmar et al., 2019)</ref>. Apa h limited or no supervision when they are pretrained with autoregressive (Radford et al., 2018;</ref>2019)</ref> or masked language modeling objectives (Devlin et al., 2019;</ref>Yang et al., 2019;</ref>Song et al., 2019;</ref>Li
-designed neural architectures [1]</ref>, [2]</ref>, [3]</ref> to automatically designed neural architectures [4]</ref>, [5]</ref>, [6]</ref>, [7]</ref>, [8]</r former [10]</ref>. However, manually designing one architecture requires human experts to frequently try and evaluate numerous different operation and connection options [4]</ref>. In contrast to architectures that are manually designed, those automatically found by neural architecture search (NAS) algorithms require much less human inter l architecture search (NAS) algorithms require much less human interaction and expert effort. These NAS-generated architectures have shown promising results in many domains, such as image recognition [4]</ref>, [5]</ref>, [6]</ref> and sequence modeling [5]</ref>, <ref type="bibr i.e., convolution, cell, or block). We predefine 8 candidates for the number of channels, which generates a total search space of itive training procedure of each selected architecture can be avoided [4]</ref>, [16]</ref> so that researchers can target on the essence of NAS, i.e., search algorithm. Another benefit is that the validation
><p>In the past few years, different kinds of search spaces and search algorithms have been proposed. They brought great advancements in many applications of neural network, such as visual perception [22]</ref>, [23]</ref>, [24]</ref>, language modelling [5]</ref>, <ref type="
"bibr" target="#b0">[1]</ref>, [2]</ref>, [3]</ref> to automatically designed neural architectures [4]</ref>, [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>. In its early stages, the great succe quire much less human interaction and expert effort. These NAS-generated architectures have shown promising results in many domains, such as image recognition [4]</ref>, [5]</ref>, [6]</ref> and sequence modeling [5]</ref>, [7]</ref>, <ref type="bibr sing results in many domains, such as image recognition [4]</ref>, [5]</ref>, [6]</ref> and sequence modeling [5]</ref>, [7]</ref>, [8]</ref>.</p><p>Recently, a variety of NAS algorithms have been increasingly proposed. of macro skeletons of the whole architecture [11]</ref>, [12]</ref> and a different operation set for the micro cell within the skeleton [5]</ref>, etc. (2) After a good architecture is selected, various strategies can be employed to train this architecture and report the performance, e.g., different data [16]</ref>, [17]</ref>. (3)</ref> The validation set for testing the performance of the selected architecture is not split in the same way [5]</ref>, [8]</ref>. These discrepancies cause a problem when comparing the performance of various NAS algorithms, making it difficult to c ations of neural network, such as visual perception [22]</ref>, [23]</ref>, [24]</ref>, language modelling [5]</ref>, [7]</ref>, [8]</ref>, etc. Despite their success, many researchers have raised concerns about the r e search space, they constrain the maximum number of edges in the DAG. However, it is difficult to incorporate this constraint in all NAS algorithms, such as NAS algorithms based on parameter sharing [5]</ref>, [8]</ref>. Therefore, many NAS algorithms cannot be directly evaluated on NAS-Bench-101. Our NATS-Bench solves this problem by sa ei-c.org/ns/1.0"><head n="3.1">Architectures in the Search Space</head><p>Macro Skeleton. Our search space follows the design of its counterpart as used in the recent neural cell-based NAS algorithms [5]</ref>, [8]</ref>, [11]</ref>. As shown in the middle part of Figure 1< PS) [27]</ref>. (II) ES methods, e.g., REA [6]</ref>. (III) RL algorithms, e.g., REINFORCE [48]</ref>, ENAS [5]</ref>. (IV) Differentiable algorithms. e.g., first order DARTS (DARTS-V1) [8]</ref>, second order DARTS (DARTS-V2), GDAS <ref type="bibr nformation are provided. We hope that more insights about NAS could be found by analyzing these diagnostic information and further motivate potential solutions for NAS. For example, parameter sharing [5]</ref> is the crucial technique to improve searching efficiency, but shared parameter would sacrifice the accuracy of each architecture. Could we find a better way to more participation in NAS. ( 4</ref>) It provides results of each architecture on multiple datasets. The model transferability can be thoroughly evaluated for most NAS algorithms. (5)</ref> In NATS-Bench, we provide systematic analysis of the proposed search space. We also evaluate 10 recent advanced NAS algorithms including reinforcement learning
cally designed neural architectures [4]</ref>, [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>. In its early stages, the great success of deep learning was promoted by the introductions of novel neural architectures, such as ResNet <ref type="bibr" target b3">[4]</ref>, [5]</ref>, [6]</ref> and sequence modeling [5]</ref>, [7]</ref>, [8]</ref>.</p><p>Recently, a variety of NAS algorithms have been increasingly proposed. While these NAS techniques are methodically designed and show promising improvemen ">[17]</ref>. (3)</ref> The validation set for testing the performance of the selected architecture is not split in the same way [5]</ref>, [8]</ref>. These discrepancies cause a problem when comparing the performance of various NAS algorithms, making it difficult to conclude their relative contributions.</p> >[22]</ref>, [23]</ref>, [24]</ref>, language modelling [5]</ref>, [7]</ref>, [8]</ref>, etc. Despite their success, many researchers have raised concerns about the reproducibility and generalization ability of the NAS algorithms <ref type="bibr" t l cells, represented as a DAG. Differently, NAS-Bench-101 defines operation candidates on the node, whereas we associate operations on the edge as inspired by [7]</ref>, [8]</ref>, [11]</ref>. We summarize characteristics of our NATS-Bench and NAS-Bench-101 in Table 1</ref>. The main highli m number of edges in the DAG. However, it is difficult to incorporate this constraint in all NAS algorithms, such as NAS algorithms based on parameter sharing [5]</ref>, [8]</ref>. Therefore, many NAS algorithms cannot be directly evaluated on NAS-Bench-101. Our NATS-Bench solves this problem by sacrificing the number of nodes and includi res in the Search Space</head><p>Macro Skeleton. Our search space follows the design of its counterpart as used in the recent neural cell-based NAS algorithms [5]</ref>, [8]</ref>, [11]</ref>. As shown in the middle part of Figure 1</ref>, the skeleton is initiated with one feature vector into the final prediction.</p><p>The Topology Search Space S t . The topology search space is inspired by the popular cell-based NAS algorithms [7]</ref>, [8]</ref>, [11]</ref>. Since all cells in an architecture have the same topology, an architecture candidate in S t corresponds to a differe he most popular image classification datasets.</p><p>We split each dataset into training, validation and test sets to provide a consistent training and evaluation settings for previous NAS algorithms [8]</ref>. Most NAS methods use the validation set to evaluate architectures after the architecture is optimized on the training set. The validation performance of the ar kept the same. We demonstrate, using 13 state-of-the-art NAS algorithms applied on NATS-Bench, how the process has been unified through an easy-to-use API. The implementation difference between DARTS [8]</ref> and GDAS [7]</ref> is only less than 20 lines of code. Our library reduces the effect caused by the implementation difference when /ref>. (III) RL algorithms, e.g., REINFORCE [48]</ref>, ENAS [5]</ref>. (IV) Differentiable algorithms. e.g., first order DARTS (DARTS-V1) [8]</ref>, second order DARTS (DARTS-V2), GDAS [7]</ref>, SETN [17]</ref>, TAS <ref type="bibr" target="#b20" and select the candidate with the highest validation accuracy. Such strategy is more robust than using the arg max over the learned architecture parameters in [7]</ref>, [8]</ref>. (3)</ref> The searched architecture of GDAS slowly converges to the similar one as ENAS and SETN. Some observations on S t are di
ironments for NAS. Zela et al. [20]</ref> proposed a general framework for oneshot NAS methods and reused NAS-Bench-101 to benchmark different NAS algorithms. Yu et al. [29]</ref> designed a novel evaluation framework to evaluate the search phase of NAS algorithms by comparing with a random search. The aforementioned works have mainly f
ironments for NAS. Zela et al. [20]</ref> proposed a general framework for oneshot NAS methods and reused NAS-Bench-101 to benchmark different NAS algorithms. Yu et al. [29]</ref> designed a novel evaluation framework to evaluate the search phase of NAS algorithms by comparing with a random search. The aforementioned works have mainly f
ns will be discussed in Section 6.</p><p>In the NAS community, there has been a growing attention to the field of joint searching for both topology and size [43]</ref>, [44]</ref>. By benchmarking their sub-modules for either topology or size on NATS-Bench, it may help researchers to understand the effectiveness of the submodules and gi t="#b7">[8]</ref>, second order DARTS (DARTS-V2), GDAS [7]</ref>, SETN [17]</ref>, TAS [21]</ref>, FBNet-V2 [44]</ref>, TuNAS [49]</ref>. (V) HPO methods, e.g., BOHB [36]</ref>.</p><p>Among them, RANDOM, REA, REINFO ture parameters [21]</ref>. (2) FBNetV2 utilises a masking mechanism to represent different candidate #channels and aggregate the masks with the architecture parameters [44]</ref>. (3) TuNAS samples masks based on the learnable distribution [49]</ref>. TAS and FBNetV2 optimize the architecture parameters i hing. For example, how to design a FLOPs constrain loss to regularize the discovered architecture to be efficient [21]</ref>, [43]</ref>, [44]</ref>?</p><p>Since the latency and FLOPs information are off-the-shelf in NATS-Bench, our NATS-Bench can also be used to benchmark NAS algorithms using different ki
f our NATS-Bench are as follows. (1) NATS-Bench is algorithm-agnostic while NAS-Bench-101 without any modification is only applicable to selected algorithms [20]</ref>, [28]</ref>. The original complete search space, based on the nodes in NAS-Bench-101, is huge. So, it is exceedingly difficult to efficiently traverse the training of all
iscrepancies cause a problem when comparing the performance of various NAS algorithms, making it difficult to conclude their relative contributions.</p><p>In response to this challenge, NAS-Bench-101 [18]</ref> and NAS-HPO-Bench [19]</ref> were proposed. However, some NAS algorithms cannot be applied directly on NAS-Bench-101, and NAS-H ="#b6">[7]</ref>, [8]</ref>, etc. Despite their success, many researchers have raised concerns about the reproducibility and generalization ability of the NAS algorithms [18]</ref>, [20]</ref>, [25]</ref>, [26]</ref>, <ref type="bibr" target="#b2 problem, and we will introduce them in Section 2.1 and Section 2.2.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">NAS Benchmark</head><p>To the best of our knowledge, NAS-Bench-101 [18]</ref> is the only existing large-scale architecture dataset. Similar to NATS-Bench, NAS-Bench-101 also transforms the problem of architecture search into the proble the cell to be densely connected, since we include zeroize in the operation set, which is an operation of dropping the associated edge. We do not impose the constraint on the maximum number of edges [18]</ref>, and thus S t is applicable to most NAS algorithms, including all cell-based NAS algorithms. For each architecture in S t , each cell is stacked N = 5 times, ataset. One possible strategy is to do all benchmark experiments on a much larger search space. Unfortunately, it is prohibitive regarding the expensive computational cost. We bring some results from [18]</ref> and [20]</ref> to provide some preliminary evidence of generalization. In Figure 6</ref>, w
h random crop 16×16 patch and 2 pixels padding on each border. In H 0 , we train each architecture by 12 epochs, which can be used in banditbased algorithms [36]</ref>, [37]</ref>. Since 12 epochs are not sufficient to evaluate the relative ranking of different architectures, we train each candidate with more epochs (H 1 and H 2 ) to ob
ns will be discussed in Section 6.</p><p>In the NAS community, there has been a growing attention to the field of joint searching for both topology and size [43]</ref>, [44]</ref>. By benchmarking their sub-modules for either topology or size on NATS-Bench, it may help researchers to understand the effectiveness of the submodules and gi t="#b7">[8]</ref>, second order DARTS (DARTS-V2), GDAS [7]</ref>, SETN [17]</ref>, TAS [21]</ref>, FBNet-V2 [44]</ref>, TuNAS [49]</ref>. (V) HPO methods, e.g., BOHB [36]</ref>.</p><p>Among them, RANDOM, REA, REINFO ture parameters [21]</ref>. (2) FBNetV2 utilises a masking mechanism to represent different candidate #channels and aggregate the masks with the architecture parameters [44]</ref>. (3) TuNAS samples masks based on the learnable distribution [49]</ref>. TAS and FBNetV2 optimize the architecture parameters i hing. For example, how to design a FLOPs constrain loss to regularize the discovered architecture to be efficient [21]</ref>, [43]</ref>, [44]</ref>?</p><p>Since the latency and FLOPs information are off-the-shelf in NATS-Bench, our NATS-Bench can also be used to benchmark NAS algorithms using different ki
</p><p>The Size Search Space S s . The size search space is inspired by transformable architecture search methods [21]</ref>, [31]</ref>, [32]</ref>. In the size search space, every stack in each architecture is constructed by stacking N = 1 cell. All cells in every architecture have the same topology, whi
cally designed neural architectures [4]</ref>, [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>. In its early stages, the great success of deep learning was promoted by the introductions of novel neural architectures, such as ResNet <ref type="bibr" target b3">[4]</ref>, [5]</ref>, [6]</ref> and sequence modeling [5]</ref>, [7]</ref>, [8]</ref>.</p><p>Recently, a variety of NAS algorithms have been increasingly proposed. While these NAS techniques are methodically designed and show promising improvemen ">[17]</ref>. (3)</ref> The validation set for testing the performance of the selected architecture is not split in the same way [5]</ref>, [8]</ref>. These discrepancies cause a problem when comparing the performance of various NAS algorithms, making it difficult to conclude their relative contributions.</p> >[22]</ref>, [23]</ref>, [24]</ref>, language modelling [5]</ref>, [7]</ref>, [8]</ref>, etc. Despite their success, many researchers have raised concerns about the reproducibility and generalization ability of the NAS algorithms <ref type="bibr" t l cells, represented as a DAG. Differently, NAS-Bench-101 defines operation candidates on the node, whereas we associate operations on the edge as inspired by [7]</ref>, [8]</ref>, [11]</ref>. We summarize characteristics of our NATS-Bench and NAS-Bench-101 in Table 1</ref>. The main highli m number of edges in the DAG. However, it is difficult to incorporate this constraint in all NAS algorithms, such as NAS algorithms based on parameter sharing [5]</ref>, [8]</ref>. Therefore, many NAS algorithms cannot be directly evaluated on NAS-Bench-101. Our NATS-Bench solves this problem by sacrificing the number of nodes and includi res in the Search Space</head><p>Macro Skeleton. Our search space follows the design of its counterpart as used in the recent neural cell-based NAS algorithms [5]</ref>, [8]</ref>, [11]</ref>. As shown in the middle part of Figure 1</ref>, the skeleton is initiated with one feature vector into the final prediction.</p><p>The Topology Search Space S t . The topology search space is inspired by the popular cell-based NAS algorithms [7]</ref>, [8]</ref>, [11]</ref>. Since all cells in an architecture have the same topology, an architecture candidate in S t corresponds to a differe he most popular image classification datasets.</p><p>We split each dataset into training, validation and test sets to provide a consistent training and evaluation settings for previous NAS algorithms [8]</ref>. Most NAS methods use the validation set to evaluate architectures after the architecture is optimized on the training set. The validation performance of the ar kept the same. We demonstrate, using 13 state-of-the-art NAS algorithms applied on NATS-Bench, how the process has been unified through an easy-to-use API. The implementation difference between DARTS [8]</ref> and GDAS [7]</ref> is only less than 20 lines of code. Our library reduces the effect caused by the implementation difference when /ref>. (III) RL algorithms, e.g., REINFORCE [48]</ref>, ENAS [5]</ref>. (IV) Differentiable algorithms. e.g., first order DARTS (DARTS-V1) [8]</ref>, second order DARTS (DARTS-V2), GDAS [7]</ref>, SETN [17]</ref>, TAS <ref type="bibr" target="#b20" and select the candidate with the highest validation accuracy. Such strategy is more robust than using the arg max over the learned architecture parameters in [7]</ref>, [8]</ref>. (3)</ref> The searched architecture of GDAS slowly converges to the similar one as ENAS and SETN. Some observations on S t are di
</p><p>The Size Search Space S s . The size search space is inspired by transformable architecture search methods [21]</ref>, [31]</ref>, [32]</ref>. In the size search space, every stack in each architecture is constructed by stacking N = 1 cell. All cells in every architecture have the same topology, whi
architecture on CIFAR-10, CIFAR-100 [33]</ref>, and ImageNet-16-120 [34]</ref>. We choose these three datasets because CIFAR and ImageNet [35]</ref> are the most popular image classification datasets.</p><p>We split each dataset into training, validation and test sets to provide a consistent training and e
thms, such as platformaware NAS [12]</ref>, accuracy prediction [38]</ref>, mutation-based NAS [39]</ref>, [40]</ref>, etc.</p><p>Architecture Computational Costs: NATS-Bench provides three computation metrics for each architecturethe number of parameters, FLOPs, and latency.
ur NATS-Bench, which can serve as baselines for future NAS algorithms in our dataset. Specifically, we evaluate some typical NAS algorithms: (I) Random Search algorithms, e.g., random search (RANDOM) [47]</ref>, random search with parameter sharing (RSPS) [27]</ref>. (II) ES methods, e.g., REA [6]</ref>. (I
</p><p>The Size Search Space S s . The size search space is inspired by transformable architecture search methods [21]</ref>, [31]</ref>, [32]</ref>. In the size search space, every stack in each architecture is constructed by stacking N = 1 cell. All cells in every architecture have the same topology, whi
ation [11]</ref>, different scheduler [15]</ref>, and different selections of hyper-parameters [16]</ref>, [17]</ref>. (3)</ref> The validation set for testing the performance of the selected architecture is not split in the same way <ref type="b 5]</ref>. (IV) Differentiable algorithms. e.g., first order DARTS (DARTS-V1) [8]</ref>, second order DARTS (DARTS-V2), GDAS [7]</ref>, SETN [17]</ref>, TAS [21]</ref>, FBNet-V2 [44]</ref>, TuNAS [49]</ref>. (V) HPO m
ess of deep learning was promoted by the introductions of novel neural architectures, such as ResNet [1]</ref>, Inception [3]</ref>, VGGNet [9]</ref>, and Transformer [10]</ref>. However, manually designing one architecture requires human experts to frequently try and evaluate nu
120, about 1% compared to the best one with the same amount of parameters in CIFAR-100 and ImageNet-16-120. (II) In many vision tasks, pyramid structure has shown a surprising robustness and accuracy [45]</ref>, [46]</ref>. Regarding the parameters vs. the accuracy, the candidates in S s with a pyramid structure are far from the Pareto
putation cost but may provide insights for better designs and training strategies of different NAS algorithms, such as platformaware NAS [12]</ref>, accuracy prediction [38]</ref>, mutation-based NAS [39]</ref>, [40]</ref>, etc.</p><p>Architecture Computational Costs: NATS-Be levels, etc. These attributes may benefit the designs of NAS algorithms. Besides, some methods learn to predict the final accuracy of an architecture based on the results of few early training epochs [38]</ref>. These algorithms can be trained faster and the performance of the accuracy prediction can be evaluated using the fine-grained evaluation information.</p><p>P e and efficiency. NAS has been dominated by multi-fidelity based methods [6]</ref>, [27]</ref>, [36]</ref>, [38]</ref>, which learn to search based on an approximation of the performance of each candidate in order to accelerate searching. Running algorithms on our NATS-Bench c
total variation (TV) of the outputs of hidden layers during training. TV is a metric used in the graph signal processing literature to measure the smoothness of a signal defined over nodes of a graph (Chen et al., 2015)</ref>. More specifically, given a graph with the adjacency matrix A and a signal x defined over its nodes, TV is defined as</p><formula xml:id="formul
rmance in a variety of graph analytic tasks, such as semi-supervised node classification and link prediction (Kipf &amp; Welling, 2017;</ref>2016;</ref>Hasanzadeh et al., 2019;</ref>Hajiramezanali et al., 2019)</ref>. Despite their successes, GNNs have There exist a variety of methods to a 35">(Rong et al., 2019)</ref>.</p><p>With this hierarchical beta-Bernoulli GDC formulation, inference based on Gibbs sampling can be computationally demanding for large datasets, including graph data (Hasanzadeh et al., 2019)</ref>. In the following, we derive efficient variational inference algorithm(s) for learnable GDC.</p><p>To perform variational inference for G
. This phenomenon, which is known as posterior collapse or KL vanishing, is a common problem in variational autoencoders for language modeling (Bowman et al., 2015;</ref>Goyal et al., 2017;</ref>Liu et al., 2019)</ref>. It is often due to over-parametrization in the model, which is indeed the case in the lo
mezanali et al., 2020;</ref>Dadaneh et al., 2020a)</ref>, Markov chain Monte Carlo (MCMC) (Neal, 2012)</ref>, and stochastic gradient MCMC (Ma et al., 2015)</ref>. However, their computational cost is still much higher than the non-Bayesian methods, due to the increased model complexity and slow convergence
ps at each layer of GNNs. In existing Bayesian neural networks, the model parameters, i.e. W (l) , are considered random to enable Bayesian inference based on predictive posterior given training data (Gal et al., 2017;</ref>Boluki et al., 2020)</ref>.</p><p>Here, we show that connection sampling in GDC can be transformed from the output weights for each of the message passing along edges e = (u, v) ∈ E where E is the union of edge set of the input graph and self-loops for all nodes.</p><p>Following the variational interpretation in Gal et al. (2017)</ref>, GDC can be seen as an approximating distribution q θ (ω) for the posterior p(ω | A, X) when considering a set of random weight matrices ω = {ω e oximating q θ (ω) does not deviate too far from the prior distribution. To be able to evaluate the KL term analytically, the discrete quantised Gaussian can be adopted as the prior distribution as in Gal et al. (2017)</ref>. Further with the factorization q θ (ω) over L layers and |E| edges such that q θ (ω) = l e q θ l (W (l) e ) and letting</p><formula xml:id="form ne way to address this issue is to replace the discrete variables with a continuous approximation. We impose a concrete distribution relaxation (Jang et al., 2016;</ref>Gal et al., 2017)</ref> for the Bernoulli random variable z</p><formula xml:id="formula_30">(l)</formula><p>uv , leading to an efficient optimization by sampling from si

. This phenomenon, which is known as posterior collapse or KL vanishing, is a common problem in variational autoencoders for language modeling (Bowman et al., 2015;</ref>Goyal et al., 2017;</ref>Liu et al., 2019)</ref>. It is often due to over-parametrization in the model, which is indeed the case in the lo

Welling, 2013)</ref> are not directly applicable here for computing the expectation in the first term since the drop masks are binary. Moreover, score-function gradient estimators, such as REIN-FORCE (Williams, 1992;</ref>Fu, 2006)</ref>, possess high variance. One potential solution is continuous relaxation of the drop masks. This appro
nding drop rate at each GNN layer together with weight parameters, we define the variational distribution as q(Z (l) , π l ) = q(Z (l) | π l )q(π l ). We define q(π l ) to be Kumaraswamy distribution (Kumaraswamy, 1980)</ref>; as an alternative to the beta prior factorized over lth layer</p><formula xml:id="formula_26">q(π l ; a l , b l ) = a l b l π a l −1 l (1 − π
nding drop rate at each GNN layer together with weight parameters, we define the variational distribution as q(Z (l) , π l ) = q(Z (l) | π l )q(π l ). We define q(π l ) to be Kumaraswamy distribution (Kumaraswamy, 1980)</ref>; as an alternative to the beta prior factorized over lth layer</p><formula xml:id="formula_26">q(π l ; a l , b l ) = a l b l π a l −1 l (1 − π
a O 0 R 8 Y X 7 + b C p 4 F &lt; / l a t e x i t &gt; q(x t |x t 1 )</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e A Z 8 7  This paper presents progress in diffusion probabilistic models [50]</ref>. A diffusion probabilistic model (which we will call a "diffusion model" for brevity) is a parameterized Markov chain trained using variational inference to p ters, and expressiveness of the reverse process is ensured in part by the choice of Gaussian conditionals in p θ (x t−1 |x t ), because both processes have the same functional form when β t are small [50]</ref>. A notable property of the forward process is that it admits sampling x t at an arbitrary timestep t in closed form: using the notation α t := 1 − β t and ᾱt is optimal for x 0 deterministically set to one point. These are the two extreme choices corresponding to upper and lower bounds on reverse process entropy for data with coordinatewise unit variance [50]</ref>.</p><p>Second, to represent the mean µ θ (x t , t), we propose a specific parameterization motivated by the following analysis of</p><formula xml:id="formula_ ef type="bibr" target="#b17">[18]</ref>, which is not tractable for high dimensional data. These algorithms serve as a compression interpretation of the variational bound (5) of Sohl-Dickstein et al. [50]</ref>, not yet as a practical compression system. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A Extended derivations</head><p>Below is a derivation of ions</head><p>Below is a derivation of Eq. ( 5</ref>), the reduced variance variational bound for diffusion models. This material is from Sohl-Dickstein et al. [50]</ref>; we include it here only for completeness.</p><formula xml:id="formula_26">L = E q − log p θ (x 0:T ) q(x 1:T |x 0 ) (17) = E q   − log p(x T ) − t≥1 log p xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We set T = 1000 for all experiments so that the number of neural network evaluations needed during sampling matches previous work [50,</ref>52]</ref>. We set the forward process variances to constants increasing linearly from β 1 = 10 −4 to β T = 0.02. These constants
="bibr" target="#b29">30,</ref>5,</ref>14,</ref>21]</ref> and VAEs [31,</ref>44,</ref>34]</ref>, diffusion models are designed so that q has no parameters and the top-level latent x T has nearly zero mutual informat
>[2]</ref>, variational walkback [13]</ref>, generative stochastic networks [1]</ref>, and others [47,</ref>51,</ref>33,</ref>39]</ref>.</p><p>By the known connection between score matching and energy-based modeling
get="#b30">31,</ref>42]</ref>, and there have been remarkable advances in energy-based modeling and score matching that have produced images comparable to those of GANs [11,</ref>52]</ref>.  3 q Y G m r 3 m e M p D a w q s a A m y k p E c t S 0 l h h N l L Z P A i q t 1 Y w M C 2 O W Y m w j i y n N t q 8 elihood-based models (our models do, however, have log likelihoods better than the large estimates annealed importance sampling has been reported to produce for energy based models and score matching [11,</ref>52]</ref>). We find that the majority of our models' lossless codelengths are consumed to describe imperceptible image details ( 39]</ref>.</p><p>By the known connection between score matching and energy-based modeling, our work could have implications for other recent work on energy-based models [11,</ref>38,</ref>15,</ref>8]</ref>. Our rate-distortion curves are computed z</formula><p>, where z ∼ N (0, I). The complete sampling procedure, Algorithm 2, resembles Langevin dynamics with θ as a learned gradient of the data density. Furthermore, with the parameterization (11)</ref>, Eq. ( 10</ref>) simplifies to:</p><formula xml:id="formula_20">E x0, β 2 t 2σ 2 t α t (1 − ᾱt ) − θ ( √ ᾱt x 0 + √ 1 dexed by t [52]</ref>. As Eq. ( 12</ref>) is equal to (one term of) the variational bound for the Langevin-like reverse process (11)</ref>, we see that optimizing an objective resembling denoising score matching is equivalent to using variational inference to fit the finite-time marginal of a sam for nearest neighbor visualizations). Still, while our lossless codelengths are better than the large estimates reported for energy based models and score matching using annealed importance sampling [11]</ref>, they are not competitive with other types of likelihood-based generative models [7]</ref>.</p><p>Since samples are nonetheless
g. 9</ref>).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>While diffusion models might resemble flows [9,</ref>43,</ref>10,</ref>30,</ref>5,</ref>14,</ref><re
core matching and energy-based modeling, our work could have implications for other recent work on energy-based models [11,</ref>38,</ref>15,</ref>8]</ref>. Our rate-distortion curves are computed over time in one evaluation of the variational bound, reminiscent of how rate-di

ef>43,</ref>10,</ref>30,</ref>5,</ref>14,</ref>21]</ref> and VAEs [31,</ref>44,</ref>34]</ref>, diffusion models are design

>[2]</ref>, variational walkback [13]</ref>, generative stochastic networks [1]</ref>, and others [47,</ref>51,</ref>33,</ref>39]</ref>.</p><p>By the known connection between score matching and energy-based modeling
>23,</ref>10,</ref>30,</ref>41,</ref>54,</ref>24,</ref>31,</ref>42]</ref>, and there have been remarkable advances in energy-based modeling and score mat
th negative features, to get even harder negatives, and achieve improved performance. Our work is also related to metric learning works that employ generators [18,</ref>87]</ref>. Apart from not requiring labels, our method exploits the memory component, something not present in [18,</ref><ref type="bibr" "#b17">[18,</ref>87]</ref>. Apart from not requiring labels, our method exploits the memory component, something not present in [18,</ref>87]</ref>. It has no extra parameters or loss terms that need to be optimized.</p><p>3 Understanding hard negatives in unsupervised contrastive learning</p></div> <div x tric learning literature [18,</ref>87,</ref>35]</ref>. Works like [18,</ref>87]</ref> use generators to synthesize negatives in a supervised scenario over common metric learning losses. Apart from not requiring labels, in our case we focus on a arning losses. Apart from not requiring labels, in our case we focus on a specific contrastive loss and exploit its memory component. What is more, and unlike [18,</ref>87]</ref>, we do not require a generator, i.e. have no extra parameters or loss terms that need to be optimized. We discuss the relations and differences between MoCHi a type="bibr" target="#b31">[30]</ref>  Synthesizing for supervised metric learning. Recently, synthesizing negatives was explored in metric learning literature [18,</ref>87,</ref>35]</ref>. Works like [18,</ref>87]</ref> use generators to synthes
ch positive (query).</p><p>Contrastive learning was recently shown to be a highly effective way of learning visual representations in a self-supervised manner [11,</ref>30]</ref>. Pushing the embeddings of two transformed versions of the same image (forming the positive pair) close to each other and further apart from the embedding of a -of-the-art performance on a number of target tasks used to evaluate the quality of visual representations learned in an unsupervised way. It is however shown [11,</ref>30]</ref> that increasing the memory/batch size leads to diminishing returns in terms of performance: more negative samples does not necessarily mean hard negative sampl or self-supervised learning. The last few months have witnessed a surge of successful approaches that also use contrastive learning losses. These include MoCo [13,</ref>30]</ref>, SimCLR [11,</ref>12]</ref>, PIRL [46]</ref>, CMC <ref type="bibr" [46,</ref>77]</ref> use memories that contain the whole training set, while the recent Momentum Contrast (or MoCo) approach of He et al. [30]</ref> keeps a queue with features of the last few batches as memory. The MoCo approach with the modifications presented in [13]</ref> of contrastive learning, i.e. the effect of hard negatives, has so far been neglected in the context of self-supervised representation learning. We delve deeper into learning with a momentum encoder [30]</ref> and show evidence that harder negatives are required to facilitate better and faster learning. Based on these observations, and motivated by the success of da negative points (blue triangles).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions. a)</head><p>We delve deeper into a top-performing contrastive self-supervised learning method [30]</ref> and observe the need for harder negatives; b) We propose hard negative mixing, i.e. to synthesize hard negatives directly in the embedding space, on-the-fly, size K, i.e. a set of K embeddings in R d . Let the query q and key k embeddings form the positive pair, which is contrasted with every feature n in the bank of negatives (Q) also called the queue in [30]</ref>. A popular and highly successful loss function for contrastive learning [11,</ref>30,</ref><ref mory containing every other image in the dataset [46,</ref>64,</ref>77]</ref>, a queue of the last batches [30]</ref>, or simply be every other image in the current minibatch [11]</ref>.</p><p>The log-likelihood function of Eq (1) is defined ove ts between the "freshness" of the memory bank representations and the computational overhead for re-computing them as the encoder keeps changing. The Momentum Contrast (or MoCo) approach of He et al. [30]</ref> offers a compromise between the two negative sampling extremes: it keeps a queue of the latest K features from the last batches, encoded with a second key enc ncoder that trails the (main/query) encoder with a much higher momentum. For MoCo, the key feature k and all features in Q are encoded with the key encoder.</p><p>How hard are MoCo negatives? In MoCo [30]</ref> (resp. SimCLR [11]</ref>) the authors show that increasing the memory (resp. batch) size, is crucial to getting better and hard nificant contributions to the loss. This shows that most of the memory negatives are practically not helping a lot towards learning the proxy task.</p><p>On the difficulty of the proxy task. For MoCo [30]</ref>, SimCLR [11]</ref>, InfoMin [65]</ref>, and other approaches that learn augmentation-invariant r erimentally verify this. In Figure 2b</ref>, we plot the proxy task performance, i.e. the percentage of queries where the key is ranked over all negatives, across training for MoCo [30]</ref> and MoCo-v2 [13]</ref>. MoCo-v2 enjoys a high performance gain over MoCo by three main changes: the addition of a Multilayer Pe first epochs we do not synthesize hard negatives. For ImageNet-1K, we report accuracy for a single-crop testing. For object detection on PASCAL VOC [19]</ref> we follow [30]</ref> and fine-tune a Faster R-CNN [54]</ref>, R50-C4 on trainval07+12 and test on test2007. We use the open-source detectron2<ref ty ">[54]</ref>, R50-C4 on trainval07+12 and test on test2007. We use the open-source detectron23</ref> code and report the common AP, AP50 and AP75 metrics. Similar to [30]</ref>, we do not perform hyperparameter tuning for the object detection task. See the Appendix for more implementation details.</p><p>A note on reporting variance i In Table 2</ref> we present results for object detection and semantic segmentation on the COCO dataset [41]</ref>. Following He et al. [30]</ref>, we use Mask R-CNN [29]</ref> with a C4 backbone, with batch normalization tuned and synchronize across GPUs. The image scale i le is in [640, 800] pixels during training and is 800 at inference. We fine-tune all layers end-to-end on the train2017 set (118k images) and evaluate on val2017. We adopt feature normalization as in [30]</ref> when fine-tuning. MoCHi and MoCo use the same hyper-parameters as the ImageNet supervised counterpart (i.e. we did not do any method-specific tuning). From Ta illion dollar industry application, where the funding to get large clean datasets already exists. Following our discussion in Section 3.2, we wanted to verify that hardness of the proxy task for MoCo [30]</ref> is directly correlated to the difficulty of the transformations set, i.e. proxy task hardness can modulated via the positive pair. In Figure <ref type="figure ive pair. In Figure 4</ref>, we plot the proxy task performance, i.e. the percentage of queries where the key is ranked over all negatives, across training for MoCo [30]</ref>, MoCo-v2 [13]</ref> and some variants inbetween. In Figure 4</ref>, we track the proxy task arget="#b67">66]</ref>. In an interesting recent study, Purushwalkam and Gupta [52]</ref> study the robustness of contrastive self-supervised learning methods like MoCo [30]</ref> and PIRL [46]</ref> and saw that despite the fact that they learn occlusioninvariant representations, they fail to capture view he embedding space. BYOL makes a number of modifications over SimCLR [11]</ref>, e.g. the addition of a target network whose parameter update is lagging similar to MoCo [30]</ref>  Synthesizing for supervised metric learning. Recently, synthesizing negatives was explored in metric learning literature [18,< iation is reported, it refers to multiple runs for the fine-tuning part. For MoCHi runs we also report in parenthesis the difference to MoCo-v2. * denotes reproduced results. † results are copied from[30]</ref>. We bold (resp. underline) the highest results overall (resp. for MoCHi).</note></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab ble representations faster than BYOL.</figDesc><table /></figure> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">In this section we study contrastive learning for MoCo[30]</ref> on ImageNet-100, a subset of ImageNet consisting of 100 classes introduced in[64]</ref>. See Section 5 for details on the datas ><p>Most of the top-performing contrastive methods leverage data augmentations [11,</ref>13,</ref>26,</ref>30,</ref>46,</ref>64]</ref>. As revealed by recent studies [4,</ref><ref type nk of negatives (Q) also called the queue in [30]</ref>. A popular and highly successful loss function for contrastive learning [11,</ref>30,</ref>64]</ref> is the following:</p><formula xml:id="formula_0">L q,k,Q = − log exp(q T k/τ ) exp(q T k/τ ) + n∈Q exp(q T n/τ ) , (<la <formula xml:id="formula_1">)</formula><p>where τ is a temperature parameter and all embeddings are 2 -normalized. In a number of recent successful approaches [11,</ref>30,</ref>46,</ref>65]</ref> the query and key are the embeddings of two augmentations of the same image. Th n details.</p><p>A note on reporting variance in results. It is unfortunate that many recent self-supervised learning papers do not discuss variance ; in fact only papers from highly resourceful labs [30,</ref>11,</ref>65]</ref> report averaged results, but not always the variance. This is generally unders

deo dataset recorded from the perspective of several young children and demonstrated the emergence of high-level semantic information.</p><p>A number of works exploit the audio-visual nature of video [37,</ref>1,</ref>51,</ref>14,</ref>3]</ref> to



opies of the same image to the model and makes the self-supervised (proxy) task harder. At the same time, data mixing techniques operating at either the pixel [70,</ref>83,</ref>85]</ref> or the feature level [69]</ref> help models learn more robust features that improve both trastive learning. Mixup [85]</ref> and its numerous variants [56,</ref>69,</ref>71,</ref>83]</ref> have been shown to be highly effective data augmentation strategies when paired with a cross-entropy loss for supervised and semi-supervised learning. Manifold
/ref>79]</ref>, predicting the "arrow of time" [74]</ref>, pace [72]</ref> or predicting the "odd" element [21]</ref> from a set of clips. Recently, contrastive, memory-based self-supervised learning methods were extended to video representation learning <ref type="bibr" targ
se automatic extracted text, e.g. from speech transcripts [62,</ref>61,</ref>44]</ref> or surrounding text [24]</ref>.</p><p>Clustering losses. A number of recent works explore representation learning together with clustering losses imposed on the unlabeled dataset they learn
synchronization. Apart from audio, other methods have used use automatic extracted text, e.g. from speech transcripts [62,</ref>61,</ref>44]</ref> or surrounding text [24]</ref>.</p><p>Clustering losses. A number of recent works explore representation learning together with
tands for N = 128 when training for 100 epochs. We also added a couple of recent and concurrent methods in the table, e.g. PCL [40]</ref>, or the clustering approach of [9]</ref>. Both unfortunately use a different setup for PASCAL VOC and their VOC results are not directly comparable. We see however that our performance for linear class
tions.</p><p>A handful of works discuss issues around the selection of negatives in contrastive self-supervised learning [7,</ref>15,</ref>33,</ref>76,</ref>78]</ref>. Iscen et al. [33]</ref> mine hard negatives fro /1.0"><head n="3.2">Hard negatives in contrastive learning</head><p>Hard negatives are critical for contrastive learning [2,</ref>28,</ref>33,</ref>45,</ref>57,</ref>75,</ref>81]</ref> r" target="#b6">[7,</ref>15,</ref>33,</ref>76,</ref>78]</ref>. Iscen et al. [33]</ref> mine hard negatives from a large set by focusing on the features that are neighbors with respect to the Euclidean distance, but not when using a manifold dist
es are critical for contrastive learning [2,</ref>28,</ref>33,</ref>45,</ref>57,</ref>75,</ref>81]</ref>. Sampling negatives from the same batch leads to a need for larger batches <ref
ion [60]</ref>, shuffling and then predicting or verifying the order of frames or clips [47,</ref>38,</ref>79]</ref>, predicting the "arrow of time" [74]</ref>, pace [72]</ref> or predicting the "odd" element <ref
top contrastive approaches either substantially increase the batch size [11]</ref>, or keep large memory banks. Approaches like [46,</ref>77]</ref> use memories that contain the whole training set, while the recent Momentum Contrast (or MoCo) approach of He et al. [30]</ref> gatives for each positive pair, and may be defined as an "external" memory containing every other image in the dataset [46,</ref>64,</ref>77]</ref>, a queue of the last batches [30]</ref>, or simply be every other image in the current minibatch  ile sampling negatives from a memory bank that contains every other image in the dataset requires the time consuming task of keeping a large memory up-to-date [46,</ref>77]</ref>. In the latter case, a trade-off exists between the "freshness" of the memory bank representations and the computational overhead for re-computing them as the 15">[16,</ref>17,</ref>23,</ref>36,</ref>48]</ref>. Instance discrimination [77]</ref> and CPC [49]</ref> were among the first papers to use contrastive losses for self-supervised learning. The last few months have
ing or verifying the order of frames or clips [47,</ref>38,</ref>79]</ref>, predicting the "arrow of time" [74]</ref>, pace [72]</ref> or predicting the "odd" element [21]</ref> from a set of clips. Recently, contr
eport accuracy for a single-crop testing. For object detection on PASCAL VOC [19]</ref> we follow [30]</ref> and fine-tune a Faster R-CNN [54]</ref>, R50-C4 on trainval07+12 and test on test2007. We use the open-source detectron23</ref> code and report the common AP, AP50 f type="foot" target="#foot_6">7</ref> . The PASCAL VOC dataset can be downloaded from this link 8</ref> . As mentioned in the main text, we fine-tune a Faster R-CNN [54]</ref>, R50-C4 on trainval07+12 and test on test2007. Details on the splits can be found here 9</ref> for the 2007 part and here <r
onsistent across multiple hyperparameter configurations.</p><p>In Table 2</ref> we present results for object detection and semantic segmentation on the COCO dataset [41]</ref>. Following He et al. [30]</ref>, we use Mask R-CNN [29]</ref> with a C4 backbone, with batch nor
me, data mixing techniques operating at either the pixel [70,</ref>83,</ref>85]</ref> or the feature level [69]</ref> help models learn more robust features that improve both supervised and semi-supervised learning on subsequent (target) tasks.</p><p>In most recent contrastiv pe="bibr" target="#b84">83]</ref> have been shown to be highly effective data augmentation strategies when paired with a cross-entropy loss for supervised and semi-supervised learning. Manifold mixup [69]</ref> is a feature-space regularizer that encourages networks to be less confident for interpolations of hidden states. The benefits of interpolating have only rece ng distribution to a region around the query.</p><p>Mixing for contrastive learning. Mixup [85]</ref> and its numerous variants [56,</ref>69,</ref>71,</ref>83]</ref> have been shown to be highly effective data augmentation strategies when paired with a cross-
linear classifiers for 60 (resp. 100) epochs, with an initial learning rate of 10.0 (30.0), a batch size of 128 (resp. 512) and a step learning rate schedule that drops at epochs 30, 40 and 50 (resp. 60,</ref>80)</ref>. For training we use K = 16k (resp. K = 65k). For MoCHi, we also have a warm-up of 10 (resp. 15) epochs, i.e. for the f and multimodal visual data. A number of earlier works that learn representations from videos utilized the sequential nature of the temporal dimension, e.g. future frame prediction and reconstruction [60]</ref>, shuffling and then predicting or verifying the order of frames or clips [47,</ref>38,</ref><ref
future frame prediction and reconstruction [60]</ref>, shuffling and then predicting or verifying the order of frames or clips [47,</ref>38,</ref>79]</ref>, predicting the "arrow of time" [74]</ref>, pace [72]</re
and</ref>Garg et al. (2019)</ref> are not able to perform post-hoc debiasing and require changing the data or underlying word embeddings and retraining which is costly. Bordia and Bowman (2019)</ref> only study word-level language models and also requires re-training. Finally, Kurita et al. (2019)</ref> onl
)</ref> and multiclass (Manzini et al., 2019)</ref> bias attributes such as gender, race, and religion.</p><p>More recently, sentence-level representations such as ELMo (Peters et al., 2018)</ref>, BERT (Devlin et al., 2019)</ref>, and GPT (Radford et al., 2019)</ref> have be n estimating bias subspaces of sentence representations. Our experiments are performed on two widely popular sentence encoders BERT (Devlin et al., 2019)</ref> and ELMo (Peters et al., 2018)</ref>, showing that our approach reduces the bias while preserving performance on downstream sequence tasks. We end with a discussion about possibl t describe the details of applying SENT-DEBIAS on two widely-used sentence encoders: BERT2</ref>  (Devlin et al., 2019)</ref> and ELMo (Peters et al., 2018)</ref>. Note that the pre-trained BERT encoder must be fine-tuned on task-specific data. This implies that the final BERT encoder used during debias
r underlying word embeddings and retraining which is costly. Bordia and Bowman (2019)</ref> only study word-level language models and also requires re-training. Finally, Kurita et al. (2019)</ref> only measure bias on BERT by extending the word-level Word Embedding Association Test (WEAT) (Caliskan et al., 2
ift after the debiasing process is performed. We average the sentence representations of a concept (e.g. man, woman, science, art) across its contexts (sentence templates) and plot the t-SNE (van der Maaten and Hinton, 2008)</ref> Figure 2</ref>: Influence of the number of template domains on the effectiveness of bias removal on BERT fine-tuned on
)</ref> to sentences.</p><p>Related Work: Although there has been some recent work in measuring the presence of bias in sentence representations (May et al., 2019;</ref>Basta et al., 2019)</ref>, none of them have been able to successfully remove bias from pretrained sentence representations. In particular, <ref type="bibr" target="#b47"
ng. When compared to word-level representations, these models have achieved better performance on multiple tasks in NLP (Wu and Dredze, 2019)</ref>, multimodal learning (Zellers et al., 2019;</ref>Sun et al., 2019a)</ref>, and grounded language learning (Urbanek et al., 2019)</ref>. As the
) (Bolukbasi et al., 2016)</ref> to sentences.</p><p>Related Work: Although there has been some recent work in measuring the presence of bias in sentence representations (May et al., 2019;</ref>Basta et al., 2019)</ref>, none of them have been able to successfully remove bias from pretrained sentence represe al. (2019)</ref> only measure bias on BERT by extending the word-level Word Embedding Association Test (WEAT) (Caliskan et al., 2017)</ref> metric in a manner similar to May et al. (2019)</ref>.</p><p>In this paper, as a compelling step towards generalizing debiasing methods to sentence representations, we capture the various ways in whi n be applied to obtain sentence representations. One option is to use a simple template-based design to simplify the contextual associations a sentence encoder makes with a given term, similar to how May et al. (2019)</ref> proposed to measure (but not remove) bias in sentence representations. For example, each word can be slotted into templates such as "This is &lt; mmonly known as the effect size. An effect size with absolute value closer to 0 represents lower bias.</p><p>To measure the bias present in sentence representations, we use the method as described in May et al. (2019)</ref> which extended WEAT to the Sentence Encoder Association Test (SEAT). For a given set of words for a particular test, words are converted into sen s with respect to careers, math, and science (Greenwald et al., 2009)</ref>. To evaluate biases in the multiclass religion setting, we modify the Caliskan Tests used in May et al. (2019)</ref> with lexicons used by Manzini et al. (2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2 sentence embeddings with an average of debiased FastText (and BERT) word embeddings using word-level debiasing methods (Bolukbasi et al., 2016)</ref>. BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT representations. SENT-DEBIAS BERT represents our method using diverse templates. We report the average a presentation from average debiased BERT word representations, again debiased using word-level debiasing methods (Bolukbasi et al., 2016)</ref>, and 3) BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT sentence representations.</p><p>From Table 4</ref>, SENT-DEBIAS achieves a lower avera vlin et al., 2019)</ref> +0.354 FastText (Bojanowski et al., 2016)</ref> +0.565 BERT word (Bolukbasi et al., 2016)</ref> +0.861 BERT simple (May et al., 2019)</ref> +0.298 SENT-DEBIAS BERT (ours) +0.256</p><p>Table 4</ref>: Comparison of various debiasing methods on sentence embeddings. Fas
ch between gendered pronouns and the sentence context. For SST, it has been shown that sentiment analysis datasets have labels that correlate with gender information and therefore contain gender bias (Kiritchenko and Mohammad, 2018)</ref>. As a result, we do expect possible decreases in accuracy after debiasing. Finally, we test the effect of SENT-DEBIAS on QNLI by t
bedding layers which learn continuous representations of input information such as words, sentences, and documents from large amounts of data (Devlin et al., 2019;</ref>Mikolov et al., 2013)</ref>. Although word-level embeddings (Pennington et al., 2014;</ref>Mikolov et al., bibr" target="#b10">(Devlin et al., 2019;</ref>Mikolov et al., 2013)</ref>. Although word-level embeddings (Pennington et al., 2014;</ref>Mikolov et al., 2013)</ref> are highly informative features useful for a variety of tasks in Natural Language Processing (NLP), recent work has shown that word-level emb y of the state-of-the-art sentencebased embedding models. In contrast with conventional word-level embeddings such as GloVe (Pennington et al., 2014)</ref> and word2vec (Mikolov et al., 2013)</ref> which can be retrained on a single machine within a few hours, the best sentence encoders such as BERT (Devli
downstream tasks. All experiments are conducted on English terms and downstream tasks. We acknowledge that biases can manifest differently across different languages, in particular gendered languages (Zhou et al., 2019)</ref>, and emphasize the need for future extensions in these directions. Experimental details are in the appendix and code is released at https://git
4">Basta et al., 2019)</ref>, none of them have been able to successfully remove bias from pretrained sentence representations. In particular, Zhao et al. (2019)</ref>, Park et al. (2018), and</ref>Garg et al. (2019)</ref> are not able to perform post-hoc debiasing and require changing the data or underlyi
) (Bolukbasi et al., 2016)</ref> to sentences.</p><p>Related Work: Although there has been some recent work in measuring the presence of bias in sentence representations (May et al., 2019;</ref>Basta et al., 2019)</ref>, none of them have been able to successfully remove bias from pretrained sentence represe al. (2019)</ref> only measure bias on BERT by extending the word-level Word Embedding Association Test (WEAT) (Caliskan et al., 2017)</ref> metric in a manner similar to May et al. (2019)</ref>.</p><p>In this paper, as a compelling step towards generalizing debiasing methods to sentence representations, we capture the various ways in whi n be applied to obtain sentence representations. One option is to use a simple template-based design to simplify the contextual associations a sentence encoder makes with a given term, similar to how May et al. (2019)</ref> proposed to measure (but not remove) bias in sentence representations. For example, each word can be slotted into templates such as "This is &lt; mmonly known as the effect size. An effect size with absolute value closer to 0 represents lower bias.</p><p>To measure the bias present in sentence representations, we use the method as described in May et al. (2019)</ref> which extended WEAT to the Sentence Encoder Association Test (SEAT). For a given set of words for a particular test, words are converted into sen s with respect to careers, math, and science (Greenwald et al., 2009)</ref>. To evaluate biases in the multiclass religion setting, we modify the Caliskan Tests used in May et al. (2019)</ref> with lexicons used by Manzini et al. (2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2 sentence embeddings with an average of debiased FastText (and BERT) word embeddings using word-level debiasing methods (Bolukbasi et al., 2016)</ref>. BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT representations. SENT-DEBIAS BERT represents our method using diverse templates. We report the average a presentation from average debiased BERT word representations, again debiased using word-level debiasing methods (Bolukbasi et al., 2016)</ref>, and 3) BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT sentence representations.</p><p>From Table 4</ref>, SENT-DEBIAS achieves a lower avera vlin et al., 2019)</ref> +0.354 FastText (Bojanowski et al., 2016)</ref> +0.565 BERT word (Bolukbasi et al., 2016)</ref> +0.861 BERT simple (May et al., 2019)</ref> +0.298 SENT-DEBIAS BERT (ours) +0.256</p><p>Table 4</ref>: Comparison of various debiasing methods on sentence embeddings. Fas

d like to emphasize that both the WEAT, SEAT, and MAC metrics are not perfect since they only have positive predictive ability: they can be used to detect the presence of biases but not their absence (Gonen and Goldberg, 2019)</ref>. and paired sentence (BERT on QNLI) downstream tasks. The performance (higher is better) of debiased BERT and ELMo sentence representati
)</ref> to sentences.</p><p>Related Work: Although there has been some recent work in measuring the presence of bias in sentence representations (May et al., 2019;</ref>Basta et al., 2019)</ref>, none of them have been able to successfully remove bias from pretrained sentence representations. In particular, <ref type="bibr" target="#b47"

016)</ref>. Machine learning systems that incorporate these word embeddings can further amplify biases (Sun et al., 2019b;</ref>Zhao et al., 2017;</ref>Barocas and Selbst, 2016)</ref> and unfairly discriminate against users, particularly those from disadvantaged social groups. Fortunately, researchers working on fairness
ref>Liu et al., 2019;</ref>Wang et al., 2019)</ref> and multimodal human language (Liang et al., 2018</ref>(Liang et al., , 2019))</ref>. Table 2</ref> summarizes these datasets. We also give some examples of the diverse templates that occur
uage Processing (NLP), recent work has shown that word-level embeddings reflect and propagate social biases present in training corpora (Lauscher and Glava?, 2019;</ref>Caliskan et al., 2017;</ref>Swinger et al., 2019;</ref>Bolukbasi et al., 2016)</ref>. Machine learning system e models and also requires re-training. Finally, Kurita et al. (2019)</ref> only measure bias on BERT by extending the word-level Word Embedding Association Test (WEAT) (Caliskan et al., 2017)</ref> metric in a manner similar to May et al. (2019)</ref>.</p><p>In this paper, as a compelling step towards gene /pliang279/ sent_debias.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluating Biases</head><p>Biases are traditionally measured using the Word Embedding Association Test (WEAT) (Caliskan et al., 2017)</ref>. WEAT measures bias in word embeddings by comparing two sets of target words to two sets of attribute words. For example, to measure social ine similarity (MAC) metric which extends SEAT to a multiclass setting (Manzini et al., 2019)</ref>. For the binary gender setting, we use words from the Caliskan Tests (Caliskan et al., 2017)</ref> which measure biases in common stereotypes surrounding gendered names with respect to careers, math, and science <ref type="bibr" target="#b
in training corpora (Lauscher and Glava?, 2019;</ref>Caliskan et al., 2017;</ref>Swinger et al., 2019;</ref>Bolukbasi et al., 2016)</ref>. Machine learning systems that incorporate these word embeddings can further amplify biases (Sun et al., 2019b;</ref><ref t , particularly those from disadvantaged social groups. Fortunately, researchers working on fairness and ethics in NLP have devised methods towards debiasing these word representations for both binary (Bolukbasi et al., 2016)</ref> and multiclass (Manzini et al., 2019)</ref> bias attributes such as gender, race, and religion.</p><p>More r ttings, and even differences between spoken and written text. As a result, it is difficult to scale traditional word-level debiasing approaches (which involve bias-attribute words such as man, woman) (Bolukbasi et al., 2016)</ref> to sentences.</p><p>Related Work: Although there has been some recent work in measuring the presence of bias in sentence representations <r contextualizing bias-attribute words using a diverse set of sentence templates from various text corpora into bias-attribute sentences. We propose SENT-DEBIAS, an extension of the HARD-DEBIAS method (Bolukbasi et al., 2016)</ref>, to debias sentences for both binary1</ref> and multiclass bias attributes spanning gender and religion. airs and triplets in appendix).</p><p>Existing methods that investigate biases tend to operate at the word-level which simplifies the problem since the set of tokens is bounded by the vocabulary size (Bolukbasi et al., 2016)</ref>. This simple approach has the advantage of identifying the presence of biases using predefined sets of word associations, and estimate the , V represents the top-k orthogonal directions which most represent the bias subspace.</p><p>4) Debiasing: Given the estimated bias subspace V, we apply a partial version of the HARD-DEBIAS algorithm (Bolukbasi et al., 2016)</ref> to remove bias from new sentence representations. Taking the example of binary gender bias, the HARD-DEBIAS algorithm consists of two steps 1) FastText derives debiased sentence embeddings using an average of debiased FastText word embeddings (Bojanowski et al., 2016</ref>) using wordlevel debiasing methods (Bolukbasi et al., 2016)</ref>, 2)</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Debiasing Method</head><p>Ave. Abs. Effect Size BERT original <ref type="bibr" </head><p>Ave. Abs. Effect Size BERT original (Devlin et al., 2019)</ref> +0.354 FastText (Bojanowski et al., 2016)</ref> +0.565 BERT word (Bolukbasi et al., 2016)</ref> +0.861 BERT simple (May et al., 2019)</ref> +0.298 SENT-DEBIAS BERT (ours) +0.256</p><p>Table <ref type="tab r" target="#b5">(Bojanowski et al., 2016)</ref> (and BERT word) derives debiased sentence embeddings with an average of debiased FastText (and BERT) word embeddings using word-level debiasing methods (Bolukbasi et al., 2016)</ref>. BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT representations. SENT-D scores closer to 0 represent lower bias.</p><p>BERT word obtains a debiased sentence representation from average debiased BERT word representations, again debiased using word-level debiasing methods (Bolukbasi et al., 2016)</ref>, and 3) BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT sentence represe of bias is uncovered from data. We therefore focus on post-hoc debiasing techniques which add a post-training debiasing step to these sentence representations before they are used in downstream tasks (Bolukbasi et al., 2016;</ref>Manzini et al., 2019)</ref>. Secondly, sentences display large variety in how they are composed from individu
downstream tasks. All experiments are conducted on English terms and downstream tasks. We acknowledge that biases can manifest differently across different languages, in particular gendered languages (Zhou et al., 2019)</ref>, and emphasize the need for future extensions in these directions. Experimental details are in the appendix and code is released at https://git
ng. When compared to word-level representations, these models have achieved better performance on multiple tasks in NLP (Wu and Dredze, 2019)</ref>, multimodal learning (Zellers et al., 2019;</ref>Sun et al., 2019a)</ref>, and grounded language learning (Urbanek et al., 2019)</ref>. As the
<p>Machine learning tools for learning from language are increasingly deployed in real-world scenarios such as healthcare (Velupillai et al., 2018)</ref>, legal systems (Dale, 2019)</ref>, and computational social science (Bamman et al., 2016)</ref>. Key to the success of these models are powerful embedding
xplicit bias control mechanisms on large amounts of naturally occurring text. Given that it becomes infeasible (in standard settings) to completely retrain these large sentence encoders for debiasing (Zhao et al., 2018;</ref>Zhang et al., 2018)</ref>, future work should focus on developing better post-hoc debiasing techniques. In our ex
entences, and documents from large amounts of data (Devlin et al., 2019;</ref>Mikolov et al., 2013)</ref>. Although word-level embeddings (Pennington et al., 2014;</ref>Mikolov et al., 2013)</ref> are highly informative features useful for a variety of tasks in Natural Langua cult for two reasons. Firstly, it is usually unfeasible to fully retrain many of the state-of-the-art sentencebased embedding models. In contrast with conventional word-level embeddings such as GloVe (Pennington et al., 2014)</ref> and word2vec (Mikolov et al., 2013)</ref> which can be retrained on a single machine within a few hours, t
he specific bias attribute present. Define the mean of set j as ? j = 1 R j ? w?R j w. The bias subspace V = {v 1 , ..., v k } is given by the first k components of principal component analysis (PCA) (Abdi and Williams, 2010)</ref>:</p><formula xml:id="formula_6">V = PCA k ? ? d ? j=1 ? w?R j (w -? j ) ? ? . (<label>3</label></formula><formula xml:id="formula_7">)</fo
uage Processing (NLP), recent work has shown that word-level embeddings reflect and propagate social biases present in training corpora (Lauscher and Glava?, 2019;</ref>Caliskan et al., 2017;</ref>Swinger et al., 2019;</ref>Bolukbasi et al., 2016)</ref>. Machine learning system e models and also requires re-training. Finally, Kurita et al. (2019)</ref> only measure bias on BERT by extending the word-level Word Embedding Association Test (WEAT) (Caliskan et al., 2017)</ref> metric in a manner similar to May et al. (2019)</ref>.</p><p>In this paper, as a compelling step towards gene /pliang279/ sent_debias.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluating Biases</head><p>Biases are traditionally measured using the Word Embedding Association Test (WEAT) (Caliskan et al., 2017)</ref>. WEAT measures bias in word embeddings by comparing two sets of target words to two sets of attribute words. For example, to measure social ine similarity (MAC) metric which extends SEAT to a multiclass setting (Manzini et al., 2019)</ref>. For the binary gender setting, we use words from the Caliskan Tests (Caliskan et al., 2017)</ref> which measure biases in common stereotypes surrounding gendered names with respect to careers, math, and science <ref type="bibr" target="#b
4">Basta et al., 2019)</ref>, none of them have been able to successfully remove bias from pretrained sentence representations. In particular, Zhao et al. (2019)</ref>, Park et al. (2018), and</ref>Garg et al. (2019)</ref> are not able to perform post-hoc debiasing and require changing the data or underlyi
</ref>Bolukbasi et al., 2016)</ref>. Machine learning systems that incorporate these word embeddings can further amplify biases (Sun et al., 2019b;</ref>Zhao et al., 2017;</ref>Barocas and Selbst, 2016)</ref> and unfairly discriminate against users, particularly those from disadvantaged soci
he specific bias attribute present. Define the mean of set j as ? j = 1 R j ? w?R j w. The bias subspace V = {v 1 , ..., v k } is given by the first k components of principal component analysis (PCA) (Abdi and Williams, 2010)</ref>:</p><formula xml:id="formula_6">V = PCA k ? ? d ? j=1 ? w?R j (w -? j ) ? ? . (<label>3</label></formula><formula xml:id="formula_7">)</fo
rd et al., 2019)</ref> have become the preferred choice for text sequence encoding. When compared to word-level representations, these models have achieved better performance on multiple tasks in NLP (Wu and Dredze, 2019)</ref>, multimodal learning (Zellers et al., 2019;</ref>Sun et al., 2019a)</ref>, and grounded langu

) (Bolukbasi et al., 2016)</ref> to sentences.</p><p>Related Work: Although there has been some recent work in measuring the presence of bias in sentence representations (May et al., 2019;</ref>Basta et al., 2019)</ref>, none of them have been able to successfully remove bias from pretrained sentence represe al. (2019)</ref> only measure bias on BERT by extending the word-level Word Embedding Association Test (WEAT) (Caliskan et al., 2017)</ref> metric in a manner similar to May et al. (2019)</ref>.</p><p>In this paper, as a compelling step towards generalizing debiasing methods to sentence representations, we capture the various ways in whi n be applied to obtain sentence representations. One option is to use a simple template-based design to simplify the contextual associations a sentence encoder makes with a given term, similar to how May et al. (2019)</ref> proposed to measure (but not remove) bias in sentence representations. For example, each word can be slotted into templates such as "This is &lt; mmonly known as the effect size. An effect size with absolute value closer to 0 represents lower bias.</p><p>To measure the bias present in sentence representations, we use the method as described in May et al. (2019)</ref> which extended WEAT to the Sentence Encoder Association Test (SEAT). For a given set of words for a particular test, words are converted into sen s with respect to careers, math, and science (Greenwald et al., 2009)</ref>. To evaluate biases in the multiclass religion setting, we modify the Caliskan Tests used in May et al. (2019)</ref> with lexicons used by Manzini et al. (2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2 sentence embeddings with an average of debiased FastText (and BERT) word embeddings using word-level debiasing methods (Bolukbasi et al., 2016)</ref>. BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT representations. SENT-DEBIAS BERT represents our method using diverse templates. We report the average a presentation from average debiased BERT word representations, again debiased using word-level debiasing methods (Bolukbasi et al., 2016)</ref>, and 3) BERT simple adapts May et al. (2019)</ref> by using simple templates to debias BERT sentence representations.</p><p>From Table 4</ref>, SENT-DEBIAS achieves a lower avera vlin et al., 2019)</ref> +0.354 FastText (Bojanowski et al., 2016)</ref> +0.565 BERT word (Bolukbasi et al., 2016)</ref> +0.861 BERT simple (May et al., 2019)</ref> +0.298 SENT-DEBIAS BERT (ours) +0.256</p><p>Table 4</ref>: Comparison of various debiasing methods on sentence embeddings. Fas
nel assumption made in the training phase. These strategies include: modifying the training phase such that it covers a predefined set of downsampling kernels [38,</ref>13]</ref>; using DNNs to capture only a natural-image prior which is decoupled from the SISR task [37,</ref> se. One strategy is to train a CNN super-resolver that gets as inputs both the LR image and the degradation model and assumes that the downsampling kernels belong to a certain set of Gaussian filters [13,</ref>38]</ref>. Another approach builds on the structural prior of CNNs, which promotes signals with spatially recurring patterns (e. on filter. In general, only a few works have considered the blind SISR setting and developed kernel estimation methods [27,</ref>20,</ref>13,</ref>2]</ref>.</p><p>Finally, we would like to highlight major differences be-tween this paper and the work in <ref type="bibr" target= target="#b19">20,</ref>13,</ref>2]</ref>.</p><p>Finally, we would like to highlight major differences be-tween this paper and the work in [13]</ref>, whose "kernel correction" approach may be misunderstood as our "correction filter". In [13]</ref>, three different DNNs (super ke to highlight major differences be-tween this paper and the work in [13]</ref>, whose "kernel correction" approach may be misunderstood as our "correction filter". In [13]</ref>, three different DNNs (super-resolver, kernel estimator, and kernel corrector) are offline trained under the assumption that the downsampling kernel belongs t ted kernel as an input. So, the first major difference is that contrary to our approach, no pre-trained existing DNN methods (other than SRMD [38]</ref>) can be used in [13]</ref>. Secondly, their approach is restricted by the offline training assumptions to very certain type of downsampling kernels, contrary to our approach. Thirdly, t cted by the offline training assumptions to very certain type of downsampling kernels, contrary to our approach. Thirdly, the concepts of these works are very different: The (iterative) correction in [13]</ref> modifies the estimated downsampling kernel, while our correction filter modifies the LR image.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3." strategies (e.g. about 10 dB lower PSNR) they are deferred to Appendix A. All the experiments are performed with the official code of each method. Unfortunately, such code has not been available for [13]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The non-blind setting</head><p>In this section, we assume that the downsampling kernel k is
such as sparsity or non-local similarity [7,</ref>22,</ref>12,</ref>35,</ref>36]</ref>.</p><p>Recently, several works have shown that in practical scenarios where the test data mismatch the training data, the leading DNN methods suffer from a hug
veral works have shown that in practical scenarios where the test data mismatch the training data, the leading DNN methods suffer from a huge performance drop [37,</ref>26,</ref>29]</ref>. Such scenarios include a downsampling kernel which is not the bicubic kernel and is not available at the training phas 6">[37,</ref>4]</ref>; or completely avoid any offline training and instead train a CNN super-resolver from scratch at test time [30,</ref>26]</ref>.</p><p>Contribution. In this work we take a different strategy, inspired by the generalized sampling literature [8,</ref><ref typ ing, where the kernel is unknown, we From left to right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, SRMD [38]</ref>, ZSSR [26]</ref>, proSR [33]</ref>, RCAN [41]</ref>, DBPN [14]</ref>, proSR with c </ref>, and proSR [33]</ref>. We compare our approach to other methods that receive the downsampling kernel k (or its estimation in the blind setting) as an input: ZSSR [26]</ref> and SRMD [38]</ref>. We also compare our method to DPSR [39]</ref>, however, since its results a el with standard deviation 2.5/ √ 2. From left to right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, SRMD [38]</ref>, ZSSR [26]</ref>, proSR [33]</ref>, RCAN [41]</ref>, DBPN [14]</ref>, proSR with c ults have many artifacts. In fact, DPSR average PSNR as produced by its official code is lower by more than 10 dB than the other examined methods (SRMD [38]</ref>, ZSSR [26]</ref>, DBPN [14]</ref>, proSR [33]</ref>, RCAN [41]</ref>, and our prop downsampling kernel with std 4.5/ √ 2.From left to right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, SRMD[38]</ref>, ZSSR[26]</ref>, proSR[33]</ref>, RCAN[41]</ref>, DBPN[14]</ref>, proSR with corr d SISR methods is their sensitivity to the LR image formation model. A network performance tends to drop significantly if it has been trained for one acquisition model and then been tested on another [26,</ref>29,</ref>37]</ref>.</p><p>Recently, different SISR strategies has been proposed with the goal of approach builds on the structural prior of CNNs, which promotes signals with spatially recurring patterns (e.g. natural images) and thus allows to train a super-resolver CNN from scratch at test time [26,</ref>30]</ref>. Another line of work recovers the latent HR image by minimizing a cost function, composed of fidelity and prior terms
32">33,</ref>41]</ref> and the perceptual quality [3,</ref>18,</ref>24,</ref>32]</ref>. However, one main disadvantage of DNN-based SISR methods is their sensitivity to the LR image formation model. A network performance tends to drop significant
with the sampling kernel, to coefficients which fit the reconstruction kernel.</p><p>Several works have used the correction filter approach for image processing [9,</ref>11,</ref>23]</ref>. These works typically propose linear interpolation methods, i.e. the correction filter is followed by a linear reconst
ead><p>The task of Single Image Super-Resolution (SISR) is one of the most examined inverse problems in the past decade [10,</ref>12,</ref>35,</ref>7]</ref>. In this problem, the goal is to reconstruct a latent high-resolution (HR) image from its low-resolution (LR) version, ob are based on hand-crafted prior models such as sparsity or non-local similarity [7,</ref>22,</ref>12,</ref>35,</ref>36]</ref>.</p><p>Recently, several works have shown that in practical scenarios where the test data mismatch the training data, t
[6,</ref>15,</ref>19,</ref>18,</ref>41,</ref>33,</ref>14]</ref>.</p><p>Typically, the performance of SISR approaches is evaluated on test sets with a fixed known acquisition process, with respect to the reconstruction error [6,</ref>14,</ref>15,</ref>19,</ref>33,</ref>41]</ref> and the perceptual quality [3,</ref>18,</ref><ref type="bi [6,</ref>15,</ref>19,</ref>18,</ref>41,</ref>33,</ref>14]</ref>, assume that the observations are obtained using the bicubic kernel. Let us denote by R * the associated sampling opera c kernel. The modified LR can then be inserted into existing leading super-resolvers, such as DBPN [14]</ref>, RCAN [41]</ref>, and proSR [33]</ref>, thus, improving their performance significantly on kernels they have not been trained on. The proposed transformation is performed using a correction filter, right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, SRMD [38]</ref>, ZSSR [26]</ref>, proSR [33]</ref>, RCAN [41]</ref>, DBPN [14]</ref>, proSR with correction, RCAN with correction, DBPN with correc igure" target="#fig_1">2</ref>(c) with a DNN).</p><p>For the experiments in this paper we use DBPN [14]</ref>, RCAN [41]</ref>, and proSR [33]</ref>, but in general any other method with state-of-the-art performance (for bicubic kernel) is expected to give good results. Note that the theoretical motivation he-shelf DNN super-resolvers that serve as f (•) in (10)</ref>: DBPN [14]</ref>, RCAN [41]</ref>, and proSR [33]</ref>. We compare our approach to other methods that receive the downsampling kernel k (or its estimation in the blind setting) as an input: ZSSR <ref type="bibr" t right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, SRMD [38]</ref>, ZSSR [26]</ref>, proSR [33]</ref>, RCAN [41]</ref>, DBPN [14]</ref>, proSR with correction, RCAN with correction, DBPN with correc be robust to different kernels. From left to right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, kernelGAN [2]</ref>, proSR [33]</ref>, RCAN [41]</ref>, DBPN [14]</ref>, proSR with estimated correction, RCAN with estimated correcti more than 10 dB than the other examined methods (SRMD [38]</ref>, ZSSR [26]</ref>, DBPN [14]</ref>, proSR [33]</ref>, RCAN [41]</ref>, and our proposed approach). Therefore, it is not displayed in the tables in the paper.</p></div> <div xmlns=" to right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, SRMD[38]</ref>, ZSSR[26]</ref>, proSR[33]</ref>, RCAN[41]</ref>, DBPN[14]</ref>, proSR with correction, RCAN with correction, DBPN with correcti l with standard deviation 1.5/ √ 2.From left to right and top to bottom: original image, cropped zoom of the original image, bicubic upsampling, kernelGAN[2]</ref>, proSR[33]</ref>, RCAN[41]</ref>, DBPN[14]</ref>, proSR with estimated correction, RCAN with estimated correction
th the developments in deep learning, many SISR methods that are based on Deep Neural Networks (DNNs) have been proposed [6,</ref>15,</ref>19,</ref>18,</ref>41,</ref>33,</ref>14]</ref> showing a great advance in performance with respect to the reconstruction error [6,</ref>14,</ref>15,</ref>19,</ref>33,</ref>41]</ref> and the perceptual quality [3,</ref><ref type="bi operator S * is presented in Figure 2</ref>(a). Most SISR deep learning methods, e.g. [6,</ref>15,</ref>19,</ref>18,</ref>41,</ref>33,</ref>14]</ref>
raining data, clearly outperform other alternative algorithms, e.g. methods that are based on hand-crafted prior models such as sparsity or non-local similarity [7,</ref>22,</ref>12,</ref>35,</ref>36]</ref>.</p><p>Recently, several works have sho
-sampling. In the recent years, along with the developments in deep learning, many SISR methods that are based on Deep Neural Networks (DNNs) have been proposed [6,</ref>15,</ref>19,</ref>18,</ref>41,</ref>33,</ref> ks have employed DNNs for the SISR task, showing a great advance in performance with respect to the reconstruction error [6,</ref>14,</ref>15,</ref>19,</ref>33,</ref>41]</ref> and the perceptual quality <ref type="b followed by sub-sampling. The sampling operator S * is presented in Figure 2</ref>(a). Most SISR deep learning methods, e.g. [6,</ref>15,</ref>19,</ref>18,</ref>41,</ref>33,</ref>
with the sampling kernel, to coefficients which fit the reconstruction kernel.</p><p>Several works have used the correction filter approach for image processing [9,</ref>11,</ref>23]</ref>. These works typically propose linear interpolation methods, i.e. the correction filter is followed by a linear reconst
act, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage supervised learning algorithms to learn the pairwise similarity functions. However, they solve the problem in a local way, wh the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref>Yoshida et al. 2010)</ref>, which usually solve the problem in a discriminative way. These methods calculate the content similarity with the help of TF-IDF, exact-matchi e content information and relation information and to support the researches which study the author name disambiguation task using content information, we construct a new dataset collected from AceKG (Wang et al. 2018b</ref>). The benchmark dataset consists of 130,655 papers from 17,816 distinguished authors. Each sample has the relation information and content infor
e network. They account that papers connected in the network are likely to be written by the same author. Thus constructing the network becomes the critical part of these methods, e.g., paper network (Zhang et al. 2018)</ref>, paper-author network (Zhang and Al Hasan 2017)</ref>. However, either complicated feature engineering or the su o evaluate the proposed method, we collect two real-world author name disambiguation datasets for experiments:</p><p>• AMiner-AND1</ref> . The dataset is released by (Zhang et al. 2018)</ref>, which contains 500 author names for training and 100 author names for testing. We construct the heterogeneous network including papers, co-aut ritten by the same author. Thus constructing the network becomes the critical part of these methods, e.g., paper network (Zhang et al. 2018)</ref>, paper-author network (Zhang and Al Hasan 2017)</ref>. However, either complicated feature engineering or the supervision (Zhang et al. 2018</ref>) is required. "bibr" target="#b13">(Zhang et al. 2018)</ref>, paper-author network (Zhang and Al Hasan 2017)</ref>. However, either complicated feature engineering or the supervision (Zhang et al. 2018</ref>) is required.</p><p>The two categories of methods are like the two sides of the same coin. The first introduces supervision but cannot process h >: This model trains a function to measure the similarity between each pair of papers using the carefully designed pairwise features, including author names, titles, institute names etc.</p><p>AMiner (Zhang et al. 2018</ref>): This model designs a supervised global stage to fine-tune the word2vec result, and designs an unsupervised local stage based on the first stag del with several state-of-the-art models on AMiner-AND and AceKG-AND. In the experiment on AMiner-AND, we use 100 names for testing and compare the result with the results of other models reported in (Zhang et al. 2018</ref>). In the experiment on AceKG-AND, we sample 85 names for testing. Since Louppe et al. and AMiner are supervised algorithms, the results from 5-f
papers. Papers having relation features in common are connected in the HIN. Consequently, We can represent the relation features by preserving the connectivity information of the HIN. We use node2vec (Grover and Leskovec 2016)</ref> to represent these features by v i ∈ R k , where papers are close in the feature space if they have similar relation information.</p></di
papers. Papers having relation features in common are connected in the HIN. Consequently, We can represent the relation features by preserving the connectivity information of the HIN. We use node2vec (Grover and Leskovec 2016)</ref> to represent these features by v i ∈ R k , where papers are close in the feature space if they have similar relation information.</p></di
papers. Papers having relation features in common are connected in the HIN. Consequently, We can represent the relation features by preserving the connectivity information of the HIN. We use node2vec (Grover and Leskovec 2016)</ref> to represent these features by v i ∈ R k , where papers are close in the feature space if they have similar relation information.</p></di

of author name ambiguity becomes evident in many practical scenarios, e.g., scholar searching, influence evaluating and mentor recommendation, which raises the necessity of author name disambiguation (Smalheiser and Torvik 2009)</ref>.</p><p>Author name disambiguation is to split the papers under the same name into several homogeneous groups, which has attracted subst HIN. Once the discriminator cannot distinguish whether the papers are selected by the generator, the generator is guided to find the rules to select the homogeneous papers. To update θ G , we follow (Schulman et al. 2015)</ref> to compute the gradient of V(G, D) by policy gradient:</p><formula xml:id="formula_6">∇ θ G V(G, D) = p i ∈P E p∼G(• |p k ) [∇ θ G log G(p|p

of author name ambiguity becomes evident in many practical scenarios, e.g., scholar searching, influence evaluating and mentor recommendation, which raises the necessity of author name disambiguation (Smalheiser and Torvik 2009)</ref>.</p><p>Author name disambiguation is to split the papers under the same name into several homogeneous groups, which has attracted subst HIN. Once the discriminator cannot distinguish whether the papers are selected by the generator, the generator is guided to find the rules to select the homogeneous papers. To update θ G , we follow (Schulman et al. 2015)</ref> to compute the gradient of V(G, D) by policy gradient:</p><formula xml:id="formula_6">∇ θ G V(G, D) = p i ∈P E p∼G(• |p k ) [∇ θ G log G(p|p

o combine them together to build a unified model which can eliminate the requirement of labeled samples and complicated feature engineering to some extent. Inspired by generative adversarial networks (Goodfellow et al. 2014)</ref>, we may combine the two categories in an adversarial way. In this paper, we propose a unified framework with discriminative module and gene
ify the similarity among papers, content information and relation information are used. The former includes title, abstract, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage super ambiguation. To measure the similarity among papers, the existing methods can be divided into two categories according to the information they focus on. The first are based on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref><ref type="bibr" target="
a local way, which means that they cannot measure the high-order connections among papers. Methods focusing on relation information (Kanani, McCallum, and Pal 2007;</ref>Bekkerman and McCallum 2005)</ref> usually solve the problem on the bibliographic network, where the relation information is represented as edges on the network. They acc
o combine them together to build a unified model which can eliminate the requirement of labeled samples and complicated feature engineering to some extent. Inspired by generative adversarial networks (Goodfellow et al. 2014)</ref>, we may combine the two categories in an adversarial way. In this paper, we propose a unified framework with discriminative module and gene
papers. Papers having relation features in common are connected in the HIN. Consequently, We can represent the relation features by preserving the connectivity information of the HIN. We use node2vec (Grover and Leskovec 2016)</ref> to represent these features by v i ∈ R k , where papers are close in the feature space if they have similar relation information.</p></di
of author name ambiguity becomes evident in many practical scenarios, e.g., scholar searching, influence evaluating and mentor recommendation, which raises the necessity of author name disambiguation (Smalheiser and Torvik 2009)</ref>.</p><p>Author name disambiguation is to split the papers under the same name into several homogeneous groups, which has attracted subst HIN. Once the discriminator cannot distinguish whether the papers are selected by the generator, the generator is guided to find the rules to select the homogeneous papers. To update θ G , we follow (Schulman et al. 2015)</ref> to compute the gradient of V(G, D) by policy gradient:</p><formula xml:id="formula_6">∇ θ G V(G, D) = p i ∈P E p∼G(• |p k ) [∇ θ G log G(p|p
ify the similarity among papers, content information and relation information are used. The former includes title, abstract, introduction and keywords etc. Methods focusing on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Yoshida et al. 2010</ref>) usually leverage super ambiguation. To measure the similarity among papers, the existing methods can be divided into two categories according to the information they focus on. The first are based on the content information (Han et al. 2004;</ref>Huang, Ertekin, and Giles 2006;</ref>Louppe et al. 2016;</ref><ref type="bibr" target="


e pairwise similarity functions. However, they solve the problem in a local way, which means that they cannot measure the high-order connections among papers. Methods focusing on relation information (Kanani, McCallum, and Pal 2007;</ref>Bekkerman and McCallum 2005)</ref> usually solve the problem on the bibliographic network, where the r
papers. Papers having relation features in common are connected in the HIN. Consequently, We can represent the relation features by preserving the connectivity information of the HIN. We use node2vec (Grover and Leskovec 2016)</ref> to represent these features by v i ∈ R k , where papers are close in the feature space if they have similar relation information.</p></di
papers. Papers having relation features in common are connected in the HIN. Consequently, We can represent the relation features by preserving the connectivity information of the HIN. We use node2vec (Grover and Leskovec 2016)</ref> to represent these features by v i ∈ R k , where papers are close in the feature space if they have similar relation information.</p></di
alue the firm even if the mistakes are made unintentionally instead of deliberately. Some recent news reported that these numerical errors brought about huge reputation risk, and even economic losses [1]</ref>. Since the documents disclosed by the firm usually have the force of law, these errors should be thoroughly removed before officially publishing.</p><p>Extant s ill ongoing. StatCheck uses rule-based program to check inconsistency errors in the null-hypothesis significance testing, presented in the academic papers in major psychology journals. A recent study [1]</ref> published a system called AutoDoc, and introduced the module of cross-checking among only textual paragraphs. Since tables are more efficient to organize and su only textual paragraphs. Since tables are more efficient to organize and summarize data, there are much more numerical facts in tables than textual paragraphs. Therefore, as an important extension to [1]</ref>, we propose Automatic Numerical Cross-Checking over Tables (ANCOT) in this study.</p><p>The key module of such a system is to identify whether a pair of two tab org/ns/1.0"><head n="6">RELATED WORK</head><p>Claim-Checking is an important issue in academic, financial, and politic fields. It has attracted a lot of research interests in recent years. Cao et al. [1]</ref> propose a system to cross-check numerical facts by extracting structured formulas from textual paragraph in financial documents. Our study extend their work to
numerical facts in tables. And we adopt an end-to-end approach to avoid the extraction of explicit structured information which is laborious when collecting the labelling dataset. Vlachos and Riedel [17]</ref> propose a dataset to verify the claims made by public figures. Verifying such claims includes detecting whether a statement in check-worthy <ref type="bibr" t
and Schipper [2]</ref> find that investors believe that even immaterial errors mean weak corporate governance or poor quality of financial reports. Fang, Huang, and Wang [4]</ref> reveal that errors would affect the investors' reactions to firm's earnings surprises and abilities to detect fraud. Overall, investors' attention to the accoun
from table headers. Based on the extracted tables, there are many understanding tasks, such as linking text to table cells [6]</ref>, table cell search for a given query [15]</ref>, ad hoc search over tables [18]</ref>, transforming complex tables to the form that can be stored in a database <ref type="bibr
tical domains such as the field of finance, most of tables are matrixtype and have explicit or implicit hierarchical headers. There are some studies about recognizing this type of tables. Fang et al. [3]</ref> proposed a Random Forest classification to identify the complex headers in tables; Nagy et al. [11]</ref> leveraged rule-based me
leveraged rule-based method to extract data categories and data hierarchies from table headers. Based on the extracted tables, there are many understanding tasks, such as linking text to table cells [6]</ref>, table cell search for a given query [15]</ref>, ad hoc search over tables [18]</ref>, transformin
a given query [15]</ref>, ad hoc search over tables [18]</ref>, transforming complex tables to the form that can be stored in a database [14]</ref>. Our task, cross-checking over numerical tables, is also a table understanding task based on extracted table structure.</p></div> <div xmlns="http://www.tei-c
leveraged rule-based method to extract data categories and data hierarchies from table headers. Based on the extracted tables, there are many understanding tasks, such as linking text to table cells [6]</ref>, table cell search for a given query [15]</ref>, ad hoc search over tables [18]</ref>, transformin
from table headers. Based on the extracted tables, there are many understanding tasks, such as linking text to table cells [6]</ref>, table cell search for a given query [15]</ref>, ad hoc search over tables [18]</ref>, transforming complex tables to the form that can be stored in a database <ref type="bibr
tical domains such as the field of finance, most of tables are matrixtype and have explicit or implicit hierarchical headers. There are some studies about recognizing this type of tables. Fang et al. [3]</ref> proposed a Random Forest classification to identify the complex headers in tables; Nagy et al. [11]</ref> leveraged rule-based me
a given query [15]</ref>, ad hoc search over tables [18]</ref>, transforming complex tables to the form that can be stored in a database [14]</ref>. Our task, cross-checking over numerical tables, is also a table understanding task based on extracted table structure.</p></div> <div xmlns="http://www.tei-c
>Materials and methods</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model architecture of TransformerCPI</head><p>The model we proposed is based on the transformer architecture (Vaswani et al., 2017)</ref>, which was originally devised for neural machine translation tasks. Transformer is an autoregressive encoderdecoder model using a combinatio
ext xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Identifying compound-protein interaction (CPI) plays an import role in discovering hit compounds (Vamathevan et al., 2019)</ref>. Conventional methods, such as structure-based virtual screening and ligand-based virtual screening, have been studied for decades and ga
">(Bleakley and Yamanishi, 2009;</ref>Cheng et al., 2012;</ref>Gonen, 2012;</ref>Jacob and Vert, 2008;</ref>van Laarhoven et al., 2011;</ref>Wang et al., 2011;</ref>Wang and Zeng, 2013;</ref><ref type="bibr" target=
ich satisfies our first rule. GLASS database used IC 50 , Ki and EC 50 as the binding affinity values, which were transformed into negative logarithm, pIC 50 , pK i and pEC 50 . Following early works (Liu et al., 2007;</ref>Wan et al., 2019)</ref>, a threshold of 6.0 was set to divide original dataset into a positive set and a negative
s binary classification task, compounds can be considered as 1D sequences or molecular graphs (i.e. traditionally called 2D structures), and protein sequences can be regarded as 1D sequences. DeepDTA (Ozturk et al., 2018)</ref> used convolutional neural networks (CNNs) to extract low-dimensional real-valued features of compounds and proteins, and then concatenated tw
milar semantics map to the vectors that are close to each other. There have been some works to apply word2vec to represent protein sequences (Kimothi et al., 2016;</ref>Kobeissy et al., 2015;</ref>Mazzaferro and Carlo, 2017;</ref>Yang et al., 2018)</ref>, in which the amino acid sequence o
rotein descriptors as input features, which are fixed during training process and contain less information than that of end-to-end learning (Hamanaka et al., 2017;</ref>Tian et al., 2016;</ref>Wan and Zeng, 2016)</ref>. Regarding the CPI problem as binary classification task, compounds can be considered as
rted in DUD-E and MUV datasets (Sieg et al., 2019)</ref>, raising extensive concerns in the field of drug design. Structure-based virtual screening, 3D-CNN-based models (Chen et al., 2019)</ref> and other models trained on DUD-E dataset (Sieg et al., 2019)</ref> have been pointed out to make predictions mai
nd structure as molecular graph, CPI-GNN (Tsubaki et al., 2019)</ref> and GraphDTA (Nguyen et al., 2019)</ref> used graph neural networks (Scarselli et al., 2009)</ref> (GNNs) and graph CNNs (Kipf and Welling, 2016)</ref> (GCNs) instead of CNNs to learn the representation of
ich satisfies our first rule. GLASS database used IC 50 , Ki and EC 50 as the binding affinity values, which were transformed into negative logarithm, pIC 50 , pK i and pEC 50 . Following early works (Liu et al., 2007;</ref>Wan et al., 2019)</ref>, a threshold of 6.0 was set to divide original dataset into a positive set and a negative
b5">Cheng et al., 2012;</ref>Gonen, 2012;</ref>Jacob and Vert, 2008;</ref>van Laarhoven et al., 2011;</ref>Wang et al., 2011;</ref>Wang and Zeng, 2013;</ref>Yamanishi et al., 2008)</ref>.</p><p>With the rapid devel
b5">Cheng et al., 2012;</ref>Gonen, 2012;</ref>Jacob and Vert, 2008;</ref>van Laarhoven et al., 2011;</ref>Wang et al., 2011;</ref>Wang and Zeng, 2013;</ref>Yamanishi et al., 2008)</ref>.</p><p>With the rapid devel
mpound information and protein information at the same time in a unified model (Bleakley and Yamanishi, 2009;</ref>Cheng et al., 2012;</ref>Gonen, 2012;</ref>Jacob and Vert, 2008;</ref>van Laarhoven et al., 2011;</ref><ref type="bibr" target="#b44
, Ki and EC 50 as the binding affinity values, which were transformed into negative logarithm, pIC 50 , pK i and pEC 50 . Following early works (Liu et al., 2007;</ref>Wan et al., 2019)</ref>, a threshold of 6.0 was set to divide original dataset into a positive set and a negative set. Then, we selected protein-compound pairs that foll
mpound information and protein information at the same time in a unified model (Bleakley and Yamanishi, 2009;</ref>Cheng et al., 2012;</ref>Gonen, 2012;</ref>Jacob and Vert, 2008;</ref>van Laarhoven et al., 2011;</ref><ref type="bibr" target="#b44
, Ki and EC 50 as the binding affinity values, which were transformed into negative logarithm, pIC 50 , pK i and pEC 50 . Following early works (Liu et al., 2007;</ref>Wan et al., 2019)</ref>, a threshold of 6.0 was set to divide original dataset into a positive set and a negative set. Then, we selected protein-compound pairs that foll
ormation rather than interaction features, such as ligand patterns. Previous chemogenomics-based CPI prediction models used inappropriate datasets to build deep learning models, such as DUD-E dataset (Mysinger et al., 2012)</ref> and Human dataset (Liu et al., 2015;</ref>Tsubaki et al., 2019)</ref>, where DUD-E, MUV, Human and BindingDB only occur in one class, and negative samples were generated by algorithms that may introduce undetectable noise (Liu et al., 2015;</ref>Mysinger et al., 2012)</ref>. These datasets can be separated by ligand information, and cannot guarantee that models learn protein information or interaction features.<
nd rule to construct the final GPCR dataset. Our final GPCR dataset comprises 5359 ligands, 356 proteins and 15 343 CPI among them.</p><p>Second, we constructed a Kinase dataset based on KIBA dataset (Tang et al., 2014)</ref>. KIBA score was developed to combine various bioactivity types, including IC 50 , K i and K d , and to remove inconsistency between different b BA score was developed to combine various bioactivity types, including IC 50 , K i and K d , and to remove inconsistency between different bioactivity types, which greatly reduced bias in the dataset (Tang et al., 2014)</ref>. The KIBA dataset contains 467 targets and 52 498 ligands collected from ChEMBL and STITCH (Szklarczyk et al., 2 teins with at least 10 interactions, gaining a total of 229 proteins and 2111 compounds. Then, we used the suggested threshold KIBA value of 12.1 (He et al., 2017;</ref>Tang et al., 2014)</ref> to divide dataset into a positive set and a negative set, and selected protein-compound pairs where compounds occur in both positive set and neg
="bibr" target="#b9">(Gao et al., 2018)</ref>. Human dataset and C.elegans dataset include positive CPI pairs from DrugBank 4.1 (Wishart et al., 2008)</ref> and Matador (Gunther et al., 2007)</ref> and highly credible negative CPI samples obtained using a systematic screening framework (Liu et al., 2015)</
ever, some cases are not suitable to apply conventional screening methods, where the protein three-dimensional (3D) structure is unknown or the amount of known ligand dataset is too small. Therefore, Bredel and Jacoby (2004)</ref> introduced a novel perspective called chemogenomics to predict CPI without protein 3D structures. A variety of machine learning based algor
b5">Cheng et al., 2012;</ref>Gonen, 2012;</ref>Jacob and Vert, 2008;</ref>van Laarhoven et al., 2011;</ref>Wang et al., 2011;</ref>Wang and Zeng, 2013;</ref>Yamanishi et al., 2008)</ref>.</p><p>With the rapid devel
b5">Cheng et al., 2012;</ref>Gonen, 2012;</ref>Jacob and Vert, 2008;</ref>van Laarhoven et al., 2011;</ref>Wang et al., 2011;</ref>Wang and Zeng, 2013;</ref>Yamanishi et al., 2008)</ref>.</p><p>With the rapid devel
allelism, it can be detrimental to overall performance. To overcome this, several prior techniques have tried to predicate only those instances of H2P branches which have low confidence of prediction [7]</ref>, [11]</ref>- [14]</ref>. Policies like Diverge Merge Processor (DMP) <ref type="bibr" target="#b6" low confidence of prediction [7]</ref>, [11]</ref>- [14]</ref>. Policies like Diverge Merge Processor (DMP) [7]</ref>, [15]</ref> use careful compiler profiling to select target H2P branches, and then throttle their application using run-time moni (program counters) using simple heuristics, and uses a novel hardware mechanism to accurately detect control flow convergence using generic patterns of convergence. This is unlike previous approaches [7]</ref>, [12]</ref>- [14]</ref> that were dependent upon compiler analysis and profiling. With small chang gent conditional branches. We define convergent branches as those branches whose taken and not-taken paths can converge to some later point in the program (using the same convergence criterion as DMP [7]</ref>). Loops are naturally converging and contribute to another 13%. Remaining 13% conditional branches exhibit non-converging control flows. These observations lead tion level parallelism and can elongate the critical path. To mitigate this, past approaches have dynamically applied predication only on branch instances having low confidence from branch prediction [7]</ref>, [13]</ref>, [14]</ref>.</p><p>Wish Branches [12]</ref> relies on t f>) uses the compiler to identify simple, short hammocks which can be predicated dynamically (and profitably) and fetches both the directions of the hammock in hardware. Diverge Merge Processor (DMP) [7]</ref> improves upon both Wish Branches and DHP. DMP uses compiler analysis-and-profiling to identify frequently mispredicting branch candidates and modifies the compi making it effectively transparent. Any instruction on the predicated-false path, that does not produce register or flags (like stores or branches), instantly releases its resources.</p><p>Prior works [7]</ref>, [11]</ref> have relied on select-micro-op based approaches to handle correctness of data dependencies after the predicated regio king approach. Using these less intrusive micro-architectural changes, we are able to achieve register transparency without resorting to complex RAT recovery mechanisms or re-execution as proposed in [7]</ref>, [11]</ref>.</p><p>3) Predicated-False Path Loads/Stores: All ACB body loads and stores are stalled in the OOO-IQ until ACB resol tional stalls incurred. This was also vulnerable to bad tuning. Dynamo was designed to holistically evaluate this trade-off for ACB.  In this section, we compare against Diverge-Merge Processor (DMP) [7]</ref>, which relies on changes to the compiler, ISA and micro-architecture to perform selective predication on low confidence branch predictions. We modeled the enhan ]</ref>. Popular ISAs support static predication [17]</ref>, [18]</ref> but due to large overheads, the realistic benefits are diminished [7]</ref>, [12]</ref>. Wish Branches [12]</ref> rely on the compiler to supply predicated code but applies p frequently occurring basic blocks. Generalized multipath execution was proposed in [34]</ref>- [36]</ref>. Diverge-Merge Processor (DMP) [7]</ref>, [15]</ref> uses branch prediction confidence to selectively predicate conditional branches, while using the compiler for converg
t applies predication dynamically only on less predictable instances. Dynamic Hammock Predication [11]</ref> targets only small, simple hammocks. Hyperblock predication [33]</ref> uses compiler profiling to predicate frequently occurring basic blocks. Generalized multipath execution was proposed in [34]</r
imes more speculation bound than Skylake. These results clearly motivate the need for mitigating branch mis-speculations, especially since future OOO processors are expected to scale deeper and wider [9]</ref>. As it gets harder to improve branch prediction, there is an urgent need to investigate solutions to address this problem. One possible solution is to limit spe
n (DMP or ACB) changes the branch history that is being learned by the branch predictor. It is well known that speculative update of the branch history is very important for branch predictor accuracy [30]</ref>. In the baseline, branch history is always speculatively updated, assuming the previous branch predictions were correct. When a branch mispredicts, a pipeline
arget="#b22">[23]</ref> tabletmark [24]</ref>, geekbench [25]</ref>, compression, 3dmark [26]</ref>, eembc [27]</ref>, chrome Client lammps [28]</ref>, parsec [29]</ref> Server mance. Another side-effect of ACB is
b24">[25]</ref>, compression, 3dmark [26]</ref>, eembc [27]</ref>, chrome Client lammps [28]</ref>, parsec [29]</ref> Server mance. Another side-effect of ACB is noticeable in the largest negative outlier (omnetpp), where the mis-speculations slightly increase after applying
int is similar in parameters to the Skylake processor [1]</ref>. Performance potential for future processors is bound by the problem of mis-speculation.</p><p>predictors [6]</ref>- [8]</ref>. These branches cost not only performance but also significant power overheads because of pipeline flush and re-executi e them very accurate. However, there remains a class of branches that are still hard to predict. Many such branches are data dependent branches and are difficult to predict using just program history [6]</ref>.</p><p>We characterized branch mispredictions on our selected workloads 2</ref> . We found that on average, in a given program
imes more speculation bound than Skylake. These results clearly motivate the need for mitigating branch mis-speculations, especially since future OOO processors are expected to scale deeper and wider [9]</ref>. As it gets harder to improve branch prediction, there is an urgent need to investigate solutions to address this problem. One possible solution is to limit spe
ibr" target="#b6">[7]</ref>, [11]</ref>- [14]</ref>. Policies like Diverge Merge Processor (DMP) [7]</ref>, [15]</ref> use careful compiler profiling to select target H2P branches, and then throttle their application using run-time monitoring of branch prediction confidence. T g static/profiling-based branch selection criteria) can be very different from actual testing data seen during execution. Since many H2P branches are data dependent, the efficacy of compiler analyses [15]</ref> is dependent on the quality of profiled input. As a result, application of DMP and similar schemes may result in performance inversions on certain workloads. e="bibr" target="#b6">[7]</ref>, which relies on changes to the compiler, ISA and micro-architecture to perform selective predication on low confidence branch predictions. We modeled the enhanced DMP [15]</ref>, which improved upon the DMP solution through profile-assisted compiler techniques.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison wit s a detailed cost-benefit analysis through static compiler-profiling, the work itself acknowledges its limitation in being able to account for only fetch related costs and not execution related costs [15]</ref>. Compiler-based techniques are also susceptible to inefficiencies arising from differences between input sets used for profiling and actual execution.</p><p>F alized multipath execution was proposed in [34]</ref>- [36]</ref>. Diverge-Merge Processor (DMP) [7]</ref>, [15]</ref> uses branch prediction confidence to selectively predicate conditional branches, while using the compiler for convergence and branch selection information. DM
mple hammocks. Hyperblock predication [33]</ref> uses compiler profiling to predicate frequently occurring basic blocks. Generalized multipath execution was proposed in [34]</ref>- [36]</ref>. Diverge-Merge Processor (DMP) [7]</ref>, [15]</ref> u
type="bibr" target="#b32">[33]</ref> uses compiler profiling to predicate frequently occurring basic blocks. Generalized multipath execution was proposed in [34]</ref>- [36]</ref>. Diverge-Merge Processor (DMP) [7]</ref>, [15]</ref> uses branch prediction confidence to selecti
NNs is the ability to design and reliably train very deep CNN models. In contrast, it is not yet clear how to properly train deep GCN architectures, where several works have studied their limitations [19,</ref>43,</ref>53]</ref>. Stacking more layers into a GCN leads to the common vanishing gradient proble arning for GCNs</head><p>Designing deep GCN architectures [43,</ref>53]</ref> is an open problem in the graph learning space. Recent work [19,</ref>43,</ref>53]</ref> suggests that GCNs do not scale well to deep architectures, since stacking mul s to the common vanishing gradient problem. This means that back-propagating through these networks causes oversmoothing, eventually leading to features of graph vertices converging to the same value [19]</ref>. Due to these limitations, most state-of-the-art GCNs are no deeper than 4 layers [53]</ref>.</p><p>Vanishing gradients is not o select graph neighbors for each node based on graph structure. As with other works, their network is limited to a small number of layers (6)</ref>. Recently, Li et al. [19]</ref> studied the depth limitations of GCNs and showed that deep GCNs can cause over-smoothing, which results in features at vertices within each connected componen
="bibr" target="#b31">32,</ref>37]</ref>. More recent work focuses on directly processing unordered point cloud representations [27,</ref>29,</ref>8,</ref>14,</ref>49]</ref>. The recent EdgeConv method by Wang et al
[53]</ref>.</p><p>Vanishing gradients is not a foreign phenomenon in the world of CNNs. It also posed limitations on the depth growth of these types of networks. ResNet [11]</ref> provided a big step forward in the pursuit of very deep CNNs when it introduced residual connections between input and output layers. These connections massiv this gap and show that the majority of these drawbacks can be remedied by borrowing several orthogonal tricks from CNNs. Deep CNNs achieved a huge boost in performance with the introduction of ResNet [11]</ref>. By adding residual connections between inputs and outputs of layers, ResNet tends to alleviate the vanishing gradient problem. DenseNet <ref type="bibr" targ high complexity in back-propagation. As such, most state-of-the-art GCN models are usually no more than 3 layers deep [53]</ref>. Inspired by the huge success of ResNet [11]</ref>, DenseNet [13]</ref> and Dilated Convolutions [51]</ref>,  we transfer these ideas to GCNs to un </ref> (Reference) show that residual graph connections play an essential role in training deeper networks, as they tend to result in more stable gradients. This is analogous to the insight from CNNs [11]</ref>. When the residual graph connections between layers are removed (i.e. in PlainGCN-28), performance dramatically degrades (-12% mIoU). In Appendices A and B, w kpropagation and the common vanishing gradient problem.</p><p>Many difficulties facing GCNs nowadays (e.g. vanishing gradients and limited receptive field) were also present in the early days of CNNs [11,</ref>51]</ref>. We bridge this gap and show that the majority of these drawbacks can be remedied by borrowing several orthogonal tric
iven a graph representation of the scene [17]</ref>. Graphs are also used to model human joints for action recognition in video [47,</ref>16]</ref>. GCNs are a perfect candidate for 3D point cloud processing, especially since the unstructured nature of point clouds poses a representational challenge for sy (without dilation), and with fixed edges. We also study the effect of different parameters, e.g. number of k-NN neighbors (4,</ref>8,</ref>16,</ref>32)</ref>, number of filters (32,</ref>64,</ref>128)</ref>, and
e="bibr" target="#b27">28,</ref>32,</ref>37]</ref>. More recent work focuses on directly processing unordered point cloud representations [27,</ref>29,</ref>8,</ref>14,</ref>49]</ref>. epresentations. There are different variants of those two functions. For example, the aggregation function can be a mean aggregator [18]</ref>, a max-pooling aggregator [27,</ref>10,</ref>42]</ref>, an attention aggregator [39]</ref> or an LSTM a ng consecutive GCN layers to aggregate local information, and outputs a learned graph representation with 4096 vertices. The fusion and MLP prediction blocks follow a similar architecture as PointNet [27]</ref> and DGCNN [42]</ref>. The fusion block is used to fuse the global and multi-scale local features. It takes as input the extract
ng unordered point cloud representations [27,</ref>29,</ref>8,</ref>14,</ref>49]</ref>. The recent EdgeConv method by Wang et al. [42]</ref> applies GCNs to point clouds. In particular, they propose a dynamic edge c
rocess, where an image is reconstructed given a graph representation of the scene [17]</ref>. Graphs are also used to model human joints for action recognition in video [47,</ref>16]</ref>. GCNs are a perfect candidate for 3D point cloud processing, especially since the unstructured nature of point clouds
onnections between input and output layers. These connections massively alleviated the vanishing gradient problem. Today, ResNets can reach 152 layers and beyond. Further extension came with DenseNet [13]</ref>, where more connections are introduced across layers. More layers could potentially mean more spatial information loss due to pooling. This issue was also add troduction of ResNet [11]</ref>. By adding residual connections between inputs and outputs of layers, ResNet tends to alleviate the vanishing gradient problem. DenseNet [13]</ref> takes this idea a step further and adds connections across layers as well. Dilated Convolutions [51]</ref> are a more recent ap tate-of-the-art GCN models are usually no more than 3 layers deep [53]</ref>. Inspired by the huge success of ResNet [11]</ref>, DenseNet [13]</ref> and Dilated Convolutions [51]</ref>,  we transfer these ideas to GCNs to unleash their full potential. This enables much deeper ormula_3">G l+1 = H(G l , W l ) = F(G l , W l ) + G l = G res l+1 + G l .</formula><p>(3)</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Dense Connections in GCNs</head><p>DenseNet [13]</ref> was proposed to exploit dense connectivity among layers, which improves information flow in the network and enables efficient reuse of features among layers. s layers. Since we fuse GCN representations densely, we refer to our dense model as DenseGCN. The growth rate of DenseGCN is equal to the dimension D of the output graph (similar to DenseNet for CNNs [13]</ref>). For example, if F produces a D dimensional vertex feature, where the vertices of the input graph G 0 are D 0 dimensional, the dimension of each vertex featu
loud dataset by 3.7%.</p><p>Contributions. We summarize our contributions as three fold. (1)</ref> We adapt residual/dense connections, and dilated convolutions to GCNs. (2)</ref> We present extensive experiments on point cloud data, showing the effect of each of these new layers to the stability and performance of training deep GCNs. We "bibr" target="#b49">50]</ref>, where accurate modelling of user interactions leads to improved product recommendations. Graphs are also popular modes of representation in natural language processing [2,</ref>23]</ref>, where they are used to represent complex relations between large text units.</p><p>GCNs also find many applications in
be interesting to study different distance measures to compute dilated k-NN, constructing graphs with different k at each layer, better dilation rate schedules [4,</ref>41]</ref> for GCNs, and combining residual and dense connections.</p><p>We also point out that, for the specific task of point cloud semantic segmentation, the common ap
l proteins for drug discovery [54,</ref>40]</ref>, enhance predictions of recommendation engines [24,</ref>50]</ref>, efficiently segment large point clouds [42]</ref>, among other fields. * equal contribution A key reason behind the success of . Understanding the bioactivities of these molecules can have substantial impact on drug discovery. Another popular use of graphs is in recommendation engines [24,</ref>50]</ref>, where accurate modelling of user interactions leads to improved product recommendations. Graphs are also popular modes of representation in natural language p
ss [7,</ref>9,</ref>22]</ref>, there are several attempts to adopt GNNs to learn with heterogeneous networks [14,</ref>23,</ref>26,</ref>27]</ref>. However, these works face several iss d.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Heterogeneous GNNs</head><p>Recently, studies have attempted to extend GNNs for modeling heterogeneous graphs. Schlichtkrull et al. [14]</ref> propose the relational graph convolutional networks (RGCN) to model knowledge graphs. RGCN keeps a distinct linear projection weight for each edge type. Zhang s. We use the implementation provided in PyG.</p><p>The second class considered is several dedicated heterogeneous GNNs as baselines, including:</p><p>• Relational Graph Convolutional Networks (RGCN) [14]</ref>, which keeps a different weight for each relationship, i.e., a relation triplet. We use the implementation provided in PyG. • Heterogeneous Graph Neural Netwo Ns keep 3 layers so that the receptive fields of each network are exactly ‡ Unless other stated, HGT refers to HGT +RT E +H e t e r .</p><p>GNN Models GCN [9]</ref> RGCN [14]</ref> GAT [22]</ref> HetGNN [27]</ref> HAN [23]</ref> HGT the same. All
denoted as ⟨τ (s), ϕ(e), τ (t)⟩. Naturally, ϕ(e) −1 represents the inverse of ϕ(e). The classical meta path paradigm [17]</ref>[18]</ref>[19]</ref> is defined as a sequence of such meta relation.</p><p>Notice that, to better model real-world heterogeneous networks, we assume that there may exist multiple , such as node classification, clustering, ranking and representation learning [3,</ref>[17]</ref>[18]</ref>[19]</ref>, while the dynamic perspective of HGs has not been extensively explored and studied.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Ne
vector back to its typespecific distribution, indexed by its node type τ (t). To do so, we apply a linear projection A-Linear τ (t ) to the updated vector H (l ) [t], followed by residual connection [8]</ref> as:</p><formula xml:id="formula_11">H (l ) [t] = A-Linear τ (t ) σ H (l ) [t] + H (l −1) [t].<label>(5)</label></formula><p>In this way, we get the l-th HGT lay
vector back to its typespecific distribution, indexed by its node type τ (t). To do so, we apply a linear projection A-Linear τ (t ) to the updated vector H (l ) [t], followed by residual connection [8]</ref> as:</p><formula xml:id="formula_11">H (l ) [t] = A-Linear τ (t ) σ H (l ) [t] + H (l −1) [t].<label>(5)</label></formula><p>In this way, we get the l-th HGT lay
vector back to its typespecific distribution, indexed by its node type τ (t). To do so, we apply a linear projection A-Linear τ (t ) to the updated vector H (l ) [t], followed by residual connection [8]</ref> as:</p><formula xml:id="formula_11">H (l ) [t] = A-Linear τ (t ) σ H (l ) [t] + H (l −1) [t].<label>(5)</label></formula><p>In this way, we get the l-th HGT lay
ires the calculation of all node representations per layer, making it not scalable for Web-scale graphs. To address this issue, different sampling-based methods [1,</ref>2,</ref>7,</ref>29]</ref> have been proposed to train GNNs on a subset of nodes. However, directly using them
have features from affiliated scholars, and coauthorships obviously differ from citation links; Second, OAG has been consistently evolving, e.g., 1) the volume of publications doubles every 12 years [4]</ref>, and 2) the KDD conference was more related to database in the 1990s whereas more to machine learning in recent years; Finally, OAG contains hundreds of million
ires the calculation of all node representations per layer, making it not scalable for Web-scale graphs. To address this issue, different sampling-based methods [1,</ref>2,</ref>7,</ref>29]</ref> have been proposed to train GNNs on a subset of nodes. However, directly using them
div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Web-Scale Datasets</head><p>To examine the performance of the proposed model and its realworld applications, we use the Open Academic Graph (OAG) [16,</ref>20,</ref>28]</ref> as our experimental basis. OAG consists of more than 178 million nodes and 2.2
n explored for mining heterogeneous graphs [17]</ref>. One of the classical paradigms is to define and use meta paths to model heterogeneous structures, such as PathSim [18]</ref> and metapath2vec [3]</ref>. Recently, in view of graph neural networks' (GNNs) success [7,</ref><r s to target node t, its meta relation is denoted as ⟨τ (s), ϕ(e), τ (t)⟩. Naturally, ϕ(e) −1 represents the inverse of ϕ(e). The classical meta path paradigm [17]</ref>[18]</ref>[19]</ref> is defined as a sequence of such meta relation.</p><p>Notice that, to better model real-world heterogeneous networks, of research on mining heterogenous graphs, such as node classification, clustering, ranking and representation learning [3,</ref>[17]</ref>[18]</ref>[19]</ref>, while the dynamic perspective of HGs has not been extensively explored and studied.</p></div> <div xmlns="http://www
div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Web-Scale Datasets</head><p>To examine the performance of the proposed model and its realworld applications, we use the Open Academic Graph (OAG) [16,</ref>20,</ref>28]</ref> as our experimental basis. OAG consists of more than 178 million nodes and 2.2
br" target="#b34">[35]</ref> analyze the asymptotic contrastive loss and propose new metrics to measure the representation quality. All of these works sample negative examples from p(x). Arora et al. [1]</ref> theoretically analyze the effect of contrastive representation learning on a downstream, "average" classification task and provide a generalization bound for th an observation x to a point on a hypersphere with radius 1/t, where t is the temperature scaling hyperparameter. Without loss of generality, we set t = 1 for all theoretical results.</p><p>Similar to [1]</ref>, we assume an underlying set of discrete latent classes C that represent semantic content, i.e., similar pairs (x, x + ) have the same latent class. Denoting th e define the supervised loss for the representation f as</p><formula xml:id="formula_17">L Sup (T , f ) = inf W∈R K×d L Softmax (T , W f ).<label>(10)</label></formula><p>In line with the approach of [1]</ref> we analyze the supervised loss of a mean classifier [30]</ref>, where for each class c, the rows of W are set to the mean of repr this on the generalization error is small if the dataset size T is much larger than N and M, as is commonly the case. The dependence on on N and T in Theorem 5 is roughly equivalent to the result in [1]</ref>, but the two bounds are not directly comparable since the proof strategies differ.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</he i=1 , {b i } M i=1 ) = log    1 + N max 1 τ − 1 N N ∑ i=1 a i − τ + 1 M M ∑ i=1 b i , e −1    .</formula><p>In order to derive our bound we will exploit a concentration of measure result due to [1]</ref>. They consider an objective of the form</p><formula xml:id="formula_62">L un ( f ) = E ({ f (x) f (x i ) − f (x + ) } k i=1 )</formula><p>where (x, x + , x − 1
get="#b20">21,</ref>25]</ref>.</p><p>Recently, self-supervised representation learning algorithms that use a contrastive loss have outperformed even supervised learning [2,</ref>14,</ref>16,</ref>24]</ref>. The key idea of contrastive learning is of the positive and unlabeled sample sizes M and N in the objective function, in line with the observation that a larger number of negative/positive examples in the objective leads to better results [2,</ref>16]</ref>. The last two terms in the bound grow slowly with N, but the effect of this on the generalization error is small if the Examples in computer vision include random cropping and flipping [27]</ref>, or different views of the same scene [33]</ref>. Chen et al. [2]</ref> extensively study verious data augmentation methods. For language, Logeswaran and Lee [24]</ref> treat the context sentences as p tp://www.tei-c.org/ns/1.0"><head n="5.1">CIFAR10 and STL10</head><p>First, for CIFAR10 [23]</ref> and STL10 [6]</ref>, we implement SimCLR [2]</ref> with ResNet-50 [15]</ref> as the encoder architecture and use the Adam optimizer [19]</ref> with l [15]</ref> as the encoder architecture and use the Adam optimizer [19]</ref> with learning rate 0.001 and weight decay 1e − 6. Following [2]</ref>, we set the temperature t = 0.5 and the dimension of the latent vector to 128. All the models are trained for 400 epochs and evaluated by training a linear clas arameter tuning and pretraining, but none of them worked.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experiment Details</head><p>Cifar10 and STL10 We adopt PyTorch to implement SimCLR [2]</ref> with Resnet-50 [15]</ref> as the encoder architecture and use the Adam optimizer [19]</ref> with l
rget="#b24">25]</ref>.</p><p>Recently, self-supervised representation learning algorithms that use a contrastive loss have outperformed even supervised learning [2,</ref>14,</ref>16,</ref>24]</ref>. The key idea of contrastive learning is to contrast semantically similar (posi
related to unbiased PU learning, where the unlabeled data is used as negative examples, but down-weighted appropriately [10,</ref>11,</ref>22]</ref>. While these works focus on zero-one losses, we here address the contrastive loss, where existing PU estimators are not directly applicable.</p></div> <div xml
up (T , f ) = inf W∈R K×d L Softmax (T , W f ).<label>(10)</label></formula><p>In line with the approach of [1]</ref> we analyze the supervised loss of a mean classifier [30]</ref>, where for each class c, the rows of W are set to the mean of representations</p><formula xml:id="formula_18">µ c = E x∼p(•|c) [ f (x)</formula><p>]. We will
lgorithms that use a contrastive loss have outperformed even supervised learning [2,</ref>14,</ref>16,</ref>24]</ref>. The key idea of contrastive learning is to contrast semantically similar (positive) and dissimilar (negative) pairs of data points, encouraging the representa of the same scene [33]</ref>. Chen et al. [2]</ref> extensively study verious data augmentation methods. For language, Logeswaran and Lee [24]</ref> treat the context sentences as positive samples to efficiently learn sentence representations. Srinivas et al. [31]</ref> impro TREC) [34]</ref>, and paraphrase identification (MSRP) [8]</ref>. Our experimental settings follow those for quick-thought (QT) vectors in [24]</ref>.</p><p>In contrast to vision tasks, positive pairs here are chosen as neighboring sentences, which can form a different positive distribution than data augmen s improves the convergence and stability of our method.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence Embedding</head><p>We adopt the official code 3 of quick-thought (QT) vectors [24]</ref>. To implement the debiased objective, we only modify the "src/s2v-model.py" file and left the rest of the code unchanged. Since the official BookCorpus <ref t
#b2">[3,</ref>13,</ref>20]</ref>. Remarkable success has also been achieved in the language domain [7,</ref>21,</ref>25]</ref>.</p><p>Recently, self-supervised representation learning algorithms that use a contrastive loss have outperformed even 0</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Sentence Embeddings</head><p>Next, we test the debiased objective for learning sentence embeddings. We use the BookCorpus dataset [21]</ref> and examine six classification tasks: movie review sentiment (MR) [29]</ref>, product reviews (CR) <ref type="bibr" target="#b1 ctors [24]</ref>. To implement the debiased objective, we only modify the "src/s2v-model.py" file and left the rest of the code unchanged. Since the official BookCorpus [21]</ref> dataset is missing, we use the unofficial version 4 for the experiments. The feature vector of QT is not normalized, therefore, we simply constrain the estima
ples, our work is also related to Positive-Unlabeled (PU) learning, i.e., learning from only positive (P) and unlabeled (U) data. Common applications of PU learning are retrieval or outlier detection [10]</ref>[11]</ref>[12]</ref>. Our approach is related to unbiased PU learning, where the unlabeled data is get="#b10">[11]</ref>[12]</ref>. Our approach is related to unbiased PU learning, where the unlabeled data is used as negative examples, but down-weighted appropriately [10,</ref>11,</ref>22]</ref>. While these works focus on zero-one losses, we here address the contrastive lo
g from only positive (P) and unlabeled (U) data. Common applications of PU learning are retrieval or outlier detection [10]</ref>[11]</ref>[12]</ref>. Our approach is related to unbiased PU learning, where the unlabeled data is used as negative examples, but down-weighted appropriately <ref type="bibr" targ
tive modeling [3,</ref>13,</ref>20]</ref>. Remarkable success has also been achieved in the language domain [7,</ref>21,</ref>25]</ref>.</p><p>Recently, self-supervised representation learning algorithms that use a c ion of code as Figure 3</ref> shows. The results with different τ + are shown in Figure 4(a,b</ref>). Increasing τ + in Objective (7)</ref> leads to more correction, and gradually improves the performance in both benchmarks for different N. Remarkably, with only a slight modification to the loss, we r" target="#b30">[31]</ref>. To implement the debiased objective, we only modify the "curl-sac.py" file and left the rest of the code unchanged. We again constrain the estimator described in equation (7)</ref> to be greater than zero since the feature vector of CURL is not normalized.</p><p>2 https://github.com/HobbitLong/CMC/ 3 https://github.com/lajanugen/S2V 4 http
g(x, {u i } N i=1 , {v i } M i=1 )<label>(8)</label></formula><p>where, for simplicity, we set Q to the finite N. The class prior τ + can be estimated from data [5,</ref>18]</ref> or treated as a hyperparameter. Theorem 3 bounds the error due to finite N and M as decreasing with rate O(N −1/2 + M −1/2 ).</p><p>Theorem 3. For any embeddin
x + ) e f (x) T f (x + ) + Q τ − (E x − ∼p [e f (x) T f (x − ) ] − τ + E v∼p + x [e f (x) T f (v) ])   . (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>The limiting objective (6)</ref>, which we denote by L Q Debiased , still samples examples x − from p, but corrects for that with additional positive samples v. This essentially reweights posit t https://github.com/chingyaoc/DCL. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">CIFAR10 and STL10</head><p>First, for CIFAR10 [23]</ref> and STL10 [6]</ref>, we implement SimCLR [2]</ref> with ResNet-50 [15]</ref> as the encoder architecture and use the Ad
lgorithms that use a contrastive loss have outperformed even supervised learning [2,</ref>14,</ref>16,</ref>24]</ref>. The key idea of contrastive learning is to contrast semantically similar (positive) and dissimilar (negative) pairs of data points, encouraging the representa of the same scene [33]</ref>. Chen et al. [2]</ref> extensively study verious data augmentation methods. For language, Logeswaran and Lee [24]</ref> treat the context sentences as positive samples to efficiently learn sentence representations. Srinivas et al. [31]</ref> impro TREC) [34]</ref>, and paraphrase identification (MSRP) [8]</ref>. Our experimental settings follow those for quick-thought (QT) vectors in [24]</ref>.</p><p>In contrast to vision tasks, positive pairs here are chosen as neighboring sentences, which can form a different positive distribution than data augmen s improves the convergence and stability of our method.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence Embedding</head><p>We adopt the official code 3 of quick-thought (QT) vectors [24]</ref>. To implement the debiased objective, we only modify the "src/s2v-model.py" file and left the rest of the code unchanged. Since the official BookCorpus <ref t
ples, our work is also related to Positive-Unlabeled (PU) learning, i.e., learning from only positive (P) and unlabeled (U) data. Common applications of PU learning are retrieval or outlier detection [10]</ref>[11]</ref>[12]</ref>. Our approach is related to unbiased PU learning, where the unlabeled data is get="#b10">[11]</ref>[12]</ref>. Our approach is related to unbiased PU learning, where the unlabeled data is used as negative examples, but down-weighted appropriately [10,</ref>11,</ref>22]</ref>. While these works focus on zero-one losses, we here address the contrastive lo
pervised learning, where auxiliary learning objectives leverage labels that can be observed without a human labeler. For instance, in computer vision, representations can be learned from colorization [38]</ref>, predicting transformations [9,</ref>26]</ref>, or generative modeling <ref type="bibr" target="#
pervised learning, where auxiliary learning objectives leverage labels that can be observed without a human labeler. For instance, in computer vision, representations can be learned from colorization [38]</ref>, predicting transformations [9,</ref>26]</ref>, or generative modeling <ref type="bibr" target="#
ine six classification tasks: movie review sentiment (MR) [29]</ref>, product reviews (CR) [17]</ref>, subjectivity classification (SUBJ) [28]</ref>, opinion polarity (MPQA) [36]</ref>, question type classification (TREC) [34]</ref>, and paraphr
tive modeling [3,</ref>13,</ref>20]</ref>. Remarkable success has also been achieved in the language domain [7,</ref>21,</ref>25]</ref>.</p><p>Recently, self-supervised representation learning algorithms that use a c ion of code as Figure 3</ref> shows. The results with different τ + are shown in Figure 4(a,b</ref>). Increasing τ + in Objective (7)</ref> leads to more correction, and gradually improves the performance in both benchmarks for different N. Remarkably, with only a slight modification to the loss, we r" target="#b30">[31]</ref>. To implement the debiased objective, we only modify the "curl-sac.py" file and left the rest of the code unchanged. We again constrain the estimator described in equation (7)</ref> to be greater than zero since the feature vector of CURL is not normalized.</p><p>2 https://github.com/HobbitLong/CMC/ 3 https://github.com/lajanugen/S2V 4 http
f (x) T f (x + ) e f (x) T f (x + ) + Ng(x, {u i } N i=1 , {v i } M i=1 )<label>(8)</label></formula><p>where, for simplicity, we set Q to the finite N. The class prior τ + can be estimated from data [5,</ref>18]</ref> or treated as a hyperparameter. Theorem 3 bounds the error due to finite N and M as decreasing with rate O(N −1/2 + M −1
abeler. For instance, in computer vision, representations can be learned from colorization [38]</ref>, predicting transformations [9,</ref>26]</ref>, or generative modeling [3,</ref>13,</ref>20]</ref>. Remarkable suc
rget="#b24">25]</ref>.</p><p>Recently, self-supervised representation learning algorithms that use a contrastive loss have outperformed even supervised learning [2,</ref>14,</ref>16,</ref>24]</ref>. The key idea of contrastive learning is to contrast semantically similar (posi
g(x, {u i } N i=1 , {v i } M i=1 )<label>(8)</label></formula><p>where, for simplicity, we set Q to the finite N. The class prior τ + can be estimated from data [5,</ref>18]</ref> or treated as a hyperparameter. Theorem 3 bounds the error due to finite N and M as decreasing with rate O(N −1/2 + M −1/2 ).</p><p>Theorem 3. For any embeddin
also argue that training objectives of these algorithms (either reconstructing the adjacency matrix [23,</ref>31]</ref> or feature matrix [24,</ref>32]</ref>) are not compatible with real-world applications. To be specific, reconstructing adjacency matrix literally sets the a matrix merely serves as a filter. [32]</ref> leverages marginalized denoising autoencoder to disturb the structure information. To build a symmetric graph autoencoder, [24]</ref> proposes Laplacian sharpening as the counterpart of Laplacian smoothing in the encoder. The authors claim that Laplacian sharpening is a process that makes th ype="bibr" target="#b22">[23]</ref> add adversarial constraints to GAE and VGAE respectively, enforcing the latent representations to match a prior distribution for robust node embeddings.</p><p>GALA [24]</ref> proposes a symmetric graph convolutional autoencoder recovering the feature matrix. The encoder is based on Laplacian smoothing while the decoder is based on
lacian eigenmaps [21]</ref>, matrix factorization [3,</ref>19,</ref>34,</ref>36]</ref>, and random walks [10,</ref>25]</ref>. However, these methods are also limited because of their sh es into account, there are several works make adjustments to encode structural and content information simultaneously. [19,</ref>34,</ref>36]</ref> are matrix factorization extensions that add feature-related regularization terms. [2,</ref>5]</ref ad n="4.1">Datasets</head><p>We conduct node clustering and link prediction experiments on four widely used network datasets (Cora, Citeseer, Pubmed [26]</ref> and Wiki [36]</ref>). Features in Cora and Citeseer are binary word vectors, while in Wiki and Pubmed, nodes are associated with tf-idf weighted word vectors. The statistics of t ity matrix. DeepWalk [25]</ref> learns node embeddings by using SkipGram on generated random walk paths on graphs.</p><p>(3) Methods using both features and graph. TADW [36]</ref> interprets DeepWalk as matrix factorization and incorporates node features under the DeepWalk framework. MGAE [32]</ref> is a d
igenvalues of the four datasets are all around 3/2. Thus we set k = 2/3 universally. For the adaptive encoder, we train the MLP encoder for 400 epochs with a 0.001 learning rate by the Adam optimizer [14]</ref>. The encoder consists of a single 500-dimensional embedding layer, and we update the thresholds every 10 epochs. We tune other hyperparameters including Lapla
e features under the DeepWalk framework. MGAE [32]</ref> is a denoising marginalized graph autoencoder. Its training objective is reconstructing the feature matrix. AGC [38]</ref> exploits high-order graph convolution to filter node features. The number of graph convolution layers are selected for different datasets. DAEGC <ref type="bi
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Visualization</head><p>To intuitively show the learned node embeddings, we visualize the node representations in 2D space using t-SNE algorithm [29]</ref>. The figures are shown in Figure 6</ref> and each subfigure corresponds to a variant in the ablation study. From the visual
mbeddings by generating random walks and input the sequences into SkipGram model [17]</ref>, assuming that similar nodes tend to cooccur in same sequences. Other models [4,</ref>27,</ref>33]</ref> can be concluded by an encoder-decoder framework 
l [17]</ref>, assuming that similar nodes tend to cooccur in same sequences. Other models [4,</ref>27,</ref>33]</ref> can be concluded by an encoder-decoder framework [11]</ref>, while they differ from model structure and training objectives.</p>
matrix factorization [3,</ref>19,</ref>34,</ref>36]</ref>, and random walks [10,</ref>25]</ref>. However, these methods are also limited because of their shallow architecture.</p><p>More recently, there has been a s ctorization [3]</ref> are two widely used algorithms for these methods. Another line of researches manages to learn node embeddings with a particular objective function. [10,</ref>25]</ref> learn node embeddings by generating random walks and input the sequences into SkipGram model <ref type="bibr" target="#
f type="bibr" target="#b33">34,</ref>36]</ref> are matrix factorization extensions that add feature-related regularization terms. [2,</ref>5]</ref> model features as latent variables in Bayesian networks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GCN-based Graph Embedding</head><p>As m
state-of-the-art graph embedding methods considerably on these tasks.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"> [15]</ref><p>. The components we argue about are marked in red blocks: Entanglement of the filters and weight matrices, design of the filters, and the reconstruction los blems in deep graph learning and GCN-based methods have also made great progress on it. Among these methods, most of them are based on graph autoencoder (GAE) and variational graph autoencoder (VGAE) [15]</ref>. As shown in Figure 1</ref>, they comprise a GCN encoder and a reconstruction decoder. Nevertheless, these GCN-based method nstruct the adjacency matrix. This kind of approaches forces the learned embeddings to recover their localized neighborhood structure. Graph autoencoder (GAE) and variational graph autoencoder (VGAE) [15]</ref> learn node embeddings by using GCN as the encoder, then decode by inner product with cross-entropy loss. As variants of GAE (VGAE), <ref type="bibr" target="# ; </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Methods</head><p>For attributed graph embedding methods, we include 5 baseline algorithms in our comparisons: GAE and VGAE [15]</ref> combine graph convolutional networks with the (variational) autoencoder for representation learning.</p><p>ARGA and ARVGA [23]< on of the pairwise similarity matrix.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: The architecture of graph autoencoder[15]</ref>. The components we argue about are marked in red blocks: Entanglement of the filters and weight matrices, design of the filters, and the reconstruction loss.<
ph embedding approaches are based on Laplacian eigenmaps [21]</ref>, matrix factorization [3,</ref>19,</ref>34,</ref>36]</ref>, and random walks [10,</ref>25]</ref>. However, these meth ing objectives.</p><p>Taking node features into account, there are several works make adjustments to encode structural and content information simultaneously. [19,</ref>34,</ref>36]</ref> are matrix factorization extensions that add feature-related regularization terms. [2,</r
ven larger for higher accuracy. However, large images usually come at a high computational cost and high memory footprint, both of which grow quadratically with respect to the image height (or width) [38]</ref>. In real-world applications like content-based image search [54]</ref> or autonomous vehicles [3] "bibr" target="#b35">36]</ref> and EfficientNet [50]</ref>, can be deployed for higher efficiency. This differentiates our method from early recurrent attention methods [38]</ref> which adopt pure recurrent models. In addition, we focus on improving the computational efficiency under the adaptive inference setting, while most existing w e="bibr" target="#b25">26,</ref>12,</ref>8]</ref>.</p><p>One similar work to our GFNet is the recurrent visual attention model proposed in [38]</ref>. However, our method differs from it in two important aspects: 1) we adopt a flexible and general CNN-based framework that is compatible with a wide variety o ss of recognizing an image. In fact, CNNs are shown to be able to produce correct classification results with only a few class-discriminative patches, such as the head of a dog or the wings of a bird [38,</ref>12,</ref>8]</ref>. These regions are typically smaller than the whole image, and thus require much
</ref>:</p><p>where 0 &lt; &lt; 1 is a hyper-parameter. Then we are ready to give the final maximization objective:</p><p>Herein, S π (s t ) denotes the entropy bonus to ensure sufficient exploration [58,</ref>37,</ref>44]</ref>, and L VF t is a squared-error loss on the estimated state value: (V (s t ) −
f type="bibr" target="#b49">[50]</ref>. Since deep networks typically have a considerable number of redundant weights [11]</ref>, some other approaches focus on pruning [30,</ref>31,</ref>34,</ref>35]</ref> or quantizing the weights <ref type="b
rformance on the competitive ILSVRC [9]</ref> competition with 224×224 or 320×320 images [47,</ref>14,</ref>61,</ref>18,</ref>22]</ref>. Recent works [50,</ref><ref type="bibr" target=
sually translates into latency and power consumption, which should be minimized for both safety and economical reasons [17,</ref>21,</ref>43]</ref>.</p><p>In this paper, we seek to reduce the computational cost introduced by high-resolution inputs in image classification tasks. Our motivation is that consi ssifier and the region proposal network are treated as two independent modules. Therefore, most of the stateof-the-art light-weighted CNNs, such as MobileNets [17,</ref>43,</ref>16]</ref>, CondenseNet [21]</ref>, ShuffleNets [66,</ref><ref type= y research works focus on reducing the inference cost of the networks. A promising direction is to develop efficient network architectures, such as MobileNets [17,</ref>43,</ref>16]</ref>, CondenseNet [21]</ref>, ShuffleNets [66,</ref><ref type= d on an iPhone XS Max (with Apple A12 Bionic) using TFLite [1]</ref>. The single-thread mode with batch size 1 is used following [17,</ref>43,</ref>16]</ref>. We first measure the time consumption of obtaining the prediction with each possible length of the input sequence, and We also compare GFNet with a number of highly competitive baselines, i.e., MnasNets [49]</ref>, ShuffleNets-V2 [36]</ref>, MobileNets-V2 [43]</ref>, CondenseNets [21]</ref>, FBNets [59]</ref>, ProxylessNAS [5]</ref
on pruning [30,</ref>31,</ref>34,</ref>35]</ref> or quantizing the weights [41,</ref>24,</ref>25]</ref>. Another technique is knowledge distillation [1
or training and 50,000 images for validation. We adopt the same data augmentation and pre-processing configurations as [22,</ref>14,</ref>57]</ref>. In our implementation, we estimate the confidence thresholds of GFNet on the training set, since we find that it achieves nearly the same performance as estim
eatures. The Spatially Adaptive Computation Time (SACT) [10]</ref> dynamically adjusts the number of executed layers for different image regions. The methods proposed in [19]</ref> and [62]</ref> skip the computation on some less important regions of feature maps. These works mainly reduce the spatial redun
. Another approach is to ensemble multiple models, and selectively execute a subset of them in the cascading [4]</ref> or mixing [45,</ref>42]</ref> paradigm. Some other works propose to dynamically skip unnecessary layers [52,</ref>55,</ref><ref
et="#b48">[49]</ref>, ShuffleNets-V2 [36]</ref>, MobileNets-V2 [43]</ref>, CondenseNets [21]</ref>, FBNets [59]</ref>, ProxylessNAS [5]</ref>, SkipNet [55]</ref>, SACT [10]</ref>, GoogL
et="#b26">27,</ref>65]</ref>. In the context of image recognition, the attention mechanism is typically exploited to extract information from some task-relevant regions [29,</ref>2,</ref>26,</ref>12,</ref>8]</ref>.</
s the datacenter provides the power slack and criticality-awareness needed to increase oversubscription.</p><p>Accurately predicting (black-box) workload criticality is itself a challenge. Prior work [6]</ref> associated a diurnal utilization pattern with user interactivity and the critical need for high performance. It inferred criticality using the Fast Fourier Tran r draws or capping.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Azure's existing ML system</head><p>To integrate predictions into VM scheduling in practice, we target Resource Central [6]</ref>, the existing ML and predictionserving system in Azure. The system provides a REST service for clients (in our case the VM scheduler) to query for predictions. ng criticality. Predicting criticality requires a method to determine the VM labels, i.e. whether the workload of each VM is performance-critical or not, before we can train a model. As in prior work [6]</ref>, we consider a workload critical if it is user-facing, i.e. a human is interacting with the workload (e.g., front-end webservers, backend databases), and less c orkloads exhibit utilization patterns that repeat daily (e.g., high during the day, low at night), the problem reduces to identifying VMs whose time series of CPU utilizations exhibit 24-hour periods [6]</ref>.</p><p>Obviously, some background VMs may exhibit 24-hour periods. This is not a problem as we seek to be conservative (i.e., it is fine to classify a non-user- to bring data in for batch processing). Identifying periodicity. There are statistical methods for identifying periods in time series, such as FFT or the autocorrelation function (ACF). For example, [6]</ref> assumes a workload is user-facing if the FFT indicates a 24-hour period. We evaluated ACF and FFT methods on 840 workloads on Azure.</p><p>Surprisingly, we find ated works. Leveraging predictions. Some works predict resource demand, resource utilization, or job/task length for provisioning or scheduling purposes, e.g. [5]</ref>, [6]</ref>, [10]</ref>, [16]</ref>, [17]</ref>, 

re manner. Server power capping. Most efforts have focused on selecting the DVFS setting required to meet a tight power budget as applications execute, e.g. [13]</ref>, [15]</ref>, [20]</ref>, [22]</ref>- [25]</ref>, <ref type="bibr" target="#b2
g low-level counters at scale involves undesirable overhead. Cluster-wide workload placement/scheduling. Many works select workload placements to reduce performance interference or energy usage, e.g. [3]</ref>, [4]</ref>, [8]</ref>, [26]</ref>, [30
l budget enforcement, we can place VMs across rows trying to balance rows and servers.</p><p>Finally, researchers have proposed using energy storage to shave power peaks in oversubscribed datacenters [12]</ref>, [18]</ref>. When peaks last long, this approach may require large amounts of storage, which our work does not require. Neverth
, we discuss some of the most closely related works. Leveraging predictions. Some works predict resource demand, resource utilization, or job/task length for provisioning or scheduling purposes, e.g. [5]</ref>, [6]</ref>, [10]</ref>, [16]</ref>, [1
g, networking) in existing ones, thus incurring huge unnecessary capital costs.</p><p>To improve efficiency and avoid these costs, prior work has proposed combining power capping and oversubscription [9]</ref>, [32]</ref>. The idea is to leverage actual server utilization and statistical multiplexing across workloads to oversubscribe the rip, leading to wasted resources (chiefly space, cooling, and networking). Combining hierarchical power capping and oversubscription enables more capacity to be deployed and better utilizes resources [9]</ref>, [32]</ref>. For example, if designers find that the historical per-row power draw is consistently lower than the row PDU budget, atacenter oversubscription. Researchers have proposed to use statistical oversubscription, where one profiles the aggregate power draw of multiple services and deploy them to prevent correlated peaks [9]</ref>, [11]</ref>, [14]</ref>, [31]</ref>. Our work extends these works b versubscription strategy is also the first to carefully control the extent and impact of capping on important cloud workloads.</p><p>Others have studied hierarchical capping in production datacenters [9]</ref>, [14]</ref>, [32]</ref>. Our paper focuses on chassis-level power budget enforcement to make our e

re manner. Server power capping. Most efforts have focused on selecting the DVFS setting required to meet a tight power budget as applications execute, e.g. [13]</ref>, [15]</ref>, [20]</ref>, [22]</ref>- [25]</ref>, <ref type="bibr" target="#b2
er draw of multiple services and deploy them to prevent correlated peaks [9]</ref>, [11]</ref>, [14]</ref>, [31]</ref>. Our work extends these works by using predictions to place the workload, inform capping, and increase oversubscription. Our oversubscription strategy is also
ts have focused on selecting the DVFS setting required to meet a tight power budget as applications execute, e.g. [13]</ref>, [15]</ref>, [20]</ref>, [22]</ref>- [25]</ref>, [27]</ref>, <ref type="bibr" target="#b3
thod as Uncer-tainGCN. Figure 2</ref> simulates the UncertainGCN sampling technique. Furthermore, we adapt the higher-order graph node information under the CoreSet [31]</ref> for a new sampling technique by introducing latent space distancing. In principle, CoreSet [31]</ref> uses risk minimisation be we adapt the higher-order graph node information under the CoreSet [31]</ref> for a new sampling technique by introducing latent space distancing. In principle, CoreSet [31]</ref> uses risk minimisation between core-sets on the learner feature space while we employ this operation over GCN features. We called this sampling technique as C t="#b19">[20,</ref>35,</ref>14]</ref>), the first work applying it for CNNs as an active learning problem, CoreSet, has been presented in [31]</ref>. The key principle depends on minimising the difference between the loss of a labelled set and a small unlabelled subset through a geometric-defined bound. We the pool-based active learning scenario. In the second part, we discuss our two novel sampling methods: UncertainGCN and CoreGCN. UncertainGCN is based on the standard AL method uncertainty sampling [31]</ref> which tracks the confidence scores of the designed graph nodes. Furthermore, CoreGCN adapts the highly successful CoreSet [31]< dard AL method uncertainty sampling [31]</ref> which tracks the confidence scores of the designed graph nodes. Furthermore, CoreGCN adapts the highly successful CoreSet [31]</ref> on the induced graph embeddings by the sequentially trained GCN network.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Learner</head><p>In ew D L 12: until Equation 3 is satisfied CoreGCN: CoreSet sampling on GCN. To integrate geometric information between the labelled and unlabelled graph representation, we approach a CoreSet technique [31]</ref> in our sampling stage. This has shown better performance in comparison to uncertainty-based methods [38]</ref>. <ref type="bibr eSet technique [31]</ref> in our sampling stage. This has shown better performance in comparison to uncertainty-based methods [38]</ref>. [31]</ref> shows how bounding the difference between the loss of the unlabelled samples and the one of the labelled is similar to the k-Centre minimisation problem state rner. We set the value of s margin Testing accuracy on CIFAR10 Random UncertainGCN(Ours) VAAL [33]</ref> Learning Loss [42]</ref> CoreSet [31]</ref> CoreGCN(Ours) FeatProp [38]</ref> 2000 4000 6000 8000 10000 12000 14000 16000 18000 20000  Compared Methods and Evaluation Metr 0 20000  Compared Methods and Evaluation Metric: We compare our method with a wide range of baselines which we describe here. Random sampling is by default the most common sampling technique. CoreSet [31]</ref> on learner feature space is one of the best performing geometric techniques to date and it is another competitive baseline for us. VAAL <ref type="bibr" targe 8x128.</p><p>Compared Methods and Evaluation Metric: We compare our methods from the two ends of the spectrum of baselines. One is random sampling which is the default mechanism. The other is CoreSet [31]</ref>, one of the best performing baselines from the previous experiments. We report the performance in terms of mean squared error averaged from 5 different trials /ref>, we adopt a pool-based scenario for active learning. This has become a standard in deep learning system due to its successful deployment in recent methods [2,</ref>31,</ref>33,</ref>42]</ref>. In this scenario, from a pool of unlabeled dataset D U , we randomly select an
org/ns/1.0"><head n="4.2.">Regression</head><p>Dataset and Experimental Settings: We further applied our method on a challenging dataset for 3D Hand Pose Estimation benchmarks from depth images. ICVL [34]</ref>  joints from depth images. Thus, we replace ResNet-18 by commonly used DeepPrior [26]</ref> as learner. The sampler and the oth e learner's objective to regression. As we tackle the 3D Hand Pose Estimation task, we benchmark our baselines on one of the most challenging, widely been used and first of depth based datasets, ICVL [34]</ref>. This is composed of 16,004 images for training and 1,600 for testing. The dataset has a single frontal viewpoint and a wide range of articulation and hand po
utperformed MC Dropout. Geometric-based methods. Although there have been studies exploring the data space through the representations of the learning model ( [20,</ref>35,</ref>14]</ref>), the first work applying it for CNNs as an active learning problem, CoreSet, has been presented in <ref type="bibr" ta
r" target="#b22">[23]</ref> for translation of face expressions. Although Generative Adversarial Networks [12]</ref> are closing the gap between real and synthetic data [29]</ref>, still the synthetic images and its associated labels are not yet suitable to train a downstream discriminative model. Recent study <ref type="bibr" target="#
wn great advancements in several computer vision tasks such as image classification [15,</ref>22]</ref> and 3D Hand Pose Estimation (HPE) [26,</ref>41,</ref>25]</ref>. This has been possible due to the availability of both the powerful computing </formula><p>where N l is the number of labelled training examples and f (x i , y i ; ?) is the posterior probability of the model M. Regression: To tackle the 3D HPE, we deploy a wellknown DeepPrior [26]</ref> architecture as model M. Unlike the previous case, we regress the 3D hand joint coordinates from the hand depth images. Thus, the objective function of the mo nging dataset for 3D Hand Pose Estimation benchmarks from depth images. ICVL [34]</ref>  joints from depth images. Thus, we replace ResNet-18 by commonly used DeepPrior [26]</ref> as learner. The sampler and the other components in our pipeline remain the same as in the image classification task. This is yet another evidence for our sam
8 [15]</ref> as the CNN model due to its relatively higher performance in comparison to other networks with comparable parameter complexity. Any other model like VGG-11 [32]</ref> can also be easily deployed (refer to Supplementary Material B.4). A loss function L(x, y; ?) is minimized during the training process. The objective function 10 % of their original data (500 samples each). Therefore, the new unlabelled pool is composed of 27,500 images. The experiment architecture and settings are similar to the one on the full scale.    [32]</ref>. Therefore, we analyse how the AL methods are affected in terms of accuracy at the fourth sampling stage.</p><p>In training the VGG-11 network, we kept the sa
e it by the factor of 10 after 160 epochs. We use the same set of hyper-parameters in all the experiments. For the sampler, GCN has 2 layers and we set the dropout rate to 0.3 to avoid over-smoothing [43]</ref>. The dimension of initial representations of a node is 1024 and it is projected to 512. The objective function is binary cross-entropy per node. We set the va
while optimizing deep neural network architectures, a gap is present concerning the representative- ness of the data [4]</ref>. To overcome these issues, active learning [10,</ref>20]</ref> has been successfully deployed to efficiently select the most meaningful samples. Essentially, there are three distinct [9]</ref> produce meaningful uncertainty measurements by variational inference of a Monte Carlo Dropout (MC Dropout) adapted architecture. Hence, it is successfully integrated into active learning by [10,</ref>16,</ref>19,</ref>28]</ref>. With the rise of GPU computation power ostic. Taskdependents are the ones where the sampler is specially designed for a specific task of the learner. Majority of the previous works in active learning [8,</ref>10,</ref>1,</ref>38,</ref>6,</ref>11]</ref> are
type="bibr" target="#b30">[31]</ref> shows how bounding the difference between the loss of the unlabelled samples and the one of the labelled is similar to the k-Centre minimisation problem stated in [37]</ref>.</p><p>In this approach, the sampling is based on the l2 distances between the features extracted from the trained classifier. Instead of that, we will make u
on [15,</ref>22]</ref> and 3D Hand Pose Estimation (HPE) [26,</ref>41,</ref>25]</ref>. This has been possible due to the availability of both the powerful computing infrastructure and the large-scale datasets. Data annotation is a time-consuming
on [15,</ref>22]</ref> and 3D Hand Pose Estimation (HPE) [26,</ref>41,</ref>25]</ref>. This has been possible due to the availability of both the powerful computing infrastructure and the large-scale datasets. Data annotation is a time-consuming
tworks are built from interleaved linear maps φ and equivariant nonlinearities. In the case of 3D roto-translations it has already been shown that a suitable structure for φ is a tensor field network [25]</ref>, explained below. Note that Romero et al. [21]</ref> recently introduced a 2D roto-translationally equivariant attention module ctors have length 2 + 1. They can be stacked, forming a feature vector f transforming according to Eq. (5)</ref>.</p><p>Tensor Field Networks Tensor field networks (TFN) [25]</ref> are neural networks, which map point clouds to point clouds under the constraint of SE(3)-equivariance, the group of 3D rotations and translations. For point in,j , node j → node i message<label>(7)</label></formula><p>We can also include a sum over input channels, but we omit it here. Weiler et al. [33]</ref>, Thomas et al. [25]</ref> and Kondor [13]</ref> showed that the kernel W k lies in the span of an equivariant basis</p><formula xml:id="formula_9">{W k J degree of freedom in the radial direction. Note that W k J (0) = 0 only when k = and J = 0, which reduces the kernel to a scalar w multiplied by the identity, W = w I, referred to as self-interaction [25]</ref>. As such we can rewrite the TFN layer as</p><formula xml:id="formula_11">f out,i = w f in,i self-interaction + k≥0 n j =i W k (x j − x i )f k in,j ,<label>(9) f>, output channels are a learned linear combination of input channels using one set of weights w i,c c = w c c per representation degree, shared across all points.</p><p>As proposed in Thomas et al. [25]</ref>, this is followed by a norm-based non-linearity.</p><p>Attentive: We propose an extension of linear self-interaction, attentive self-interaction, combining se -world object Table 1</ref>: Predicting future locations and velocities in an electron-proton simulation.</p><p>Linear DeepSet [40]</ref> Tensor Field [25]</ref> Set Transformer [14]</ref>  classification task. Here, the network is confronted with large point clouds of noisy data with sym results as well as a set of our own baselines. Specifically, we compare to the Set-Transformer [14]</ref>, a non-equivariant attention model, and Tensor Field Networks [25]</ref>, which is similar to SE(3)-Transformer but does not leverage attention.</p><p>Similar to [24,</ref><ref type="bibr" target="#b3 speed up of spherical harmonics computation of up to 3 orders of magnitudes. This speed-up allowed us to train significantly larger versions of both the SE(3)-Transformer and the Tensor Field network [25]</ref> and to apply these models to real-world datasets.</p><p>Our experiments showed that adding attention to a roto-translation-equivariant model consistently led ange of basis matrices Q k are given the special name of the Clebsch-Gordan coefficients. These can be found in many mathematical physics libraries.</p><p>Tensor Field Layers In Tensor Field Networks [25]</ref> and 3D Steerable CNNs [33]</ref>, the authors solve for the intertwiners between SO(3) equivariant point clouds. Here we run th eline, we had to decrease the model size to obtain stable training. However, we would like to stress that all the Tensor Field networks we trained were significantly bigger than in the original paper [25]</ref>, mostly enabled by the faster computation of the spherical harmonics.</p><p>For the ablation study in Fig. 4</ref>, we trai 3 and 5 channels per degree, which we again had to reduce to 3 channels for the Tensor Field network to obtain stable training. We used a norm based non-linearity for the Tensor Field network (as in [25]</ref>) and no extra non-linearity (beyond the softmax in the self-attention algorithm) for the SE(3) Transformer.</p><p>For all experiments, the final layer of the rchitectures All our baselines fulfill permutation invariance (ordering of input points), but only the Tensor Field network and the linear baseline are SE(3) equivariant. For the Tensor Field Network [25]</ref> baseline, we used the same hyper parameters as for the SE(3) Transformer but with a linear self-interaction and an additional norm-based nonlinearity in each b24">[25]</ref> baseline, we used the same hyper parameters as for the SE(3) Transformer but with a linear self-interaction and an additional norm-based nonlinearity in each layer as in Thomas et al. [25]</ref>. For the DeepSet [40]</ref> baseline, we used 3 fully connected layers, a pooling layer, and two more fully connected layers wi
exp(q i k j )<label>(1)</label></formula><p>where we used a softmax as a nonlinearity acting on the weights. In general, the number of query vectors does not have to equal the number of input points [14]</ref>. In the case of self-attention the query, key, and value vectors are embeddings of the input features, so</p><formula xml:id="formula_1">q = h Q (f), k = h K ntion algorithms to point cloud data [39,</ref>37,</ref>14]</ref>. One such example is the Set Transformer [14]</ref>. When applied to object classification on ModelNet40 [36]</ref>, the input to the Set Transformer are the cartesian coordinates future locations and velocities in an electron-proton simulation.</p><p>Linear DeepSet [40]</ref> Tensor Field [25]</ref> Set Transformer [14]</ref>  classification task. Here, the network is confronted with large point clouds of noisy data with symmetry only around the gravitational axis. Finally, we test on its ability to incorporate rich graph structures. We compare to publicly available, state-of-the-art results as well as a set of our own baselines. Specifically, we compare to the Set-Transformer [14]</ref>, a non-equivariant attention model, and Tensor Field Networks [25]</ref>, which is similar to SE(3)-Transformer but does not le instead of 256) and no dropout but the same number of layers and type of non-linearity as in [40]</ref>.</p><p>Set Transformer Baseline We used the same architecture as [14]</ref> in their object classification experiment on ModelNet40 [36]</ref> with an ISAB (induced set attention block)-based encoder fol ate information from all points, but concatenates this with a skip connection for each point. Each hidden layer was followed by a LeakyReLU. The learning rate was set to 1e-3. For the Set Transformer [14]</ref>, we used 4 self-attention blocks with 64 hidden units and 4 heads each. For each point this was then followed by a fully connected layer (64 units), a LeakyRe ibr" target="#b6">7]</ref>, a recent stream of work has applied forms of self-attention algorithms to point cloud data [39,</ref>37,</ref>14]</ref>. One such example is the Set Transformer [14]</ref>. When applied to object classification on ModelNet40 <ref type="bibr" target cause of the orthonormality of representations of SO(3), mentioned in the background section. We follow the common practice from the self-attention literature [28,</ref>14]</ref>, and chosen a softmax nonlinearity to normalise the attention weights to unity, but in general any nonlinear function could be used.</p></div> <div xmlns="http
s of the input features, so</p><formula xml:id="formula_1">q = h Q (f), k = h K (f), v = h V (f),<label>(2)</label></formula><p>where {h Q , h K , h V } are, in the most general case, neural networks [27]</ref>. For us, query q i is associated with a point i in the input, which has a geometric location x i . Thus if we have n points, we have n possible queries. For q deling [28]</ref>, image recognition [16]</ref>, graph-based problems [29]</ref>, and relational reasoning [27,</ref>7]</ref>, a recent stream of work has applied forms of self-attention algorithms to point cloud data <ref type="bibr" target="#b3
formula><formula xml:id="formula_45">=⇒ f out,i = N j=1 D (g) −1 W k (R −1 g (x j − x i ))D k (g)f k in,j<label>(34)</label></formula><p>Now we notice that this expression should also be equal to Eq. (32)</ref>, which is the convolution with an unrotated point cloud. Thus we end up at</p><formula xml:id="formula_46">W k (R −1 g x) = D (g)W k (x)D k (g) −1 ,<label>(35 ref type="bibr" target="#b2">[3]</ref>, PointNet[17]</ref>, SpiderCNN[38]</ref>, PointNet++[18]</ref>, DGCN[32]</ref>.</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2">Over a field of characteristic zero.</note> 		</body> 		<back>  			<di
target="#b36">37,</ref>14]</ref>. One such example is the Set Transformer [14]</ref>. When applied to object classification on ModelNet40 [36]</ref>, the input to the Set Transformer are the cartesian coordinates of the points. Each layer embeds this positional information further while dynamically queryin .org/ns/1.0"><head>DeepSet Baseline</head><p>We originally replicated the implementation proposed in [40]</ref> for their object classification experiment on ModelNet40 [36]</ref>. However, most likely due to the relatively small number of objects in the ScanObjectNN dataset, we found that reducing the model size helped the performance type="bibr" target="#b39">[40]</ref>.</p><p>Set Transformer Baseline We used the same architecture as [14]</ref> in their object classification experiment on ModelNet40 [36]</ref> with an ISAB (induced set attention block)-based encoder followed by PMA (pooling by multihead attention) and an MLP.</p></div> <div xmlns="http://www.tei-c.o
ons can be decomposed as</p><formula xml:id="formula_4">ρ(g) = Q D (g) Q, (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>where Q is an orthogonal, N × N , change-of-basis matrix [4]</ref>; each D for = 0, 1, 2, ... is a (2 + 1) × (2 + 1) matrix known as a Wigner-D matrix 3</ref> ; and the is the direct sum or con sum of irreps, as</p><formula xml:id="formula_30">ρ(g) = Q J D J (g) Q, (<label>20</label></formula><formula xml:id="formula_31">)</formula><p>where Q is an orthogonal, N × N , change-of-basis matrix [4]</ref>; and each D J for J = 0, 1, 2, ... is a (2J + 1) × (2J + 1) matrix known as a Wigner-D matrix. The Wigner-D matrices are the irreducible representations of SO < n the embeddings to shape (4, 2). We then combine each of the 8 sets of shape (4, 2) queries, keys, and values individually and then concatenate the results into a single vector of the original shape (4,</ref>16)</ref>. The keys and queries are edge embeddings, and thus the embedding matrices are of TFN type (c.f. Eq. ( <ref type="formul
l:id="foot_0">The 'D' stands for Darstellung, German for representation</note> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1">PointGLR is a recently published preprint[20]</ref>. The performance of the following models was taken from the official benchmark of the dataset as of June 4th, 2020 (https://hkust-vgd.github.io/benchmark/): 3
f type="bibr" target="#b27">28,</ref>29,</ref>10,</ref>23]</ref>. These methods were unified by Wang et al. [31]</ref> with the non-local neural network. This has the simple form</p><formula xml:id="formula_2">y i = 1 C({f j ∈ N i }) j∈Ni w(f i , f j )h(f j )<label>(3)</label>
resenting itself in diverse forms such as 3D object scans [26]</ref>, 3D molecular structures [19]</ref>, or N -body particle simulations [12]</ref>. Finding neural structures which can adapt to the varying number of points in an input, while respecting the irregular sampling of point positions, is challen Φ(f ) 2<label>(14)</label></formula></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">N-Body Simulations</head><p>In this experiment, we use an adaptation of the dataset from Kipf et al. [12]</ref>. Five particles each carry either a positive or a negative charge and exert repulsive or attractive forces on each other. The input to the network is the posi tion block)-based encoder followed by PMA (pooling by multihead attention) and an MLP.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Relational Inference</head><p>Following Kipf et al. [12]</ref>, we simulated trajectories for 5 charged, interacting particles. Instead of a 2d simulation setup, we considered a 3d setup. Positive and negative charges wer
elocities of the particles. Next, we evaluate on a real-world object Table 1</ref>: Predicting future locations and velocities in an electron-proton simulation.</p><p>Linear DeepSet [40]</ref> Tensor Field [25]</ref> Set Transformer [14]</ref>  classification task. Here, the network is co ons as a degree 1 field (where the z-component is set to 0).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>DeepSet Baseline</head><p>We originally replicated the implementation proposed in [40]</ref> for their object classification experiment on ModelNet40 [36]</ref>. However, most likely due to the relatively small number of ng the model size helped the performance significantly. The reported model had 128 units per hidden layer (instead of 256) and no dropout but the same number of layers and type of non-linearity as in [40]</ref>.</p><p>Set Transformer Baseline We used the same architecture as [14]</ref> in their object classification experiment on ModelN as for the SE(3) Transformer but with a linear self-interaction and an additional norm-based nonlinearity in each layer as in Thomas et al. [25]</ref>. For the DeepSet [40]</ref> baseline, we used 3 fully connected layers, a pooling layer, and two more fully connected layers with 64 units each. All fully connected layers act pointwise.
resenting itself in diverse forms such as 3D object scans [26]</ref>, 3D molecular structures [19]</ref>, or N -body particle simulations [12]</ref>. Finding neural structures which can adapt to the varying number of points in an input, while respecting the irregular sampling of point positions, is challen Φ(f ) 2<label>(14)</label></formula></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">N-Body Simulations</head><p>In this experiment, we use an adaptation of the dataset from Kipf et al. [12]</ref>. Five particles each carry either a positive or a negative charge and exert repulsive or attractive forces on each other. The input to the network is the posi tion block)-based encoder followed by PMA (pooling by multihead attention) and an MLP.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Relational Inference</head><p>Following Kipf et al. [12]</ref>, we simulated trajectories for 5 charged, interacting particles. Instead of a 2d simulation setup, we considered a 3d setup. Positive and negative charges wer
.org/ns/1.0"><head>Experiments Datasets and Setting</head><p>We evaluated models on two datasets: New York Times (NYT) (Riedel, Yao, and McCallum 2010)</ref> and WebNLG (Gardent et al. 2017)</ref>. NYT comes from the distant supervised relation extraction task (DSRE), which aims to leverage the strength of the knowledge base to generate another method for solving the overlapping relation problem, which extracts triplets by a Seq2Seq framework (Sutskever, Vinyals, and Le 2014)</ref> with copy mechanism (Gu et al. 2016)</ref>. But it cannot predict the entire entities. In addition, the weak performance hinders it from real-world usage. Our work resolves the problems and
multiple tokens. As shown in Fig. 2</ref>, we first derive the emission potential from the encoder output. Then, an additional Conditional Random Field (CRF) layer (Lafferty, McCallum, and Pereira 2001)</ref> is employed to calculate the most probable tag for each token. We use the BIO scheme (Begin, Inside, Outside) to recognize al
/ref>Christopoulou, Miwa, and Ananiadou 2018;</ref>Qin, Xu, and Wang 2018)</ref>, the pipeline methods introduce error propagation problem (Li and Ji 2014)</ref>, which does harm to the overall performance.</p><p>Table filling</ref>: The joint extraction task is formalized as a table consti
rom the overlapping relation problem that the model cannot assign different relation tags to one token. To solve this problem, the followers (Takanobu et al. 2018;</ref>Dai et al. 2019</ref>) run tagging on a sentence for multiple turns, which is akin to the table filling method together with the heavy computational burden. Relatively sp -pass tagging training, HRL5</ref> , has been purposed (Takanobu et al. 2018)</ref>, based on the reinforcement learning framework and (Dai et al. 2019</ref>) leverage attention mechanism. Although these methods solve the overlapping relation problem, their nature and complexities are akin to table filli
/ref>Christopoulou, Miwa, and Ananiadou 2018;</ref>Qin, Xu, and Wang 2018)</ref>, the pipeline methods introduce error propagation problem (Li and Ji 2014)</ref>, which does harm to the overall performance.</p><p>Table filling</ref>: The joint extraction task is formalized as a table consti
also matches with the human annotation process, that the annotators first read the sentences, understand the meaning and then point out the entity-relation pairs sequentially.</p><p>Currently, CopyRE (Zeng et al. 2018)</ref> is the most powerful Seq2Seq based joint extraction method which expands a Seq2Seq framework with copy mechanism in the decoder. The copying mec and the learning rate was 0.001. The weight of L E , λ, was set to 1.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines and Evaluation Metrics</head><p>We compare CopyMTL with CopyRE (Zeng et al. 2018)</ref>, NovelTagging (Zheng et al. 2017)</ref> and GraphRel (Fu, Li, and Ma 2019)</ref>. N e the strength of the knowledge base to generate a largescale dataset (Mintz et al. 2009</ref>). To make joint extraction more challenging than DSRE experiment setting, Zeng et al. (2018)</ref> additionally modified the data to include more overlapping relations. WebNLG is originally used for natural language generation, in which all of b4">(Dai et al. 2019</ref>) leverage attention mechanism. Although these methods solve the overlapping relation problem, their nature and complexities are akin to table filling.</p><p>Seq2Seq: CopyRE (Zeng et al. 2018</ref>) is another method for solving the overlapping relation problem, which extracts triplets by a Seq2Seq framework (S
studies on joint models of entity and relation extraction have three major research lines: Table Filling, Tagging, and Sequence-to-Sequence (Seq2Seq). Among these approaches, the table filling method (Gupta, Schütze, and Andrassy 2016;</ref>Adel and Schütze 2017)</ref> requires the model to enumerate over all possible entity pairs, which and Sekine 2007)</ref>, a.k.a extract entities first then classify the relations. Most of the recent neural models also focus on pipeline methods, include (1) Fully-Supervised Relation Classification (Hendrickx et al. 2009)</ref> (2) Distant Supervised Relation Extraction (Mintz et al. 2009)</ref>. In spite of the recent progress of neur nput sentence to itself. The table blanks, except for that on the diagonal, are to be predicted as relations. The models include history-based searching (Miwa and Sasaki 2014), neuralbased prediction (Gupta, Schütze, and Andrassy 2016)</ref> and global normalization (Adel and Schütze 2017). The stateof-the-art model, GraphRel, also belongs to this genre. This model in
also matches with the human annotation process, that the annotators first read the sentences, understand the meaning and then point out the entity-relation pairs sequentially.</p><p>Currently, CopyRE (Zeng et al. 2018)</ref> is the most powerful Seq2Seq based joint extraction method which expands a Seq2Seq framework with copy mechanism in the decoder. The copying mec and the learning rate was 0.001. The weight of L E , λ, was set to 1.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines and Evaluation Metrics</head><p>We compare CopyMTL with CopyRE (Zeng et al. 2018)</ref>, NovelTagging (Zheng et al. 2017)</ref> and GraphRel (Fu, Li, and Ma 2019)</ref>. N e the strength of the knowledge base to generate a largescale dataset (Mintz et al. 2009</ref>). To make joint extraction more challenging than DSRE experiment setting, Zeng et al. (2018)</ref> additionally modified the data to include more overlapping relations. WebNLG is originally used for natural language generation, in which all of b4">(Dai et al. 2019</ref>) leverage attention mechanism. Although these methods solve the overlapping relation problem, their nature and complexities are akin to table filling.</p><p>Seq2Seq: CopyRE (Zeng et al. 2018</ref>) is another method for solving the overlapping relation problem, which extracts triplets by a Seq2Seq framework (S
tention in recent years. Relation extraction aims to automatically learn triplets (relation, head, tail) from the unstructured text without human intervention.</p><p>Early studies use pipeline models (Nadeau and Sekine 2007;</ref>Chan and Roth 2011)</ref>, where they cast the relation extraction problem into two separate tasks, i.e. Name Extraction of entities and relations is of significance to many NLP tasks. In recent years, there have been four mainstream methods.</p><p>Pipeline methods: Previous works mainly use pipeline methods (Nadeau and Sekine 2007)</ref>, a.k.a extract entities first then classify the relations. Most of the recent neural models also focus on pipeline methods, include (1) Fu
et="#b6">(Gardent et al. 2017)</ref>. NYT comes from the distant supervised relation extraction task (DSRE), which aims to leverage the strength of the knowledge base to generate a largescale dataset (Mintz et al. 2009</ref>). To make joint extraction more challenging than DSRE experiment setting, Zeng et al. (2018)</ref> additionally m ural models also focus on pipeline methods, include (1) Fully-Supervised Relation Classification (Hendrickx et al. 2009)</ref> (2) Distant Supervised Relation Extraction (Mintz et al. 2009)</ref>. In spite of the recent progress of neural models (Cai, Zhang, and Wang 2016;</ref><ref type="bibr" target="#b17"
cally learn triplets (relation, head, tail) from the unstructured text without human intervention.</p><p>Early studies use pipeline models (Nadeau and Sekine 2007;</ref>Chan and Roth 2011)</ref>, where they cast the relation extraction problem into two separate tasks, i.e. Named Entity Recognition (NER) to extract the entities and Relati
diseases are popular nowadays [1]</ref>. However, unexpected DDI can also trigger side effects, adverse reactions, and even serious toxicity, leading patients in danger [2]</ref>. As there exists increasing needs of multi-drug treatments, the identification of DDIs is more and more urgent. Nevertheless, it is expensive and time-consuming ref>. They are quite useful in building DDI-related databases. However, those methods cannot detect unannotated DDIs, and cannot give alerts to potential DDIs before a combinational treatment is made [2]</ref>. In contrast, machine learning-based methods provide a promising way to identify unannotated potential drug-drug interactions for downstream experimental valida ased methods consist of the feature extractor and the supervised predictor. The feature extractor represents drugs in a form of feature vector according to drug properties, such as chemical structure [2,</ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref><ref r" target="#b9">[10]</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ref>, targets [2,</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref>, The supervised predictor is usually implemented by classification algorithms, such as KNN [12]</ref>, SVM [12]</ref>, logistic regression [2,</ref>8,</ref>10]</ref>, decision tree [10]</ref>, na?ve Bayes <ref type="bib predictor first trains a model with both feature vectors/similarity matrices and annotated DDI labels, then deduces potential DDIs with the well-trained model. Most methods utilize a single predictor [2,</ref>[5]</ref>[6]</ref>[7]</ref>[8]</ref><ref
ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref>[12]</ref>[13]</ref>[14]</ref>, targets <ref type="bibr" target="# e="bibr" target="#b13">[14]</ref>, targets [2,</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref>, Anatomical Therapeutic Chemical classification (ATC) codes [8]</ref>[9]</ref><ref type="bibr" tar 9,</ref>11,</ref>13,</ref>14]</ref>, medication and/or clinical observations [11]</ref>.</p><p>The supervised predictor is usually implemented by classification algorithms, such as KNN [12]</ref>, SVM <ref type="bib ) [6,</ref>7]</ref>, label propagationbased method (named as LP) [13]</ref> and Zhang's method (named as CE) [11]</ref> in 5-CV test. Vilar et al [6]</ref> integrates a Tanimoto similarity matrix of molecular structures with known DDI matrix by a l target="#b12">[13]</ref> applies label propagation to assign labels from known DDIs to previously unlabeled nodes by computing drug similarityderived weights of edges on the DDI network. Zhang et al [11]</ref> collects a variety of drug-related data (e.g., known drug-drug interactions, drug substructures, proteins, pathways, indications, and side effects, etc.) to b ays, indications, and side effects, etc.) to build many base classifiers, then performed the prediction with an ensemble (CE) classifier model.</p><p>To ensure a fair comparison, the DB2 dataset from [11]</ref> is adopted. In the DB2 dataset, all unlabeled drug pairs are considered as the negative samples. The comparison results in 5CV test are shown in Table <ref ty ree methods of Vilar 1, Vilar 2 and LP in terms of AUC, AUPR, Recall, Precision, Accuracy, and F1-score, respectively. Although the AUC and ACC of DPDDI are slightly lower than that of Zhang's method [11]</ref>, the AUPR and F 1 of DPDDI are higher. AUPR is often believed to be a more significant quality measure than AUC, as it punishes much more the existence of fal so on the proportion of correctly predicted drug-drug non-interaction pairs. For the prediction of drug-drug interaction, F 1 should be more effective measure than ACC.</p><p>In addition, Zhang et al [11]</ref> used 9 drug-related data sources, while our DPDDI just use the known drug-drug interaction data. If we integrate more drug-related data sources (e.g., drug su . If we integrate more drug-related data sources (e.g., drug substructure, drug target, drug enzyme, drug transporter, drug pathway, drug indication, drug side effect and drug off side effect used in [11]</ref>) to construct the dug-drug similarity network, using DPDDI framework to predict DDIs, DPDDI should be able to achieve better performance.</p></div> <div xmlns he DB1 dataset which contains 1562 drugs and 180, 576 annotated drug-drug interactions. In order to compare with other state-of-the-art methods, a smaller dataset (named as DB2) built by Zhang et al. [11]</ref> was adopted to evaluate the performance of our DPDDI. DB2 contains 548 drugs and 48,584 annotated drug-drug interactions. Moreover, we also collected a new an <cell>0.956</cell><cell>0.907</cell><cell>0.810</cell><cell>0.754</cell><cell>0.940</cell><cell>0.840</cell></row></table><note><p><p><p><p><p>a</p>The results are taken from Table</p>5</p>in Ref.</p>[11]</ref> </p></note></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Results of three fea bibr" target="#b8">[9]</ref>[10]</ref>12]</ref>, side effects [8,</ref>9,</ref>11,</ref>13,</ref>14]</ref>, medication and/or clinical observations [11]</r ructure [6]</ref>[7]</ref>[8]</ref>, label propagation [13]</ref>, random walk [11,</ref>15]</ref>, probabilistic soft logic [9,</ref>10]</ref>) or matrix fa
rator was adopted in our DPDDI.  In addition, we paid particular attention to how to balance samples in the training phase. Many former works in similar areas [22,</ref>30,</ref>31]</ref> adopted the same number of negative samples and positive samples to avoid the computational challenge caused by the sam
to the field of drug development and discovery [20]</ref>, such as molecular activity prediction [21]</ref>, drug side effect prediction [22]</ref>, drug target interactions prediction [23]</ref>.</p><p>In this work, we introduced a deep predictor of drug-drug interactions ( performance. Therefore, concatenation operator was adopted in our DPDDI.  In addition, we paid particular attention to how to balance samples in the training phase. Many former works in similar areas [22,</ref>30,</ref>31]</ref> adopted the same number of negative samples and positive samples to avoid the
to examine the effectiveness of a predictor [24]</ref>. Of the two test methods, the jackknife test is deemed the least arbitrary that can always yield a unique result [25]</ref>. However, for large scale database, the jackknife test is quite time consuming. To reduce the computational time and evaluate performance of a predictor, in t
to examine the effectiveness of a predictor [24]</ref>. Of the two test methods, the jackknife test is deemed the least arbitrary that can always yield a unique result [25]</ref>. However, for large scale database, the jackknife test is quite time consuming. To reduce the computational time and evaluate performance of a predictor, in t
scientific literatures, electronic medical records [3,</ref>4]</ref>, insurance claim databases and the FDA Adverse Event Reporting System [5]</ref>. They are quite useful in building DDI-related databases. However, those methods cannot detect unannotated DDIs, and cannot give alerts to potential DDIs before h feature vectors/similarity matrices and annotated DDI labels, then deduces potential DDIs with the well-trained model. Most methods utilize a single predictor [2,</ref>[5]</ref>[6]</ref>[7]</ref>[8]</ref>[13]</ref><re
CN takes the adjacency matrix A as the input and outputs embedding vectors fZ i ?R 1?H p ; i ? 1; 2; ?; mg for every drug in the DDI network, where H p is the dimension of the last hidden layer. Like [38]</ref> recommendation, our GCN adopts two layers as well. Suppose that H (0) is the feature matrix in which each row denotes the input feature vector of each node in
ead>Background</head><p>By taking advantage of the synergistic effects caused by drug-drug interactions (DDIs), the combinational treatment of multiple drugs for complex diseases are popular nowadays [1]</ref>. However, unexpected DDI can also trigger side effects, adverse reactions, and even serious toxicity, leading patients in danger [
e feature extractor represents drugs in a form of feature vector according to drug properties, such as chemical structure [2,</ref>[6]</ref>[7]</ref>[8]</ref>[9]</ref>[10]</ref>[11]</ref><r get="#b9">[10]</ref>, na?ve Bayes [10]</ref>), and network propagation methods, such as reasoning over drug-drug network structure [6]</ref>[7]</ref>[8]</ref>, label propagation [13]</ref>, random walk [11,</ref><ref t otential DDIs with the well-trained model. Most methods utilize a single predictor [2,</ref>[5]</ref>[6]</ref>[7]</ref>[8]</ref>[13]</ref>[14]</ref>[15]</ref [6]</ref> integrates a Tanimoto similarity matrix of molecular structures with known DDI matrix by a linear matrix transformation to identify potential DDIs. Vilar et al [7]</ref> uses the drug interaction profile fingerprints (IPFs) to measure similarity for predicting DDIs. Label propagation method [13]</r -art methods</head><p>We compared our DPDDI with four other state-of-the-art methods, including two Vilar's methods (named as Vilar 1 and Vilar 2, respectively) [6,</ref>7]</ref>, label propagationbased method (named as LP) [13]</ref> and Zhang's method (named as CE) [11]</ref>
w the effectiveness of DPDDI through a case study.</p><p>In statistical prediction, the jackknife test and q-fold cross-validation (CV) test are often used to examine the effectiveness of a predictor [24]</ref>. Of the two test methods, the jackknife test is deemed the least arbitrary that can always yield a unique result [25]</ref>. Ho
, remains to be a fundamental task towards effective personalized recommendation [8,</ref>18,</ref>26,</ref>39]</ref>.</p><p>The most common paradigm for CF is to learn latent features (a.k.a. embedding) to represent a user and an item, and perform prediction based on the embe connection). This is different from most existing graph convolution operations [12,</ref>21,</ref>34,</ref>39]</ref> that typically aggregate extended neighbors and need to handle the self-connection specially. The layer combination operation, to be introduced in the next sub using the subgraph structure of a user -more specifically, her one-hop neighbors -to improve the embedding learning.</p><p>To deepen the use of subgraph structure with high-hop neighbors, Wang et al. [39]</ref> recently proposes NGCF and achieves state-of-the-art performance for CF. It takes inspiration from the Graph Convolution Network (GCN) <ref type="bibr" target ear activation, have no positive effect on the effectiveness of collaborative filtering. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>We first introduce NGCF [39]</ref>, a representative and state-of-the-art GCN model for recommendation. We then perform ablation studies on NGCF to judge the usefulness of each operation in NGC ng on the Gowalla and Amazon-Book datasets in Table 1</ref>, where the scores of NGCF are directly copied from the Table 3</ref> of [39]</ref>. As can be seen, removing feature transformation (i.e., NGCF-f) leads to consistent improvements over NGCF on all three datasets. In contrast, removing nonlin yer Combination, we sum over the embeddings at each layer to obtain the final representations.</p><p>transformation and nonlinear activation. The graph convolution operation (a.k.a., propagation rule [39]</ref>) in LightGCN is defined as:</p><formula xml:id="formula_5">e (k +1) u = i ∈N u 1 |N u | |N i | e (k ) i , e (k +1) i = u ∈N i 1 |N i | |N u | e (k )</formula> r enforces smoothness on users and items that have interactions, the second layer smooths users (items) that have overlap on interacted items (users), and higher-layers capture higher-order proximity [39]</ref>. Thus combining them will make the representation more comprehensive. ( 3</ref>) Combining embeddings at different lay and items) as future work.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We first describe experimental settings, and then conduct detailed comparison with NGCF [39]</ref>, the method that is most relevant with LightGCN but more complicated (Section 4.2). We next compare with other state-of-the-art methods in Section 4.3. To jus > <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>To reduce the experiment workload and keep the comparison fair, we closely follow the settings of the NGCF work [39]</ref>. We request the experimented datasets (including train/test splits) from the authors, for which the statistics are shown in Table <ref type="table" target="#t sing the number of layers can improve the performance, but the benefits diminish. The general observation is that increasing the layer number from 0 (i.e., the matrix factorization model, results see [39]</ref>) to 1 leads to the largest performance gain, and  using a layer number of 3 leads to satisfactory performance in most cases. This observation is consistent wi formulation of GNNs and is being widely used [9,</ref>27]</ref>. Motivated by the strength of graph convolution, recent efforts like NGCF [39]</ref>, GC-MC [33]</ref>, and PinSage [46]</ref> adapt GCN to the user-item interaction graph, capturin <head>Table 3 :</head><label>3</label><figDesc>Performance comparison between NGCF and LightGCN at different layers. The scores of NGCF on Gowalla and Amazon-Book are directly copied from the Table3of[39]</ref>; the scores of NGCF on Yelp2018 are re-run by us.</figDesc><table><row><cell cols="2">Dataset</cell><cell></cell><cell>Gowalla</cell><cell></cell><cell>Yelp20
ggregating the embeddings of neighbors to refine the target node's embedding. Owing to its interpretability and efficiency, it quickly becomes a prevalent formulation of GNNs and is being widely used [9,</ref>27]</ref>. Motivated by the strength of graph convolution, recent efforts like NGCF [39]</ref>, GC-
"http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To alleviate information overload on the web, recommender system has been widely deployed to perform personalized information filtering [5,</ref>46]</ref>. The core of recommender system is to predict whether a user will interact with an item, e.g., click, rate, purchase, am /head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK 5.1 Collaborative Filtering</head><p>Collaborative Filtering (CF) is a prevalent technique in modern recommender systems [5,</ref>46]</ref>. One common paradigm of CF model is to parameterize users and items as embeddings, and learn the embedding parameters by
="bibr" target="#b20">21]</ref>. Early studies define graph convolution on the spectral domain, such as Laplacian eigen-decomposition [1]</ref> and Chebyshev polynomials [6]</ref>, which are computationally expensive. Later on, GraphSage [12]</ref> and GCN [21]</ref> re-define
v> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Compared Methods.</head><p>The main competing method is NGCF, which has shown to outperform several methods including GCNbased models GC-MC [33]</ref> and PinSage [46]</ref>, neural network-based models NeuMF [18]</ref> and CMN <ref type="bibr" ta f type="bibr" target="#b8">[9,</ref>27]</ref>. Motivated by the strength of graph convolution, recent efforts like NGCF [39]</ref>, GC-MC [33]</ref>, and PinSage [46]</ref> adapt GCN to the user-item interaction graph, capturing CF signals in high-hop neighbors for recommenda
ds this end, attention mechanisms are introduced to capture the varying contributions, such as ACF [3]</ref>, NAIS [17]</ref>, and DeepICF [43]</ref>, to automatically learn the importance of each historical item. When revisiting historical interactions as a user-item bipartite graph, the performance improv
neighbors, Wang et al. [39]</ref> recently proposes NGCF and achieves state-of-the-art performance for CF. It takes inspiration from the Graph Convolution Network (GCN) [12,</ref>21]</ref>, following the same propagation rule to refine embeddings: feature transformation, neighborhood aggregation, and nonli rth noting that in LGC, we aggregate only the connected neighbors and do not integrate the target node itself (i.e., selfconnection). This is different from most existing graph convolution operations [12,</ref>21,</ref>34,</ref>39]</ref> that typically aggregate extended neig uraging connected nodes to have similar labels. Recently emerged graph neural networks (GNNs) shine a light on modeling graph structure, especially high-hop neighbors, to guide the embedding learning [12,</ref>21]</ref>. Early studies define graph convolution on the spectral domain, such as Laplacian eigen-decomposition <ref type="bibr" are inspirational to future developments of recommender models. With the prevalence of linked graph data in real applications, graph-based models are becoming increasingly important in recommendation [12,</ref>37]</ref>; by explicitly exploiting the relations among entities in the predictive model, they are advantageous to traditional s ified the AGG, such as the weighted sum aggregator in GCN [21]</ref> and GIN [42]</ref>, mean aggregator and LSTM aggregator in GraphSAGE [12]</ref>, etc. However, most of the work ties feature transformation or nonlinear activation with the AGG function. Although they perform well on node or graph classif ch as Laplacian eigen-decomposition [1]</ref> and Chebyshev polynomials [6]</ref>, which are computationally expensive. Later on, GraphSage [12]</ref> and GCN [21]</ref> re-define graph convolution in the spatial domain, i.e., aggregating the embeddings of neighbors to refine t
"http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To alleviate information overload on the web, recommender system has been widely deployed to perform personalized information filtering [5,</ref>46]</ref>. The core of recommender system is to predict whether a user will interact with an item, e.g., click, rate, purchase, am /head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK 5.1 Collaborative Filtering</head><p>Collaborative Filtering (CF) is a prevalent technique in modern recommender systems [5,</ref>46]</ref>. One common paradigm of CF model is to parameterize users and items as embeddings, and learn the embedding parameters by
neighbors, Wang et al. [39]</ref> recently proposes NGCF and achieves state-of-the-art performance for CF. It takes inspiration from the Graph Convolution Network (GCN) [12,</ref>21]</ref>, following the same propagation rule to refine embeddings: feature transformation, neighborhood aggregation, and nonli rth noting that in LGC, we aggregate only the connected neighbors and do not integrate the target node itself (i.e., selfconnection). This is different from most existing graph convolution operations [12,</ref>21,</ref>34,</ref>39]</ref> that typically aggregate extended neig uraging connected nodes to have similar labels. Recently emerged graph neural networks (GNNs) shine a light on modeling graph structure, especially high-hop neighbors, to guide the embedding learning [12,</ref>21]</ref>. Early studies define graph convolution on the spectral domain, such as Laplacian eigen-decomposition <ref type="bibr" are inspirational to future developments of recommender models. With the prevalence of linked graph data in real applications, graph-based models are becoming increasingly important in recommendation [12,</ref>37]</ref>; by explicitly exploiting the relations among entities in the predictive model, they are advantageous to traditional s ified the AGG, such as the weighted sum aggregator in GCN [21]</ref> and GIN [42]</ref>, mean aggregator and LSTM aggregator in GraphSAGE [12]</ref>, etc. However, most of the work ties feature transformation or nonlinear activation with the AGG function. Although they perform well on node or graph classif ch as Laplacian eigen-decomposition [1]</ref> and Chebyshev polynomials [6]</ref>, which are computationally expensive. Later on, GraphSage [12]</ref> and GCN [21]</ref> re-define graph convolution in the spatial domain, i.e., aggregating the embeddings of neighbors to refine t
rmation such as item knowledge graph [35,</ref>38]</ref>, social network [41]</ref> and multimedia content [45]</ref> for recommendation, where GCNs have set up the new state-of-the-art. However, these models may also suffer from the similar issues of NGCF since the user-item
ctors [18]</ref>. Matrix factorization is an early such model, which directly projects the single ID of a user to her embedding [24,</ref>30]</ref>. Later on, several research find that augmenting user ID with the her interaction history as the input can improve the quality of embedding. For example, SVD++ beddings, and learn the embedding parameters by reconstructing historical useritem interactions. For example, earlier CF models like matrix factorization (MF) [24,</ref>30]</ref> project the ID of a user (or an item) into an embedding vector. The recent neural recommender models like NCF [18]</ref> and LRM ly the embeddings of the 0-th layer, i.e., Θ = {E (0) }; in other words, the model complexity is same as the standard matrix factorization (MF). We employ the Bayesian Personalized Ranking (BPR) loss [30]</ref>, which is a pairwise loss that encourages the prediction of an observed entry to be higher than its unobserved counterparts:</p><formula xml:id="formula_24">L ef type="bibr" target="#b45">[46]</ref>, neural network-based models NeuMF [18]</ref> and CMN [8]</ref>, and factorization-based models MF [30]</ref> and HOP-Rec [44]</ref>. As the comparison is done on the same datasets under the same evaluation protocol, we do not further co
as authentication and classifier occur only once, while the terms that occur more than once are stopwords like of and on. Therefore, a better mechanism for local weights is needed.</p><p>Inspired by [60]</ref>, we propose a local weight network based on distributed word representations. The basic idea is that, because of the linearity of word embeddings, the subject
the expected loss based on Bayesian decision theory. In [41]</ref> a Bayesian active learning algorithm for deep learning in image data is proposed based on the idea in [42]</ref>.</p><p>Most works that apply active learning to recommender systems are based on collaborative filtering [43]</ref>, <ref type= :id="formula_1">L V I = q(ω) log p(D train |f ω (x))dω − KL(q(ω)||p(ω))</formula><p>(2) which is the basic equation of Variational Inference [52]</ref>.</p><p>Following [42]</ref>, we use the distribution of the network parameter with dropout [53]</ref> as q(ω). Consider a neural network with only one laye irectly drop to zero, but gradually decrease to zero as f + − f − increases. Therefore, it can be considered as the smoothed version of hinge loss.</p><p>As for the second term in (2), it's proved in [42]</ref> that it can be approximated by L2 regularization term</p><formula xml:id="formula_30">Wi∈ω λ i ||W i || 2 ,</formula><p>as long as the weight decay λ i satisf
n active learning method can be applied to any deep models for ranking or recommendation with a pairwise approach.</p><p>• Combining the proposed model with densityweighted Expected Loss Optimization [17]</ref>, we introduce active learning into POLAR [16]</ref>, an attentionbased CNN combined with one-shot learning for personalized art ing approach is presented in [40]</ref>. Unlabeled instances whose prediction the parameters under the posterior disagree about are selected. Expected Loss Optimization [17]</ref> selects the instance that maximizes the expected loss based on Bayesian decision theory. In [41]</ref> a Bayesian active learni </ref> to avoid over-fitting.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Expected Loss Optimization</head><p>The active learning metric we choose is Expected Loss Optimization [17]</ref>. The basic idea is to choose the instance that maximizes the expected loss of the current best action. For the ranking problem, the action for an instance ref
strategy are two representative heuristic methods, but they are not personalized. More advanced methods are based on uncertainty reduction [48]</ref> or error reduction [49]</ref>, [50]</ref>. For example, in [44]</ref> a decision tree is built to model the Ask-To-Rate proces
ng [5]</ref> in this scenario. Inspired by the recent success of one-shot deep learning [6]</ref>, [7]</ref>, [8]</ref>, we propose to learn a one-shot deep matching metric for personalized article recommendation by actively querying the user for feedback. For new users, we may n nce. In [6]</ref>, a Siamese network is learned with several convolutional layers used before the fully-connected layers and the top-level energy function. Matching Nets [8]</ref> take as input not only the new sample but also a small support set that contains labeled examples. An LSTM with read-attention over the support set implements t em, where d is a training instance and ŷ is the corresponding label. It is probable to make an analogy between oneshot learning and our problem because S is of minimal size or even empty. Inspired by [8]</ref>, our model computes f ω (d q , S, d i ) as:</p><formula xml:id="formula_4">f ω (d q , S, d i ) =    c ω (d q , d i ) S = ∅ c ω (d q , d i ) + 1 |S| ( d,ŷ)∈S
ortant role in academic search sites and digital libraries and has attracted a lot of research interest. Giles et al. introduced the first research-article recommender as part of the CiteSeer project [18]</ref>. Content-based filtering [4]</ref> is one of the most widely used and researched recommendation method and has been successfully plain words as features, although some use n-grams [20]</ref>, topics [9]</ref>, [21]</ref>, and citations [18]</ref>. Collaborative filtering [5]</ref> makes recommendation predictions by utilizing the explicit or implicit ratings of the current
re. There are three different scenarios: membership query synthesis [32]</ref>, stream-based sampling [33]</ref>, and pool-based sampling [34]</ref>. One of the most common frameworks for active learning is Uncertainty Sampling [34]</ref>, where the active learner selects the ed sampling [33]</ref>, and pool-based sampling [34]</ref>. One of the most common frameworks for active learning is Uncertainty Sampling [34]</ref>, where the active learner selects the instance for which the prediction uncertainty is highest. The uncertainty measure includes Entropy <ref type="bibr" targ the support set is empty, which means that it is impossible to provide personalized recommendations for the user.</p><p>Moving from this, we define the new problem in the pool-based sampling setting [34]</ref> of active learning : Definition 2 (Active One-shot Article Recommendation Problem). The input of the problem is a query article d q , an unlabeled set U, and
ch contain parts of certain objects are selected through a supervised process to extract discriminative features.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Matrix</head><p>In [56]</ref>, an attention matrix is employed to give different attention weights to units in a feature map.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Confi
="#b46">[47]</ref>. The Popularity strategy and the Coverage strategy are two representative heuristic methods, but they are not personalized. More advanced methods are based on uncertainty reduction [48]</ref> or error reduction [49]</ref>, [50]</ref>. For example, in [44]</
ng [5]</ref> in this scenario. Inspired by the recent success of one-shot deep learning [6]</ref>, [7]</ref>, [8]</ref>, we propose to learn a one-shot deep matching metric for personalized article recommendation by actively querying the user for feedback. For new users, we may n nce. In [6]</ref>, a Siamese network is learned with several convolutional layers used before the fully-connected layers and the top-level energy function. Matching Nets [8]</ref> take as input not only the new sample but also a small support set that contains labeled examples. An LSTM with read-attention over the support set implements t em, where d is a training instance and ŷ is the corresponding label. It is probable to make an analogy between oneshot learning and our problem because S is of minimal size or even empty. Inspired by [8]</ref>, our model computes f ω (d q , S, d i ) as:</p><formula xml:id="formula_4">f ω (d q , S, d i ) =    c ω (d q , d i ) S = ∅ c ω (d q , d i ) + 1 |S| ( d,ŷ)∈S
2]</ref>.</p><p>Most works that apply active learning to recommender systems are based on collaborative filtering [43]</ref>, [44]</ref>, [45]</ref>. The active learning method is also called the Ask-To-Rate technique [46]</ref>. A comprehensive survey can be found in <ref ty
2]</ref>.</p><p>Most works that apply active learning to recommender systems are based on collaborative filtering [43]</ref>, [44]</ref>, [45]</ref>. The active learning method is also called the Ask-To-Rate technique [46]</ref>. A comprehensive survey can be found in <ref ty
posterior disagree about are selected. Expected Loss Optimization [17]</ref> selects the instance that maximizes the expected loss based on Bayesian decision theory. In [41]</ref> a Bayesian active learning algorithm for deep learning in image data is proposed based on the idea in [42]</ref>.</p><p>Most wo
on, collaborative filtering often suffers from the cold-start problem [10]</ref>. Some works also use graph-based methods to explore the inherent connections in academia [23]</ref>, [24]</ref>.</p><p>Our work is also related to information retrieval [11]</ref>, <ref type="bibr mula_40">argmax di EL(d i |d q , S) × 1 |U| dj ∈U c(d i , d j )<label>(23)</label></formula><p>where c(d i , d j ) is the similarity between d i and d j predicted by our CNN model. The latter part in (23)</ref> is the average similarity between d i and articles in U. (23)</ref> aims to find the instance that is representative of most un e c(d i , d j ) is the similarity between d i and d j predicted by our CNN model. The latter part in (23)</ref> is the average similarity between d i and articles in U. (23)</ref> aims to find the instance that is representative of most unlabeled articles while maximizing the expected loss at the same time. The completed algorithm for a
"#b17">[18]</ref>. Collaborative filtering [5]</ref> makes recommendation predictions by utilizing the explicit or implicit ratings of the current user and similar users [22]</ref>. However, in article recommendation, collaborative filtering often suffers from the cold-start problem [10]</ref>. Some works al can be approximated by the variance of predicted y in Monte-Carlo Sampling.</p><p>• POLAR++ELO The active selection strategy is to maximize the Expected Loss for Ranking without density according to (22)</ref>.</p><p>• POLAR++DWELO DWELO (Density-Weighted Expected Loss Optimization) is the complete active leraning algorithm which combines ELO and density, as describ
strategy are two representative heuristic methods, but they are not personalized. More advanced methods are based on uncertainty reduction [48]</ref> or error reduction [49]</ref>, [50]</ref>. For example, in [44]</ref> a decision tree is built to model the Ask-To-Rate proces
ddings and neural networks, many neural similarity models that can directly deal with word sequences are proposed [11]</ref>, [12]</ref>, [13]</ref>, [14]</ref>, [15]</ref>, but they often treat all the words in an article indiscriminately. Ther rieval [11]</ref>, [25]</ref>, [26]</ref> and semantic matching [12]</ref>, [13]</ref>. Traditional methods for measuring the similarity between two pieces of texts, such as BM25 [26]</ref> and TF-IDF <ref type="bi icle with neural networks and then take as the similarity score the similarity (often cosine similarity) between distributed representations of two articles [11]</ref>, [13]</ref>, [27]</ref>. However, these models cannot identify the specific matching signals. The second group of models, called interactio div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>AMiner</head><p>Patent RARD Method NG@3 NG@5 NG@10 NG@3 NG@5 NG@10 NG@1 NG@3 NG@5 The following are several neural matching models.</p><p>• MV-LSTM [13]</ref>:The interactions between different positional sentence representations generated by a Bi-LSTM form a similarity matrix to generate the matching score.</p><p>•

a_9">Z (m,n) = M (m,n) ⊗ A (m,n)<label>(7)</label></formula><p>Z (m,n) is the input of a CNN that consists of several convolutional layers and max-pooling layers. Similar to CNNs in image recognition [58]</ref>, the filters in low-level convolutional layers can capture different matching signals between phrases, while the filters in high-level convolutional layers ca
trix cannot reflect the term importance, thus cannot distinguish the matching  </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Object Parts Selection</head><p>In fine-grained classification [55]</ref>, image patches which contain parts of certain objects are selected through a supervised process to extract discriminative features.</p></div> <div xmlns="http
g in controversial regions of the input space, which are instances the committee disagree about most. Based on the decision theory, Expected Error Reduction [38]</ref>, [39]</ref> aims to maximize the expected reduction of the generalization error, but is also the most computationally expensive framework.</p><p>Bayesian-based active lea
active learner selects the instance for which the prediction uncertainty is highest. The uncertainty measure includes Entropy [35]</ref> for classification and Variance [36]</ref> for regression. The drawback of uncertainty sampling is that it often samples the outliers or the instances with greater noise. Query-by-Committee <ref type="
xml:id="formula_10">r ij = µ ij • υ ij<label>(8)</label></formula><p>Local Weight: The local weight measures the relevance of a term to the subject of the document. For example, in the following text [59]</ref>:</p><p>Example 1. We propose a low-complexity audio-visual person authentication framework based on multiple features and multiple nearest-neighbor classifier
ttp://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>R ECOMMENDER systems play a key role in today's web applications. For example, in academic search sites such as Google Scholar and AMiner [1]</ref>, article recommendation is essential for users to find the right articles as the number of articles has been increasing dramatically in the past years. The rece performance of the proposed model on article recommendation two small, manually labeled datasets and a large-scale dataset based on user clicks.</p><p>The first dataset is based on papers from AMiner [1]</ref> and consists of 188 query papers with ten candidate papers for each query. The second dataset is based on documents of patents coming from the Patent Full-Text articles are combined as texts. Texts longer than 64 terms are truncated.</p><p>To conduct experiments on Active One-shot Article Recommendation Problem, we use the Citation Network Dataset in AMiner [1]</ref>. The citation data is extracted from DBLP, ACM, MAG (Microsoft Academic Graph), and other sources. The version we used contains 3,272,991 papers and 8,466,859 c
"#b17">[18]</ref>. Collaborative filtering [5]</ref> makes recommendation predictions by utilizing the explicit or implicit ratings of the current user and similar users [22]</ref>. However, in article recommendation, collaborative filtering often suffers from the cold-start problem [10]</ref>. Some works al can be approximated by the variance of predicted y in Monte-Carlo Sampling.</p><p>• POLAR++ELO The active selection strategy is to maximize the Expected Loss for Ranking without density according to (22)</ref>.</p><p>• POLAR++DWELO DWELO (Density-Weighted Expected Loss Optimization) is the complete active leraning algorithm which combines ELO and density, as describ
="#b3">[4]</ref> or Collaborative Filtering [5]</ref> in this scenario. Inspired by the recent success of one-shot deep learning [6]</ref>, [7]</ref>, [8]</ref>, we propose to learn a one-shot deep matching metric for personalized article recommendation by actively querying the u the embedding function. Meta-learning-based approaches aim to learn how to update the parameters or directly predict the parameters given a few training instances, including Memory-Augmented Network [7]</ref> and LSTM-based meta-learner [30]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Active Learning</head><p
/ref>, [45]</ref>. The active learning method is also called the Ask-To-Rate technique [46]</ref>. A comprehensive survey can be found in [47]</ref>. The Popularity strategy and the Coverage strategy are two representative heuristic methods, but they are not personalized. More advanced methods are based on vely-built support set Q. The output is the recommendation result R(d q , Q).</p><p>We define the active learning problem in the adaptive setting (which is also called Personalized Active Learning in [47]</ref>). When the model selects the i-th article, it has access to the previous (i − 1) articles and ratings, so that the strategy can dynamically adapt to different
[31]</ref> in the statistic literature. There are three different scenarios: membership query synthesis [32]</ref>, stream-based sampling [33]</ref>, and pool-based sampling [34]</ref>. One of the most common frameworks for active learning is Uncertainty Sampling <ref type="b
strategy are two representative heuristic methods, but they are not personalized. More advanced methods are based on uncertainty reduction [48]</ref> or error reduction [49]</ref>, [50]</ref>. For example, in [44]</ref> a decision tree is built to model the Ask-To-Rate proces
re. There are three different scenarios: membership query synthesis [32]</ref>, stream-based sampling [33]</ref>, and pool-based sampling [34]</ref>. One of the most common frameworks for active learning is Uncertainty Sampling [34]</ref>, where the active learner selects the ed sampling [33]</ref>, and pool-based sampling [34]</ref>. One of the most common frameworks for active learning is Uncertainty Sampling [34]</ref>, where the active learner selects the instance for which the prediction uncertainty is highest. The uncertainty measure includes Entropy <ref type="bibr" targ the support set is empty, which means that it is impossible to provide personalized recommendations for the user.</p><p>Moving from this, we define the new problem in the pool-based sampling setting [34]</ref> of active learning : Definition 2 (Active One-shot Article Recommendation Problem). The input of the problem is a query article d q , an unlabeled set U, and
ch it learns. It is closely related to Optimal Experiment Design [31]</ref> in the statistic literature. There are three different scenarios: membership query synthesis [32]</ref>, stream-based sampling [33]</ref>, and pool-based sampling [34]</ref>. One of the most common fr
ttp://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>R ECOMMENDER systems play a key role in today's web applications. For example, in academic search sites such as Google Scholar and AMiner [1]</ref>, article recommendation is essential for users to find the right articles as the number of articles has been increasing dramatically in the past years. The rece performance of the proposed model on article recommendation two small, manually labeled datasets and a large-scale dataset based on user clicks.</p><p>The first dataset is based on papers from AMiner [1]</ref> and consists of 188 query papers with ten candidate papers for each query. The second dataset is based on documents of patents coming from the Patent Full-Text articles are combined as texts. Texts longer than 64 terms are truncated.</p><p>To conduct experiments on Active One-shot Article Recommendation Problem, we use the Citation Network Dataset in AMiner [1]</ref>. The citation data is extracted from DBLP, ACM, MAG (Microsoft Academic Graph), and other sources. The version we used contains 3,272,991 papers and 8,466,859 c
head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Pairwise Loss for Bayesian Learning</head><p>We formulate the training set in the setting of Pairwise Approach of Learning to Rank [61]</ref>. It means that D train = {(d q and support set S (i) . We transform it into the constraint on the recommendation score as y</p><formula xml:id="formula_21">(i
often difficult to obtain. Meanwhile, traditional machine learning-based methods apply various features [32,</ref>8]</ref> and descriptors [7,</ref>13,</ref>6]</ref>, and simply depend on the similarities between drugtarget pairs <ref type="bibr" t
ext. To remedy this, we propose to use Smi2Vec [26]</ref>, a method similar to Word2Vec [20,</ref>15,</ref>27]</ref>, to represent the symbols in the SMILES sequence. Algorithm 1 shows the pseudo-codes of encoding SMILES symbols, based on the pre-trained Smi2Vec embeddings. I
s 2-6). Finally, it constructs an atom matrix A by aggregating embedding vectors (Lines 7-8), where each line represents the pre-trained vector of an atom.</p><p>Motivated by the gate function in GRU [5]</ref>, we apply a 1-layer Bi-GRU on the resulting matrix to obtain a latent representation of the drug, which allows us to model the local chemical context. Note that
et binding affinity, it is possible to find out candidate drugs that are able to inhibit the target/protein and benefits many other bioinformatic applications [28,</ref>18,</ref>25]</ref>. As a result, DTA prediction has received much attention in recent years [3,</ref><ref ty
tein [30,</ref>9]</ref>, which are often difficult to obtain. Meanwhile, traditional machine learning-based methods apply various features [32,</ref>8]</ref> and descriptors [7,</ref>13,</ref><ref type="bibr" target="
score is widely used for binary classification. A commonly used binding affinity value is defined based on the logarithm of K d as pK d = -log10( K d 1e9 ), where K d refers to the dissociation value [29]</ref>. Here, we transformed the datasets into binary datasets with predefined thresholds. We followed the prior work [23]</ref> to se
et binding affinity, it is possible to find out candidate drugs that are able to inhibit the target/protein and benefits many other bioinformatic applications [28,</ref>18,</ref>25]</ref>. As a result, DTA prediction has received much attention in recent years [3,</ref><ref ty
A dataset, respectively.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Baseline Methods</head><p>We compared DeepGS against the following state-of-the-art models:</p><p>? KronRLS [24]</ref>: This approach is based on Kronecker Regularized Least Square (http://staff.cs.utu.fi/?aatapa/software/RLScore/). It aims to minimize the objective function,< s) or machine  learning-based models. For example, Li et al. [16]</ref> proposed a docking method based on random forrest (RF). The RF model was also adopted in KronRLS [24]</ref> with a similarity score through the Kronecker product of similarity matrix to improve the predictive performance. To remedy the limitation of linear dependenc
.g., MKKFFDSRREQ... shown in Figure 1</ref>). Similar to the SMILES string, we propose to first encode the amino acids into a ddimensional vector following Prot2Vec [2]</ref>, which allows us to capture local chemical information in targets/proteins. As a single amino acid often makes no sense, we apply a fixed-length N -gram splitti 1">[x1; x2; x3], [x4; x5; x6], ..., [x |l|-2 ; x |l|-1 ; x |l| ].</formula><p>For each biological word, we map it to an embedding vector by looking up a pretrained embedding dictionary for 9048 words [2]</ref>, which is obtained from Swiss-Prot (https://www.uniprot.org/) with 560,118 manually annotated sequences. As a result, we transform each target sequence to a mat
8">[39]</ref>. By understanding drug-target binding affinity, it is possible to find out candidate drugs that are able to inhibit the target/protein and benefits many other bioinformatic applications [28,</ref>18,</ref>25]</ref>. As a result, DTA prediction has received much attention in recent years <ref
rization parameter, f 2 k is the norm of f with kernel k. ? SimBoost [12]</ref>: This baseline constructs three kinds of features and trains a gradient boosting machine [4]</ref> model to represent the nonlinear associations between the input features and the binding affinities.</p><p>? DeepCPI [31]</ref>:
llenge, in this paper we introduce Limago, an open-source 100 Gbit/s TCP/IP network stack on an FPGA. Limago explores the changes needed to upgrade an existing open-source TCP/IP stack from 10 Gbit/s [11]</ref> to 100 Gbit/s, but maintaining the same high-productivity design methodology, based on Vivado-HLS, that was utilized in the previous design. In doing so, Lima 48 connections working as a server. It also can send up to 40 Gbit/s but only receive up to 4 Gbit/s. The starting point for Limago is a 10 Gbit/s TOE written by Sidler et al. in C++ using Vivado-HLS [11]</ref>, [29]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. LIMAGO ARCHITECTURE</head><p>Figure <ref type="figure hitecture of the TOE (Figure 2</ref>). It is divided into three parts, the incoming data path (Rx Engine), the outgoing data path (Tx Engine), and the state-keeping data structures [11]</ref>, [29]</ref>. The dash boxes are optional modules that can be enabled at synthesis.</p></div> <div xmlns="http://www.tei-c.org/n
ula xml:id="formula_0">#conn = 2 DRAM b -W S b -16</formula><p>(1)</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RELATED WORK</head><p>The benefits of TCP/IP offloading are well-known [16]</ref>- [18]</ref>: reduced CPU utilization and bypassing of the Operating System. In a TOE, packet processing is moved to the NIC, wh

owards specialization seen in cloud computing opens up the possibility of tailored network designs through Smart Network Interface Cards (NICs), which push application-level processing to the network [2]</ref>. As a result, we are witnessing a flurry of activity around programmable networks based on a variety of designs and architectures.</p><p>A concrete example of t
ad>D. TCP Window Scale Option</head><p>Links with a large bandwidth ? delay product suffer from the Long Fat Pipe issue: those links where the bandwidth ? delay product is larger than the buffer size [15]</ref>. The Window Scale option is used to allocate any fix-size buffer in the range of 2 16 to 2 30 bytes, thereby leading to a better usage of links.</p><p>Current
[6]</ref>, or for distributed machine learning algorithms [7]</ref>. Catapult is, by far, not the only possible design. In IBM's cloudFPGA [8]</ref>, the FPGA is deployed as a network-attached accelerator. Similarly, Caribou [9]</ref> deploys FPGAs as storage nodes that extend t
lability of High Bandwidth Memory in FPGAs. This feature will improve the throughput when packet loss occurs as well as support application level processing [34]</ref>, [35]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: General Architecture Overview.</fig
, we are witnessing a flurry of activity around programmable networks based on a variety of designs and architectures.</p><p>A concrete example of these developments is provided by Microsoft Catapult [3]</ref>, a deployment of FPGAs in the cloud that has evolved through several generations [4]</ref>, [5]</ref
get="#b4">[5]</ref>, application-level functionality such as RDMA packet processing to support key-value stores [6]</ref>, or for distributed machine learning algorithms [7]</ref>. Catapult is, by far, not the only possible design. In IBM's cloudFPGA [8]</ref>, the FPGA is deployed as a network-attached accel

bed in detail in [13]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>B. CuckooCAM</head><p>The 10 Gbit/s version of the stack is based on the smart-CAM [14]</ref> module provided by Xilinx. It used a four-tuple consisting of IP source and destination addresses plus TCP source and destination ports as a key. We replaced
g="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Human identification by the uniqueness of every individual is an indispensable part of human life nowadays [1,</ref>2]</ref>. However, because of the lack of liveness check, traditional biometric recognition techniques via fingerprint, palm print,
(ECG), which records the electrical depolarizationrepolarization patterns of the heart, has been proposed and studied [14,</ref>15,</ref>16,</ref>10,</ref>8]</ref>. Different from other biometrics, ECG signals can only be captured with the activi
cial features are strictly influenced by the accuracy of the detection, especially for one-lead ECG signals with poor quality. For nonfiducial features, they are subdivided into auto-correction based [42,</ref>33]</ref>, phase space based [43,</ref>44]</ref>, and frequency ba
new human identification technique by biometric recognition via electrocardiogram (ECG), which records the electrical depolarizationrepolarization patterns of the heart, has been proposed and studied [14,</ref>15,</ref>16,</ref>10,</ref>8]</ref>.
(ECG), which records the electrical depolarizationrepolarization patterns of the heart, has been proposed and studied [14,</ref>15,</ref>16,</ref>10,</ref>8]</ref>. Different from other biometrics, ECG signals can only be captured with the activi
simply compared with some methods, as shown in  and much better than those of [33,</ref>50,</ref>51,</ref>62,</ref>63,</ref>64]</ref> by a large margin. However, the dedicated methods presented in Table <ref type=
chor points [38,</ref>26]</ref>, amplitude features of various peaks [24]</ref> and morphological features [39,</ref>40]</ref>are favored in the literatures. Based on the fiducial points, Safie et al. [13]</ref> ad
ype="bibr" target="#b0">[1,</ref>2]</ref>. However, because of the lack of liveness check, traditional biometric recognition techniques via fingerprint, palm print, face [11,</ref>12]</ref>, iris, or speech recognition are facing severe challenges caused by data replication and malicious forgery.</p><p>In t
features, they are subdivided into auto-correction based [42,</ref>33]</ref>, phase space based [43,</ref>44]</ref>, and frequency based [45,</ref>46]</ref> features. However, although these methods help extract c
nt for others to implement and compare with the proposed method, five public datasets FANTASIA [57]</ref>,</p><p>CEBSDB [58]</ref>, NSRDB [59]</ref>, STDB [60]</ref>, and AFDB [61]</ref> are used for conducting experiments. These datasets are co
methods. The datasets for evaluating different methods are various and inconsistent. To make it convenient for others to implement and compare with the proposed method, five public datasets FANTASIA [57]</ref>,</p><p>CEBSDB [58]</ref>, NSRDB [59]</ref>, STDB [60]</ref>, and
tropy predictions, prompting us to ask which one is better?</p><p>To resolve the first issue, taking two well-accepted propositions-deep neural networks learn meaningful patterns before fitting noise [3]</ref> and minimum entropy regularisation principle [10]-we propose a novel end-to-end method named ProSelfLC, which is designed according to learning time and entropy more reliable than its own predictions in the early phase, during which the model is learning simple meaningful patterns before fitting noise, even when severe label noise exists in human annotations [3]</ref>. (2) As a learner attains confident knowledge as time progresses, we leverage it to revise annotated labels. This is surrounded by minimum entropy regularisatio more reliable than its own predictions in the early phase, during which the model is learning simple meaningful patterns before fitting noise, even when severe label noise exists in human annotations[3]</ref>. (2) As a learner attains confident knowledge as time progresses, we leverage it to revise annotated labels. This is surrounded by minimum entropy regularisatio
knowledge as time progresses, we leverage it to revise annotated labels. This is surrounded by minimum entropy regularisation, which is widely evaluated in unsupervised and semi-supervised scenarios [9,</ref>10]</ref>.</p><p>Secondly, note that OR methods penalise low entropy while LC rewards it, intuitively leading to a second vital que t knowledge as time progresses, we leverage it to revise annotated labels. This is surrounded by minimum entropy regularisation, which is widely evaluated in unsupervised and semi-supervised scenarios[9,</ref>10]</ref>.Secondly, note that OR methods penalise low entropy while LC rewards it, intuitively leading to a second vital question:S se a low-entropy status or reward it?</p><p>Entropy minimisation is the most widely used principle in machine learning [14,</ref>38,</ref>9,</ref>10,</ref>22]</ref>. In standard classification, minimising categorical cross entropy (CCE) optimises
t B, ǫ are in Table 5</ref>. We note that when the noise rate is higher, a smaller B performs better.</p><p>We further discuss their differences on model calibration [11]</ref> in Appendix B, the changes of entropy and ǫ ProSelfLC during training in Appendix C.</p><p>Revising the semantic class and similarity structure. In Figures <r
tion, which is generally necessary for any method and differs from the methods [44,</ref>45,</ref>19,</ref>36,</ref>26,</ref>16,</ref>53,</ref>60]</ref>
="2">72.2 71.8 72.6 72.4</cell><cell>72.3</cell><cell>73.4</cell></row></table></figure> 			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">We do not consider DisturbLabel[49]</ref>, which flips labels randomly and is counter-intuitive. It weakens the generalisation because generally the accuracy drops as the uniform label noise increases
19,</ref>36,</ref>26,</ref>16,</ref>53,</ref>60]</ref> which use a clean dataset to train a network's learning parameters.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Standard image classifica
g self KD, two examples of the same class are constrained to have consistent output distributions [51,</ref>56]</ref>. In another self KD [57]</ref>, the deepest classifier provides knowledge for shallower classifiers. In a recent self KD method [55]</ref>, Tf-KD self applies iting its knowledge learned in the first stage. Our focus is to improve the end-to-end self LC. First, self KD methods [51,</ref>56,</ref>57]</ref> maximise the consistency of intraclass images' predictions or the consistency of different classifiers. In our view, they do not modify labels, thus being less
ef>25]</ref>, which relate to our focus in this work. Their strategy is to annotate unlabelled samples or correct noisy labels.</p><p>LC and knowledge distillation (KD) [5,</ref>17]</ref>. Mathematically, we derive that some KD methods also modify labels. We use the term label correction instead of KD for t
olving label noise: (1) Loss correction, in which we are given or we need to estimate a noisetransition matrix, which defines the distribution of noise labels [26,</ref>8,</ref>41,</ref>44,</ref>52,</ref>12,</ref><r a and about 1 million images of 14 classes from shopping websites. Its internal noise structure is agnostic.</p><p>Baselines. For loss correction and estimating the noisetransition matrix, S-adaption [8]</ref> uses an extra softmax layer, while Masking [12]</ref> exploits human cognition. MD-DYR-SH [2]</ref>
ansition matrix [32]</ref>. D2L monitors the subspace dimensionality change at training [27]</ref>. GCE denotes generalised cross entropy [59]</ref> and SL is symmetric cross entropy [46]</ref>. They are robust losses designed for solving label noise. Training details are the

ral networks. It includes label smoothing (LS) [42,</ref>29]</ref> and confidence penalty (CP) [33]</ref>; (2)</ref> Label correction (LC). On the one hand, LC regularises neural networks by adding the similarity structure information over training classes into onehot label di isting approaches: (1) OR methods naively penalise confident outputs without leveraging easily accessible knowledge from other learners or itself (Figure 1a</ref>); (2)</ref> Non-self LC relies on accurate auxiliary models to generate predictions (Figure 1b</ref>). (3) Self LC is the most appealing the noisetransition matrix, S-adaption [8]</ref> uses an extra softmax layer, while Masking [12]</ref> exploits human cognition. MD-DYR-SH [2]</ref> is a combination of three techniques: dynamic mixup (MD), dynamic bootstrapping together with label regularisation (DYR) and soft to hard (SH). The other baseli
distance between their feature maps is reduced in [37]</ref>. Regarding self KD, two examples of the same class are constrained to have consistent output distributions [51,</ref>56]</ref>. In another self KD [57]</ref>, the deepest classifier provides knowledge for shallower self applies two-stage training. In the second stage, a model is trained by exploiting its knowledge learned in the first stage. Our focus is to improve the end-to-end self LC. First, self KD methods [51,</ref>56,</ref>57]</ref> maximise the consistency of intraclass images' predictions or the consistency
defines the distribution of noise labels [26,</ref>8,</ref>41,</ref>44,</ref>52,</ref>12,</ref>32,</ref>48]</ref>. A noise-transition matrix is difficult points; (4) Label engineering methods [40,</ref>23,</ref>35,</ref>43,</ref>52,</ref>25]</ref>, which relate to our focus in this work. Their strategy is to annotate unlabelled samples or correct noisy labels.</p><
t B, ǫ are in Table 5</ref>. We note that when the noise rate is higher, a smaller B performs better.</p><p>We further discuss their differences on model calibration [11]</ref> in Appendix B, the changes of entropy and ǫ ProSelfLC during training in Appendix C.</p><p>Revising the semantic class and similarity structure. In Figures <r
distance between their feature maps is reduced in [37]</ref>. Regarding self KD, two examples of the same class are constrained to have consistent output distributions [51,</ref>56]</ref>. In another self KD [57]</ref>, the deepest classifier provides knowledge for shallower self applies two-stage training. In the second stage, a model is trained by exploiting its knowledge learned in the first stage. Our focus is to improve the end-to-end self LC. First, self KD methods [51,</ref>56,</ref>57]</ref> maximise the consistency of intraclass images' predictions or the consistency
educed in [37]</ref>. Regarding self KD, two examples of the same class are constrained to have consistent output distributions [51,</ref>56]</ref>. In another self KD [57]</ref>, the deepest classifier provides knowledge for shallower classifiers. In a recent self KD method econd stage, a model is trained by exploiting its knowledge learned in the first stage. Our focus is to improve the end-to-end self LC. First, self KD methods [51,</ref>56,</ref>57]</ref> maximise the consistency of intraclass images' predictions or the consistency of different classifiers. In our view, th
45,</ref>19,</ref>36,</ref>26,</ref>16,</ref>53,</ref>60]</ref> which use a clean dataset to train a network's learning parameters.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0">
se</head><p>Noise generation. (1) Symmetric label noise: the original label of an image is uniformly changed to one of the other classes with a probability of r; (2) Asymmetric label noise: we follow [46]</ref> to generate asymmetric label noise to fairly compare with their reported results. Within each coarse class, we randomly select two fine classes A and B. Then and r × 100% labels of B to A. We remark that the overall label noise rate is smaller than r. Baselines. 1</ref> We compare with the results reported recently in SL [46]</ref>. Forward is a loss correction approach that uses a noise-transition matrix [32]</ref>. D2L monitors the subspace dimensionality subspace dimensionality change at training [27]</ref>. GCE denotes generalised cross entropy [59]</ref> and SL is symmetric cross entropy [46]</ref>. They are robust losses designed for solving label noise. Training details are the same as Section 5.1.</p><p>Result analysis. For all methods, we directly re
</ref>. A noise-transition matrix is difficult and complex to estimate in practice; (2) Exploiting an auxiliary trusted training set to differentiate examples [45,</ref>24,</ref>16]</ref>. This requires extra annotation cost;</p><p>(3) Co-training strategies, which train two or more learners <ref type="bib
defines the distribution of noise labels [26,</ref>8,</ref>41,</ref>44,</ref>52,</ref>12,</ref>32,</ref>48]</ref>. A noise-transition matrix is difficult points; (4) Label engineering methods [40,</ref>23,</ref>35,</ref>43,</ref>52,</ref>25]</ref>, which relate to our focus in this work. Their strategy is to annotate unlabelled samples or correct noisy labels.</p><
,</ref>48]</ref>. A noise-transition matrix is difficult and complex to estimate in practice; (2) Exploiting an auxiliary trusted training set to differentiate examples [45,</ref>24,</ref>16]</ref>. This requires extra annotation cost;</p><p>(3) Co-training strategies, which s a separate clean validation set. Here, a clean dataset is used only for validation, which is generally necessary for any method and differs from the methods [44,</ref>45,</ref>19,</ref>36,</ref>26,</ref>16,</ref>
ust to the corruptions of edge labels. For the first requirement, the idea is to use a symmetric function on transformed elements in the point set to approximate a general function defined on the set [21]</ref>:</p><formula xml:id="formula_12">AGGREGATE({x 1 , • • • , x n }) ≈ g(o(x 1 ), • • • , o(x n )), where f : 2 R N → R, o : R N → R K and g : R K ×• • •×R K → R
the two functions in GNNs is crucial and leads to different kinds of GNNs [17]</ref>. The most popular GNNs are listed as follows.</p><p>1) Graph Convolutional Network [20]</ref>: It uses the mean pooling and relu as the aggregation and combination functions,</p><formula xml:id="formula_9">β (k) v = RELU(W (k) • 1 |N (v)| + 1 u β (k−1) pe="bibr" target="#b9">10]</ref> meters during training. In the test, the link distance is uniformly distributed in [l r , u r ] meters, where l r is uniform in [2,</ref>20]</ref> meters and u r is uniform in [l r , 20] meters. The performance of IGCNet is 101.2% compared to WMMSE in this situation. It shows that the performance of IGCNe
ead>I. INTRODUCTION</head><p>Effective resource allocation plays a crucial role for performance optimization in wireless networks. However, typical resource allocation problems, such as power control [7]</ref>, [8]</ref>, are non-convex and computationally challenging. Moreover, they need to be solved in a real-time manner to accommodate pair. The channel matrix is defined as</p><formula xml:id="formula_4">H = [h 1 , • • • , h K ] T and h i = [h 1i , • • • , h Ki ] T , i = 1, • • • , K.</formula><p>This problem is known to be NP-hard [7]</ref>. Although several optimization-based methods have been proposed in [12]</ref>, [14]</ref>, they ar
for the performance loss when the input and output dimensions are large.</p><p>CNN has demonstrated its effectiveness in solving such performance deterioration problems in image analysis applications [16]</ref>, but it is not effective for wireless power control. Specifically, for images, the geometric property means that adjacent pixels are meaningful to be consider ibr" target="#b15">[16]</ref>, but it is not effective for wireless power control. Specifically, for images, the geometric property means that adjacent pixels are meaningful to be considered together [16]</ref>. In CNN, a 2D convolution kernel is applied to each patch (adjacent pixels) in the image. The weights in the neural network are shared among different patches
for the performance loss when the input and output dimensions are large.</p><p>CNN has demonstrated its effectiveness in solving such performance deterioration problems in image analysis applications [16]</ref>, but it is not effective for wireless power control. Specifically, for images, the geometric property means that adjacent pixels are meaningful to be consider ibr" target="#b15">[16]</ref>, but it is not effective for wireless power control. Specifically, for images, the geometric property means that adjacent pixels are meaningful to be considered together [16]</ref>. In CNN, a 2D convolution kernel is applied to each patch (adjacent pixels) in the image. The weights in the neural network are shared among different patches
ead>I. INTRODUCTION</head><p>Effective resource allocation plays a crucial role for performance optimization in wireless networks. However, typical resource allocation problems, such as power control [7]</ref>, [8]</ref>, are non-convex and computationally challenging. Moreover, they need to be solved in a real-time manner to accommodate pair. The channel matrix is defined as</p><formula xml:id="formula_4">H = [h 1 , • • • , h K ] T and h i = [h 1i , • • • , h Ki ] T , i = 1, • • • , K.</formula><p>This problem is known to be NP-hard [7]</ref>. Although several optimization-based methods have been proposed in [12]</ref>, [14]</ref>, they ar
"#b16">[17]</ref> for a more detailed information. GNNs deal with learning problems with graph data or non-Euclidean data. There are many sucessful applications of GNNs such as recommendation systems [18]</ref> and solving combinatorial problems [19]</ref>. GNNs utilize the graph structure of data, the node features, and the edge featur
source allocation plays a crucial role for performance optimization in wireless networks. However, typical resource allocation problems, such as power control [7]</ref>, [8]</ref>, are non-convex and computationally challenging. Moreover, they need to be solved in a real-time manner to accommodate the time variation of wireless channels.
nce channel has attracted most of the attention [1]</ref>- [5]</ref>. The first attempts came from [1]</ref>, [2]</ref>, which applied MLP and CNN, respectively, to approximate the classic weighted minimum mean square error (WMMSE) algorithm [12]</r while achieving near-optimal performance, machine learning based methods have been proposed. Specifically, MLP [1]</ref>, [3]</ref> and CNN [2]</ref> have been used to approximate the input-output mapping of this problem. The optimization-based methods involve many iterations, with each iteration having a tim t. An illustration of the proposed network structure and parameter setting is shown in Fig. 3</ref>.</p><p>The loss function adopted is the negative sum rate, as in [2]</ref>, [3]</ref>,</p><formula xml:id="formula_15">= −E H K k=1 w k log 2 1 + |h kk | 2 p k (θ) i =k |h ki | 2 p i (θ) + σ 2 k ,</formula rages MLP to learn the input-output mapping of WMMSE. 3) PCNet [3]</ref>: It employs MLP and an unsupervised loss function to learn near-optimal power allocation. 4) DPC [2]</ref>: CNN and the unsupervised loss function are used in this method to learn a near-optimal power control. 5) Baseline: We find a fixed proportion of pairs with the </ref> as they can not incorporate instantaneous CSI.</p><p>We generate 20000 training samples, i.e., network realizations, to train MLP, PCNet, and DPC as in [1]</ref>, [2]</ref> while the number of training samples used for IGCNet is 2000. The test dataset contains 500 network realizations. We use a 5-layer IGCNet and adopt the adam opt situation where the locations of users in each sample vary. The transmitters are uniformly distributed in the square region [0, 100] × [0, 100] meters. The receivers are uniformly distributed within [2,</ref>10]</ref> meters away from the transmitter. The adopted channel model is</p><formula xml:id="formula_18">h ij = 10 −L(dij )/20 φ ij ink distance distribution in the test is different from that in the training. We follow [4]</ref> to set up the simulation. The link distance is uniformly distributed in [2,</ref>10]</ref> meters during training. In the test, the link distance is uniformly distributed in [l r , u r ] meters, where l r is unif pe="bibr" target="#b1">[2,</ref>10]</ref> meters during training. In the test, the link distance is uniformly distributed in [l r , u r ] meters, where l r is uniform in [2,</ref>20]</ref> meters and u r is uniform in [l r , 20] meters. The performance of IGCNet is 101.2% compared to WMMSE in this situation.
"#b16">[17]</ref> for a more detailed information. GNNs deal with learning problems with graph data or non-Euclidean data. There are many sucessful applications of GNNs such as recommendation systems [18]</ref> and solving combinatorial problems [19]</ref>. GNNs utilize the graph structure of data, the node features, and the edge featur
source allocation plays a crucial role for performance optimization in wireless networks. However, typical resource allocation problems, such as power control [7]</ref>, [8]</ref>, are non-convex and computationally challenging. Moreover, they need to be solved in a real-time manner to accommodate the time variation of wireless channels.
ce chain. Instructions in a performance-critical slice are scheduled in order but independently from the rest of the application using multiple parallel IQs [15]</ref>, [16]</ref>. This is effectively a limited form of OoO scheduling. However, the slice-based approaches could experience a severe slowdown because the various shapes and s slice-based approaches could experience a severe slowdown because the various shapes and sizes of dependence chains may impede the exploitation of ILP and MLP in such parallel InO scheduling windows [16]</ref>, [17]</ref>.</p><p>To sum up, discovered architectures so far suffer from either high complexity or limited performance, since to wait for all previous stores to resolve the target addresses and then issue the following loads, thereby eliminating the need for associative LQ searches [15]</ref>, [16]</ref>. However, this approach could significantly degrade performance if an address-generating instruction (AGI) belongs to a dependence chain involving one or more p>A. Performance 1) Comparison to InO and OoO: Figure 6</ref> shows the performance of Load Slice Core (LSC) [15]</ref>, Freeway core [16]</ref>, CASINO core, and OoO core, normalized to that of an InO core. CASINO achieves significant performance gains across all applications over InO (51% on average ay lose opportunities to extract MLP when consecutive slices have a dependence relationship, and a dependent slice blocks the issue of younger, independent slices. To address this limitation, Freeway [16]</ref> introduces a dependence-aware slice scheduling policy. In Freeway, dependent slices, which have at least one instruction that depends on a load of an older sl dware support. To address this issue, another work has proposed slice-based MLP exploitation techniques built upon an energy-efficient stall-on-use InO core [15]</ref>, [16]</ref>. However, the various shapes and sizes of dependence chains could restrict their ability to exploit ILP [16]</ref>, <ref type=" e InO core [15]</ref>, [16]</ref>. However, the various shapes and sizes of dependence chains could restrict their ability to exploit ILP [16]</ref>, [17]</ref>.</p><p>2) Energy-Efficient Dynamic Scheduling: To reduce the power consumption of dynamic scheduling, researchers h
nd committed in original program order. Such inflight instructions are scheduled by the IQ which consists of the wakeup logic, select logic, and payload RAM [21]</ref>, [22]</ref>, [23]</ref>, [24]</ref>. The wakeup and select logic is responsible for examining the readiness
#b72">[72]</ref>, [73]</ref>, [74]</ref>, [75]</ref>, [76]</ref>. Recently, [77]</ref>, [78]</ref> go one step further by leveraging physical register sharing for a register consumed only once. For its consumer, su ecause it requires neither a prediction mechanism nor checkpointed PRF [74]</ref>, [75]</ref>, [76]</ref>, [77]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>By leveraging the key insight that the performance benefit of OoO scheduli
nce perspective [9]</ref>.</p><p>3) Memory Disambiguation: Several memory disambiguation techniques have been proposed either to improve the accuracy of load speculation [60]</ref>, [61]</ref>, [62]</ref>, [63]</ref>, <ref type="bibr" target="#b6
crucial role in achieving high performance. A large body of prior work has focused on extracting MLP on an OoO core, such as prefetching, runahead execution [51]</ref>, [52]</ref>, and speculative pre-execution [53]</ref>, [54]</ref>, [55]</ref>
8">[9]</ref>.</p><p>3) Memory Disambiguation: Several memory disambiguation techniques have been proposed either to improve the accuracy of load speculation [60]</ref>, [61]</ref>, [62]</ref>, [63]</ref>, [64]</ref>, <ref type="bibr" target="#b6
dow, where they are executed out of order and committed in original program order. Such inflight instructions are scheduled by the IQ which consists of the wakeup logic, select logic, and payload RAM [21]</ref>, [22]</ref>, [23]</ref>, [24]</ref>. The wakeup and select logic
ergy efficient by addressing the complexity of the scheduling logic [2]</ref>, [4]</ref> or reducing the accesses to powerhungry structures [5]</ref>, [6]</ref>, [7]</ref>, [8]</ref>. Recently, an alternative approach ha endence chain (or a slice [14]</ref>) cannot be executed in parallel, and thus, such instructions do not need to be scheduled by the complex wakeup and select logic. In [5]</ref>, [56]</ref>, instructions dependent on long-latency operations are temporarily kept in a small buffer until their dependences are
66]</ref>, [67]</ref>. Another approach is to eliminate the LQ or SQ, as well as the associative searches on these structures [19]</ref>, [68]</ref>, [69]</ref>. We adopt the latter approach because it can easily be implemented by extending the existing SB in the baseline InO
pes of dependence chains [17]</ref>.</p><p>Another approach is filtering ready-to-execute instructions using an InO execution engine. "Flea-flicker" two pass pipelining [57]</ref> employs two sequential InO back-ends to hide cache miss stalls. Ready-at-dispatch instructions are executed in the advance pipeline, but the others are deferr
re fetched to all consumers [34]</ref>, [72]</ref>, [73]</ref>, [74]</ref>, [75]</ref>, [76]</ref>. Recently, [77]</ref>, [78]</ref> go one step further sed renaming scheme is an attractive approach for an energy-constrained environment, because it requires neither a prediction mechanism nor checkpointed PRF [74]</ref>, [75]</ref>, [76]</ref>, [77]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSI
thods are complexity in the size of model, thus yield inefficient computation which will be great challenge to process massive remote sensing images. In our work, two lightweight attention mechanisms [17]</ref> which contains spatial attention and channel attention are adopted for the semantic segmentation of HRRSIs. The spatial attention mechanism decides where to e ) = sigmoid(f 7×7 ([Avgpool(F ); M axpool(F )]))<label>(2)</label></formula><p>where f 7×7 represents a convolution operation with 7 × 7 kernel size.</p><p>In this study, we follow the method of Woo [17]</ref>to integrate the two attention mechanisms. First, we use channel attention to capture good semantic information, and then use spatial attention to capture spat
us, the range of imaging is wide, and the background is complex and diverse. Especially in HRRSIs, the difference of ground objects becomes further notable. To segment HRRSIs effectively, Chen et al. [8]</ref> used a shuffle convolution neural network and found that the method is effective in segmenting small objects. Liu et al. [9]</ref>
egment HRRSIs effectively, Chen et al. [8]</ref> used a shuffle convolution neural network and found that the method is effective in segmenting small objects. Liu et al. [9]</ref> designed an hourglass-shaped network (HSN) network based on inception network and skip connection and the network achieved better results compared with the refe A 1080Ti GPU.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Vaihingen dataset</head><p>Table I reports the semantic segmentation of the ISPRS Vaihingen dataset. We adopt the practice of [9]</ref>[10] [11]</ref> and do not report the accuracy of the clutter/background class because the Vaihingen dataset has less clutter/back
es and show some bottlenecks. Recently, deep learning based methods have been regarded as a promising approach to solve image semantic segmentation problems [3]</ref>[4] [5]</ref>. For example, methods based on fully convolutional network (FCN) [4]</ref> have achieved stateof-the-art segmentation results on m al. [12]</ref> designed two deep networks based on residual module, and achieved better results compared with FCN-8s [4]</ref> and SegNet [5]</ref>. In summary, these networks mainly change the depth and width of the network, or combine multimodal data such as digital surface models (DSMs) to improve the ac
us, the range of imaging is wide, and the background is complex and diverse. Especially in HRRSIs, the difference of ground objects becomes further notable. To segment HRRSIs effectively, Chen et al. [8]</ref> used a shuffle convolution neural network and found that the method is effective in segmenting small objects. Liu et al. [9]</ref>

(HSN) network based on inception network and skip connection and the network achieved better results compared with the reference networks on the ISPRS Vaihingen and ISPRS Potsdam datasets. Guo et al. [10]</ref> learned from the spatial pyramid pooling model to capture multiscale features in HRRSIs, and then used conditional random fields to perform postclassification
hape, and spatial position relationships of an object to extract features and then use clustering, classification, and threshold algorithms to segment an image [1]</ref> [2]</ref>. However, these methods depend heavily on artificial design features and show some bottlenecks. Recently, deep learning based methods have been regarded as a pr
tional methods use the color, texture, shape, and spatial position relationships of an object to extract features and then use clustering, classification, and threshold algorithms to segment an image [1]</ref> [2]</ref>. However, these methods depend heavily on artificial design features and show some bottlenecks. Recently, deep learning
one is called the self attention mechanism, which calculates the feature representation in each position by weighted sum the features of all other positions [15]</ref> [16]</ref>. Thus, it can model the longrange context information for semantic segmentation task. For example, DANet [15]</ref> uses two se
hape, and spatial position relationships of an object to extract features and then use clustering, classification, and threshold algorithms to segment an image [1]</ref> [2]</ref>. However, these methods depend heavily on artificial design features and show some bottlenecks. Recently, deep learning based methods have been regarded as a pr
/div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Large-scale knowledge graphs (KGs) such as YAGO (Suchanek, Kasneci, and Weikum 2007)</ref>, NELL (Carlson et al. 2010), and</ref>Wikidata (Vrandečić and</ref><ref type="b uch as YAGO (Suchanek, Kasneci, and Weikum 2007)</ref>, NELL (Carlson et al. 2010), and</ref>Wikidata (Vrandečić and</ref>Krötzsch 2014)</ref> usually represent facts in the form of relations (edges) between (head-tail) entity pairs (nodes). This kind of graphstructured knowledge is essenti ckel, Tresp, and Kriegel 2011;</ref>Bordes et al. 2013;</ref>Socher et al. 2013;</ref>Yang et al. 2015;</ref>Trouillon et al. 2016;</ref>Schlichtkrull et al. 2018;</ref>Dettmers et al. 2018</ref>) have been proposed to ) number of entity pairs. The few-shot scenario incurs the infeasibility of previous models which assume available, sufficient training instances for all relations.</p><p>In light of the above issue, Xiong et al. (2018)</ref> proposed GMatching which introduces a local neighbor encoder to learn entity embeddings. It achieves considerable performance in one-shot relat ef type="bibr" target="#b0">Bordes et al. 2013;</ref>Yang et al. 2015)</ref> have been proposed to learn entity embeddings by using relational information, Xiong et al. (Xiong et al. 2018</ref>) demonstrated that explicitly encoding graph local structure (i.e., one-hop neighbors) can benefit relation prediction. The proposed neighbor en et R r , we can obtain two embedding vectors E h l ,t l = [f θ (h l ) ⊕ f θ (t l )] and f (R r ), respectively. In order to measure the similarity between two vectors, we employ a recurrent processor (Vinyals et al. 2016</ref>) f µ to perform multiple steps matching. The t-th process step is formulated as:</p><formula xml:id="formula_11">g t , c t = RNN match (E h l




r incompleteness. In order to automate the KG completion process, many work (Nickel, Tresp, and Kriegel 2011;</ref>Bordes et al. 2013;</ref>Socher et al. 2013;</ref>Yang et al. 2015;</ref>Trouillon et al. 2016;</ref>Sc
n capability. Inspired by the common practices in learning sentence embeddings (Conneau et al. 2017</ref>) in natural language processing and aggregating node embeddings (Hamilton, Ying, and Leskovec 2017)</ref> in graph neural networks, we tackle the challenge and formulate the embedding of R r by aggregating representations of all entit n function which can be pooling operation, feed-forward neural network, etc. Motivated by the recent success of recurrent neural network aggregator in order-invariant problems such as graph embedding (Hamilton, Ying, and Leskovec 2017)</ref>, we design a recurrent autoencoder aggregator which achieves good capability. Specifically, the entity pair embeddings E h k ,t



y> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Large-scale knowledge graphs (KGs) such as YAGO (Suchanek, Kasneci, and Weikum 2007)</ref>, NELL (Carlson et al. 2010), and</ref>Wikidata (Vrandečić and</ref>Krötzsch 2014)</ref> usually represent facts in the form of r ring, and semantic web. However, KGs are known for their incompleteness. In order to automate the KG completion process, many work (Nickel, Tresp, and Kriegel 2011;</ref>Bordes et al. 2013;</ref>Socher et al. 2013;</ref>Yang et al. 2015;</ref>Troui ork of FSRL.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoding Heterogeneous Neighbors</head><p>Although many work (Nickel, Tresp, and Kriegel 2011;</ref>Bordes et al. 2013;</ref>Yang et al. 2015)</ref> have been proposed to learn entity embeddings by using relational information, Xiong et al Socher et al. 2013;</ref>Yang et al. 2015;</ref>Trouillon et al. 2016;</ref>Schlichtkrull et al. 2018;</ref>Dettmers et al. 2018</ref>) have been proposed to infer missing relations by learning existing ones. For example, RESCAL (Nickel, Tresp, and ting ones. For example, RESCAL (Nickel, Tresp, and Kriegel 2011)</ref> employs tensor factorization to capture inherent structure of multi-relational data in KGs. TransE (Bordes et al. 2013)</ref> interprets relations as translation operation on the low-dimensional embeddings of entities. And recently, G-GCN  y pairs is challenging as it requires modeling interactions among different entity pairs and accumulating their expression capability. Inspired by the common practices in learning sentence embeddings (Conneau et al. 2017</ref>) in natural language processing and aggregating node embeddings (Hamilton, Ying, and Leskovec 2017)</ref> in grap
how the data is generated, thus benefiting downstream tasks such as representation learning, generating new samples, etc. Two of the most popular methods are Generative Adversarial Networks (GANs) by Goodfellow et al. (2014)</ref> and Variational 2.z combines with x for the target gene and is fed into an MLP model for predicting gene expression. Autoencoders (VAEs) by
t techniques. These techniques include Linear Regression by Karlic et al. (2010)</ref>, SVM by Cheng et al. (2011)</ref>, Random Forests by Dong et al. (2012)</ref>, Rule-Based Learning by Ho et al. (2015)</ref>, and Deep Learning by Singh et al. (2
a classification or a regression task. The studies that have attempted to model it as a classification task have applied a slew of different techniques. These techniques include Linear Regression by Karlic et al. (2010)</ref>, SVM by Cheng et al. (2011)</ref>, Random Forests by Dong et al. (2012)</ref>, Rule
downstream tasks such as predictions will greatly benefit.There exist multiple dimension reduction techniques in literature, specifically by Scholz et al. (2008)</ref>; Kasun et al. (2016)</ref>, such as Principle Component Analysis (PCA), Tensor Factorization, Singular Value Decomposition (SVD) which are based on linear transformations;
t techniques. These techniques include Linear Regression by Karlic et al. (2010)</ref>, SVM by Cheng et al. (2011)</ref>, Random Forests by Dong et al. (2012)</ref>, Rule-Based Learning by Ho et al. (2015)</ref>, and Deep Learning by Singh et al. (2
t techniques. These techniques include Linear Regression by Karlic et al. (2010)</ref>, SVM by Cheng et al. (2011)</ref>, Random Forests by Dong et al. (2012)</ref>, Rule-Based Learning by Ho et al. (2015)</ref>, and Deep Learning by Singh et al. (2
odifications on gene expression experimentally validated that there exists a correlation between histone modifications and Gene expression. Following computational methods, most notably DeepChrome by Singh et al. (2016)</ref> and AttentiveChrome by Singh et al. (2017)</ref> that employ deep learning to learn complex combinatorial intera ="bibr" target="#b1">Dong et al. (2012)</ref>, Rule-Based Learning by Ho et al. (2015)</ref>, and Deep Learning by Singh et al. (2017</ref>Singh et al. ( , 2016))</ref>. DeepChrome and AttentiveChrome are cell-specific gene expression prediction frameworks that outperform the previously published machine le ed neighbor genes data as input into the prediction model.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Data Preparation and Dimension Reduction</head><p>Following the work from Singh et al. (2016</ref>Singh et al. ( , 2017))</ref>, we use five core Histone Modification marks for 56 different cell types derived fro
t techniques. These techniques include Linear Regression by Karlic et al. (2010)</ref>, SVM by Cheng et al. (2011)</ref>, Random Forests by Dong et al. (2012)</ref>, Rule-Based Learning by Ho et al. (2015)</ref>, and Deep Learning by Singh et al. (2

t techniques. These techniques include Linear Regression by Karlic et al. (2010)</ref>, SVM by Cheng et al. (2011)</ref>, Random Forests by Dong et al. (2012)</ref>, Rule-Based Learning by Ho et al. (2015)</ref>, and Deep Learning by Singh et al. (2
the gated network structure can stabilize variances and also avoid gradients vanishing and exploding and thus may converge to a better model. Beside, multiple embedding modules were also proposed by Guo et al. (2020b)</ref> to learn DNA representations which was shown with better performance compared with just RNN, or gated networks. Thus, learning more efficient emb
k pretty well in the settings of homogeneous and heterogeneous graphs, most of them are not tailored for modeling bipartite graphs. As a result, they are suboptimal to learn bipartite graph embedding [7,</ref>8]</ref>. To remedy such a problem, several studies have been specifically proposed for modeling bipartite graphs. They can be roug a problem, several studies have been specifically proposed for modeling bipartite graphs. They can be roughly divided into two branches: random walk-based and reconstruction-based methods. The former [7,</ref>8,</ref>44]</ref> relies on designing the heuristics of random walks to generate different node sequ thods achieve promising results to some extent, but they mainly focus on learning local graph structures with the assumption that nodes within the sliding window or neighborhoods are closely relevant [7,</ref>37,</ref>41]</ref>. We argue that they lack the capability of better modeling the global properties graphs, and the structural characteristics of bipartite graph are hard to be preserved by them. IGE [44]</ref>, PinSage [40]</ref>, BiNE [7]</ref> and FOBE [32]</ref> are specially designed for bipartite graphs. However, as mentioned in the introduction, they mainly focus on e it is used to test whether our model can be deployed to large-scale bipartite graphs.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Data Preprocessing.</head><p>As used in BiNE [7]</ref>, we select 60% edges for training and remaining edges for test in both of DBLP and ML-10M. We use the same division in IGMC [42]< le of MI maximization, and it uses the same infomax objective in DGI [36]</ref>. • Bipartite graph embedding: PinSage [40]</ref> and BiNE [7]</ref>.</p><p>PinSage integrates random walk into GNN architectures for high-scalable performances. BiNE jointly optimizes explicit and implicit relations in a unified
nal graph into multiple homogeneous ones and adopts the infomax objective used in DGI for modeling split graphs. So DMGI still puts more emphasis on learning the correlation of homogeneous nodes. GMI [26]</ref> proposes a new approach  The yellow dotted lines (Eq.( 1</ref>) and Eq.( 3</re
te different node sequences. Afterwards, they learn node representations via predicting context nodes within a sliding window [45]</ref>. The reconstruction-based works [15,</ref>32,</ref>34,</ref>37,</ref>40,</ref focus on how to model local graph structures in the latent space.</p><p>Matrix completion [34,</ref>42]</ref> and collaborative filtering [15,</ref>37]</ref> are also connected with modeling bipartite graphs closely. They propose various DNNs to solve recommendation tasks. Fo then used to reconstruct the rating links through a bilinear decoder. IGMC proposes a novel GNN based on local subgraphs for the task of inductive matrix completion. • Collaborative filtering: NeuMF [15]</ref> and NGCF [37]</ref>. NeuMF uses MLP to learn the nonlinear interactions between user and item embeddings. NGCF considers the hi
</ref>. The reconstruction-based works [15,</ref>32,</ref>34,</ref>37,</ref>40,</ref>42]</ref> are closely related with collaborative filtering [28]</ref>. They attempt to reconstruct [28]</ref>. They attempt to reconstruct the adjacency matrix by learning different encoders. In particular, some works [34,</ref>37,</ref>40,</ref>42]</ref> train graph neural networks (GNNs) [9,</ref>20,</ref><ref ]</ref>. But they are not tailored for bipartite graphs, and the structural characteristics of bipartite graph are hard to be preserved by them. IGE [44]</ref>, PinSage [40]</ref>, BiNE [7]</ref> and FOBE [32]</ref> are specially designed for bipartite graphs. However, as ment " target="#b41">[41]</ref> also follows the principle of MI maximization, and it uses the same infomax objective in DGI [36]</ref>. • Bipartite graph embedding: PinSage [40]</ref> and BiNE [7]</ref>.</p><p>PinSage integrates random walk into GNN architectures for high-scalable performances. BiNE jointly opt inciple of GNN to learn the initial node representations. The proposed encoder is well compatible with our infomax objective. Compared with other GNN encoders [37,</ref>40]</ref> for bipartite graphs, it achieves promising performances empirically. Different from homogeneous graphs, each node in bipartite graph is not the same type as i
ks [34,</ref>37,</ref>40,</ref>42]</ref> train graph neural networks (GNNs) [9,</ref>20,</ref>22,</ref>38]</ref> to learn node representations via aggreg )</label></formula><p>where 𝛿 denotes the LeakyReLU activation function, 𝑊 𝑘 𝑣 is a weight matrix and N (𝑣 𝑗 ) denotes one-hop neighbors of 𝑣 𝑗 . In contrast with common graph convolutional operators [9,</ref>13,</ref>20]</ref>, we only aggregate neighborhood features, and the own feature 𝒗 𝑘−1 𝑗 is not inv
variables or the product of their marginals. DIM [16]</ref> introduces the structural information into input patches and adopts different infomax objectives.</p><p>DGI [36]</ref> is the first work that applies the infomax objective to homogeneous graphs. It provides a new approach for the task of unsupervised node classification. Based RR@5 MRR@10 DeepWalk 7.25 3.12 4.39  learn node embeddings. DMGI [41]</ref> also follows the principle of MI maximization, and it uses the same infomax objective in DGI [36]</ref>. • Bipartite graph embedding: PinSage [40]</ref> and BiNE [7]</ref>.</p><p>PinSage integrates ran
d 𝒈, based on Jensen-Shannon divergence between the joint distribution and the product of marginals. Because it follows a standard minmax game originated from the generative adversarial network (GAN) [10]</ref>, and the "GAN" distance and Jensen-Shannon divergence are closely related [24]</ref>.</p><p>From Eq.( <ref type="formula" targe
rget="#b3">[3]</ref> is used here. CHI measures the ratio between the withincluster dispersion and the between-cluster dispersion. It is also commonly used to evaluate the task of community detection [4,</ref>23]</ref>. As shown in Figure 5</ref>, compared with other graph embeddings, BiGI achieves the
ms which are conducted on ML-100K. We first save all representations of users and items and then cluster them via the well-known K-Means algorithm. The clustering metric Calinski-Harabasz Index (CHI) [3]</ref> is used here. CHI measures the ratio between the withincluster dispersion and the between-cluster dispersion. It is also commonly used to evaluate the task of c
measures the ratio between the withincluster dispersion and the between-cluster dispersion. It is also commonly used to evaluate the task of community detection [4,</ref>23]</ref>. As shown in Figure 5</ref>, compared with other graph embeddings, BiGI achieves the best clustering results with the varyin
el>(4)</label></formula><p>𝑊 𝑘 𝑢 , 𝑊 𝑘 𝑣 and 𝑊 𝑘 𝑣 in Eq.( 3</ref>) and Eq.( 4</ref>) are also weight matrices. Dropout [30]</ref> is applied to each layer of our encoder to regularize model parameters.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Local-Global Infomax<
′ ∈ 𝑈 ∪ (𝑢, 𝑣 ′ )|𝑣 ′ ∈ 𝑉 .<label>(14)</label></formula><p>The negative sampling used in Eq.( 14</ref>) is similar to [12,</ref>21]</ref>: 𝐸 ′ (𝑢,𝑣) is composed of real interactions with either the head or tail replaced by a random node from the same node set. BiGI is an end-to-end model which is
measures the ratio between the withincluster dispersion and the between-cluster dispersion. It is also commonly used to evaluate the task of community detection [4,</ref>23]</ref>. As shown in Figure 5</ref>, compared with other graph embeddings, BiGI achieves the best clustering results with the varyin

ms which are conducted on ML-100K. We first save all representations of users and items and then cluster them via the well-known K-Means algorithm. The clustering metric Calinski-Harabasz Index (CHI) [3]</ref> is used here. CHI measures the ratio between the withincluster dispersion and the between-cluster dispersion. It is also commonly used to evaluate the task of c
variables or the product of their marginals. DIM [16]</ref> introduces the structural information into input patches and adopts different infomax objectives.</p><p>DGI [36]</ref> is the first work that applies the infomax objective to homogeneous graphs. It provides a new approach for the task of unsupervised node classification. Based RR@5 MRR@10 DeepWalk 7.25 3.12 4.39  learn node embeddings. DMGI [41]</ref> also follows the principle of MI maximization, and it uses the same infomax objective in DGI [36]</ref>. • Bipartite graph embedding: PinSage [40]</ref> and BiNE [7]</ref>.</p><p>PinSage integrates ran
a long-standing challenge. Recently, a significant amount of progresses have been made toward the graph embedding paradigm [2,</ref>5,</ref>14]</ref>. Although they work pretty well in the settings of homogeneous and heterogeneous graphs, most of them are not tailored for modeling bipartite graphs. As a resu
ms which are conducted on ML-100K. We first save all representations of users and items and then cluster them via the well-known K-Means algorithm. The clustering metric Calinski-Harabasz Index (CHI) [3]</ref> is used here. CHI measures the ratio between the withincluster dispersion and the between-cluster dispersion. It is also commonly used to evaluate the task of c
tite graphs. They can be roughly divided into two branches: random walk-based and reconstruction-based methods. The former [7,</ref>8,</ref>44]</ref> relies on designing the heuristics of random walks to generate different node sequences. Afterwards, they learn node representations via predicting context nod ]</ref> and DMGI [41]</ref>. But they are not tailored for bipartite graphs, and the structural characteristics of bipartite graph are hard to be preserved by them. IGE [44]</ref>, PinSage [40]</ref>, BiNE [7]</ref> and FOBE [32]</ref> are specia
44">44]</ref> relies on designing the heuristics of random walks to generate different node sequences. Afterwards, they learn node representations via predicting context nodes within a sliding window [45]</ref>. The reconstruction-based works [15,</ref>32,</ref>34,</ref><ref
ually used for modeling bipartite graphs. The pioneering homogeneous graph methods include DeepWalk [27]</ref>, LINE [33]</ref>, Node2vec [11]</ref> and VGAE [19]</ref>. Some representative heterogeneous graph methods are Metapath2vec [6]</ref> a following strong baselines which can be divided into:</p><p>• Homogeneous graph embedding: DeepWalk [27]</ref>, LINE [33]</ref>, Node2vec [11]</ref> and VGAE [19]</ref>. DeepWalk and Node2vec are typically random-walk based. LINE learns a joint probability distribution of con nto the global representation via the generated prototype representations, and these two prototypes are not entangled together. Through Eq.( 10</ref>) and Eq. (11)</ref>, each node has access to the homogeneous prototype and to the heterogeneous prototype simultaneously, which enables our model to break the limit of local grap
/ref>37,</ref>40,</ref>42]</ref> train graph neural networks (GNNs) [9,</ref>20,</ref>22,</ref>38]</ref> to learn node representations via aggregating features of neighborhood nodes re is a weight matrix and N (𝑣 𝑗 ) denotes one-hop neighbors of 𝑣 𝑗 . In contrast with common graph convolutional operators [9,</ref>13,</ref>20]</ref>, we only aggregate neighborhood features, and the own feature 𝒗 𝑘−1 𝑗 is not involved in Eq.( 1</ref>). Hence, 𝒗 𝑘 𝑗 ca es, and LINE (2nd) is exploited here due to its expressive performances. Based on variational auto-encoder [18]</ref>, VGAE adopts the graph convolutional network (GCN) [20]</ref> as the basic encoder to learn graph-structured data.  Model F1@10 NDCG@3 NDCG@5 NDCG@10 MAP@3 MAP@5 MAP@10 MRR@3 MRR@5 MRR@10 DeepWalk  Model F1@10 NDCG@3 NDC
l prompts are likely to be suboptimal. We address this issue by introducing a novel decoding objective to automatically generate prompts given the few-shot training data using the generative T5 model (Raffel et al., 2020)</ref>. This allows us to cheaply obtain effective prompts that match or outperform our manually chosen ones.</p><p>Second, we adopt the idea of inc tion of templates</head><p>Next, we study how to generate a diverse set of templates {T } automatically from a fixed set of label words M(Y). To address this challenging problem, we propose to use T5 (Raffel et al., 2020)</ref>, a large pre-trained text-to-text Transformer. T5 is pre-trained on a mixture of unsupervised objectives. One of its most effective unsupervi ning All of the manual templates and label words that we use in our experiments are provided in Table B</ref>.1.</p><p>For automatic template search with T5, we take the T5-3B model (Raffel et al., 2020)</ref>, which is the largest publicly available one that can fit on a single GPU. For automatically searching label words, we set k to 100 for all t
r of recent studies have focused on better methods for fine-tuning language models (Howard and Ruder, 2018;</ref>Dodge et al., 2020;</ref>Lee et al., 2020;</ref>Zhang et al., 2020)</ref>. These works mainly focus on optimization and regularization techniques to stabilize fine-tuning. Here rmance can be up to several points lower. As described in §2, several recent studies have tried to counter instability in standard fine-tuning (Dodge et al., 2020;</ref>Lee et al., 2020;</ref>Zhang et al., 2020)</ref> and we expect these methods to also help here.</p><p>With respect to our automatic prompt generation pr
g/ns/1.0"><head>A Datasets</head><p>For SNLI (Bowman et al., 2015)</ref> and datasets from GLUE (Wang et al., 2019)</ref>, including SST-2 (Socher et al., 2013)</ref>, CoLA (Warstadt et al., 2019)</ref>, MNLI (Williams et al., 2018)</ref>, QNLI < b43">(Wiebe et al., 2005)</ref>, Subj (Pang and Lee, 2004</ref>)-we simply randomly sample 2,000 examples as the testing set and leave them out from training. For SST-5 (Socher et al., 2013)</ref> and TREC (Voorhees and Tice, 2000)</ref>, we use their official test sets.</p></div> <div xmlns="http://www.te
ntly, while in inference we ensemble predictions across all sets. This is reminiscent of Matching Networks (Vinyals et al., 2016)</ref>, and more specifically BERT-PAIR (Gao et al., 2019)</ref>, used in metalearning, but here we do not explicitly learn a similarity metric, and only focus on the end prediction.</p></div> <div xmlns="http
r of recent studies have focused on better methods for fine-tuning language models (Howard and Ruder, 2018;</ref>Dodge et al., 2020;</ref>Lee et al., 2020;</ref>Zhang et al., 2020)</ref>. These works mainly focus on optimization and regularization techniques to stabilize fine-tuning. Here rmance can be up to several points lower. As described in §2, several recent studies have tried to counter instability in standard fine-tuning (Dodge et al., 2020;</ref>Lee et al., 2020;</ref>Zhang et al., 2020)</ref> and we expect these methods to also help here.</p><p>With respect to our automatic prompt generation pr
ef type="bibr" target="#b19">(Jiang et al., 2020)</ref> such as finding patterns to express specific relations, e.g., (X, born in, ?), or require a large number of examples for gradient-guided search (Shin et al., 2020)</ref>. Our approach aims to develop general-purpose search methods that rely only on a few annotations.</p><p>Fine-tuning of language models A number
elop general-purpose search methods that rely only on a few annotations.</p><p>Fine-tuning of language models A number of recent studies have focused on better methods for fine-tuning language models (Howard and Ruder, 2018;</ref>Dodge et al., 2020;</ref>Lee et al., 2020;</ref>Zhang et al.
ype="bibr" target="#b41">(Wang et al., 2019)</ref>, including SST-2 (Socher et al., 2013)</ref>, CoLA (Warstadt et al., 2019)</ref>, MNLI (Williams et al., 2018)</ref>, QNLI (Rajpurkar et al., 2016)</ref>, RTE (Dagan et al., 2005;</ref><ref type=
mi-supervised learning (Miyato et al., 2017;</ref>Xie et al., 2020)</ref>, where a set of unlabeled examples are given; (2) meta-learning (Yu et al., 2018;</ref>Han et al., 2018;</ref>Bansal et al., 2020a,b;</ref>Bao et al., 2020 (Miyato et al., 2017;</ref>Xie et al., 2020)</ref>, where a set of unlabeled examples are given; (2) meta-learning (Yu et al., 2018;</ref>Han et al., 2018;</ref>Bansal et al., 2020a,b;</ref>Bao et al., 2020)</ref>, where a set of auxiliary tasks are given; and
hich makes it challenging to use in most real-wold applications.</p><p>In this work, we study a more practical scenario in which we only assume access to a moderatelysized language model such as BERT (Devlin et al., 2019)</ref> or RoBERTa (Liu et al., 2019)</ref>, and a small number of examples (i.e., a few-shot setting), which we can u
labeled examples are given; (2) meta-learning (Yu et al., 2018;</ref>Han et al., 2018;</ref>Bansal et al., 2020a,b;</ref>Bao et al., 2020)</ref>, where a set of auxiliary tasks are given; and (3) intermediate training (Phang et al., 2018;</ref><ref type="bibr"
/ref> have shown to work well on many benchmarks.</p><p>In a nutshell, consistency training methods simply regularize model predictions to be invariant to small noise applied to either input examples (Miyato et al., 2018;</ref>Sajjadi et al., 2016;</ref>Clark et al., 2018)</ref> or hidden states <ref type=" consistency training family mostly differ in how the noise is defined: Pseudoensemble (Bachman et al., 2014)</ref> directly applies Gaussian noise and Dropout noise; VAT (Miyato et al., 2018;</ref>2016)</ref> defines the noise by approximating the direction of change in the input space that the model is most sensitive to ing where the noise is injected to the input x, i.e., x = q(x, ), as considered by prior works (Sajjadi et al., 2016;</ref>Laine &amp; Aila, 2016;</ref>Miyato et al., 2018)</ref>. But different from existing work, we focus on the unattended question of how the form or "quality" of the noising operation q can influence t for ImageNet.</p><p>Sharpening Predictions. Since regularizing the predictions to have low entropy has been shown to be beneficial (Grandvalet &amp; Bengio, 2005;</ref>Miyato et al., 2018)</ref>, we sharpen predictions when computing the target distribution on unlabeled examples by using a low Softmax temperature τ . When combined with E denotes cross entropy, q(x | x) is a data augmentation transformation and θ is a fixed copy of the current parameters θ indicating that the gradient is not propagated through θ, as suggested by VAT (Miyato et al., 2018)</ref>. We set λ to 1 for most of our experiments and use different batch sizes for the labeled data and the unlabeled data. In practice, we use a l t al., 2016)</ref> as the backbone model and evaluate UDA with varied supervised data sizes. Specifically, we compare UDA with two highly competitive baselines: (1) Virtual adversarial training (VAT) (Miyato et al., 2018)</ref>, an algorithm that generates adversarial Gaussian noise on input, and (2) MixMatch (Berthelot et al., 2019)</re l images, data augmentation mostly generates diverse and realistic images.   (Tarvainen &amp; Valpola, 2017)</ref> Conv-Large 3.1M 12.31 ± 0.28 3.95 ± 0.19 VAT + EntMin (Miyato et al., 2018)</ref> Conv-Large 3.1M 10.55 ± 0.05 3.86 ± 0.11 SNTG (Luo et al., 2018)</ref> Conv-Large 3.1M 10.93 ± 0.14 3.86 ± 0.2


rget="#b3">Carmon et al., 2019)</ref>. Enforcing consistency w.r.t data augmentation has also been shown to work well for representation learning (Hu et al., 2017;</ref>Ye et al., 2019)</ref>. Invariant representation learning (Liang et al., 2018;</ref>Salazar et al., 2018)</
s of leveraging unlabeled data to address this weakness. The recent works in SSL are diverse but those that are based on consistency training (Bachman et al., 2014;</ref>Rasmus et al., 2015;</ref>Laine &amp; Aila, 2016;</ref>Tarvainen &amp; Valpola, 2017)</ref> have shown to work well on ma
icantly on semantic role labeling. Later, the pre-training of word embeddings was simplified and substantially scaled in Word2Vec (Mikolov et al., 2013)</ref> and Glove (Pennington et al., 2014)</ref>  2018</ref>) have shown that pre-training using language modeling and denoising auto-encoding leads to significant im
d data since it is usually much easier to collect, but the class distributions of out-of-domain data are mismatched with those of in-domain data, which can result in performance loss if directly used (Oliver et al., 2018)</ref>. To obtain data relevant to the domain for the task at hand, we adopt a common technique for detecting out-of-domain data. We use our baselin g algorithms. To answer the question, we focus on the most commonly used semi-supervised learning benchmarks CIFAR-10 and SVHN.</p><p>Vary the size of labeled data. Firstly, we follow the settings in (Oliver et al., 2018)</ref> and employ Wide-ResNet-28-2 (Zagoruyko &amp; Komodakis, 2016;</ref>He et al., 2016)</ref> as
1">(Tarvainen &amp; Valpola, 2017)</ref> Conv-Large 3.1M 12.31 ± 0.28 3.95 ± 0.19 VAT + EntMin (Miyato et al., 2018)</ref> Conv-Large 3.1M 10.55 ± 0.05 3.86 ± 0.11 SNTG (Luo et al., 2018)</ref> Conv-Large 3.1M 10.93 ± 0.14 3.86 ± 0.27 VAdD (Park et al., 2018)</ref> Conv-Large 3.1M 11.32 ± 0.11 4.16 ± 0.08 ype="bibr" target="#b41">(Tarvainen &amp; Valpola, 2017)</ref>, fast-Stochastic Weight Averaging (Athiwaratkun et al., 2018)</ref> and Smooth Neighbors on Teacher Graphs (Luo et al., 2018)</ref>. For a complete version of related work, please refer to Appendix D.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</ thiwaratkun et al. (2018)</ref> propose fast-SWA that improves Mean Teacher by encouraging the model to explore a diverse set of plausible parameters. In addition to parameter-level consistency, SNTG (Luo et al., 2018)</ref>  There are also recent works on generating diverse translations (He et al., 2018;</ref>Shen et a

also been shown to work well for representation learning (Hu et al., 2017;</ref>Ye et al., 2019)</ref>. Invariant representation learning (Liang et al., 2018;</ref>Salazar et al., 2018)</ref> applies the consistency loss not only to the predicted distributions but also to rep
ategory. For unlabeled data, we use the whole training set for DBPedia, the concatenation of the training set and the unlabeled set for IMDb and external data for Yelp-2, Yelp-5, Amazon-2 and Amazon-5(McAuley et al., 2015)</ref> 5 . Note that for Yelp and Amazon based datasets, the label distribution of the unlabeled set might not match with that of labeled datasets
ific latency bounds to guarantee QoS and provide a satisfactory user experience.</p><p>As a representative set of latency-critical applications, we use the benchmarks of the TailBench benchmark suite [20]</ref>. This suite includes eight representative applications of today's latency-critical applications. For the sake of completeness, we briefly describe the studied phinx (**) is over 4 s, which seems rather high in comparison with other speech recognition services. However, we found that these values are in line with the results of this application presented in [20]</ref>.</p><p>Once we have defined the QoS requirements for each application, we can study the effect of adding another server thread from a QoS perspective. To do s T configuration. That is, increasing the amount of threads from one to two reduces considerably the saturation QPS (i.e., point at which the LQoS is achieved). This issue has been also pointed out in [20]</ref>, where authors realized of this unexpected behavior and demonstrated by simulation that this poor scalability is due to both the overhead of adding threads (i
[4]</ref>, which is a hybrid partitioning approach that combines Intel MBA with two additional techniques. In the experimental evaluation, mostly high performance benchmarks are employed. Finally, in [5]</ref>, the Quasar cluster management system is presented. The main aim of Quasar is to increase resource utilization.</p><p>Next, we move to works that consider just
ifferent LC Google workloads, detects the situations when guaranteeing SLO becomes problematic, and then limits the amount of resources assigned to the BE workloads. Pursuing the same target, PARTIES [8]</ref> monitors tail latency applications, memory capacity and network bandwidth usage. Upon SLO violation detection, this approach initiates the allocation of one or
kload scenarios (from low to high load variability) that run a mix of batch workloads and LC workloads. However, authors do not consider reducing unpredictability through resource partitioning. AVMMC [10]</ref>, on the other hand, determines dynamically the best VM to core mapping on the studied system. In this ap- proach, authors pursue to improve the capabilities of
ifferent LC Google workloads, detects the situations when guaranteeing SLO becomes problematic, and then limits the amount of resources assigned to the BE workloads. Pursuing the same target, PARTIES [8]</ref> monitors tail latency applications, memory capacity and network bandwidth usage. Upon SLO violation detection, this approach initiates the allocation of one or
o the number of LLC misses and the consumed memory bandwidth. Highperformance workloads and a single latency-critical application are studied in this work. A similar methodology is followed in HyPart [4]</ref>, which is a hybrid partitioning approach that combines Intel MBA with two additional techniques. In the experimental evaluation, mostly high performance benchma rtitioning.</p><p>Figure 17</ref> shows the results of limiting both the memory bandwidth of img-dnn to 4000 MB/s and the LLC to 2 cache 0.2 0.4 0.6 0.8 1.0 1.2 1. 4</ref>    ways, which corresponds to approximately one third of the maximum memory bandwidth achievable with one core. As it can observed, limiting the memory bandwidth
KVM is installed as hypervisor, QEMU as virtualizer and Libvirt as virtualization manager in both client and server nodes. This configuration is similar to that used by OpenStack on its compute nodes [16]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">VM Infrastructure</head><p>To replicate a common infrastructure that cloud service provider
requests are timely. It is also important to take into account that, to prevent performance from being dominated by huge queuing delays, latency-critical workloads are typically run at low CPU loads [24]</ref>. To make our experiments representative, we make sure that, for each application, we evaluate a QPS range that covers, at least, from 20% to 50% CPU utilizati
ifferent LC Google workloads, detects the situations when guaranteeing SLO becomes problematic, and then limits the amount of resources assigned to the BE workloads. Pursuing the same target, PARTIES [8]</ref> monitors tail latency applications, memory capacity and network bandwidth usage. Upon SLO violation detection, this approach initiates the allocation of one or
o the number of LLC misses and the consumed memory bandwidth. Highperformance workloads and a single latency-critical application are studied in this work. A similar methodology is followed in HyPart [4]</ref>, which is a hybrid partitioning approach that combines Intel MBA with two additional techniques. In the experimental evaluation, mostly high performance benchma rtitioning.</p><p>Figure 17</ref> shows the results of limiting both the memory bandwidth of img-dnn to 4000 MB/s and the LLC to 2 cache 0.2 0.4 0.6 0.8 1.0 1.2 1. 4</ref>    ways, which corresponds to approximately one third of the maximum memory bandwidth achievable with one core. As it can observed, limiting the memory bandwidth
iffer depending on the virtualization level that is supported by the system.</p><p>First we focus on those works that do not consider virtualization. With the aim of improving system fairness, CoPart [3]</ref> leverages Intel's CAT and MBA technologies and characterizes the behavior of each application according to the number of LLC misses and the consumed memory band
orrectly labeled data and mislabeled data. Co-learning is motivated by the self-training algorithm (Zhu, 2006;</ref>Li et al., 2008;</ref>Rosenberg et al., 2005;</ref>Riloff and Jones, 1999)</ref>, which uses the prediction of models with high confidence to produce pseudo lab nes the labels of training samples and updates model parameters, in a way similar to self-training (Zhu, 2006;</ref>Li et al., 2008;</ref>Rosenberg et al., 2005;</ref>Riloff and Jones, 1999)</ref>. However, in order to prevent the deep model from overfitting to the noise easi
tivated by the self-training algorithm (Zhu, 2006;</ref>Li et al., 2008;</ref>Rosenberg et al., 2005;</ref>Riloff and Jones, 1999)</ref>, which uses the prediction of models with high confidence to produce pseudo labels for unlabeled samples. The algorithm then alternates bet ers, in a way similar to self-training (Zhu, 2006;</ref>Li et al., 2008;</ref>Rosenberg et al., 2005;</ref>Riloff and Jones, 1999)</ref>. However, in order to prevent the deep model from overfitting to the noise easily and amplifying its own mistakes, we introduce two innovat
ted labels, such that the model could leverage both correctly labeled data and mislabeled data. Co-learning is motivated by the self-training algorithm (Zhu, 2006;</ref>Li et al., 2008;</ref>Rosenberg et al., 2005;</ref>Riloff and Jones, 1999)</ref>, which uses the prediction target="#fig_0">1</ref>. Co-learning iteratively refines the labels of training samples and updates model parameters, in a way similar to self-training (Zhu, 2006;</ref>Li et al., 2008;</ref>Rosenberg et al., 2005;</ref>Riloff and Jones, 1999)</ref>. However, in order to prev
tt et al., 2017;</ref>Chang et al., 2017)</ref>. Adding pre-defined curriculums in loss functions to dynamically adjust weights of samples is also proved to be effective (Lin et al., 2017;</ref>Jiang et al., 2018;</ref>Bengio et al., 2009)</ref>. From the perspective of loss fu
tely different networks.</p><p>In our experiments, the network is modified from classical convolutional networks such as ResNets (He et al., 2016)</ref> and Wide ResNets (Zagoruyko and Komodakis, 2016)</ref>. We simply duplicate the final convolutional group (conv4) to build the two branches B1 and B2.</p></div> <div xmlns="http://www.te ported in (Reed et al., 2014)</ref>. For b6), we use hyper-parameters recommended by Han et al. (2018)</ref>.</p><p>Training details. Wide-ResNet (WRN) (Zagoruyko and Komodakis, 2016)</ref> and ResNet-32 (He et al., 2016)</ref> are implemented in this paper. WRN is used in experiments on CI
that the distribution of corrupted labels only depends on their true labels, but independent of the samples. Based on this assumption, a confusion matrix can be introduced to describe the label noise (Sukhbaatar et al., 2018)</ref>, and many existing work is dedicated to estimate this matrix (Patrini et al., 2017;</ref><ref type="bibr"
ang et al., 2017;</ref>Simonyan and Zisserman, 2015;</ref>Ren et al., 2015;</ref>Silver et al., 2016;</ref>Schmidhuber, 2015)</ref>. They can learn highly generalizable representations when fueled by large scale datasets with precise annotations, such as ImageNet <ref type="b
that the distribution of corrupted labels only depends on their true labels, but independent of the samples. Based on this assumption, a confusion matrix can be introduced to describe the label noise (Sukhbaatar et al., 2018)</ref>, and many existing work is dedicated to estimate this matrix (Patrini et al., 2017;</ref><ref type="bibr"
hms are also proposed to handle the label noise with probabilistic models (Goldberger and Ben-Reuven, 2017;</ref>Khetan et al., 2018;</ref>Xiao et al., 2015)</ref>. In addition, recent work also models the label noise via more complicated distributions, which takes the instances distribution into considerat
="#b38">(Sogawa et al., 2013;</ref>Zhang and Sabuncu, 2018)</ref>.</p><p>To address the aforementioned challenge, a number of methods have been proposed in recent years (Frenay and Verleysen, 2014;</ref>Ghosh et al., 2017;</ref>Ren et al., 2018;</ref><ref type="bibr" target="#b
R under uniform label noise. ResNet-32 is used in experiments on MNIST and SVHN under uniform label noise and experiments under background label noise. The models are trained with a Nesterov momentum (Sutskever et al., 2013)</ref> of 0.9, a dropout rate of 0.3 and a l2 weight decay of 1e-4. The mini-batch size is set as 100 for a total number of 160 epochs. The learn
aforementioned challenge, a number of methods have been proposed in recent years (Frenay and Verleysen, 2014;</ref>Ghosh et al., 2017;</ref>Ren et al., 2018;</ref>Kumar et al., 2010;</ref>Li et al., 2018;</ref>Jiang </ref>Zhao et al., 2019)</ref>. Popular approaches include designing robust loss functions (Ghosh et al., 2017)</ref>, reweighting samples (Ren et al., 2018)</ref>, and learning with meta-learning (Li et al., 2018;</ref>Jiang et al., 2018)</ref>. ) Background : True label is replaced by a single background label with the probability ρ. This type of noise is pretty common and challenging as it's a combination of label imbalance and label noise (Ren et al., 2018)</ref>.</p><p>Baselines. Our method is compared with several state-of-the-art methods to make DNN robust against label noise. b1) MentorNet <ref type=" a lack of representation power and can not handle complex conditions well.</p><p>Sample reweighting and pruning. Another popular approach to handle corrupted labels is sample reweighting or pruning. Ren et al. (2018)</ref> propose a meta-learning method to reweight training samples based on their gradient directions. Jiang et al. (2018 network. For experiments without the validation set, we use the same 45000 images for training. On MNIST and SVHN, we use all the provided training data for training.</p><p>Noise settings. Following Ren et al. (2018)</ref>, we design two label noise distribution forms: 1) Uniform: True label is uniformly replaced by other labels with the probability ρ (Noise rate).
without a proper collaborative mechanism, the two networks may result in similar errors and negatively influence each other, especially for the training set with a large portion of corrupted labels. Veit et al. (2017)</ref> trains an auxiliary cleaning network jointly with a classifier to clean up labels. Generally, most existing work does not pay much attention to
ref type="bibr" target="#b23">(Lin et al., 2014)</ref>. However, collecting high-quality labeled data is usually very time-consuming and costly (Tao and Dai, 2019;</ref>Tavanaei et al., 2019)</ref>. In contrast, obtaining coarsely labeled data, e.g., images retrieved by search engines (Li et al., 2017)</re
hms are also proposed to handle the label noise with probabilistic models (Goldberger and Ben-Reuven, 2017;</ref>Khetan et al., 2018;</ref>Xiao et al., 2015)</ref>. In addition, recent work also models the label noise via more complicated distributions, which takes the instances distribution into considerat
aforementioned challenge, a number of methods have been proposed in recent years (Frenay and Verleysen, 2014;</ref>Ghosh et al., 2017;</ref>Ren et al., 2018;</ref>Kumar et al., 2010;</ref>Li et al., 2018;</ref>Jiang </ref>Zhao et al., 2019)</ref>. Popular approaches include designing robust loss functions (Ghosh et al., 2017)</ref>, reweighting samples (Ren et al., 2018)</ref>, and learning with meta-learning (Li et al., 2018;</ref>Jiang et al., 2018)</ref>. ) Background : True label is replaced by a single background label with the probability ρ. This type of noise is pretty common and challenging as it's a combination of label imbalance and label noise (Ren et al., 2018)</ref>.</p><p>Baselines. Our method is compared with several state-of-the-art methods to make DNN robust against label noise. b1) MentorNet <ref type=" a lack of representation power and can not handle complex conditions well.</p><p>Sample reweighting and pruning. Another popular approach to handle corrupted labels is sample reweighting or pruning. Ren et al. (2018)</ref> propose a meta-learning method to reweight training samples based on their gradient directions. Jiang et al. (2018 network. For experiments without the validation set, we use the same 45000 images for training. On MNIST and SVHN, we use all the provided training data for training.</p><p>Noise settings. Following Ren et al. (2018)</ref>, we design two label noise distribution forms: 1) Uniform: True label is uniformly replaced by other labels with the probability ρ (Noise rate).
"bibr" target="#b3">(Deng et al., 2009)</ref> and COCO (Lin et al., 2014)</ref>. However, collecting high-quality labeled data is usually very time-consuming and costly (Tao and Dai, 2019;</ref>Tavanaei et al., 2019)</ref>. In contrast, obtaining coarsely labeled data, e.g., images retrieved by search engi
ing the confidence-based relabelling mechanism ineffective. Inspired by the intriguing phenomenon that DNNs tend to learn meaningful patterns before overfitting to noise during the course of training (Arpit et al., 2017)</ref>, we trigger the relabelling operation early in the training stage, before the network starting to overfit noise. Such an on-the-fly relabelling st 100% accuracy. This phenomenon is in line with that observed by Zhang et al. (2017)</ref> that DNNs are able fit random noise. We also observed similar results as in (Arpit et al., 2017)</ref> that DNNs tend to learn meaningful patterns from correctly labeled samples firstly, while overfit to noise in a later stage. In contrast, co-le cording to the model's predictions, and gradually shift from receiving supervision from the original labels to learning from the pseudo labels. It is inspired by the intriguing phenomenon observed by Arpit et al. (2017)</ref> that DNNs tend to learn meaningful patterns before overfitting to corrupted labels. With the dynamic loss function, co-learning can quickly lear
2016;</ref>Schmidhuber, 2015)</ref>. They can learn highly generalizable representations when fueled by large scale datasets with precise annotations, such as ImageNet (Deng et al., 2009)</ref> and COCO (Lin et al., 2014)</ref>. However, collecting high-quality labeled data is usually very time-consuming a
vanaei et al., 2019)</ref>. In contrast, obtaining coarsely labeled data, e.g., images retrieved by search engines (Li et al., 2017)</ref>, web social data, Flickr tags (Vahdat, 2017)</ref>, is a relatively easier task. Unfortunately, DNNs are easy to overfit the label noise in the dataset, and thus achieve poor generalization performan type="bibr" target="#b47">Xiao et al., 2015)</ref>. In addition, recent work also models the label noise via more complicated distributions, which takes the instances distribution into consideration (Vahdat, 2017)</ref>. However, estimating the label noise distribution is usually challenging in practice, especially when deep learning approaches are involved. Moreove
head><p>Deep neural networks (DNNs) have achieved remarkable success in the past few years (He et al., 2016;</ref>Huang et al., 2017;</ref>Simonyan and Zisserman, 2015;</ref>Ren et al., 2015;</ref>Silver et al., 2016;</ref><ref type="bibr" target >(He et al., 2016;</ref>Huang et al., 2017;</ref>Simonyan and Zisserman, 2015;</ref>Ren et al., 2015;</ref>Silver et al., 2016;</ref>Schmidhuber, 2015)</ref>. They can learn highly generalizable representations when fueled by large scale dataset
f which generates pseudo labels for the other. The two branches tend to make different mistakes with stochastic training techniques like dropout (Lan et al., 2018;</ref>Szegedy et al., 2016;</ref>Huang et al., 2018)</ref>. Therefore, co-learning is stable even a large portion of the labels are corrupted.</ to supervise each other. As the model is trained with stochastic techniques like dropout, two separate branches tend to make different mistakes (Lan et al., 2018;</ref>Szegedy et al., 2016;</ref>Huang et al., 2018)</ref>. Collaboratively they could significantly reduce the risk of amplifying a branch's ow n mechanisms (e.g. dropout) adopted to train the models, the two branches tend to converge to different local minima and make different mistakes (Lan et al., 2018;</ref>Szegedy et al., 2016)</ref>. Therefore, pseudo labels generated from each other tend to be more reliable. It is more robust than using a single model as in traditional s
ssumption, a confusion matrix can be introduced to describe the label noise (Sukhbaatar et al., 2018)</ref>, and many existing work is dedicated to estimate this matrix (Patrini et al., 2017;</ref>Hendrycks et al., 2018;</ref>Jindal et al., 2016)</ref>. As true labels can be or them: random 32x32 cropping with 4-pixel padded and random horizontal flipping (Jiang et al., 2018;</ref>Zhang and Sabuncu, 2018;</ref>Patrini et al., 2017;</ref>Tanaka et al., 2018)</ref>. The MNIST dataset consists of 32x32 images of handwritten digits with 10 classes, 6
et al., 2018)</ref>, and many existing work is dedicated to estimate this matrix (Patrini et al., 2017;</ref>Hendrycks et al., 2018;</ref>Jindal et al., 2016)</ref>. As true labels can be seen as latent variables, EM-based algorithms are also proposed to handle the label noise with probabilistic models <re
R under uniform label noise. ResNet-32 is used in experiments on MNIST and SVHN under uniform label noise and experiments under background label noise. The models are trained with a Nesterov momentum (Sutskever et al., 2013)</ref> of 0.9, a dropout rate of 0.3 and a l2 weight decay of 1e-4. The mini-batch size is set as 100 for a total number of 160 epochs. The learn
without a proper collaborative mechanism, the two networks may result in similar errors and negatively influence each other, especially for the training set with a large portion of corrupted labels. Veit et al. (2017)</ref> trains an auxiliary cleaning network jointly with a classifier to clean up labels. Generally, most existing work does not pay much attention to
labels can be seen as latent variables, EM-based algorithms are also proposed to handle the label noise with probabilistic models (Goldberger and Ben-Reuven, 2017;</ref>Khetan et al., 2018;</ref>Xiao et al., 2015)</ref>. In addition, recent work also models the label noise via more complicated distribution
dom horizontal flipping (Jiang et al., 2018;</ref>Zhang and Sabuncu, 2018;</ref>Patrini et al., 2017;</ref>Tanaka et al., 2018)</ref>. The MNIST dataset consists of 32x32 images of handwritten digits with 10 classes, 60000 for training and 10000 for testing. Following <ref ty
http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks (DNNs) have achieved remarkable success in the past few years (He et al., 2016;</ref>Huang et al., 2017;</ref>Simonyan and Zisserman, 2015;</ref>Ren et al., 2015;</ref><ref type="bibr" target= "#b27">(Netzer et al., 2011)</ref> consists of 32x32 colored images of digits. 73,257 images for training, 26,032 images for testing and 531,131 images for additional training are provided. Following Huang et al. (2017)</ref>, we use all the training data without any data augmentation. For all experiments, we test the performance of the network on the test sets provi
ing the confidence-based relabelling mechanism ineffective. Inspired by the intriguing phenomenon that DNNs tend to learn meaningful patterns before overfitting to noise during the course of training (Arpit et al., 2017)</ref>, we trigger the relabelling operation early in the training stage, before the network starting to overfit noise. Such an on-the-fly relabelling st 100% accuracy. This phenomenon is in line with that observed by Zhang et al. (2017)</ref> that DNNs are able fit random noise. We also observed similar results as in (Arpit et al., 2017)</ref> that DNNs tend to learn meaningful patterns from correctly labeled samples firstly, while overfit to noise in a later stage. In contrast, co-le cording to the model's predictions, and gradually shift from receiving supervision from the original labels to learning from the pseudo labels. It is inspired by the intriguing phenomenon observed by Arpit et al. (2017)</ref> that DNNs tend to learn meaningful patterns before overfitting to corrupted labels. With the dynamic loss function, co-learning can quickly lear
are easy to overfit the label noise in the dataset, and thus achieve poor generalization performance. In fact, it has been proved that DNNs have the capacity to overfit even completely random labels (Zhang et al., 2017)</ref>. Therefore, training DNNs reliably on datasets with corrupted labels remains challenging (Sogawa et al., 2013;< show that although basic DNNs are able to fit correct labels perfectly, it also learns to fit the randomly labeled samples with almost 100% accuracy. This phenomenon is in line with that observed by Zhang et al. (2017)</ref> that DNNs are able fit random noise. We also observed similar results as in (Arpit et al., 2017)</ref> that DNNs
">Zhang and Sabuncu, 2018)</ref>.</p><p>To address the aforementioned challenge, a number of methods have been proposed in recent years (Frenay and Verleysen, 2014;</ref>Ghosh et al., 2017;</ref>Ren et al., 2018;</ref>Kumar et al., 2010;</ref>Li e #b20">Li et al., 2018;</ref>Jiang et al., 2018;</ref>Zhao et al., 2019)</ref>. Popular approaches include designing robust loss functions (Ghosh et al., 2017)</ref>, reweighting samples (Ren et al., 2018)</ref>, and learning with meta-learning (L 1">Bengio et al., 2009)</ref>. From the perspective of loss functions, many robust forms are designed to reduce the effect of label noise (Zhang and Sabuncu, 2018;</ref>Ghosh et al., 2017)</ref>. One disadvantage of these methods is that they tend to ignore the information of samples with wrong Branch I learns from both the original part
f which generates pseudo labels for the other. The two branches tend to make different mistakes with stochastic training techniques like dropout (Lan et al., 2018;</ref>Szegedy et al., 2016;</ref>Huang et al., 2018)</ref>. Therefore, co-learning is stable even a large portion of the labels are corrupted.</ to supervise each other. As the model is trained with stochastic techniques like dropout, two separate branches tend to make different mistakes (Lan et al., 2018;</ref>Szegedy et al., 2016;</ref>Huang et al., 2018)</ref>. Collaboratively they could significantly reduce the risk of amplifying a branch's ow n mechanisms (e.g. dropout) adopted to train the models, the two branches tend to converge to different local minima and make different mistakes (Lan et al., 2018;</ref>Szegedy et al., 2016)</ref>. Therefore, pseudo labels generated from each other tend to be more reliable. It is more robust than using a single model as in traditional s
mpare the performance of CPGNN with baseline methods under a more realistic experimental setup by using significantly fewer training data comparing to the few previous works which address heterophily (Pei et al. 2020;</ref>Zhu et al. 2020)</ref>. These experiments demonstrate the effectiveness of incorporating the heterophily matrix H i another 10% for the validation set and the remaining as the test set. Notice that we are using a significantly smaller fraction of training samples compared to previous works that address heterophily (Pei et al. 2020;</ref>Zhu et al. 2020)</ref>. This is a more realistic assumption in many real-world applications. Synthetic Benchmarks. y, which are Cora, Pubmed and Citeseer (Sen et al. 2008;</ref>Namata et al. 2012)</ref>. We use the features and class labels provided by Pei et al. (2020)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Node Classification with Contextual Features</head><p>Experimental Setup. For s Kipf and Welling (2017)</ref> by replacing the node features X in each benchmark with an identity matrix I. We use the training, validation and test splits provided by Pei et al. (2020)</ref>.</p><p>Heterophily. We report results on graphs with strong heterophily under the featureless settings in Table <ref type="table" target="#tab_4"

rrel and Chameleon (Rozemberczki, Allen, and Sarkar 2019), and 3 widely adopted graphs with strong homophily, which are Cora, Pubmed and Citeseer (Sen et al. 2008;</ref>Namata et al. 2012)</ref>. We use the features and class labels provided by Pei et al. (2020)</ref>.</p></div> <div xmlns="http://www.tei-

ted the design of many GNN models, which tend to generate similar representations for nodes within close proximity, as studied in previous works (Ahmed et al. 2018;</ref>Rossi et al. 2020;</ref>Wu et al. 2019)</ref>. However, there are also many instances in the real world where nodes of different classes a ous work on semi-supervised node classification have focused only on graphs that have contextual features on the nodes. However, the vast majority of graph data does not have such node-level features (Rossi and Ahmed 2015)</ref>, which greatly limits the utility of the methods proposed in prior work that assume such features are available. Therefore, we conduct exten l. 2018)</ref> and AGNN (Thekumparampil et al. 2018)</ref>   (Li et al. 2019</ref>(Li et al. , 2020;;</ref>Rong et al. 2020)</ref>.</p><p>Although many of these GNN methods work well when the data exhibits strong homophily, none of these methods (except Geom-GCN) was proposed
apted in applications including recommendation systems (Ying et al. 2018)</ref>, bioinformatics (Zitnik, Agrawal, and Leskovec 2018;</ref>Yan et al. 2019)</ref>, fraud detection (Dou et al. 2020)</ref>, and more. While many different GNN models have been proposed, existing methods have lar
h where each node iteratively sends its neighboring nodes estimations of their beliefs based on its current belief, and updates its own belief based on the estimations received from its neighborhood. Koutra et al. (2011)</ref> and Gatterbauer et al. (2015)</ref> have proposed linearized versions which are faster to compute. However, thes
n the effectiveness of GNN to capture graph information: GAT (Veličković et al. 2018)</ref> and AGNN (Thekumparampil et al. 2018)</ref>   (Li et al. 2019</ref>(Li et al. , 2020;;</ref>Rong et al. 2020)</ref>.</p><p>Although many of these GNN met
r" target="#b18">McDowell, Gupta, and Aha 2007;</ref>Rossi et al. 2012</ref>) can be solved with iterative methods (J. Neville 2000;</ref>Lu and Getoor 2003)</ref>, graph-based regularization and probabilistic graphical models (London and Getoor 2014)</ref>. Among these metho
cally, many GNN models which are designed under implicit homophily assumptions suffer from poor performance in heterophily settings, which can be problematic for applications like fraudster detection (Pandit et al. 2007;</ref>Dou et al. 2020)</ref> or analysis of protein structures (Fout et al. 2017)</ref>, where heterop
the prior beliefs of nodes within their neighborhoods using a parameterized, end-to-end trainable compatibility matrix H.</p><p>To propagate the belief vectors through linear formulations, following Gatterbauer et al. (2015)</ref>, we first center B p with</p><formula xml:id="formula_8">B(0) = Bp − 1 |Y| (5)</formula><p>We parameterize the compatibility matrix as H t mations of their beliefs based on its current belief, and updates its own belief based on the estimations received from its neighborhood. Koutra et al. (2011)</ref> and Gatterbauer et al. (2015)</ref> have proposed linearized versions which are faster to compute. However, these approaches require the class-compatibility matrix to be dete
, we learn a prior that possesses the ability of quickly adapting to new downstream tasks with only a few fine-tuning updates. The proposed learning to pre-train can be deemed a form of meta-learning (Finn, Abbeel, and Levine 2017)</ref>, also known as learning to learn. For the second challenge, we propose a self-supervised strategy with a dual adaptation mechanism, -tuning on D tr T G , our strategy becomes equivalent to conventional pre-training approaches. Furthermore, our strategy is a form of meta-learning, in particular, model agnostic meta-learning (MAML) (Finn, Abbeel, and Levine 2017)</ref>. Meta-learning aims to learn prior knowledge from a set of training tasks that can be transferred to testing tasks. Specifically, M ture or training process for rapid generalization across tasks. Finally, some optimization-based methods directly adjust the optimization algorithm to enable quick adaptation with just a few examples (Finn, Abbeel, and Levine 2017;</ref>Yao et al. 2019;</ref>Lee et al. 2019;</ref><ref type="bibr" target="#
making use of abundant unlabeled data. The primary goal of pre-training GNNs (Navarin, Tran, and Sperduti 2018;</ref>Hu et al. 2019</ref>Hu et al. , 2020) )</ref> is to learn transferable prior knowledge from mostly unlabeled data, which can be generalized to downstream tasks with a quick fine-tuning step aining (Navarin, Tran, and Sperduti 2018;</ref>Hu et al. 2019)</ref>, or still require supervised information for graph-level pretraining (Hu et al. 2020</ref>). While at the node level, predicting links between node pairs is naturally self-supervised, graphlevel self-supervision has been seldom explored. erized function Ω(•) with parameters ω. Conventional GNN Pre-training. The goal of pre-training GNNs is to learn a generic initialization for model parameters using readily available graph structures (Hu et al. 2020</ref>(Hu et al. , 2019))</ref>. Conventional pre-training strategies largely follow a twostep paradigm. (1) Pre-training a y.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>Datasets. We conduct experiments on data from two domains: biological function prediction in biology (Hu et al. 2020</ref>) and research field prediction in bibliography. The biology graphs come from a public repository1</ref> , coverin ing, while another work (Hu et al. 2019)</ref> pre-trains graph encoders with three unsupervised tasks to capture different aspects of a graph. More recently, Hu et al. (Hu et al. 2020)</ref> propose different strategies to pre-train graph neural networks at both node and graph levels, although labeled data are required at the graph lev h contains 1,054,309 paper subgraphs in 31 fields (e.g., artificial intelligence, data mining). Each subgraph is centered at a paper and contains the associated information of For biology data, as in (Hu et al. 2020)</ref>, we use 306,925 unlabeled protein ego-networks for pre-training. In fine-tuning, we predict 40 fine-grained biological functions with 88,000 label ining. In fine-tuning, we predict 40 fine-grained biological functions with 88,000 labeled subgraphs that correspond to 40 binary classification tasks. We split the downstream data with species split (Hu et al. 2020)</ref>, and evaluate the test performance with average ROC-AUC (Bradley 1997</ref>) across the 40 tasks. For PreDBLP, we ut ) (Velickovic et al. 2019</ref>) to maximize local mutual information across the graph's patch representations; (3) Context Prediction strategy (denoted by ContextPred) (Hu et al. 2020)</ref> to explore graph structures and (4) Attribute Masking strategy (denoted by AttrMasking) (Hu et al. 2020)</ref> to l (3) Context Prediction strategy (denoted by ContextPred) (Hu et al. 2020)</ref> to explore graph structures and (4) Attribute Masking strategy (denoted by AttrMasking) (Hu et al. 2020)</ref> to learn the regularities of the node and edge attributes distributed over graphs. Further details are provided in Appendix D.</p><p>GNN Architect l). The reason might be that these strategies learn information irrelevant to the downstream tasks, which harms the generalization of the pre-trained GNNs. This finding confirms previous observations (Hu et al. 2020;</ref>Rosenstein et al. 2005</ref>) that negative transfer results in limitations on the applicability and reliability of
at the graph level.</p><p>On another line, meta-learning intends to learn a form of general knowledge across similar learning tasks, so that the learned knowledge can be quickly adapted to new tasks (Vilalta and Drissi 2002;</ref>Vanschoren 2018;</ref>Peng 2020</ref>). Among previous works on meta-learnin
Ying et al. 2018b;</ref>Hasanzadeh et al. 2019;</ref>Qu, Bengio, and Tang 2019;</ref>Pei et al. 2020;</ref>Munkhdalai and Yu 2017)</ref>. Empirically, these GNNs have achieved impressive performance in many tasks, such as node and graph classification <ref type="bibr" target= ref type="bibr" target="#b34">Snell, Swersky, and Zemel 2017</ref>) learn a metric or distance function over tasks, while model-based methods (Santoro et al. 2016;</ref>Munkhdalai and Yu 2017)</ref> aim to design an architecture or training process for rapid generalization across tasks. Finally, some optimization-based methods directly
ve for pre-training GNNs. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>GNNs have received significant attention due to the prevalence of graph-structured data (Bronstein et al. 2017)</ref>. Originally proposed (Marco, Gabriele, and Franco 2005;</ref>Scarselli et al.
lly, some optimization-based methods directly adjust the optimization algorithm to enable quick adaptation with just a few examples (Finn, Abbeel, and Levine 2017;</ref>Yao et al. 2019;</ref>Lee et al. 2019;</ref>Lu, Fang, and Shi 2020)</ref>.</p><p>3 Learning to Pre-train:</
n limited and expensive to obtain.</p><p>Inspired by pre-trained language models (Devlin et al. 2019;</ref>Mikolov et al. 2013</ref>) and image encoders (Girshick et al. 2014;</ref>Donahue et al. 2014;</ref>He et al. 2019)</ref>, recent advances in pre-training ifferent graph neural networks. Sec. 3.2 demonstrates the divergence between pre-training and fine-tuning, which is widely known in the literature (Lv et al. 2020;</ref>Gururangan et al. 2020</ref>), whether it is on the graph data, or in natural language process or computer vision. L2P-GNN directly optimizes the pre-trained model's qui
espond to 40 binary classification tasks. We split the downstream data with species split (Hu et al. 2020)</ref>, and evaluate the test performance with average ROC-AUC (Bradley 1997</ref>) across the 40 tasks. For PreDBLP, we utilize 794,862 subgraphs to pre-train a GNN model. In fine-tuning, we predict the research field with 299,447 l
formula><p>is the node representation matrix. READOUT is typically implemented as a simple pooling operation like sum, max or mean-pooling (Atwood and Towsley 2016;</ref>Duvenaud et al. 2015)</ref> or more complex approaches (Bruna et al. 2014;</ref>Ying et al. 2018b</ref>). We
proposed (Kipf and Welling 2017;</ref>Hamilton, Ying, and Leskovec 2017;</ref>Velickovic et al. 2018;</ref>Ying et al. 2018b;</ref>Hasanzadeh et al. 2019;</ref>Qu, Bengio, and Tang 2019;</ref><ref type="bibr" targe ref type="bibr" target="#b1">(Atwood and Towsley 2016;</ref>Duvenaud et al. 2015)</ref> or more complex approaches (Bruna et al. 2014;</ref>Ying et al. 2018b</ref>). We abstract READOUT as a parameterized function Ω(•) with parameters ω. Conventional GNN Pre-training. The goal of pre-training GNNs is to lear
sively aggregate information from neighborhoods on the graph, naturally capturing both graph structures as well as node or edge features (Zhang, Cui, and Zhu 2020;</ref>Wu et al. 2020;</ref>Dwivedi et al. 2020)</ref>. Various GNN architectures with different aggregation schemes have been proposed <ref type l methods (Defferrard, Bresson, and Vandergheynst 2016;</ref>Bruna et al. 2014;</ref>Levie et al. 2019;</ref>Xu et al. 2019a</ref>) and message passing architectures to aggregate neighbors' features (Kipf and Welling 2017;</ref>Ni ype="bibr" target="#b39">Velickovic et al. 2018;</ref>Abu-El-Haija et al. 2019)</ref>. For a more comprehensive understanding of GNNs, we refer readers to the literature (Wu et al. 2020;</ref>Battaglia et al. 2018;</ref>Zhang, Cui, and Zhu 2020;</ref><ref type="bibr" target="#b
at the graph level.</p><p>On another line, meta-learning intends to learn a form of general knowledge across similar learning tasks, so that the learned knowledge can be quickly adapted to new tasks (Vilalta and Drissi 2002;</ref>Vanschoren 2018;</ref>Peng 2020</ref>). Among previous works on meta-learnin
br" target="#b46">You et al. 2018</ref>). However, training GNNs usually requires abundant labeled data, which are often limited and expensive to obtain.</p><p>Inspired by pre-trained language models (Devlin et al. 2019;</ref>Mikolov et al. 2013</ref>) and image encoders (Girshick et al. 2014;</ref><ref type="bibr" targe
formula><p>is the node representation matrix. READOUT is typically implemented as a simple pooling operation like sum, max or mean-pooling (Atwood and Towsley 2016;</ref>Duvenaud et al. 2015)</ref> or more complex approaches (Bruna et al. 2014;</ref>Ying et al. 2018b</ref>). We
"bibr" target="#b19">(Kipf and Welling 2017;</ref>Hamilton, Ying, and Leskovec 2017)</ref>, recommendation systems (Fan et al. 2019;</ref>Ying et al. 2018a</ref>) and graph generation (Li et al. 2018;</ref>You et al. 2018</ref>). However, traini
formula><p>is the node representation matrix. READOUT is typically implemented as a simple pooling operation like sum, max or mean-pooling (Atwood and Towsley 2016;</ref>Duvenaud et al. 2015)</ref> or more complex approaches (Bruna et al. 2014;</ref>Ying et al. 2018b</ref>). We
"bibr" target="#b19">(Kipf and Welling 2017;</ref>Hamilton, Ying, and Leskovec 2017)</ref>, recommendation systems (Fan et al. 2019;</ref>Ying et al. 2018a</ref>) and graph generation (Li et al. 2018;</ref>You et al. 2018</ref>). However, traini
"#b33">Scarselli et al. 2008</ref>) as a framework of utilizing neural networks to learn node representations on graphs, this concept is extended to convolution neural networks using spectral methods (Defferrard, Bresson, and Vandergheynst 2016;</ref>Bruna et al. 2014;</ref>Levie et al. 2019;</ref><ref type=
Ying et al. 2018b;</ref>Hasanzadeh et al. 2019;</ref>Qu, Bengio, and Tang 2019;</ref>Pei et al. 2020;</ref>Munkhdalai and Yu 2017)</ref>. Empirically, these GNNs have achieved impressive performance in many tasks, such as node and graph classification <ref type="bibr" target= ref type="bibr" target="#b34">Snell, Swersky, and Zemel 2017</ref>) learn a metric or distance function over tasks, while model-based methods (Santoro et al. 2016;</ref>Munkhdalai and Yu 2017)</ref> aim to design an architecture or training process for rapid generalization across tasks. Finally, some optimization-based methods directly
">He et al. 2019)</ref>, recent advances in pre-training GNNs have provided insights into reducing the labeling burden and making use of abundant unlabeled data. The primary goal of pre-training GNNs (Navarin, Tran, and Sperduti 2018;</ref>Hu et al. 2019</ref>Hu et al. , 2020) )</ref> is to learn transfera -tuning step.</p><p>(2) How to simultaneously preserve node-and graph-level information with completely unlabeled graph data? Existing methods either only take into account the node-level pretraining (Navarin, Tran, and Sperduti 2018;</ref>Hu et al. 2019)</ref>, or still require supervised information for graph-level pretraining <ref ty get="#b48">Zhou et al. 2018)</ref>. To enable more effective learning on graphs, researchers have explored how to pre-train GNNs for node-level representations on unlabeled graph data. Navarin et al. (Navarin, Tran, and Sperduti 2018)</ref> utilize the graph kernel for pre-training, while another work (Hu et al. 2019)</ref> pre-trains g
o learn node representations on graphs, this concept is extended to convolution neural networks using spectral methods (Defferrard, Bresson, and Vandergheynst 2016;</ref>Bruna et al. 2014;</ref>Levie et al. 2019;</ref>Xu et al. 2019a</ref>) and message passing architectures to imple pooling operation like sum, max or mean-pooling (Atwood and Towsley 2016;</ref>Duvenaud et al. 2015)</ref> or more complex approaches (Bruna et al. 2014;</ref>Ying et al. 2018b</ref>). We abstract READOUT as a parameterized function Ω(•) with parameters ω. Conventional GNN
ad n="2">Related Work</head><p>GNNs have received significant attention due to the prevalence of graph-structured data (Bronstein et al. 2017)</ref>. Originally proposed (Marco, Gabriele, and Franco 2005;</ref>Scarselli et al. 2008</ref>) as a framework of utilizing neural networks to learn node representat 7">(Hu et al. 2020</ref>) and research field prediction in bibliography. The biology graphs come from a public repository1</ref> , covering 394,925 protein subgraphs (Marinka et al. 2019)</ref>. We further present a new collection of bibliographic graphs called PreDBLP, purposely compiled for pre-training GNNs based on DBLP<ref type=
sed recommendation approaches, we propose a new training framework based on Bayesian Graph Neural Networks (BGNNs). The proposed BGNN incorporates a random graph generative model based on nodecopying [24]</ref>. The node-copying model can be used to produce sample graphs that are similar to the observed graph, but they contain sufficient diversity in terms of edges t works [23,</ref>24]</ref>, where [23]</ref> uses a non-parametric model for the graph generative model and [24]</ref> proposes a node copying model to achieve flexibility in the generative model and improve computational efficiency.</p><p>In the context of recommendation, <re ture in a recommender system bipartite graph, the MMSBM is not an applicable graph model. As an alternative, we use a more general generative model for graphs based on copying nodes, as introduced in [24]</ref>. We demonstrate in the following sections that this model can be adapted naturally to the recommender system setting.</p></div> <div xmlns="http://www.tei-c.o nstrate in the following sections that this model can be adapted naturally to the recommender system setting.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Node Copying</head><p>In [24]</ref>, Pal et al. introduce the node copying model for 𝑝 (G). Samples from this model are generated by probabilistically rearranging (with replacement) the adjacenc ivation figure for node copying in the context of recommender system setting.Bayesian Graph Neural Networks (BGNNs). The proposed BGNN incorporates a random graph generative model based on nodecopying[24]</ref>. The node-copying model can be used to produce sample graphs that are similar to the observed graph, but they contain sufficient diversity in terms of edges t ut it has been shown that they can produce significant performance improvements in semi-supervised node classification when there are very few training labels [23,</ref>24,</ref>30,</ref>39]</ref>.</p><p>In this paper, we propose a novel Bayesian graph convolutional neural ba but it has been shown that they can produce significant performance improvements in semi-supervised node classification when there are very few training labels[23,</ref>24,</ref>30,</ref>39]</ref>.In this paper, we propose a novel Bayesian graph convolutional neural based rec n framework. However, the approach is not flexible and does not utilize the node attributes or labels. These limitations were addressed in the follow-up works [23,</ref>24]</ref>, where [23]</ref> uses a non-parametric model for the graph generative model and [24]</ref> propo
top-𝑁 recommendation focus on the relevance of each individual item independently and overlook the diversity of the top-𝑁 recommended items (i.e., the mutual influence between items). As observed in [22]</ref>, ignoring diversity of the recommended list leads to sub-optimal performance.</p><p>Recently, graphs have been used to represent the relational information pr e evaluate the recommendation accuracy of our model and baselines in terms of Recall@k and NDCG@k. Because accuracy alone does not guarantee satisfactory recommendations, we also assess serendipity@k [22]</ref>, which factors in how surprising and relevant a recommendation is. Surprise is measured as a weighted average of the differences between the probability that
-item interactions. The learned user and item embeddings are expected to characterize user preferences and item features. More recently, deep learning models ( [10,</ref>13]</ref>), which can learn more complex non-linear relationships between users and items, have been developed to enhance the performance of traditional MF models.</p><p y. Many approaches have been proposed to address these two problems. Recently, neural networks have been incorporated into collaborative filtering architectures [8,</ref>13]</ref>. These use a combination of fully-connected layers, convolution, inner-products and sub-nets to capture complex similarity relationships. An effective and comm by</p><formula xml:id="formula_10">𝑝 {&gt; 𝑢 } 𝐷 𝑆 | Θ G , G</formula><p>, where Θ G are the model parameters that maximize 𝑝 (Θ|{&gt; 𝑢 } 𝐷 𝑆 , G). This latter maximization is the same as BPR-OPT in (13)</ref>, as outlined in Section 3.3, but the inclusion of G indicates that x𝑢𝑖 𝑗 (Θ, G, G 𝑜𝑏𝑠 ) now takes into account the embeddings derived using G (and G 𝑜𝑏𝑠 ), as lines. To demonstrate the effectiveness, we compare our proposed model with the following methods: 1) Classical collaborative filtering methods: BPRMF [26]</ref>, NeuMF [13]</ref> 2) Graph neural network-based CF methods: GC-MC [31]</ref>, PinSAGE [38]</ref>, PinSAGE-LSTM, an assical collaborative filtering methods:</p><p>• BPRMF [26]</ref>: A general learning framework for personalized ranking recommendation using implicit feedback. • NeuMF [13]</ref>: NeuMF replaces the inner product with an MLP to learn the user-item interaction function.</p><p>Graph neural network-based CF methods:</p><p>• GC-MC <ref typ
and sub-nets to capture complex similarity relationships. An effective and common approach to alleviate the data sparsity problem is to leverage side information. For example, factorization machines [25]</ref> can provide a mechanism for incorporating side information such as user demographics and item attributes. Another line of research to tackle the sparsity prob
g Bayesian Graph Convolutional Neural Networks. We discuss how inference can be performed under our framework and provide a concrete formulation using the Bayesian Probabilistic Ranking training loss [26]</ref>.</p><p>2) By performing thorough experiments on three commonly used recommendation datasets and one industrial large-scale dataset, we demonstrate that our pr 𝑠,𝜁 𝑖 } (1 − 𝜖) 1 {G 𝑖 =G 𝑜𝑏𝑠,𝑖 } .<label>(3)</label></formula></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Bayesian Personalized Ranking loss for Implicit Recommendation</head><p>In [26]</ref>, Rendle et al. introduce a ranking loss for recommendation systems based on a Bayesian model. We build on that model in this work, extending it to take into a relation &gt; 𝑢 is required to be a total order on the set of items 𝐼 . The relation 𝑖 &gt; 𝑢 𝑗 specifies that user 𝑢 prefers item 𝑖 to item 𝑗.</p><p>In the Bayesian personalized ranking framework of [26]</ref>, our task is to maximize:</p><formula xml:id="formula_4">𝑝 Θ|{&gt; 𝑢 } 𝐷 𝑆 ∝ 𝑝 {&gt; 𝑢 } 𝐷 𝑆 |Θ 𝑝 (Θ) .<label>(5)</label></formula><p>Here Θ are the parameter s="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGY 4.1 Bayesian Graph Neural Networks for Personalized Ranking</head><p>In this section we build on the Bayesian Personalized Ranking framework of [26]</ref> to develop an approach that incorporates the strengths of Bayesian GNNs and thus takes into account the uncertainty in the graph observations. We develop two em 𝑖 and user 𝑢 in the observed graph.</p><p>Baselines. To demonstrate the effectiveness, we compare our proposed model with the following methods: 1) Classical collaborative filtering methods: BPRMF [26]</ref>, NeuMF [13]</ref> 2) Graph neural network-based CF methods: GC-MC [31]</ref>, PinSAGE <ref type= "><head n="9">SUPPLEMENTARY 9.1 Baselines</head><p>To demonstrate its effectiveness, we compare our proposed model with the following methods: Classical collaborative filtering methods:</p><p>• BPRMF [26]</ref>: A general learning framework for personalized ranking recommendation using implicit feedback. • NeuMF [13]</ref>: NeuMF replac ng Bayesian Graph Convolutional Neural Networks. We discuss how inference can be performed under our framework and provide a concrete formulation using the Bayesian Probabilistic Ranking training loss[26]</ref>.2) By performing thorough experiments on three commonly used recommendation datasets and one industrial large-scale dataset, we demonstrate that our proposed
f>38]</ref>, user-user and (or) item-item co-occurrence graphs [19]</ref> and heterogeneous graphs [3,</ref>6]</ref> coming from heterogeneous interaction types (search, guide, click, etc.) or interaction motives.</p><p>Although there has been progress, existing graph-based rec worth mentioning another line of work which addresses the complex and heterogeneous interaction types between users and items in large-scale e-commerce networks [3,</ref>6]</ref>. This problem setting is not in the scope of this paper since we address only the setting where there is a single type of interaction between user and item. Howe
cessful implementations of model-based CF methods, matrix factorization (MF) [18]</ref> models achieved the best performance in Netflix contest. MF models (such as pLAS [15]</ref>, MF [18]</ref> and SVD++ [17]</ref>) learn user and item embeddings by reconstructing the histor d CF methods learn the similarities between items and users by fitting a model to the user-item interaction data. Latent factor models are common, such as probabilistic Latent Semantic Analysis (pLAS [15]</ref>), Matrix Factorization (MF [18]</ref>) and SVD++ [17]</ref>. They learn user and item embeddings
top-𝑁 recommendation focus on the relevance of each individual item independently and overlook the diversity of the top-𝑁 recommended items (i.e., the mutual influence between items). As observed in [22]</ref>, ignoring diversity of the recommended list leads to sub-optimal performance.</p><p>Recently, graphs have been used to represent the relational information pr e evaluate the recommendation accuracy of our model and baselines in terms of Recall@k and NDCG@k. Because accuracy alone does not guarantee satisfactory recommendations, we also assess serendipity@k [22]</ref>, which factors in how surprising and relevant a recommendation is. Surprise is measured as a weighted average of the differences between the probability that
>34,</ref>38]</ref>, user-user and (or) item-item co-occurrence graphs [19]</ref> and heterogeneous graphs [3,</ref>6]</ref> coming from heterogeneous interaction types (search, guide, click, etc.) or interaction motives.</p><p>Although there has the user's social relationships. It is worth mentioning another line of work which addresses the complex and heterogeneous interaction types between users and items in large-scale e-commerce networks [3,</ref>6]</ref>. This problem setting is not in the scope of this paper since we address only the setting where there is a single type of 𝑚 ( 𝑗,𝑖) if 𝑗, 𝑚 ∈ U 0 otherwise<label>(15)</label></formula><p>Having specified this distribution, we can then adopt the graph sampling strategy from the copying model 𝑝 (G|𝜁 ) according to equation (3)</ref>. By sampling multiple graphs from our graph generative model, the observed graph, which is usually very sparse, can be directly augmented with likely neighbors
"http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Based Recommendation</head><p>There has been a considerable research effort devoted to the use of graph models in recommendation systems. Early works [9,</ref>37]</ref> use traditional random walks and label propagation to model the similarity scores for user-item pairs. With the success
gs by reconstructing the historical user-item interactions. The learned user and item embeddings are expected to characterize user preferences and item features. More recently, deep learning models ( [10,</ref>13]</ref>), which can learn more complex non-linear relationships between users and items, have been developed to enhance the per
which belong to an identical name or names with highly similar spellings to different people entities. Plenty of researches have been conducted to solve the name ambiguity problem. Supervised methods [1]</ref>,</p><p>The research is supported by the National Key Research and Development Plan (2017YFC1601504), the Natural Science Foundation of China (61836013), the CNT semantic information of text information and discrete features (e.g., authors, venue). High quality representations play a critical role to quantify distinctions and similarities between publications [1]</ref>. The majority of existing solutions utilize biographical features such as title, abstract, organization, author and venue, as well as relationship features such ews, which means most of publications belong to a few dominant authors. Hierarchical Agglomerative Clustering (HAC) method works well for skewed data and is widely in many name disambiguation methods [1]</ref>, [5]</ref>, [9]</ref>, [20]</ref>, [21 these baseline methods are as follows: Component: This method simply partitions each PHNet into connected components to generate the clustering results for each name to be disambiguated. Zhang et al. [1]</ref>: This method uses a global metric learning and local linkage learning based on a graph auto-encoder method to learn the publications embeddings, then it propose demonstrated in their own paper. These comparison methods use different kinds of cluster strategy. For example, [5]</ref> need to specify the number of distinct author, [1]</ref> need labeled data to estimate the number. For a fair comparison, we assume the number of clusters is set to real value and choose HAC as the clustering method o [5]</ref> ignore the text information, and Xu et al. just use the word co-occurrence information of text and loss a certain amount of semantic information. Zhang et al. [1]</ref> also use a graph convolutional network based encoder-decoder model but on homogeneous graph that can not extract multi-layer relationship that contains various elongs to a distinct person. [8]</ref> propose a Markov random fields based framework to extract multiple types of characteristics and relations in publication database. [1]</ref> use a global metric learning and local linkage graph auto-encoder algorithm to learn the representation of publications, but it requires lots of human labeled d
n neural networks to obtain node representations. [35]</ref> introduces a relational graph convolutional network to link prediction task and entity classification task. [36]</ref> propose a heterogeneous graph neural network model which considers both types and heterogeneous attributes of nodes. There are a large amount of works on name
cluster, then the two closest clusters (with biggest similarity) are merged in each step until the number of clusters reaches the specified K.</p><p>When K is unknown, we adopt an optimal modularity [22]</ref> partitioning mechanism to determine the partition of publications. The modularity M of a partition of nodes on graph G r is defined as follows:</p><formula xm
citation to generate these representations. Most works design relationships such as coauthorship between publications by these characteristics and construct publication networks, then use graph-based [3]</ref>- [5]</ref> or heuristic methods [6]</ref>, [7]</ref> to learn the simi ring strategies for name disambiguation are demanded.</p><p>The third challenge is how to efficiently process the new published publications that may contain potentially ambiguous names. Many methods [3]</ref>, [5]</ref>, [6]</ref>, [12]</ref>, [13
s how to efficiently determine the assignment of publications when we do not exactly know the number of distinct person for an ambiguous name. Some researches [5]</ref>, [11]</ref> assume that the cluster number of ambiguous author K is known in advance, but in real world we actually have no clue about the number. Some <ref type="bibr" t
ental name disambiguation methods, [27]</ref> propose a probabilistic model that use a rich set of metadata and classifies new publications to existing author entities. [28]</ref> combines several domain-specific heuristics in order to automatically create and update publication clusters and determine the author of each publication.</p>
ns, our method achieves 0.982 F1 score on it. It proves that our method can handle well the imbalance distribution of publications(46% authers have written only one publication in their entire career [26]</ref>, whereas some may have written more than 100 ones). The Macro-F1 score of methods' results on all names in each dataset(shown in last row) indicates that our
Hin2Vec is also an unweighted heterogeneous network embedding method that can capture rich semantic of relationships and the details of network structure to learn representations of nodes. GraphSAGE [25]</ref>: GraphSAGE learn node embeddings through different aggregation function form a node local neighborhood, which is similar with our designed HGCN layer, but the eural networks based method to learn a low-dimensional vector representation for each vertex by capturing the graph structural information. GCN [34]</ref> and GraphSage [25]</ref> use graph convolution neural networks to obtain node representations. [35]</ref> introduces a relational graph convolutional ne
ight Guided Random Walks: Our task is to train the HGCN model so that it can encode each publication node in PHNet to a high quality representation. Inspired by the network embedding methods DeepWalk [16]</ref> and Metapath2Vec [17]</ref> which use a random walk strategy and the skip-gram model to learning node representation in network work embedding model. For a fair comparison, We use them to learn publication representations on the networks with same construction as PHNet, and use HAC to generate the clustering results: DeepWalk [16]</ref>: DeepWalk is a network embedding method based on random walks to learn latent node representations and it is only applicable for homogeneous unweighted networ create and update publication clusters and determine the author of each publication.</p><p>Network Embedding. Recently, there has been a growing interest in the network embedding technology. DeepWalk [16]</ref> and Node2Vec [29]</ref> use random walk strategy on network and skip-gram [30]</ref>, <ref type=
The vast majority of name disambiguation solutions are conducted on static datasets. To disambiguate the new introduced publications in DLs, some works design incremental name disambiguation methods, [27]</ref> propose a probabilistic model that use a rich set of metadata and classifies new publications to existing author entities. [28]
bel>(5)</label></formula><p>where u i represents the embedding vector of p i encoded from its initial features u (0) i by HGCN in eq.2. Then, we adopt the popular negative sampling method proposed in [18]</ref> to sample negative nodes to increase the optimization efficiency. Then, the probability can be approximately defined as:</p><formula xml:id="formula_11">log p
s how to efficiently determine the assignment of publications when we do not exactly know the number of distinct person for an ambiguous name. Some researches [5]</ref>, [11]</ref> assume that the cluster number of ambiguous author K is known in advance, but in real world we actually have no clue about the number. Some <ref type="bibr" t
shed publications that may contain potentially ambiguous names. Many methods [3]</ref>, [5]</ref>, [6]</ref>, [12]</ref>, [13]</ref> are implemented on a static collection extracted from DLs, and need to run the author disambiguation process on the
en publications by these characteristics and construct publication networks, then use graph-based [3]</ref>- [5]</ref> or heuristic methods [6]</ref>, [7]</ref> to learn the similarity between publications. Some methods [4]</ref>, <ref type="bibr" ta how to efficiently process the new published publications that may contain potentially ambiguous names. Many methods [3]</ref>, [5]</ref>, [6]</ref>, [12]</ref>, [13]</ref> are implemented on a static collection extracted from DLs, and need to run
National Tobacco Corporation ) Science and Technology Major Project (110201901027(SJ-06)), and the Guangdong Provincial Key Laboratory of Biocomputing (2016B030301007).</p><p>1 Corresponding author. [2]</ref> regard this problem as a classification of authors with same name, however, they require labeled data. A widely used and effective idea is to learn publication
ns, our method achieves 0.982 F1 score on it. It proves that our method can handle well the imbalance distribution of publications(46% authers have written only one publication in their entire career [26]</ref>, whereas some may have written more than 100 ones). The Macro-F1 score of methods' results on all names in each dataset(shown in last row) indicates that our
ental name disambiguation methods, [27]</ref> propose a probabilistic model that use a rich set of metadata and classifies new publications to existing author entities. [28]</ref> combines several domain-specific heuristics in order to automatically create and update publication clusters and determine the author of each publication.</p>
ork (GNN) based methods that applies deep neural networks on graph-structured data are significant developed in recent years, GNNs can also be used as a node encoder to learn network embeddings. DNGR [33]</ref> proposes a deep neural networks based method to learn a low-dimensional vector representation for each vertex by capturing the graph structural information. G
many name disambiguation methods [1]</ref>, [5]</ref>, [9]</ref>, [20]</ref>, [21]</ref>. However, the HAC has the following drawbacks: its time complexity is high compared with some other clustering methods and it needs to take the number of clus rk, [4]</ref> construct five relationship networks among publications and use a network embedding algorithm to learn representations of publications via their neighbors, [21]</ref> introduce a simple random walk strategy and a graph embedding method on a homogeneous network and use HAC to partition the publications. However, these method
n they are applied on heterogeneous networks, such random walks ignore the types of relations, are biased by highly visible relation types and concentrated nodes, and generate incorporated node paths [32]</ref>. Metapath2Vec [17]</ref> proposes an embedding method on heterogeneous network based on meta-path. Some other methods have offe
e="bibr" target="#b15">[16]</ref>: DeepWalk is a network embedding method based on random walks to learn latent node representations and it is only applicable for homogeneous unweighted network. LINE [23]</ref>: LINE can preserve both the first-order and secondorder proximities of nodes and is applicable for homogeneous weighted network. Metapath2Vec <ref type="bibr" 2Vec [17]</ref> proposes an embedding method on heterogeneous network based on meta-path. Some other methods have offered different solutions to network embedding. LINE [23]</ref> aims to learn the node embedding that preserve both first-order and second-order proximities. Graph neural network (GNN) based methods that applies deep neura
e author of each publication.</p><p>Network Embedding. Recently, there has been a growing interest in the network embedding technology. DeepWalk [16]</ref> and Node2Vec [29]</ref> use random walk strategy on network and skip-gram [30]</ref>, [31]</ref> model to learn the repr
ns, our method achieves 0.982 F1 score on it. It proves that our method can handle well the imbalance distribution of publications(46% authers have written only one publication in their entire career [26]</ref>, whereas some may have written more than 100 ones). The Macro-F1 score of methods' results on all names in each dataset(shown in last row) indicates that our
The vast majority of name disambiguation solutions are conducted on static datasets. To disambiguate the new introduced publications in DLs, some works design incremental name disambiguation methods, [27]</ref> propose a probabilistic model that use a rich set of metadata and classifies new publications to existing author entities. [28]
The vast majority of name disambiguation solutions are conducted on static datasets. To disambiguate the new introduced publications in DLs, some works design incremental name disambiguation methods, [27]</ref> propose a probabilistic model that use a rich set of metadata and classifies new publications to existing author entities. [28]
ns, our method achieves 0.982 F1 score on it. It proves that our method can handle well the imbalance distribution of publications(46% authers have written only one publication in their entire career [26]</ref>, whereas some may have written more than 100 ones). The Macro-F1 score of methods' results on all names in each dataset(shown in last row) indicates that our
ansformation matrices {W (l) r } in each layer, where r ∈ R and l ∈ {0, ..., L−1}, and the sizes of parameters are independent with the size of publication set. Besides, we use the alias table method [19]</ref> to sample neighbors and negative nodes, which only takes O(1) time when repeatedly sampling nodes from the same discrete distribution. In this paper, we set t
s. Most works design relationships such as coauthorship between publications by these characteristics and construct publication networks, then use graph-based [3]</ref>- [5]</ref> or heuristic methods [6]</ref>, [7]</ref> to learn the similarity between publications. Some methods ublications.</p><p>The second challenge is how to efficiently determine the assignment of publications when we do not exactly know the number of distinct person for an ambiguous name. Some researches [5]</ref>, [11]</ref> assume that the cluster number of ambiguous author K is known in advance, but in real world we actually have no clue re demanded.</p><p>The third challenge is how to efficiently process the new published publications that may contain potentially ambiguous names. Many methods [3]</ref>, [5]</ref>, [6]</ref>, [12]</ref>, [13]</ref> are implemented on a static colle ong to a few dominant authors. Hierarchical Agglomerative Clustering (HAC) method works well for skewed data and is widely in many name disambiguation methods [1]</ref>, [5]</ref>, [9]</ref>, [20]</ref>, [21]</ref>. However, the HAC has the followi lications embeddings are learned by a novel network embedding method, the final result of clustering is determined adaptively based on the results of HDBSCAN and AP clustering algorithm. Zhang et al. [5]</ref>: This method constructs three different networks on relational data for each ambiguous name's publication set, and use a network embedding method to learn the p sed in each method, so the performance of some baselines maybe a little lower than that demonstrated in their own paper. These comparison methods use different kinds of cluster strategy. For example, [5]</ref> need to specify the number of distinct author, [1]</ref> need labeled data to estimate the number. For a fair comparison, we assum better performance is that our method is able to learn high quality publication representations by our HGCN based heterogenous network embedding method. Among the compared methods, both Zhang et al. [5]</ref> and Xu et al. construct several graphs based on various relationships between publications, and use network embedding based methods to learn representations of ef> and Xu et al. construct several graphs based on various relationships between publications, and use network embedding based methods to learn representations of publications. However, Zhang et al. [5]</ref> ignore the text information, and Xu et al. just use the word co-occurrence information of text and loss a certain amount of semantic information. Zhang et al. < neous attributes of nodes. There are a large amount of works on name disambiguation that attempt to use network embedding methods to learn publication embeddings by constructing publication networks. [5]</ref> utilize a network representation learning based approach on three anonymized network, [4]</ref> construct five relationship networ
aph structural information. GCN [34]</ref> and GraphSage [25]</ref> use graph convolution neural networks to obtain node representations. [35]</ref> introduces a relational graph convolutional network to link prediction task and entity classification task. [36]</ref> propose
e="bibr" target="#b15">[16]</ref>: DeepWalk is a network embedding method based on random walks to learn latent node representations and it is only applicable for homogeneous unweighted network. LINE [23]</ref>: LINE can preserve both the first-order and secondorder proximities of nodes and is applicable for homogeneous weighted network. Metapath2Vec <ref type="bibr" 2Vec [17]</ref> proposes an embedding method on heterogeneous network based on meta-path. Some other methods have offered different solutions to network embedding. LINE [23]</ref> aims to learn the node embedding that preserve both first-order and second-order proximities. Graph neural network (GNN) based methods that applies deep neura
e author of each publication.</p><p>Network Embedding. Recently, there has been a growing interest in the network embedding technology. DeepWalk [16]</ref> and Node2Vec [29]</ref> use random walk strategy on network and skip-gram [30]</ref>, [31]</ref> model to learn the repr
shed publications that may contain potentially ambiguous names. Many methods [3]</ref>, [5]</ref>, [6]</ref>, [12]</ref>, [13]</ref> are implemented on a static collection extracted from DLs, and need to run the author disambiguation process on the
and construct publication networks, then use graph-based [3]</ref>- [5]</ref> or heuristic methods [6]</ref>, [7]</ref> to learn the similarity between publications. Some methods [4]</ref>, [8]</ref>- <ref type="bibr" ta
ht hamper NMT's ability to generate fluent outputs.</p><p>Our model is an Edit-Based TransfOrmer with Repositioning (EDITOR), which builds on recent progress on non-autoregressive sequence generation (Lee et al., 2018;</ref>Ghazvininejad et al., 2019)</ref>. 1  Specifically, the Levenshtein Transformer (Gu hese issues have been addressed via partially parallel decoding (Wang et al., 2018;</ref>Stern et al., 2018)</ref> or multi-pass decoding (Lee et al., 2018;</ref>Ghazvininejad et al., 2019;</ref>Gu et al., 2019)</ref>. This work adopts multipass We stop refining if 1) the output sequences from two consecutive iterations are the same (Gu et al., 2019)</ref>, or 2) the maximum number of decoding steps is reached (Lee et al., 2018;</ref>Ghazvininejad et al., 2019)</ref>.5</ref> </p><p>Incorporating Soft Constraints illation</head><p>We apply sequencelevel knowledge distillation from autoregressive teacher models as widely used in nonautoregressive generation (Gu et al., 2018;</ref>Lee et al., 2018;</ref>Gu et al., 2019)</ref>. Specifically, when training the non-autoregressive models, we replace the reference sequenc
<p>Our model is an Edit-Based TransfOrmer with Repositioning (EDITOR), which builds on recent progress on non-autoregressive sequence generation (Lee et al., 2018;</ref>Ghazvininejad et al., 2019)</ref>. 1  Specifically, the Levenshtein Transformer (Gu et al., 2019)</ref> showed that iteratively refining o onsecutive iterations are the same (Gu et al., 2019)</ref>, or 2) the maximum number of decoding steps is reached (Lee et al., 2018;</ref>Ghazvininejad et al., 2019)</ref>.5</ref> </p><p>Incorporating Soft Constraints Although ED-ITOR is trained without lexical constraints decoding (Wang et al., 2018;</ref>Stern et al., 2018)</ref> or multi-pass decoding (Lee et al., 2018;</ref>Ghazvininejad et al., 2019;</ref>Gu et al., 2019)</ref>. This work adopts multipass decoding, where the model generates the target sequenc al., 2019)</ref>. This work adopts multipass decoding, where the model generates the target sequences by iteratively editing the outputs from previous iterations. Edit operations such as substitution (Ghazvininejad et al., 2019)</ref> and insertion-deletion (Gu et al., 2019)</ref> have reduced the quality gap between non-autoregressive
ighlight the benefits of soft constraints over hard ones -EDITOR with soft constraints achieves translation quality on par or better than both EDITOR and Levenshtein Transformer with hard constraints (Susanto et al., 2020)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Non-Autoregressive MT While autoregressive models that d lity to incorporate terminology constraints and to further compare it with prior work (Dinu et al., 2019;</ref>Post and Vilar, 2018;</ref>Susanto et al., 2020)</ref>. Compared to Post and Vilar (2018)</ref> and Dinu et al. (2019)</ref>, EDITOR w onstraints achieves higher absolute BLEU, and higher BLEU improvements over its counterpart without constraints (Table 6</ref>). Consistent with previous findings by Susanto et al. (2020)</ref>, incorporating soft constraints in LevT improves BLEU by +0.3 on Wiktionary and by +0.4 on IATE. Enforcing hard constraints as in <ref type=" indings by Susanto et al. (2020)</ref>, incorporating soft constraints in LevT improves BLEU by +0.3 on Wiktionary and by +0.4 on IATE. Enforcing hard constraints as in Susanto et al. (2020)</ref> increases the term usage by +8-10% and improves BLEU by +0.3-0.6 over LevT using soft constraints. 14  For EDITOR, adding soft constraints im are provided as soft constraints, so there is little benefit to enforcing hard constraints instead: they help close the small gap to reach 100% term usage and do not 14 We use our implementations of Susanto et al. (2020)</ref>'s technique for a more controlled comparison. The LevT baseline in Susanto et al. (2020)</ref> achieves higher gap to reach 100% term usage and do not 14 We use our implementations of Susanto et al. (2020)</ref>'s technique for a more controlled comparison. The LevT baseline in Susanto et al. (2020)</ref> achieves higher BLEU than ours on the small Wiktionary and IATE test sets, while it underperforms our LevT on the full WMT14 test set (26.5 v
<p>Non-Autoregressive MT While autoregressive models that decode from left-to-right are the de facto standard for many sequence generation tasks (Cho et al., 2014;</ref>Chorowski et al., 2015;</ref>Vinyals and Le, 2015)</ref>, non-autoregressive models offer a promising alternative to speed up decoding by
n-English (Ro-En) from WMT16 (Bojar et al., 2016), English-German (En-De) from WMT14 (Bojar et al., 2014)</ref>, and English-Japanese (En-Ja) from WAT2017 Small-NMT Task (Nakazawa et al., 2017)</ref>. We also evaluate EDITOR on the two En- with initial learning rate of 0.0005 and a batch size of 64,800 tokens for maximum 300,000 steps. <
div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dual-Path Imitation Learning</head><p>We train EDITOR using imitation learning (Daumé III et al., 2009;</ref>Ross et al., 2011;</ref>Ross and Bagnell, 2014)</ref> to efficiently explore the space of valid action sequences that can reach a referenc
Ma et al., 2019;</ref>Wang et al., 2019)</ref>. These issues have been addressed via partially parallel decoding (Wang et al., 2018;</ref>Stern et al., 2018)</ref> or multi-pass decoding (Lee et al., 2018;</ref>Ghazvininejad et al., 2019;</ref><
Ma et al., 2019;</ref>Wang et al., 2019)</ref>. These issues have been addressed via partially parallel decoding (Wang et al., 2018;</ref>Stern et al., 2018)</ref> or multi-pass decoding (Lee et al., 2018;</ref>Ghazvininejad et al., 2019;</ref><
spanning different language families and data conditions (Table 1</ref>): Romanian-English (Ro-En) from WMT16 (Bojar et al., 2016), English-German (En-De) from WMT14 (Bojar et al., 2014)</ref>, and English-Japanese (En-Ja) from WAT2017 Small-NMT Task (Nakazawa et al., 2017)</ref>. We also evaluate EDITOR
and Liu, 2017)</ref>. Lexical constraints or preferences have previously been incorporated by re-training NMT models with constraints as inputs (Song et al., 2019;</ref>Dinu et al., 2019)</ref> or with constrained beam search that drastically slows down decoding (Hokamp and Liu, 2017;</ref><ref type="bibr" ined training where NMT models are trained on parallel samples augmented with constraint target phrases in both the source and target sequences (Song et al., 2019;</ref>Dinu et al., 2019)</ref>, or 2) constrained decoding where beam search is modified to include constraint words or phrases in the output (H omly select one to four words from the reference as lexical constraints. We then randomly shuffle the constraints and apply BPE to the constraint sequence. Different from the terminology test sets in Dinu et al. (2019)</ref> which contain only several hundred sentences with mostly nominal constraints, our constructed test sets are larger and include lexical constrain g/ns/1.0"><head>Impact of Dual</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">MT with Terminology Constraints</head><p>We evaluate EDITOR on the terminology test sets released by Dinu et al. (2019)</ref> to test its ability to incorporate terminology constraints and to further compare it with prior work (Dinu et al. ;</ref>Post and Vilar, 2018;</ref>Susanto et al., 2020)</ref>. Compared to Post and Vilar (2018)</ref> and Dinu et al. (2019)</ref>, EDITOR with soft constraints achieves higher absolute BLEU, and higher BLEU improvements over its counterpart without constraints (Table <ref t row><row><cell>parisons when using our fairseq-based im-</cell></row><row><cell>plementation of EDITOR and Sockeye-based</cell></row></table><note>De test sets with terminology constraints released byDinu et al. (2019)</ref>. Machine Translation Results. For each metric, we underline the top scores among all models and boldface the top scores among NAR models based o rovided in the wrong order. While LevT generates an incorrect output by using constraints in the provided order, EDI-TOR's reposition operation helps generate a more fluent and adequate translation.  (Dinu et al., 2019)</ref> provided with correct terminology entries (exact matches on both source and target sides). EDITOR with soft constraints achieves higher BLEU th R on the terminology test sets released by Dinu et al. (2019)</ref> to test its ability to incorporate terminology constraints and to further compare it with prior work (Dinu et al., 2019;</ref>Post and Vilar, 2018;</ref>Susanto et al., 2020)</ref>. Compared to <ref type="bib
o En- with initial learning rate of 0.0005 and a batch size of 64,800 tokens for maximum 300,000 steps. 7</ref>We select the best checkpoint based on validation BLEU (Papineni et al., 2002)</ref>. All models are trained on 8 NVIDIA V100 Tensor Core GPUs.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Distillation<
entence-level models that generate a bag of target words that is reordered to construct a target sentence (Bangalore et al., 2007)</ref>, or the Operation Sequence Model (Durrani et al., 2015;</ref>Stahlberg et al., 2018)</ref>, which views translation as a sequence of translation and reordering operations
<p>Non-Autoregressive MT While autoregressive models that decode from left-to-right are the de facto standard for many sequence generation tasks (Cho et al., 2014;</ref>Chorowski et al., 2015;</ref>Vinyals and Le, 2015)</ref>, non-autoregressive models offer a promising alternative to speed up decoding by
p://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Non-Autoregressive MT While autoregressive models that decode from left-to-right are the de facto standard for many sequence generation tasks (Cho et al., 2014;</ref>Chorowski et al., 2015;</ref>Vinyals and Le, 2015)</ref>, non-autoregressive models
specific content or style constraints (Abu Sheikha and Inkpen, 2011;</ref>Mei et al., 2016)</ref>, or via segmentlevel "side-constraints" (Sennrich et al., 2016a;</ref>Ficler and Goldberg, 2017;</ref>Scarton and Specia, 2018)</ref>, which condit
s between target tokens (Ma et al., 2019;</ref>Wang et al., 2019)</ref>. These issues have been addressed via partially parallel decoding (Wang et al., 2018;</ref>Stern et al., 2018)</ref> or multi-pass decoding (Lee et al., 2018;</ref><ref type
g (EDITOR), which makes sequence generation flexible by seamlessly allowing users to specify preferences in output lexical choice. Building on recent models for non-autoregressive sequence generation (Gu et al., 2019)</ref>, EDI-TOR generates new sequences by iteratively editing hypotheses. It relies on a novel reposition operation designed to disentangle lexical cho sions, while enabling efficient oracles for imitation learning and parallel edits at decoding time. Empirically, EDITOR uses soft lexical constraints more effectively than the Levenshtein Transformer (Gu et al., 2019)</ref> while speeding up decoding dramatically compared to constrained beam search (Post and Vilar, 2018)</ref>. EDITOR a utoregressive sequence generation (Lee et al., 2018;</ref>Ghazvininejad et al., 2019)</ref>. 1  Specifically, the Levenshtein Transformer (Gu et al., 2019)</ref> showed that iteratively refining output sequences via insertions and deletions yields a fast and flexible generation process for MT and automatic Experiments on Romanian-English, English-German, and English-Japanese MT show that EDITOR achieves comparable or better translation quality with faster decoding speed than the Levenshtein Transformer (Gu et al., 2019)</ref> on the standard MT tasks and exploit soft lexical constraints better: it achieves significantly better translation quality and matches more const et sequences by iteratively editing the outputs from previous iterations. Edit operations such as substitution (Ghazvininejad et al., 2019)</ref> and insertion-deletion (Gu et al., 2019)</ref> have reduced the quality gap between non-autoregressive and autoregressive models. However, we argue that these operations limit the flexibility ual policy predictors. Figure 4</ref> shows an example for creating the roll-in sequences: we first create the initial sequence y 0 by applying random word dropping (Gu et al., 2019)</ref> and random word shuffle (Lample et al., 2018)</ref> with probability of 0.5 and maximum shuffle distance of 3 to the reference s ; ...). We greedily select the best action at each iteration given the model policy in Eqs.</p><p>(1) to (3). We stop refining if 1) the output sequences from two consecutive iterations are the same (Gu et al., 2019)</ref>, or 2) the maximum number of decoding steps is reached (Lee et al., 2018;</ref>Ghaz t the AR (Sockeye) baseline. As expected, both EDI-TOR and LevT achieve close translation quality to their AR teachers with 2-4 times speedup. BLEU differences are small (∆ &lt; 1.1) as in prior work (Gu et al., 2019)</ref>. The RIBES trends are more surprising: both NAR models significantly outperform the AR models (Sockeye) on RIBES, except for En-Ja, where EDITOR ut sequences that flexibly incorporate user's lexical choice preferences. Extensive experiments showed that ED-ITOR exploits soft lexical constraints more effectively than the Levenshtein Transformer (Gu et al., 2019)</ref> while speeding up decoding dramatically compared to constrained beam search (Post and Vilar, 2018)</ref>. Results >Stern et al., 2018)</ref> or multi-pass decoding (Lee et al., 2018;</ref>Ghazvininejad et al., 2019;</ref>Gu et al., 2019)</ref>. This work adopts multipass decoding, where the model generates the target sequences by iteratively editing the outputs from previous iterations. tillation from autoregressive teacher models as widely used in nonautoregressive generation (Gu et al., 2018;</ref>Lee et al., 2018;</ref>Gu et al., 2019)</ref>. Specifically, when training the non-autoregressive models, we replace the reference sequences y * in the training data with translation outputs f ther to delete the token. The dot product in the softmax function captures the similarity between the hidden state h i and each input embedding e j or the deletion vector b.</p><p>Insertion Following Gu et al. (2019)</ref>, the insertion operation consists of two phases: (1) placeholder insertion: given an input sequence y 1...n , the placeholder predictor π plh (p | ><formula xml:id="formula_12">d π in ins = y 0 , if u &lt; α E(y 0 , r), otherwise<label>(7)</label></formula><p>where the mixture factor α ∈ [0, 1] and random variable u ∼ Uniform(0, 1).</p><p>While Gu et al. (2019)</ref> define roll-in using only the model's insertion policy, we call our approach dual-path because roll-in creates two distinct intermediate sequences ndard (Section 4.2) and lexically constrained machine translation (Sections 4.3-4.4).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Dataset Following Gu et al. (2019)</ref>, we experiment on three language pairs spanning different language families and data conditions (Table 1</ref>):
> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural machine translation (MT) architectures (Bahdanau et al., 2015;</ref>Vaswani et al., 2017)</ref> make it difficult for users to specify preferences that could be incorporated more "bibr" target="#b44">Stahlberg et al., 2018)</ref>, which views translation as a sequence of translation and reordering operations over bilingual minimal units. By contrast, autoregressive NMT models (Bahdanau et al., 2015;</ref>Vaswani et al., 2017)</ref> do not explicitly separate lexical choice and reordering, and previous non-autoreg
016;</ref>Tang et al., 2016)</ref>. Despite their success at domain adaptation for MT (Hokamp and Liu, 2017)</ref> and caption generation (Anderson et al., 2017)</ref>, they suffer from several issues: constrained training requires building dedicated models for constrained language generation, while constra

ssive models.</p><p>Evaluation We evaluate translation quality via case-sensitive tokenized BLEU (as in Gu et al. ( 2019</ref>))9</ref> and RIBES (Isozaki et al., 2010)</ref>, which is more sensitive to word order differences. Before computing the scores, we tokenize the German and English outputs using Moses and
n-English (Ro-En) from WMT16 (Bojar et al., 2016), English-German (En-De) from WMT14 (Bojar et al., 2014)</ref>, and English-Japanese (En-Ja) from WAT2017 Small-NMT Task (Nakazawa et al., 2017)</ref>. We also evaluate EDITOR on the two En- with initial learning rate of 0.0005 and a batch size of 64,800 tokens for maximum 300,000 steps. <
tectures ranging from the word-based IBM models (Brown et al., 1990)</ref>, sentence-level models that generate a bag of target words that is reordered to construct a target sentence (Bangalore et al., 2007)</ref>, or the Operation Sequence Model (Durrani et al., 2015;</ref>Stahlberg et al.
entence-level models that generate a bag of target words that is reordered to construct a target sentence (Bangalore et al., 2007)</ref>, or the Operation Sequence Model (Durrani et al., 2015;</ref>Stahlberg et al., 2018)</ref>, which views translation as a sequence of translation and reordering operations
2019)</ref>. Machine Translation Results. For each metric, we underline the top scores among all models and boldface the top scores among NAR models based on the paired bootstrap test with p &lt; 0.05(Clark et al., 2011)</ref>. EDITOR decodes 6-7% faster than LevT on Ro-En and En-De, and 33% faster on En-Ja, while achieving comparable or higher BLEU and RIBES.</note>
spanning different language families and data conditions (Table 1</ref>): Romanian-English (Ro-En) from WMT16 (Bojar et al., 2016), English-German (En-De) from WMT14 (Bojar et al., 2014)</ref>, and English-Japanese (En-Ja) from WAT2017 Small-NMT Task (Nakazawa et al., 2017)</ref>. We also evaluate EDITOR
straints as hard constraints which may hurt fluency. In other tasks, various constraint types have been introduced by designing complex architectures tailored to specific content or style constraints (Abu Sheikha and Inkpen, 2011;</ref>Mei et al., 2016)</ref>, or via segmentlevel "side-constraints" (Sennric

specific content or style constraints (Abu Sheikha and Inkpen, 2011;</ref>Mei et al., 2016)</ref>, or via segmentlevel "side-constraints" (Sennrich et al., 2016a;</ref>Ficler and Goldberg, 2017;</ref>Scarton and Specia, 2018)</ref>, which condit
ssive models.</p><p>Evaluation We evaluate translation quality via case-sensitive tokenized BLEU (as in Gu et al. ( 2019</ref>))9</ref> and RIBES (Isozaki et al., 2010)</ref>, which is more sensitive to word order differences. Before computing the scores, we tokenize the German and English outputs using Moses and
s between target tokens (Ma et al., 2019;</ref>Wang et al., 2019)</ref>. These issues have been addressed via partially parallel decoding (Wang et al., 2018;</ref>Stern et al., 2018)</ref> or multi-pass decoding (Lee et al., 2018;</ref><ref type
div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dual-Path Imitation Learning</head><p>We train EDITOR using imitation learning (Daumé III et al., 2009;</ref>Ross et al., 2011;</ref>Ross and Bagnell, 2014)</ref> to efficiently explore the space of valid action sequences that can reach a referenc

ibr" target="#b17">Guo &amp; Barbosa, 2018)</ref>. More task details and hyperparameters setting are reported in Appendix A.1.</p><p>End-to-End Entity Linking (EL) For EL, we reproduce the setting of Kolitsas et al. (2018)</ref> using the same in-domain and out-of-domain datasets as well as evaluating the InKB micro-F 1 on the GERBIL benchmark platform <ref type="bib a document d j (e.g., a sentence) a system has to return a set of tuples m i , e i where m i is a entity mentions (a span contained in d j ) and e i ∈ E its corresponding entity in the KB. Following Kolitsas et al. (2018)</ref>, we considered only mentions that have entities in the KB (i.e., Wikipedia) and we used their candidate sets with the additions of the table alidation set. Afterward, we fine-tuned on AIDA resetting the learning rate and the optimizer statistics for 10k steps and we do model selection on the validation set. Again, following previous works (Kolitsas et al., 2018)</ref>, we considered only mentions that have entities in Wikipedia. Training was done on 64 GPUs (with 32GB of memory) and it completed in ∼30h f


scenario, we fine-tune using the AIDA-CoNLL dataset. We evaluate on seven out-of-domain test sets: MSNBC, Derczynski (Der) (Derczynski et al., 2015)</ref>, KORE 50 (K50) (Hoffart et al., 2012)</ref>, N3-Reuters-128 (R128), N3-RSS-500 (R500) (Röder et al., 2014)</ref>, and OKE challenge 2015 and 2016 (OKE15

>; open domain question answering using Natural Questions (Kwiatkowski et al., 2019)</ref>, HotpotQA (Yang et al., 2018c)</ref>, TriviaQA (Joshi et al., 2017)</ref>, ELI5 (Fan et al., 2019)</ref>; slot filling with T-REx (Elsahar et al., 2018)</
we use BART weights from Lewis et al. (2019)</ref>) and finetuned to generate entity names. This architecture has been shown to retain factual knowledge to some extent (Petroni et al., 2019)</ref> and language translation skills (Radford et al., 2019)</ref> among other things, both desirable properties fo

In Table 3</ref> we compare GENRE against all methods reported in the public leaderboard: DPR (Karpukhin et al., 2020)</ref>, DPR+BERT (Devlin et al., 2019)</ref>, DPR+BART, tf-idf (Leskovec et al., 2014)</ref>, RAG (Lewis et al., 2020)</ref>,

lsahar et al., 2018)</ref>, Zero Shot RE (Levy et al., 2017)</ref>; entity disambiguation on AIDA CoNLL-YAGO, WNED-WIKI and WNED-CWEB; dialogue with Wizard of Wikipedia (Dinan et al., 2019)</ref>. We train GENRE on BLINK and all KILT data simultaneously with a single model. 5</ref> More details on the h
nclusion of pre-specified words for machine translation (Hokamp &amp; Liu, 2017;</ref>Post &amp; Vilar, 2018)</ref>, and image captioning (Anderson et al., 2017)</ref>. To the best of our knowledge, we are the first to exploit constrained generation for entity disambiguation, end-to-end entity linking, and


ef type="bibr" target="#b59">(Sutskever et al., 2011;</ref>2014)</ref> and regularized with dropout (Srivastava et al., 2014)</ref> and label smoothing (Szegedy et al., 2016)</ref>. Concretely, we use the objective that is typically used for neural machine translation (NMT, Wu et al., 2016
so add it to the dataset as a mention/entity pairs). Then, for the in-domain scenario, we fine-tune using the AIDA-CoNLL dataset. We evaluate on seven out-of-domain test sets: MSNBC, Derczynski (Der) (Derczynski et al., 2015)</ref>, KORE 50 (K50) (Hoffart et al., 2012)</ref>, N3-Reuters-128 (R128), N3-RSS-500 (R500) <ref type="bibr" targ
/ns/1.0"><head n="5">RELATED WORKS</head><p>Casting NLP tasks with a structured input or output into sequence-to-sequence problems has been explored for different problems, including semantic parsing (Rongali et al., 2020)</ref>, semantic role labelling (Daza &amp; Frank, 2018)</ref>, discourse representation structure parsing <ref type=
we evaluate using R-precision (Beitzel et al., 2009)</ref>. KILT consists of five tasks that use the same Wikipedia dump as a knowledge source: fact checking with FEVER (Thorne et al., 2018)</ref>; open domain question answering using Natural Questions (Kwiatkowski et al., 2019)</ref>, HotpotQA <ref type="

ambiguous name to the candidate set.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A EXPERIMENTAL DETAILS</head><p>We implemented, trained, and evaluate our model using the fariseq library (Ott et al., 2019)</ref>. We trained GENRE for every task using Adam (Kingma &amp; Ba, 2014) with a learning rate 3 • 10 −5 with a linear warm-up for 500 steps and then
retrieval, it requires a limited list of candidates documents, obtained with BM25 for instance, in order to be computationally possible. Massarelli et al. (2019)</ref>; Petroni et al. (2020a)</ref> explore the idea of using an autoregressive language model as neural retriever, by exploiting the implicit knowledge stored in their paramet
ute a score for every element in E and then sort them. Unfortunately, this might be prohibitively expensive when E is very large (e.g., Wikipedia has ∼6M entities). Hence, we exploit Beam Search (BS, Sutskever et al., 2014)</ref>, an established approximate decoding strategies to efficiently navigate the search space. Instead of explicitly scoring all entities in E,
to lip-sync. The existing metrics, such as SSIM [27]</ref> and PSNR, were developed to evaluate overall image quality and not fine-grained lip-sync errors. Although LMD [4]</ref> focuses on the lip region, we found that lip landmarks can be quite inaccurate on generated faces. Thus, there is a need for a metric that is designed specifica
upport a new metric or a future method that aims to study the temporal consistency aspect of this problem.</p><p>4.1.4 Current metrics are not specific to lip-sync. The existing metrics, such as SSIM [27]</ref> and PSNR, were developed to evaluate overall image quality and not fine-grained lip-sync errors. Although LMD [4]</ref> focuses
p sync to match the desired target speech. Consequently, lip-syncing talking face videos to match a given input audio stream has received considerable attention [6,</ref>13,</ref>17,</ref>18,</ref>23]</ref> in the research community.</p><p>Initia ef>22]</ref> using deep learning in this space learned a mapping from speech representations to lip landmarks using several hours of a single speaker. More recent works [13,</ref>23]</ref> in this line directly generate images from speech representations and show exceptional generation quality for specific on only a specific speaker, they cannot synthesize for new identities or voices. They also require a large amount of data of a particular speaker, typically a few hours. A recent work along this line [13]</ref> proposes to seamlessly edit videos of individual speakers by adding or removing phrases from the speech. They still require an hour of data per speaker to ach
lso have an additional overhead of requiring clean training data of each target speaker to generate for that speaker. Another limitation of existing works is in terms of the vocabulary. Several works [5,</ref>26,</ref>28]</ref> train on datasets with a limited set of words such as GRID <ref type="bibr" targ
p sync to match the desired target speech. Consequently, lip-syncing talking face videos to match a given input audio stream has received considerable attention [6,</ref>13,</ref>17,</ref>18,</ref>23]</ref> in the research community.</p><p>Initia ef>22]</ref> using deep learning in this space learned a mapping from speech representations to lip landmarks using several hours of a single speaker. More recent works [13,</ref>23]</ref> in this line directly generate images from speech representations and show exceptional generation quality for specific on only a specific speaker, they cannot synthesize for new identities or voices. They also require a large amount of data of a particular speaker, typically a few hours. A recent work along this line [13]</ref> proposes to seamlessly edit videos of individual speakers by adding or removing phrases from the speech. They still require an hour of data per speaker to ach
v ∥ 2 • ∥s ∥ 2 , ϵ)<label>(1)</label></formula><p>We train our expert lip-sync discriminator on the LRS2 train split (≈ 29 hours) with a batch size of 64, with T v = 5 frames using the Adam optimizer [12]</ref> with an initial learning rate of 1e −3 . Our expert lip-sync discriminator is about 91% accurate on the LRS2 test set, while the discriminator used in LipGAN accuracy and quality using two disjoint discriminators.</p><p>We train our model only on the LRS2 train set [1]</ref>, with a batch size of 80. We use the Adam optimizer [12]</ref> with an initial learning rate of 1e −4 and betas β 1 = 0.5, β 2 = 0.999 for both the generator and visual quality discriminator D. Note that the lip-sync disc
ask. Firstly, instead of feeding grayscale images concatenated channel-wise as in the original model, we feed color images. Secondly, our model is significantly deeper, with residual skip connections [15]</ref>. Thirdly, inspired by this public implementation 2 , we use a different loss function: cosine-similarity with binary cross-entropy loss. That is, we compute a
nced videos.</p><p>Thus, we believe that our model can enable a wide range of real-world applications where previous speaker-independent lipsyncing approaches [17,</ref>18]</ref> struggle to produce satisfactory results.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.o ire models that can readily work for generic identities and speech inputs. This has led to the creation of speaker-independent speech to lip generation models [17,</ref>18]</ref> that are trained on thousands of identities and voices. They can generate accurate lip motion on a single, static image of any identity in any voice, including a small vocabulary. This allows them to, at test time, lip-sync random identities for any speech. To the best of our knowledge, only two such prominent works [17,</ref>18]</ref> exist in the current literature. Note that [17]</ref> is an extended version of [7]</ref>. Both th he current literature. Note that [17]</ref> is an extended version of [7]</ref>. Both these works [17,</ref>18]</ref> formulate the task of learning to lip-sync in the wild as follows: Given a short speech segment S and a random reference face image R, the task of the network n 2.2) produce inaccurate lip-sync for videos in the wild. We argue that the loss functions, namely the L1 reconstruction loss used in both the existing works [17,</ref>18]</ref> and the discriminator loss in LipGAN [18]</ref> are inadequate to penalize inaccurate lip-sync generation.</p></div> <div xmlns= ld.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparing the Models on the New Benchmark</head><p>We compare the previous two approaches [17,</ref>18]</ref> on our newly created test set using the LSE-D and LSE-C metrics. During inference, we now feed the same reference and pose-prior at each time-step, similar to e each of the three classes of videos separately and report our results in Table 2</ref>. An outcome worth noting is that the previous works [17,</ref>18]</ref> which produce several out-of-sync segments are less preferred over the unsynced version as the latter still preserves good Visual quality. Thus, ours is the fi e videos to match a given input audio stream has received considerable attention [6,</ref>13,</ref>17,</ref>18,</ref>23]</ref> in the research community.</p><p>Initial works [19,</ref> sands of identities and voices. They can generate accurate lip motion on a single, static image of any identity in any voice, including that of a synthetic speech generated by a text-to-speech system [18]</ref>. However, to be used for applications like translating a lecture/TV series, for example, these models need to be able to morph the broad diversity of lip shap r" target="#b13">[14]</ref> and LRW [8]</ref> (1000 words) which significantly hampers a model from learning the vast diversity of phoneme-viseme mappings in real videos [18]</ref>. Our work focuses on lip-syncing unconstrained talking face videos to match any target speech, not limited by identities, voices, or vocabulary.</p></div> <di hey work very well on static images of arbitrary identities but produce inaccurate lip generation when trying to lip-sync unconstrained videos in the wild. In contrast to the GAN setup used in LipGAN [18]</ref>, we use a pre-trained, accurate lip-sync discriminator that is not trained further with the generator. We observe that this is an important design choice to a oss functions, namely the L1 reconstruction loss used in both the existing works [17,</ref>18]</ref> and the discriminator loss in LipGAN [18]</ref> are inadequate to penalize inaccurate lip-sync generation.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pixel-level Reconstruction loss is erform fine-grained lip shape correction. This is further supported by the fact that the network begins morphing lips only at around half-way (≈ 11 th epoch) through its training process (≈ 20 epochs [18]</ref>). Thus, it is crucial to have an additional discriminator to judge lip-sync, as also done in LipGAN [18]</ref>. But, how powerf (≈ 11 th epoch) through its training process (≈ 20 epochs [18]</ref>). Thus, it is crucial to have an additional discriminator to judge lip-sync, as also done in LipGAN [18]</ref>. But, how powerful is the discriminator employed in LipGAN?</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A Weak Lip-sync Discriminator</he learning from an "already well-trained lip-sync expert". Unlike previous works that employ only a reconstruction loss [17]</ref> or train a discriminator in a GAN setup [18]</ref>, we use a pre-trained discriminator that is already quite accurate at detecting lip-sync errors. We show that fine-tuning it further on the noisy generated fa ing time. We start by describing the generator architecture.</p><p>2 github.com/joonson/syncnet_trainer 3.4.1 Generator Architecture Details. We use a similar generator architecture as used by LipGAN [18]</ref>. Our key contribution lies in training this with the expert discriminator. The generator G contains three blocks: (i) Identity Encoder, (ii) Speech Encoder, a nator is not fine-tuned further, so its weights are frozen. We conclude the description of our proposed architecture by explaining how it works during the inference on real videos. Similar to Lip-GAN [18]</ref>, the model generates a talking face video frame-by-frame. The visual input at each time-step is the current face crop (from the source frame), concatenated wi rking the lip-syncing performance on synthetic speech obtained from a text-to-speech system. This is essential for future works that aspire to automatically translate videos (Face-to-Face Translation [18]</ref>) or rapidly create new video content. We manually transcribe the text, use Google Translate (about 5 languages totally) and publicly available text-to-speech on the visual artifacts in the generated Figure 3</ref>: Examples of faces generated from our proposed models (green and yellow outlines). We compare with the current best approach [18]</ref> (red outline). The text is shown for illustration to denote the utterance being spoken in the frame shown. We can see that our model produces accurate, natura
="bibr" target="#b16">17,</ref>18,</ref>23]</ref> in the research community.</p><p>Initial works [19,</ref>22]</ref> using deep learning in this space learned a mapping from speech representations to lip landmarks using several hours of a single speaker. More recent works <re of identities they can generate or the range of vocabulary they are limited to. Realistic generation of talking face videos was achieved by a few recent works [19,</ref>22]</ref> on videos of Barack Obama. They learn a mapping between the input audio and the corresponding lip landmarks. As they are trained on only a specific speaker, th
content, leading to significant portions of the generated video being out-of-sync with the new target audio. A viewer can recognize an out-of-sync video segment as small as just ≈ 0.05 − 0.1 seconds [9]</ref> in duration. Thus, convincingly lip-syncing a real-world video to an entirely new speech is quite challenging, given the tiny degree of allowed error. Further, . Next, we re-examine the current evaluation protocols and devise new, rigorous evaluation benchmarks derived from three standard test sets. We also propose reliable evaluation metrics using Sync-Net [9]</ref> to precisely evaluate lip sync in unconstrained videos. We also collect and release ReSyncED, a challenging set of real-world videos that can benchmark how the ipGAN. One such network that has been used to correct lip-sync errors for creating large lip-sync datasets [1,</ref>3]</ref> is the SyncNet [9]</ref> model. We propose to adapt and train a modified version of SyncNet [9]</ref> for our task.</p></div> <div xmlns="http://www.tei-c. [1,</ref>3]</ref> is the SyncNet [9]</ref> model. We propose to adapt and train a modified version of SyncNet [9]</ref> for our task.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Overview of SyncNet.</head><p>SyncNet [9]</ref> i and train a modified version of SyncNet [9]</ref> for our task.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Overview of SyncNet.</head><p>SyncNet [9]</ref> inputs a window V of T v consecutive face frames (lower half only) and a speech segment S of size T a × D, where T v and T a are the video and audio timesteps r ally, we also employ a visual quality discriminator to improve the visual quality along with the sync accuracy.</p><p>3.3.2 Our expert lip-sync discriminator. We make the following changes to SyncNet [9]</ref> to train an expert lip-sync discriminator that suits our lip generation task. Firstly, instead of feeding grayscale images concatenated channel-wise as in the o pe for the sampled speech is unavailable.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">A Metric to</head><p>Measure the Lip-Sync Error. We propose to use the pre-trained SyncNet [9]</ref> available publicly 3 to measure the lip-sync error between the generated frames and the randomly chosen speech segment. The accuracy of SyncNet averaged over a ="#b8">[9]</ref> available publicly 3 to measure the lip-sync error between the generated frames and the randomly chosen speech segment. The accuracy of SyncNet averaged over a video clip is over 99% [9]</ref>. Thus, we believe this can be a good automatic evaluation method that explicitly tests for accurate lipsync in unconstrained videos in the wild. Note that this licitly tests for accurate lipsync in unconstrained videos in the wild. Note that this is not the expert lip-sync discriminator that we have trained above, but the one released by Chung and Zisserman [9]</ref>, which was trained on a different, non-public dataset. Using a SyncNet resolves major issues of the existing evaluation framework. We no longer need to sample r the audio-video correlation. A lower confidence score denotes that there are several portions of the video with completely out-of-sync lip movements. Further details can be found in the SyncNet paper [9]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">A Consistent</head><p>Benchmark to Evaluate Lip-sync in the wild. Now that we have an automa new evaluation framework and metrics allow us to evaluate on real-world videos on which these models are most likely to be used. Further, given the sensitivity of humans to audio-lip synchronization [9]</ref>, it is necessary to also evaluate our results with the help of human evaluators. Thus, contrary to the previous works on speakerindependent lip-syncing, we cond to match this synthetic speech. 4.4.2 Real-world Evaluation on ReSyncED. We first evaluate the generated real video results using our new automatic metrics, "LSE-D" and "LSE-C" obtained from SyncNet [9]</ref>. For the human evaluation, we ask 14 evaluators to judge the different synced versions of the videos based on the following parameters: (a) Sync Accuracy (b) Vi
>26,</ref>28]</ref> train on datasets with a limited set of words such as GRID [10]</ref> (56 words), TIMIT [14]</ref> and LRW [8]</ref> (1000 words) which significantly hampers a model from learning the vast diversity of phoneme-viseme mappings i
able representative graph embeddings from networks?</p><p>The similar question has also been asked and pursued in natural language processing [10]</ref>, computer vision [17]</ref>, and other domains. To date, the most powerful solution is to pre-train a representation learning model from a large dataset, that is, self-supervised represe d encourages the model to distinguish similar instances from dissimilar instances. Next, we introduce how to define (dis)similar instances.</p><p>Q2: Define (dis)similar instances. In computer vision [17]</ref>, two random data augmentations (e.g., random crop, random resize, random color jitering, random flip, etc) of the same image are treated as a similar instance dicator of the ego vertex [42]</ref> as vertex features. After encoded by the graph encoder, the final d-dimensional output vectors are then normalized by their L2-Norm [17]</ref>.</p><p>A running example. We illustrate a running example of GCC in Figure 2</ref>. For simplicity, we set the dictionary size to be 3, i.e owever, due to the computational constraints, we usually design and adopt economical strategies to effectively build and maintain the dictionary, such as end-to-end (E2E) and momentum contrast (MoCo) [17]</ref>. We discuss the two strategies as follows.</p><p>E2E samples mini-batches of instances and considers samples in the same mini-batch as the dictionary. The obj mini-batches. During optimization, MoCo only updates the parameters of f q (denoted by θ q ) by backpropagation. The parameters of f k (denoted by θ k ) are not updated by gradient descent. He et al. [17]</ref> propose a momentum-based update rule for θ k . More formally, MoCo updates θ k by θ k ← mθ k + (1 − m)θ q , where m ∈ [0, 1) is a momentum hyper-parameter. Th oder.</p><p>In addition to E2E and MoCo, there are other contrastive learning mechanisms to maintain the dictionary, such as memory bank [59]</ref>. Recently, He et al. [17]</ref> show that MoCo is a more effective option than memory bank in computer vision tasks. Therefore, we mainly focus on E2E and MoCo for GCC.</p></div> <div xmlns= r IMDB-B, we attribute it to the domain shift between pre-training data and down-stream tasks.</p><p>Contrastive loss mechanisms. The common belief is that MoCo has stronger expression power than E2E [17]</ref>, and a larger dictionary size K always helps. We also observe such trends, as shown in Figure 3</ref>. However, the effect . We also observe such trends, as shown in Figure 3</ref>. However, the effect of a large dictionary size is not as significant as reported in computer vision tasks [17]</ref>. For example, MoCo (K = 16384) merely outperforms MoCo (K = 1024) by small margins in terms of accuracy -1.0 absolute gain in US-Airport and 0.8 absolute gain es 5 days and 16 hours, while MoCo (K=16384) only needs 9 hours. Detailed training time can be found in Table 5</ref> in the Appendix. Momentum. As mentioned in MoCo [17]</ref>, momentum m plays a subtle role in learning high-quality representations. Table 5</ref> shows accuracy with different moment " target="#tab_6">5</ref> shows accuracy with different momentum values on US-Airport and COL-LAB datasets. For US-Airport, the best performance is reached by m = 0.999, which is the desired value in [17]</ref>, showing that building a consistent dictionary is important for MoCo. However, in COLLAB, it seems that a larger momentum value brings better performance. Mor nsistent dictionary is important for MoCo. However, in COLLAB, it seems that a larger momentum value brings better performance. Moreover, we do not observe the "training loss oscillation" reported in [17]</ref> when setting m = 0. GCC (MoCo) converges well, but the accuracy is much worse.</p><p>Pre-training datasets. We ablate the number of datasets used for pre-trai br" target="#b29">[30]</ref> model uses cooccurring words and negative sampling to learn word embeddings.</p><p>In computer vision, a large collection of work [15,</ref>17,</ref>50,</ref>59</ref>] learns self-supervised image representation by minimizing the distance between ns behind these graphs. To achieve this, we need to design proper self-supervised tasks and learning objectives for graph structured data. Inspired by the recent success of contrastive learning in CV [17,</ref>59]</ref> and NLP [9,</ref>30]</ref>, we propose to use instance di 34">[35]</ref> as our learning objective. Our choice of pre-training task and learning objective treats each instance as a distinct class of its own and learns to discriminate between these instances [17,</ref>59]</ref>. The promise is that it can output instance representations that are capable of capturing the similarities between ins
graph sampling. In random walk with restart sampling, the restart probability controls the radius of ego-network (i.e., r ) which GCC conducts data augmentation on. In this work, we follow Qiu et al. [42]</ref> to use 0.8 as the restart probability. The proposed GCC framework is flexible to other graph sampling algorithms, such as neighborhood sampling <ref type="bib ributions. In addition to the generalized positional embedding, we also add the one-hot encoding of vertex degrees [60]</ref> and the binary indicator of the ego vertex [42]</ref> as vertex features. After encoded by the graph encoder, the final d-dimensional output vectors are then normalized by their L2-Norm <ref type="bibr" target="#


.0"><head n="2.1">Vertex Similarity</head><p>Quantifying similarity of vertices in networks/graphs has been extensively studied in the past years. The goal of vertex similarity is to answer questions [26]</ref> like "How similar are these two vertices?" or "Which other vertices are most similar to these vertices?" The definition of similarity can be different in diff
hs.</p><p>Recent graph neural networks models, such as GCN [25]</ref>, GAT [54]</ref>, GraphSAGE [16,</ref>63]</ref> and MPNN [13]</ref>, leverage additional attributes as side information or supervised signals to learn representations which are
these instances. Specifically, there are three questions to answer for GCC such that it can learn the transferable structural patterns: (1)</ref> what are the instances? (2)</ref> what are the discrimination rules? And (3) how to encode the instances?</p><p>In GCC's pre-training stage, we propose to distinguish vertices according to their ive patterns based on domain knowledge. Examples include vertex degree, structural diversity [52]</ref>, structural hole [7]</ref>, k-core [2]</ref>, motif [5,</ref>32]</ref>, etc. Consequently, models of this genre, such as Struc2vec <ref type="bi
nto two groups -academic graphs and social graphs. As for academic graphs, we collect the Academia dataset from NetRep [44]</ref> as well as two DBLP datasets from SNAP [62]</ref> and NetRep [44]</ref>, respectively. As for social graphs, we collect Facebook and IMDB datasets from NetRep <ref type="bibr" t

>, motif [5,</ref>32]</ref>, etc. Consequently, models of this genre, such as Struc2vec [43]</ref> and RolX [18]</ref>, usually involve explicit featurization. The second line of research leverages the spectral graph theory to model structural similarity. A recent example is G nd v to be the inner product of their representations. Finally, by sorting the above scores, we use HITS@10 (top-10 accuracy) to measure the performance of different methods. We compare GCC with RolX [18]</ref>, Panther++ [66]</ref> and GraphWave [12]</ref>. We also provide random guess results for referen Table 7</ref>.</p><p>Code: https://github.com/weihua916/powerful-gnns.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.3 Top-k Similarity Search.</head><p>Random, RolX [18]</ref>, Panther++ [66]</ref> We obtainÂăthe experimental results for these baselines from Zhang et al. 
scratch. For example, for node classification on the US-Airport network, GCC pre-trained on the Facebook, IMDB, and DBLP graphs outperforms GraphWave [12]</ref>, ProNE [65]</ref> and Struc2vec [43]</ref> which are trained directly on the US-Airport graph, empirically demonstrating our hypothesis at the be extracted from OAG [64]</ref>. The labels indicate whether the h-index of the author is above or below the median.</p><p>Experimental results. We compare GCC with ProNE [65]</ref>, Graph-Wave [12]</ref>, and Struc2vec [43]</ref>. Table 2</ref failed to finish. We observed that the sampling strategy in Struc2vec takes up most of the time, as illustrated in the original paper.</p><p>Code: https://github.com/leoribeiro/struc2vec.</p><p>ProNE [65]</ref> We download the authors' official code and keep hyper-parameters as the same: (1) step = 10; (2) θ = 0.5; (3) µ = 0.2. The dimension size is set to 64. Code:
="bibr" target="#b19">(Liu et al., 2020)</ref>, e.g., anchor generation, rule-based training target assignment, non-maximum suppression (NMS) post-processing. They are not fully end-to-end. Recently, Carion et al. (2020)</ref> proposed DETR to eliminate the need for such hand-crafted components, and built the first fully end-to-end object detector, achieving very comp ls, N q = N k C, the complexity is dominated by the third term, as O(N q N k C). Thus, the multi-head attention module suffers from a quadratic complexity growth with the feature map size. DETR. DETR (Carion et al., 2020)</ref> is built upon the Transformer encoder-decoder architecture, combined with a set-based Hungarian loss that forces unique predictions for each g or deformable attentions by default. Parameters of the deformable Transformer encoder are shared among different feature levels. Other hyper-parameter setting and training strategy mainly follow DETR (Carion et al., 2020)</ref>, except that Focal Loss (Lin et al., 2017b)</ref> with loss weight of 2 is used for bounding box classification these modifications for a fair comparison, denoted as DETR-DC5 + . By default, models are trained for 50 epochs and the learning rate is decayed at the 40-th epoch by a factor of 0.1. Following DETR (Carion et al., 2020)</ref>, we train our models using Adam optimizer (Kingma &amp; Ba, 2015)</ref> with base learning rate of 2 × 10 −4 ,
>(Liu et al., 2018b)</ref> further adds an bottom-up path on the top of FPN. Kong et al. (2018)</ref> combines features from all scales by a global attention operation. Zhao et al. (2019)</ref> proposes a U-shape module to fuse multi-scale features. Recently, NAS-FPN (Ghiasi et al., 2019)</ref> and Auto-FPN
By using ResNeXt-101 with DCN (Zhu et al., 2019b)</ref>, the accuracy rises to 50.1 AP. With additional test-time augmentations, the proposed method achieves 52.3 AP.  (Tian et al., 2019)</ref> ResNeXt-101 44.7 64.1 48.4 27.6 47.5 55.6 ATSS (Zhang et al., 2020)</ref> ResNeXt-101 + DCN 50.7 68.9 56.3 33.2
p><p>Despite its interesting design and good performance, DETR has its own issues: (1) It requires much longer training epochs to converge than the existing object detectors. For example, on the COCO (Lin et al., 2014)</ref> benchmark, DETR needs 500 epochs to converge, which is around 10 to 20 times slower than Faster R-CNN (Ren et al. TR, where the region proposals are also generated by a vaiant of Deformable DETR, which are further fed into the decoder for iterative bounding box refinement.</p><p>Extensive experiments on the COCO (Lin et al., 2014)</ref> benchmark demonstrate the effectiveness of our approach. Compared with DETR, Deformable DETR can achieve better performance (especially on small pplied before feeding the region proposals to the second stage.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT</head><p>Dataset. We conduct experiments on COCO 2017 dataset (Lin et al., 2014)</ref>. Our models are trained on the train set, and evaluated on the val set and test-dev set.</p><p>Implementation Details. ImageNet <ref type="bibr"
fixed local windows. Most works (Liu et al., 2018a;</ref>Parmar et al., 2018;</ref>Child et al., 2019;</ref>Huang et al., 2019;</ref>Ho et al., 2019;</ref>Hu et al., 2019;</ref>Parmar e m. Although restricting the attention pattern to a local neighborhood can decrease the complexity, it loses global information. To compensate, Child et al. (2019)</ref>; Huang et al. (2019)</ref>; Ho et al. (2019)</ref> attend key elements at fixed intervals to significantly increase the receptive field on k ion.</p><p>In the image domain, the designs of efficient attention mechanism (e.g., Parmar et al. (2018)</ref>; Child et al. (2019)</ref>; Huang et al. (2019)</ref>; Ho et al. (2019)</ref>; Hu et al. (2019)</ref>; Pa
f> combines features from all scales by a global attention operation. Zhao et al. (2019)</ref> proposes a U-shape module to fuse multi-scale features. Recently, NAS-FPN (Ghiasi et al., 2019)</ref> and Auto-FPN (Xu et al., 2019)</ref> are proposed to automatically design cross-scale connections via neural ar
uch slower in implementation than traditional convolution with the same FLOPs (at least 3× slower), due to the intrinsic limitation in memory access patterns.</p><p>On the other hand, as discussed in Zhu et al. (2019a)</ref>, there are variants of convolution, such as deformable convolution (Dai et al., 2017;</ref>Zhu e

ower than traditional convolution.  (Lin et al., 2017a</ref>) 43.8 62.6 47.8 26.5 47.3 58.1 4 BiFPN (Tan et al., 2020) 43.9 62.5 47.7 25.6 47.4</ref>   (Xie et al., 2017)</ref>, our method achieves 48.7 AP and 49.0 AP without bells and whistles, respectively. By using ResNeXt-101 with DCN 
n, which hashes both the query and key elements to different bins. A similar idea is proposed by Roy et al. (2020)</ref>, where k-means finds out the most related keys. Tay et al. (2020a)</ref> learns block permutation for block-wise sparse attention.</p><p>The third category is to explore the low-rank property in self-attention. <ref t
get="#b22">Parmar et al., 2018;</ref>Child et al., 2019;</ref>Huang et al., 2019;</ref>Ho et al., 2019;</ref>Hu et al., 2019;</ref>Parmar et al., 2019;</ref>Qiu et al., 2019;</ref>Beltag 2">Parmar et al. (2018)</ref>; Child et al. (2019)</ref>; Huang et al. (2019)</ref>; Ho et al. (2019)</ref>; Hu et al. (2019)</ref>; Parmar et al. (2019)</ref>) are still limited to the first category. Despite the theoretically reduced complexity, type="bibr" target="#b23">Parmar et al. (2019)</ref>) are still limited to the first category. Despite the theoretically reduced complexity, Parmar et al. (2019)</ref>; Hu et al. (2019)</ref> admit such approaches are much slower in implementation than traditional convolution with the same FLOPs (at least 3× slower), due to the intrinsi to the second category. It only focuses on a small fixed set of sampling points predicted from the feature of query elements. Different from Parmar et al. (2019)</ref>; Hu et al. (2019)</ref>, deformable attention is just slightly slower than the traditional convolution under the same FLOPs.</p><p>Multi-scale Feature Representation for
et="#b24">(Wu et al., 2019;</ref>Cai et al., 2017)</ref>. Current works on Graph Convolutional Networks (GCNs) (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Gao et al., 2018;</ref>Huang et al., 2018;</ref>Chen e et relatively small datasets and thus the training proceeds in full batch. In order to scale GCNs to large graphs, layer sampling techniques (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Ying et al., 2018a;</ref>Chen et al., 2018a;</ref>Gao 6">Ying et al. (2018a)</ref>; Chen et al. (2018a)</ref> ensure that only a small number of neighbors (typically from 2 to 50) are selected by one node in the next layer. Chen et al. (2018b)</ref> and Huang et al. (2018)</ref> further propose samplers to restrict the neighbor expansion factor to 1, by ensurin es us to design other samplers, which are presented in Section 3.4.</p><p>Remark We can also apply the above edge sampler to perform layer sampling. Under the independent layer sampling assumption of Chen et al. (2018b)</ref>, one would sample a connection u ( ) , v ( +1)  with probability p</p><formula xml:id="formula_16">( ) u,v ∝ 1 deg(u) + 1 deg(v) .</formula><p>F . (2017)</ref>; Ying et al. (2018a)</ref>; Chen et al. (2018a)</ref>. Point (2) is due to the better interlayer connectivity compared with Chen et al. (2018b)</ref>, and unbiased minibatch estimator compared with Chiang et al. (2019)</ref>. Point (3) is due to the simple and tri er restricts neighborhood size by requiring only two support nodes in the previous layer. The idea is to use the historical activations in the previous layer to avoid redundant re-evaluation. FastGCN (Chen et al., 2018b)</ref> performs sampling from another perspective. Instead of tracking down the inter-layer connections, node sampling is performed independently for ‡ . We compare with six baselines: 1. vanilla GCN (Kipf &amp; Welling, 2016)</ref>, 2. GraphSAGE (Hamilton et al., 2017)</ref>, 3. FastGCN (Chen et al., 2018b)</ref>, 4. S-GCN (Chen et al., 2018a)</ref>, 5. AS-GCN (Huang et al., 2018)</ref>, and 6. complete multi-layer GCN is difficult due to non-linear activations. Thus, we analyze the embedding of each layer independently. This is similar to the treatment of layers independently by prior work (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>. Consider a layer-( + 1) node v and a layernode u. If v is sampled (i.e., v ∈ V s ), we "#b25">(Xu et al., 2018)</ref>: since our GCNs constructed during training are complete, applying skip connections to GraphSAINT is straightforward. On the other hand, for some layer sampling methods (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>, extra modification to their samplers is required, since the jumping knowledge architec
such as classification and clustering (Wu et al., 2019;</ref>Cai et al., 2017)</ref>. Current works on Graph Convolutional Networks (GCNs) (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Gao et al., 2018;</ref>Hu h localized filters based on Chebyshev expansion. They target relatively small datasets and thus the training proceeds in full batch. In order to scale GCNs to large graphs, layer sampling techniques (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Ying et al., 2018a;</ref> es (and thus the training time) potentially grows exponentially with the GCN depth. To mitigate such "neighbor explosion", state-of-the-art methods use various layer sampling techniques. The works by Hamilton et al. (2017)</ref>; Ying et al. (2018a)</ref>; Chen et al. (2018a)</ref> ensure that only a small n hbors. It enforces a pre-defined budget on the sample size, so as to bound the minibatch computation complexity. Ying et al. (2018a)</ref> enhances the layer sampler of Hamilton et al. (2017)</ref> by introducing an importance score to each neighbor. The algorithm presumably leads to less information loss due to weighted aggregation. S-G /p><p>Comparison GraphSAINT enjoys: 1. high scalability and efficiency, 2. high accuracy, and 3. low training complexity. Point (1) is due to the significantly reduced neighborhood size compared with Hamilton et al. (2017)</ref>; Ying et al. (2018a)</ref>; Chen et al. (2018a)</ref>. Point (2) is due to the b 1 :</head><label>1</label><figDesc>Figure 1: GraphSAINT training algorithm</figDesc></figure> <figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>2), sinceHamilton et al. (2017)</ref> andChen et al. (2018a)</ref> report accuracy for this version in their original papers. We use the large versio atches. 3. Propagate forward and backward among the sampled GCN. Steps (2) and (3) proceed iteratively to update the weights via stochastic gradient descent. The layer sampling algorithm of GraphSAGE (Hamilton et al., 2017)</ref> performs uniform node sampling on the previous layer neighbors. It enforces a pre-defined budget on the sample size, so as to bound the mini s significant accuracy improvement on GCNs with more than two layers. Note, however, that JK-net (Xu et al., 2018)</ref> follows the same sampling strategy as GraphSAGE (Hamilton et al., 2017)</ref>. Thus, its training cost is high due to neighbor explosion. In addition, high order graph convolutional layers <ref type="bibr" target="#b31 d under inductive and transductive settings. While GraphSAINT is applicable to both, in this paper, we focus on inductive learning. It has been shown that inductive learning is especially challenging (Hamilton et al., 2017)</ref> -during training, neither attributes nor connections of the test nodes are present. Thus, an inductive model has to generalize to completely plits. Appendix C.2 includes further details. We open source GraphSAINT ‡ . We compare with six baselines: 1. vanilla GCN (Kipf &amp; Welling, 2016)</ref>, 2. GraphSAGE (Hamilton et al., 2017)</ref>, 3. FastGCN (Chen et al., 2018b)</ref>, 4. S-GCN (Chen et al., 2018a)</ref>, 5.
in both accuracy and training time on five large graphs, and achieves new state-of-the-art F1 scores for PPI (0.995) and Reddit (0.970). * Equal contribution * The skip-connection design proposed by Huang et al. (2018)</ref> does not have such "subset" requirement, and thus is compatible with both graph sampling and layer sampling based methods.</p><p>† When applyin r sampling based methods.</p><p>† When applying GraphSAINT to GAT (Veličković et al., 2017), we remove the softmax step which normalizes attention values within the same neighborhood, as suggested by Huang et al. (2018)</ref>. See Appendix C.3.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1 Chen et al. (2018a)</ref> ensure that only a small number of neighbors (typically from 2 to 50) are selected by one node in the next layer. Chen et al. (2018b)</ref> and Huang et al. (2018)</ref> further propose samplers to restrict the neighbor expansion factor to 1, by ensuring a fixed sample size in all layers. While these methods sig for each layer. It applies importance sampling to reduce variance, and results in constant sample size in all layers. However, the minibatches potentially become too sparse to achieve high accuracy. Huang et al. (2018)</ref> improves FastGCN by an additional sampling neural network. It ensures high accuracy, since sampling is conditioned on the selected nodes in the ed minibatch estimator compared with Chiang et al. (2019)</ref>. Point (3) is due to the simple and trivially parallelizable pre-processing compared with the sampling of Huang et al. (2018)</ref> and clustering of Chiang et al. (2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPE eighbors of v. We make such modification since under the minibatch setting, node v does not see all its neighbors in the training graph. The removal of softmax is also seen in the attention design of Huang et al. (2018)</ref>. Note that during the minibatch training, GAT-SAINT further applies another edge coefficient on top of attention for aggregator normalization.< ph Convolutional Networks (GCNs) (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Gao et al., 2018;</ref>Huang et al., 2018;</ref>Chen et al., 2018a)</ref> mostly focus on shallow models (2 layers) on relatively small graphs. Scaling GCNs to la rget="#b4">Chen et al., 2018b;</ref>Ying et al., 2018a;</ref>Chen et al., 2018a;</ref>Gao et al., 2018;</ref>Huang et al., 2018)</ref> have been proposed for efficient minibatch training. All of them follow the three meta steps: 1. Construct a complete GCN on the full training activations. Thus, we analyze the embedding of each layer independently. This is similar to the treatment of layers independently by prior work (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>. Consider a layer-( + 1) node v and a layernode u. If v is sampled (i.e., v ∈ V s ), we can compute the aggregated feature of v as:</p><formula ed during training are complete, applying skip connections to GraphSAINT is straightforward. On the other hand, for some layer sampling methods (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>, extra modification to their samplers is required, since the jumping knowledge architecture requires layersamples to be a subset of layer-( − 1 pe="bibr" target="#b9">(Hamilton et al., 2017)</ref>, 3. FastGCN (Chen et al., 2018b)</ref>, 4. S-GCN (Chen et al., 2018a)</ref>, 5. AS-GCN (Huang et al., 2018)</ref>, and 6. ClusterGCN (Chiang et al., 2019)</ref>. All baselines are executed with their officially released code (
2017;</ref>Lee et al., 2018;</ref>Abu-El-Haija et al., 2019)</ref> or even more complicated networks for the task of graph classification (Ying et al., 2018b)</ref>, we replace the full adjacency matrix A with the (normalized) one for the subgraph A s to perform layer propagation.</p><p>Comparison GraphSAI
in both accuracy and training time on five large graphs, and achieves new state-of-the-art F1 scores for PPI (0.995) and Reddit (0.970). * Equal contribution * The skip-connection design proposed by Huang et al. (2018)</ref> does not have such "subset" requirement, and thus is compatible with both graph sampling and layer sampling based methods.</p><p>† When applyin r sampling based methods.</p><p>† When applying GraphSAINT to GAT (Veličković et al., 2017), we remove the softmax step which normalizes attention values within the same neighborhood, as suggested by Huang et al. (2018)</ref>. See Appendix C.3.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1 Chen et al. (2018a)</ref> ensure that only a small number of neighbors (typically from 2 to 50) are selected by one node in the next layer. Chen et al. (2018b)</ref> and Huang et al. (2018)</ref> further propose samplers to restrict the neighbor expansion factor to 1, by ensuring a fixed sample size in all layers. While these methods sig for each layer. It applies importance sampling to reduce variance, and results in constant sample size in all layers. However, the minibatches potentially become too sparse to achieve high accuracy. Huang et al. (2018)</ref> improves FastGCN by an additional sampling neural network. It ensures high accuracy, since sampling is conditioned on the selected nodes in the ed minibatch estimator compared with Chiang et al. (2019)</ref>. Point (3) is due to the simple and trivially parallelizable pre-processing compared with the sampling of Huang et al. (2018)</ref> and clustering of Chiang et al. (2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPE eighbors of v. We make such modification since under the minibatch setting, node v does not see all its neighbors in the training graph. The removal of softmax is also seen in the attention design of Huang et al. (2018)</ref>. Note that during the minibatch training, GAT-SAINT further applies another edge coefficient on top of attention for aggregator normalization.< ph Convolutional Networks (GCNs) (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Gao et al., 2018;</ref>Huang et al., 2018;</ref>Chen et al., 2018a)</ref> mostly focus on shallow models (2 layers) on relatively small graphs. Scaling GCNs to la rget="#b4">Chen et al., 2018b;</ref>Ying et al., 2018a;</ref>Chen et al., 2018a;</ref>Gao et al., 2018;</ref>Huang et al., 2018)</ref> have been proposed for efficient minibatch training. All of them follow the three meta steps: 1. Construct a complete GCN on the full training activations. Thus, we analyze the embedding of each layer independently. This is similar to the treatment of layers independently by prior work (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>. Consider a layer-( + 1) node v and a layernode u. If v is sampled (i.e., v ∈ V s ), we can compute the aggregated feature of v as:</p><formula ed during training are complete, applying skip connections to GraphSAINT is straightforward. On the other hand, for some layer sampling methods (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>, extra modification to their samplers is required, since the jumping knowledge architecture requires layersamples to be a subset of layer-( − 1 pe="bibr" target="#b9">(Hamilton et al., 2017)</ref>, 3. FastGCN (Chen et al., 2018b)</ref>, 4. S-GCN (Chen et al., 2018a)</ref>, 5. AS-GCN (Huang et al., 2018)</ref>, and 6. ClusterGCN (Chiang et al., 2019)</ref>. All baselines are executed with their officially released code (
n improving model capacity. Applying attention on graphs, the architectures of Veličković et al. (2017)</ref>; Zhang et al. (2018)</ref>; Lu et al. (2019)</ref> better capture neighbor features by dynamically adjusting edge weights. Klicpera et al. (2018)</ref> combines PageR
t="#b2">Cai et al., 2017)</ref>. Current works on Graph Convolutional Networks (GCNs) (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Gao et al., 2018;</ref>Huang et al., 2018;</ref>Chen et al., 2018a)</ref> mostly focus on shallow models (2 l #b9">(Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Ying et al., 2018a;</ref>Chen et al., 2018a;</ref>Gao et al., 2018;</ref>Huang et al., 2018)</ref> have been proposed for efficient minibatch training. All of them follow the three meta ste

in both accuracy and training time on five large graphs, and achieves new state-of-the-art F1 scores for PPI (0.995) and Reddit (0.970). * Equal contribution * The skip-connection design proposed by Huang et al. (2018)</ref> does not have such "subset" requirement, and thus is compatible with both graph sampling and layer sampling based methods.</p><p>† When applyin r sampling based methods.</p><p>† When applying GraphSAINT to GAT (Veličković et al., 2017), we remove the softmax step which normalizes attention values within the same neighborhood, as suggested by Huang et al. (2018)</ref>. See Appendix C.3.</p></div> 			</abstract> 		</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1 Chen et al. (2018a)</ref> ensure that only a small number of neighbors (typically from 2 to 50) are selected by one node in the next layer. Chen et al. (2018b)</ref> and Huang et al. (2018)</ref> further propose samplers to restrict the neighbor expansion factor to 1, by ensuring a fixed sample size in all layers. While these methods sig for each layer. It applies importance sampling to reduce variance, and results in constant sample size in all layers. However, the minibatches potentially become too sparse to achieve high accuracy. Huang et al. (2018)</ref> improves FastGCN by an additional sampling neural network. It ensures high accuracy, since sampling is conditioned on the selected nodes in the ed minibatch estimator compared with Chiang et al. (2019)</ref>. Point (3) is due to the simple and trivially parallelizable pre-processing compared with the sampling of Huang et al. (2018)</ref> and clustering of Chiang et al. (2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPE eighbors of v. We make such modification since under the minibatch setting, node v does not see all its neighbors in the training graph. The removal of softmax is also seen in the attention design of Huang et al. (2018)</ref>. Note that during the minibatch training, GAT-SAINT further applies another edge coefficient on top of attention for aggregator normalization.< ph Convolutional Networks (GCNs) (Hamilton et al., 2017;</ref>Chen et al., 2018b;</ref>Gao et al., 2018;</ref>Huang et al., 2018;</ref>Chen et al., 2018a)</ref> mostly focus on shallow models (2 layers) on relatively small graphs. Scaling GCNs to la rget="#b4">Chen et al., 2018b;</ref>Ying et al., 2018a;</ref>Chen et al., 2018a;</ref>Gao et al., 2018;</ref>Huang et al., 2018)</ref> have been proposed for efficient minibatch training. All of them follow the three meta steps: 1. Construct a complete GCN on the full training activations. Thus, we analyze the embedding of each layer independently. This is similar to the treatment of layers independently by prior work (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>. Consider a layer-( + 1) node v and a layernode u. If v is sampled (i.e., v ∈ V s ), we can compute the aggregated feature of v as:</p><formula ed during training are complete, applying skip connections to GraphSAINT is straightforward. On the other hand, for some layer sampling methods (Chen et al., 2018b;</ref>Huang et al., 2018)</ref>, extra modification to their samplers is required, since the jumping knowledge architecture requires layersamples to be a subset of layer-( − 1 pe="bibr" target="#b9">(Hamilton et al., 2017)</ref>, 3. FastGCN (Chen et al., 2018b)</ref>, 4. S-GCN (Chen et al., 2018a)</ref>, 5. AS-GCN (Huang et al., 2018)</ref>, and 6. ClusterGCN (Chiang et al., 2019)</ref>. All baselines are executed with their officially released code (
2017;</ref>Lee et al., 2018;</ref>Abu-El-Haija et al., 2019)</ref> or even more complicated networks for the task of graph classification (Ying et al., 2018b)</ref>, we replace the full adjacency matrix A with the (normalized) one for the subgraph A s to perform layer propagation.</p><p>Comparison GraphSAI
n improving model capacity. Applying attention on graphs, the architectures of Veličković et al. (2017)</ref>; Zhang et al. (2018)</ref>; Lu et al. (2019)</ref> better capture neighbor features by dynamically adjusting edge weights. Klicpera et al. (2018)</ref> combines PageR
</profileDesc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Self-attention-based architectures, in particular Transformers (Vaswani et al., 2017)</ref>, have become the model of choice in natural language processing (NLP). The dominant approach is to pre-train on a large text corpus and then rain Transformers instead of ResNet-based models used in prior works.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>In model design we follow the original Transformer (Vaswani et al., 2017)</ref> as closely as possible. An advantage of this intentionally simple setup is that scalable NLP Transformer architectures -and their efficient icant performance gains from using more advanced 2D-aware position embeddings (Appendix D.3). The resulting sequence of embedding vectors serves as input to the encoder.</p><p>The Transformer encoder (Vaswani et al., 2017)</ref> consists of alternating layers of multiheaded selfattention (MSA, see Appendix A) and MLP blocks (Eq. 2, 3). Layernorm (LN) is applied befor 72% on ImageNet-ReaL, 94.55% on CIFAR-100, and 77.63% on the VTAB suite of 19 tasks.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Transformers were proposed by Vaswani et al. (2017)</ref> for machine translation, and have since become the state of the art method in many NLP tasks. Large Transformer-based models are often pre-tr Raffel for useful discussions.</p></div> 			</div>  			<div type="annex"> <div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A MULTIHEAD SELF-ATTENTION</head><p>Standard qkv self-attention (SA, Vaswani et al. (2017)</ref>) is a popular building block for neural architectures. For each element in an input sequence z ∈ R N ×D , we compute a weighted sum over all

(Child et al., 2019)</ref> employ scalable approximations to global self-attention in order to be applicable to images. An alternative way to scale attention is to apply it in blocks of varying sizes (Weissenborn et al., 2019)</ref>, in the extreme case only along individual axes (Ho et al., 2019;</ref>Wan
augmenting feature maps for image classification (Bello et al., 2019)</ref> or by further processing the output of a CNN using self-attention, e.g. for object detection (Hu et al., 2018;</ref>Carion et al., 2020)</ref>, video processing (Wang et al., 2018;</ref><ref type="bibr

ject detection (Hu et al., 2018;</ref>Carion et al., 2020)</ref>, video processing (Wang et al., 2018;</ref>Sun et al., 2019)</ref>, image classification (Wu et al., 2020)</ref>, unsupervised object discovery (Locat
image classification (Wu et al., 2020)</ref>, unsupervised object discovery (Locatello et al., 2020)</ref>, or unified text-vision tasks (Chen et al., 2020c;</ref>Lu et al., 2019;</ref>Li et al., 2019)</ref>.</p><p>We are not aware of prior appl
adratic cost in the number of pixels, this does not scale to realistic input sizes. Thus, to apply Transformers in the context of image processing, several approximations have been tried in the past: Parmar et al. (2018)</ref> applied the self-attention only in local neighborhoods for each query pixel instead of globally. Such local multi-head dot-product self attent
effectively on modern hardware accelerators due to the use of specialized attention patterns. Therefore, in large-scale image recognition, classic ResNetlike architectures are still state of the art (Mahajan et al., 2018;</ref>Xie et al., 2020;</ref>Kolesnikov et al., 2020)</ref>.</p><p>Inspired by the Tr ction of papers that explore image recognition at larger scales than the standard ImageNet dataset. The use of additional data sources allows to achieve state-ofthe-art results on standard benchmarks (Mahajan et al., 2018;</ref>Touvron et al., 2019;</ref>Xie et al., 2020)</ref>. Moreover, <ref type="bibr"
size, with over 100B parameters. With the models and datasets growing, there is still no sign of saturating performance.</p><p>In computer vision, however, convolutional architectures remain dominant (LeCun et al., 1989;</ref>Krizhevsky et al., 2012;</ref>He et al., 2016)</ref>. Inspired by NLP successes, MLP(LN(z )) + z , = 1 . . . L (3) y = LN(z 0 L )<label>(4)</label></formula><p>Hybrid Architecture. As an alternative to raw image patches, the input sequence can be formed from feature maps of a CNN (LeCun et al., 1989)</ref>. In this hybrid model, the patch embedding projection E (Eq. 1) is applied to patches extracted from a CNN feature map. As a special case, the

b2">(Bolukbasi et al., 2016;</ref>Caliskan et al., 2017;</ref>Garg et al., 2017;</ref>May et al., 2010;</ref>Zhao et al., 2018;</ref>Rudinger et al., 2017)</ref>. Models that have learnt representations that are biased against historically disadva
ood performance on a range of NLP tasks with ALBERT generally outperforming RoBERTa by a small margin, and BERT being significantly behind both (Wang et al., 2018;</ref>Lai et al., 2017;</ref>Rajpurkar et al., 2018)</ref>. For these models we use the Transformers library (Wol
jections onto the gender-related subspace. However, follow-up work by Gonen and Goldberg (2019)</ref> shows that this method only hides the bias and does not remove it. Liang et al. (2020)</ref> introduce a debiasing algorithm and they report lower bias scores on the SEAT while maintaining downstream task performance on the GLUE benchma
mples from the dataset in Table 1</ref>.</p><p>We evaluate masked language models (MLMs) that have been successful at pushing the state-ofthe-art on a range of tasks (Wang et al., 2018</ref>(Wang et al., , 2019))</ref>.</p><p>Our findings agree with prior work and show that these models do express social biases. We g b14">(Lan et al., 2020)</ref>. These models have shown good performance on a range of NLP tasks with ALBERT generally outperforming RoBERTa by a small margin, and BERT being significantly behind both (Wang et al., 2018;</ref>Lai et al., 2017;</ref>Rajpurkar et al., 2018)</ref>. For these models we use the f type="bibr" target="#b15">Liang et al. (2020)</ref> introduce a debiasing algorithm and they report lower bias scores on the SEAT while maintaining downstream task performance on the GLUE benchmark (Wang et al., 2018)</ref>.</p><p>Discussing Bias Upon surveying 146 NLP papers that analyze or mitigate bias, Blodgett et al. (2020)</ref>
jections onto the gender-related subspace. However, follow-up work by Gonen and Goldberg (2019)</ref> shows that this method only hides the bias and does not remove it. Liang et al. (2020)</ref> introduce a debiasing algorithm and they report lower bias scores on the SEAT while maintaining downstream task performance on the GLUE benchma
is similar to the data collection procedure for WinoGrande (Sakaguchi et al., 2019)</ref>. The prompts are either premise sentences taken from MultiNLI's fiction genre (Williams et al., 2018)</ref> or 2-3 sentence story openings taken from examples in ROCStories (Mostafazadeh et al., 2016)</ref>. To encou </div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Speech Situation</head><p>For each example, a crowdworker wrote standalone sentences inspired by a prompt that was drawn from either MultiNLI (Williams et al., 2018)</ref> or ROCStories (Mostafazadeh et al., 2016)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A.
jections onto the gender-related subspace. However, follow-up work by Gonen and Goldberg (2019)</ref> shows that this method only hides the bias and does not remove it. Liang et al. (2020)</ref> introduce a debiasing algorithm and they report lower bias scores on the SEAT while maintaining downstream task performance on the GLUE benchma
cial biases. These language models, and embeddings extracted from them, have been shown to * Equal contribution. learn and use these biases (Bolukbasi et al., 2016;</ref>Caliskan et al., 2017;</ref>Garg et al., 2017;</ref>May et al., 2010;</ref>Zha ing the target provided.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Measuring Bias Bias in natural language processing has gained visibility in recent years. Caliskan et al. (2017)</ref> introduce a dataset for evaluating gender bias in word embeddings. They find that GloVe embeddings (Pennington
ed from them, have been shown to * Equal contribution. learn and use these biases (Bolukbasi et al., 2016;</ref>Caliskan et al., 2017;</ref>Garg et al., 2017;</ref>May et al., 2010;</ref>Zhao et al., 2018;</ref>Ruding
ood performance on a range of NLP tasks with ALBERT generally outperforming RoBERTa by a small margin, and BERT being significantly behind both (Wang et al., 2018;</ref>Lai et al., 2017;</ref>Rajpurkar et al., 2018)</ref>. For these models we use the Transformers library (Wol
ef type="bibr" target="#b2">Bolukbasi et al. (2016)</ref> propose reducing gender bias in word embeddings by minimizing linear projections onto the gender-related subspace. However, follow-up work by Gonen and Goldberg (2019)</ref> shows that this method only hides the bias and does not remove it. Liang et al. (2020)</ref> introduce a d
> demonstrate a tendency to aggregate features only among foreground objects or among pixels with similar semantics.</p><p>Sharing a similar philosophy, there have been works on contrastive attention [31,</ref>42]</ref>. MGCAM [31]</ref> uses the contrastive feature between persons and backgrounds, but it els with similar semantics.</p><p>Sharing a similar philosophy, there have been works on contrastive attention [31,</ref>42]</ref>. MGCAM [31]</ref> uses the contrastive feature between persons and backgrounds, but it requires extra mask supervision for persons. C-MWP [42]</r as in NL [36]</ref>, ACM explicitly uses direct comparison procedure for context modeling; instead of using extra supervision to localize regions to compare as in MGCAM [31]</ref>, ACM automatically learns to focus on meaningful regions to compare. Importantly, the efficacy of our explicit and data-driven contrastive modeling is shown b
t treatable stage. However, the problem lies in the heavy workload of reading chest X-rays. Radiologists usually read tens or hundreds of X-rays every day. Several studies regarding radiologic errors [28,</ref>9]</ref> have reported that 20-30% of exams are misdiagnosed. To compensate for this shortcoming, many hospitals equip radiologis
="#b18">19,</ref>3]</ref>, there has been a long line of works that find thoracic diseases from chest X-rays using deep learning [41,</ref>12,</ref>23,</ref>29]</ref>. Most of the works attempt to classify thoracic diseases, and some of the works target="#b36">[37]</ref> dataset is the first largescale dataset on 14 common diseases in chest X-rays. It is used as a benchmark dataset in previous studies [41,</ref>12,</ref>29,</ref>6,</ref>25,</ref>23,</ref><r been conducted on top of them to cover various issues of recognition task in the chest X-ray modality.</p><p>To address the issue of localizing diseases using only class-level labels, Guendel et al. [12]</ref> propose an auxiliary localization task where the ground truth of the location of the diseases is extracted from the text report. Other works use attention mod
iseases in chest X-rays. It is used as a benchmark dataset in previous studies [41,</ref>12,</ref>29,</ref>6,</ref>25,</ref>23,</ref>32,</ref>10]</ref>. T
tures only among foreground objects or among pixels with similar semantics.</p><p>Sharing a similar philosophy, there have been works on contrastive attention [31,</ref>42]</ref>. MGCAM [31]</ref> uses the contrastive feature between persons and backgrounds, but it requires extra mask supervision for perso "bibr" target="#b41">42]</ref>. MGCAM [31]</ref> uses the contrastive feature between persons and backgrounds, but it requires extra mask supervision for persons. C-MWP [42]</ref> is a technique for generating more accurate localization maps in a contrastive manner, but it is not a learning-based method and uses pretrained models.</p><p
Under the Receiver Operating Characteristics (AUC-ROC) for classification performances.</p><p>For localization tasks, we report the jackknife free-response receiver operating characteristic (JAFROC) [5]</ref> for localization performances. JAFROC is a metric widely used for tracking localization performance in radiology. All chest X-ray tasks are a weakly-supervised
ortcoming, many hospitals equip radiologists with computer-aided diagnosis systems. The recent developments of medical image recognition models have shown potentials for growth in diagnostic accuracy [26]</ref>.</p><p>With the recent presence of large-scale chest X-ray datasets [37,</ref>18,</ref><ref type
ases is extracted from the text report. Other works use attention module to indirectly align the class-level prediction with the potentially abnormal location [35,</ref>32,</ref>10]</ref> without the text reports on the location of the disease. Some works observe that although getting annotations for chest f>12,</ref>29,</ref>6,</ref>25,</ref>23,</ref>32,</ref>10]</ref>. The dataset contains 112,120 images from 30,805 unique patients. Image-level labels are mined from imageattached report
aid attention to how radiology residents are trained, which led to the following question: why don't we model the way radiologists read X-rays? When radiologists read chest X-rays, they compare zones [1]</ref>, paying close attention to any asymmetry between left and right lungs, or any changes between semantically related regions, that are likely to be due to disease
="#b18">19,</ref>3]</ref>, there has been a long line of works that find thoracic diseases from chest X-rays using deep learning [41,</ref>12,</ref>23,</ref>29]</ref>. Most of the works attempt to classify thoracic diseases, and some of the works target="#b36">[37]</ref> dataset is the first largescale dataset on 14 common diseases in chest X-rays. It is used as a benchmark dataset in previous studies [41,</ref>12,</ref>29,</ref>6,</ref>25,</ref>23,</ref><r been conducted on top of them to cover various issues of recognition task in the chest X-ray modality.</p><p>To address the issue of localizing diseases using only class-level labels, Guendel et al. [12]</ref> propose an auxiliary localization task where the ground truth of the location of the diseases is extracted from the text report. Other works use attention mod
mentation. The experimental results show that ACM outperforms other context-related modules, in both chest X-ray tasks and natural image tasks.</p><p>Experimental Setting Following the previous study [2]</ref> on multi-label classification with chest X-Rays, we mainly adopt ResNet-50 as our backbone network.</p><p>To show generality, we sometimes adopt DenseNet <ref t

6">(Courbariaux et al., 2016;</ref>Zhou et al., 2016;</ref>Cai et al., 2017;</ref>Hubara et al., 2016;</ref>Tang et al., 2017;</ref>Dong et al., 2017;</ref>Fromm et al., 2018;</ref>Choi e
braries exist for bitserial operations and developing one from scratch would be a challenging engineering effort that is outside the scope of most research projects. Recently, projects such as Halide (Ragan-Kelley et al., 2013)</ref> and TVM (Chen et al., 2018a)</ref> have arisen that attempt to simplify the process of creating optimized
dels and explore the impact of its various optimizations.</p><p>Most previous work in binarization has been evaluated on AlexNet (Krizhevsky et al., 2012)</ref>, VGGNet (He et al., 2015)</ref>, and Resnets (He et al., 2016)</ref>. To directly compare against these results, we train these three models with
braries exist for bitserial operations and developing one from scratch would be a challenging engineering effort that is outside the scope of most research projects. Recently, projects such as Halide (Ragan-Kelley et al., 2013)</ref> and TVM (Chen et al., 2018a)</ref> have arisen that attempt to simplify the process of creating optimized
ops.} 9: l k = clip(q k , 0, 2 N − 1) {HWF ops.} 10: p k = Pooling(l k ) {HWF ops.} 11: a k = BitPack(p k ) {At least 3HW F ops.} 12: end for 13: Y = BinaryDense(a L )</formula><p>in both TensorFlow (Abadi et al., 2016)</ref> and TVM (Chen et al., 2018a)</ref>. We use TensorFlow for training binary networks and TVM for compiling efficien
t binary models promise significant performance benefits, the accuracy they have been shown capable of achieving on challenging datasets like ImageNet has been underwhelming. For example, the AlexNet (Krizhevsky et al., 2012)</ref> based BNN used by Courbariaux et al. (2016)</ref> was only able to reach a top-1 accuracy of 27.9% when tra on results.</p><p>2. Show that Riptide can produce high speed binary models and explore the impact of its various optimizations.</p><p>Most previous work in binarization has been evaluated on AlexNet (Krizhevsky et al., 2012)</ref>, VGGNet (He et al., 2015)</ref>, and Resnets (He et al., 2016)</ref>. To di
ntations and execute dramatically fewer operations by converting operations on large floating point vectors into "bitserial" versions that apply bitwise operations on packed bit vectors. For instance (Rastegari et al., 2016)</ref> report convolution layers that use 58× fewer operations and 32 × less memory than the standard floating point versions. This increased eff ignificant accuracy loss that comes with network binarization has been the focus of research in the space, with most papers introducing modifications to the core algorithm or new training techniques. Rastegari et al. (2016)</ref> introduced XNOR-Net, which improved the accuracy of single bit binary models by adding the WeightScale function on line 6 of Algorithm 2. T
previous work in binarization has been evaluated on AlexNet (Krizhevsky et al., 2012)</ref>, VGGNet (He et al., 2015)</ref>, and Resnets (He et al., 2016)</ref>. To directly compare against these results, we train these three models with multiple bitwidth and polarity configurations. In these comparisons,
previous work in binarization has been evaluated on AlexNet (Krizhevsky et al., 2012)</ref>, VGGNet (He et al., 2015)</ref>, and Resnets (He et al., 2016)</ref>. To directly compare against these results, we train these three models with multiple bitwidth and polarity configurations. In these comparisons,
previous work in binarization has been evaluated on AlexNet (Krizhevsky et al., 2012)</ref>, VGGNet (He et al., 2015)</ref>, and Resnets (He et al., 2016)</ref>. To directly compare against these results, we train these three models with multiple bitwidth and polarity configurations. In these comparisons,

h areas such as text classification, object recognition and image classification etc. In this active research area, the studies using deep learning approaches mostly focus on dimensionality reduction [2]</ref>- [6]</ref> and anomaly-based intrusion detection [7]</ref>- [10]</ref>
ima and discover better solutions to the optimization process [64]</ref>. The additional parameters used in VAE configuration are as follow. Leaky Rectified Linear Unit [68]</ref> is used in hidden layers as activation function. It is preferred over sigmoid or tanh since it resolves the ''dying ReLU'' problem of the vanilla ReLU and the
ula" target="#formula_0">1</ref>) and (2), respectively. In this context, ? is the nonlinear transformation function and b and W are called the bias and the weight of the neural network, respectively [42]</ref>.</p><formula xml:id="formula_0">h = ? (W xh x + b xh )<label>(1)</label></formula><formula xml:id="formula_1">z = ? (W hx h + b hx ) (2) r = x -z<label>(3)</l Autoencoder (VAE) [43]</ref> is defined as a directed probabilistic graphical model, which is obtained by approximation of an artificial neural network to its posterior [42]</ref>. In VAE, the latent variable z in which the generative process begins, is the highest layer of the graphical model. The complicated procedure of data generati obtained by summing of the marginal likelihood of distinct data points in (4). Equation ( 5</ref>) is obtained if the marginal likelihood of distinct data points are reformulated [42]</ref>. In Equation ( 7</ref>), D KL is the Kullback-Leibler divergence between the approximate posterior and the prior of the latent variable z. ) vary according to the nature of the data. More specifically, multivariate Gaussian distribution is applied when the input data is in continuous form. If it is binary, Bernoulli distribution is used [42]</ref>. The flow chart of VAE training algorithm can be illustrated as in Fig. 4</ref>. The training of VAE is executed by using t ">[42]</ref>. The flow chart of VAE training algorithm can be illustrated as in Fig. 4</ref>. The training of VAE is executed by using the backpropagation algorithm [42]</ref>. The second term on (7) is computed using Monte Carlo gradient techniques in conjunction with a reparameterization approach, which employs a random variable f supposed to guarantee that z follows the distribution of q ? (z|x).</p><p>The anomaly detection task is performed in a semisupervised way, meaning that just normal data examples are used to train VAE [42]</ref>. The probabilistic decoder g ? and encoder f ? both parameterizes an isotropic normal distribution in the original input variable space and the latent variabl to the probability of the data being produced from certain latent variables taken out of the approximate posterior distribution.</p><p>RP computed in VAE differs from RE calculated in AE in some ways [42]</ref>. First of all, while latent variables are expressed as deterministic mappings in AE, they are defined as stochastic variables in VAE. The variability of the l nh [64]</ref>. Gaussian reconstruction distribution is used with hyperbolic tangent (tanh) pzx activation function because the type of data being modeled is real-valued [42]</ref>. In the additional parameters used in AE configuration, which are commonly used and constitute the basis of the studies such as <ref type="bibr" target="#b40"
d. Behaviors of users are modelled by ANNs to find a way to detect anomalies. Numerous ANNs used for anomaly-based IDSs were discussed by Beghdad [17]</ref>. Sui et al. [18]</ref> proposed an anomaly detection system that used a back-propagation neural network classifier and statistical feature vectors. They considered three scenarios o
e way than that of the RE. </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>C. ONE CLASS SUPPORT VECTOR MACHINE</head><p>Support Vector Machine (SVM) was originally suggested by Boser et al. [44]</ref>. The primary objective of SVM is to find out the best machine for a given dataset. SVM accomplishes this objective by maximizing the correctness of the machin
NSL-KDD dataset [13]</ref>, which is a revised version of KDDCUP99, is used for evaluating the methods proposed in the studies [3]</ref>, [4]</ref>, [6]</ref>- [8]</ref>. Main drawbacks of these studies could be listed as follows: a) These studies
ve class example after it is ordered by its classification probabilities. The AUC values are always bounded between 0 and 1. If AUC value is less than 0.5, it means that the classifier is unrealistic [54]</ref>. A rough classifying system can serve as a guidance to the test accuracy as follows [55]</ref>: i) Excellent (0.90-1), ii) Good
valuation of the proposed method should be performed using an appropriate metric. For a binary classification, the results can be separated into four groups [49]</ref>, [50]</ref> </p><p>Receiver Operating Characteristics (ROC): The ROC curve [51]</ref>, [52]</ref> is utilize
nsition point of each sub-protocol'' through flow features.</p><p>Decision Trees (DTs) generate a tree model by building rules based on the attribute value of each node of the tree. Thaseen and Kumar [33]</ref> discussed application of different DT-based classification algorithms for intrusion detection. Zhao et al. [34]</ref> proposed
v xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>Semi-Supervised Learning (SSL) paradigm is employed as learning strategy. SSL covers several different settings including [56]</ref>: a) Semi-supervised classification: Its alternative name is classification with labelled and unlabeled data (or partially labelled data). This emerged as an e
intrusions by using NetFlow traffic data.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BACKGROUND A. AUTOENCODER</head><p>Autoencoder (AE) [39]</ref>, [40]</ref> is a neural network method, which has an operating logic that trains the input vectors to reconstruct as output vectors with an unsupervised approach <ref typ
br" target="#b56">[57]</ref>, CTU-13 [58]</ref>, UNSW-NB15 [59]</ref>, CIDDS-001 [60]</ref> and CICIDS2017 [61]</ref>.</p><p>Kyoto 2006+ is a publicly accessible dataset, which encompasses real network traffic including numerous attacks performed against honeypots such as DoS
ima and discover better solutions to the optimization process [64]</ref>. The additional parameters used in VAE configuration are as follow. Leaky Rectified Linear Unit [68]</ref> is used in hidden layers as activation function. It is preferred over sigmoid or tanh since it resolves the ''dying ReLU'' problem of the vanilla ReLU and the
to this, the ability of the machine is also maximized in order to classify the forthcoming testing datasets accurately. The best machine is discovered by utilizing a mathematical optimization method [45]</ref>.</p><p>The SVM method is modified into a One-Class SVM (OCSVM) as explained in [46]</ref>. The dataset, which is given as an in
ve class example after it is ordered by its classification probabilities. The AUC values are always bounded between 0 and 1. If AUC value is less than 0.5, it means that the classifier is unrealistic [54]</ref>. A rough classifying system can serve as a guidance to the test accuracy as follows [55]</ref>: i) Excellent (0.90-1), ii) Good
of malicious flows was conducted in the second phase.</p><p>K-Nearest Neighbor (KNN) takes into account the knowledge of adjacent points to perform classification in the example given. Shubair et al. [27]</ref> suggested a flow-based IDS exploiting the benefits of KNN method with the combination of fuzzy logic. The study used Least Mean Square method to perform error
ect abnormal traffic in flow-based data. The interconnection weights of MLP are optimized by using Cuckoo and particle swarm optimization with a gravitational search algorithm (PSOGSA). Mirsky et al. [21]</ref> proposed Kitsune, which was an online anomaly detection system that identified the attacks on a local network by employing a group of ANNs named AEs, to coope
ect abnormal traffic in flow-based data. The interconnection weights of MLP are optimized by using Cuckoo and particle swarm optimization with a gravitational search algorithm (PSOGSA). Mirsky et al. [21]</ref> proposed Kitsune, which was an online anomaly detection system that identified the attacks on a local network by employing a group of ANNs named AEs, to coope
ect abnormal traffic in flow-based data. The interconnection weights of MLP are optimized by using Cuckoo and particle swarm optimization with a gravitational search algorithm (PSOGSA). Mirsky et al. [21]</ref> proposed Kitsune, which was an online anomaly detection system that identified the attacks on a local network by employing a group of ANNs named AEs, to coope
flow-based features, they mostly contain packet-based (content) features. As this study aims to detect the attacks from flow-based features, some of the candidate flow-based datasets are Kyoto 2006+ [57]</ref>, CTU-13 [58]</ref>, UNSW-NB15 [59]</ref>, CIDDS-001 [60]</ref> an
ostly focus on dimensionality reduction [2]</ref>- [6]</ref> and anomaly-based intrusion detection [7]</ref>- [10]</ref>.</p><p>The KDDCUP99 dataset [11]</ref>, which includes packet-based features, too, is used to evaluate the methods in the studie
bibr" target="#b22">[23]</ref> (as Doc2vec implementation [33]</ref>), and deep contextual language models from BERT [15]</ref> and XLNet [41]</ref> in a vanilla and Siamese architecture [9]</ref>. Each system is evaluated under specific configurations regarding its concatenat a shift from context-free word embeddings, like GloVe [31]</ref>, to contextual embeddings as the ones used in BERT [15]</ref> and XL-Net [41]</ref>. The Transformer architecture allowed the efficient unsupervised pretraining of language models and led to significant improvements in many NLP benchmarks <re anguage models for deep contextual text representations based on the Transformer architecture [37]</ref>, named BERT [15]</ref> and XLNet [41]</ref>. The two Transformer models are originally designed to solve sequence pair classification. The base training task (i.e., next sentence prediction) for BERT an s are pretrained with different data. While BERT is trained on English Wikipedia and the BooksCorpus [43]</ref> alone, XLNet uses additional Web corpora for pretraining [41]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Hyperparameters</head><p>3.6.1 Sequence length. The vanilla and Siamese Transformer models b t="#tab_3">2</ref>, we can state that vanilla Transformers outperform all other methods. Rather unexpected is that BERT generally achieves slightly better results than XLNet. According to Yang et al. [41]</ref>, XLNet surpasses BERT on the related GLUE benchmark [39]</ref>, so we were expecting a similar outcome. We hypothesize that thi arget="#b38">[39]</ref>, so we were expecting a similar outcome. We hypothesize that this difference may be attributed to two reasons, pretraining on different corpora, and smaller models compared to [41]</ref>. We use the BASE, not the LARGE versions of the pretrained models used by Yang et al. [41]</ref>. Furthermore, the published XL asons, pretraining on different corpora, and smaller models compared to [41]</ref>. We use the BASE, not the LARGE versions of the pretrained models used by Yang et al. [41]</ref>. Furthermore, the published XLNet BASE model we considered is pretrained on different data than the one in Yang et al. [41]</re pretrained models used by Yang et al. [41]</ref>. Furthermore, the published XLNet BASE model we considered is pretrained on different data than the one in Yang et al. [41]</ref>  15</ref> . In contrast to BERT, XLNet is pretrained on Web corpora in addition to Wikipedia and the BooksCorpus <ref type=
="#b30">[31]</ref> and Paragraph Vectors [23]</ref> (as Doc2vec implementation [33]</ref>), and deep contextual language models from BERT [15]</ref> and XLNet [41]</ref> in a vanilla and Siamese architecture [9]</ref>. Each system is evaluated un ="#b36">[37]</ref> neural language models introduced a shift from context-free word embeddings, like GloVe [31]</ref>, to contextual embeddings as the ones used in BERT [15]</ref> and XL-Net [41]</ref>. The Transformer architecture allowed the efficient unsupervised pretraining of language models and led t head><p>As the third model category, we employ two language models for deep contextual text representations based on the Transformer architecture [37]</ref>, named BERT [15]</ref> and XLNet [41]</ref>. The two Transformer models are originally designed to solve sequence pair classification. The base traini from less than 10 minutes for vanilla BERT-128 (simplest Transformer architecture), to 55 minutes for Siamese</figDesc><table /><note>XLNet-512 (most complex Transformer architecture). As suggested in[15]</ref>, the Transformer training is performed with batch size b = 4, dropout probability d = 0.1, learning rate η = 2 −4 (Adam optimizer) and 4 training epochs. If n
ombine BERT with a Siamese architecture [9]</ref> for semantic representations of sentences and their similarity [26]</ref>. In prior work [32]</ref>, we also utilized a Siamese BERT model to determine the discourse relations between text segments to generate a story for the segments. Moreover, BERT has suc
ify the semantic relations of document pairs. Second, we implement six different models using word-based document embeddings from GloVe [31]</ref> and Paragraph Vectors [23]</ref> (as Doc2vec implementation [33]</ref>), and deep contextual language models from BERT [15]</ref> otators to segment the abstracts of papers into background, purpose, mechanism, and findings. Next, they encode the segments with GloVe [31]</ref> and Paragraph Vectors [23]</ref> and compute their similarity to determine whether papers are similar with respect to those segments. However, segmentation breaks the coherence of documents. embedding space. Word2vec is widely applied in NLP tasks [19,</ref>35]</ref> but unable to represent entire documents. Paragraph Vectors [23]</ref> (also known as Doc2vec), extends word2vec to learn embeddings for word sequences of arbitrary length. In the following, we refer Paragraph Vectors as Doc2vec,
singer that published an album called "Poker Face" in 1998 (like Lady Gaga in 2008).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Transformers</head><p>Recently, Transformer-based [37]</ref> neural language models introduced a shift from context-free word embeddings, like GloVe [31]</ref>, to contextual embeddings as i-c.org/ns/1.0"><head n="3.5.3">Vanilla Transformer.</head><p>As the third model category, we employ two language models for deep contextual text representations based on the Transformer architecture [37]</ref>, named BERT [15]</ref> and XLNet [41]</ref>. The two Transformer models are originally designed
ector representations of words such that semantically similar words end up close to each other in the embedding space. Word2vec is widely applied in NLP tasks [19,</ref>35]</ref> but unable to represent entire documents. Paragraph Vectors [23]</ref> (also known as Doc2vec), extends word2vec to learn embedd
arge document collections. Despite their success in NLP, Transformers have gained little attention in the recommender system community so far and are not even mentioned in a recently published survey [5]</ref>. To our knowledge, Hassan et al. [27]</ref> are one of the first to use BERT to recommend research papers. As opposed to our work
e interested in finding a target document d t that shares the semantic relation r i with d s . We use the term "semantic relation" to indicate connections between two documents above the syntax level [21]</ref>. We model the task of finding the relation r of a document pair (d s , d t ) as a pairwise multi-class document classification problem.</p><p>The semantic rel
the discourse relations between text segments to generate a story for the segments. Moreover, BERT has successfully solved various document classification tasks [1,</ref>29]</ref>. Akkalyoncu Yilmaz et al. [2]</ref> apply BERT to an information retrieval system for an end-to-end search over large document co ion of our results.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data set &amp; Use case</head><p>Existing datasets provide either classifications of single documents (e.g., topic [29]</ref>), relations between sentences or entities (e.g., natural language inference [39]</ref>, word analogies <ref type="bibr" target=
the discourse relations between text segments to generate a story for the segments. Moreover, BERT has successfully solved various document classification tasks [1,</ref>29]</ref>. Akkalyoncu Yilmaz et al. [2]</ref> apply BERT to an information retrieval system for an end-to-end search over large document co ion of our results.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data set &amp; Use case</head><p>Existing datasets provide either classifications of single documents (e.g., topic [29]</ref>), relations between sentences or entities (e.g., natural language inference [39]</ref>, word analogies <ref type="bibr" target=
<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To cope with the ever-emerging information overload, digital libraries employ literature recommender systems (LRS) [7]</ref>. These systems recommend related documents with the help of similarity measures, which often only distinguish between similar and dissimilar documents. This sim suggest content, structure, and style as the major dimensions inherent to texts. With approximately 55% of publications using content-based filtering, it accounts for the majority of the LRS research [7]</ref>. Structure and style are not actively being accounted for. Therefore, we focus only on the content.</p><p>Giving its diversity and reach, Wikipedia had been use
b9">[10]</ref>.</p><p>Nonetheless, document similarity measures do not take into account the semantic relations that would underpin such a system. While other NLP tasks, like relation extraction (RE) [42]</ref>, deal with relations, they are not concerned with semantic relations between documents. For instance, RE is about relations between entities occurring within lations between sentences or entities (e.g., natural language inference [39]</ref>, word analogies [25]</ref>, entity relation extraction [42]</ref>), or similarity between text pairs (i.e., binary classification [16]</ref>). Our task is defined as as multi-class classificati
led to significant improvements in many NLP benchmarks [26,</ref>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to combine BERT with a Siamese architecture [9]</ref> for semantic representations of sentences and their similarity <r iamese networks, two inputs are fed through identical sub-networks with shared weights (in this case, the Transformers), and then passed to a classifier or a similarity function. Reimers and Gurevych [34]</ref> have shown that Siamese BERT networks are suitable for text similarity tasks. For our experiment, both documents d s and d t are input to the Transformer sub- by Doc2vec and AvgGlove. In contrast to Doc2vec and AvgGloVe, the document representations are neither fixed nor frozen, but continually learned during the training of the classifier. Different than [34]</ref>, our implemented Siamese architecture is applied to a multi-class classification instead of a binary one.  The architectures of the underlying BERT and XLNet e concatenation with an element-wise difference and product is used</p><formula xml:id="formula_1">([u; v; |u −v |; u * v]</formula><p>). Furthermore, we confirmed the results of Reimers and Gurevych [34]</ref>, i.e., the most crucial component is the element-wise difference |u −v |. Only for Doc2vec the element-wise difference decreases the performance in comparison

led to significant improvements in many NLP benchmarks [26,</ref>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to combine BERT with a Siamese architecture [9]</ref> for semantic representations of sentences and their similarity <r iamese networks, two inputs are fed through identical sub-networks with shared weights (in this case, the Transformers), and then passed to a classifier or a similarity function. Reimers and Gurevych [34]</ref> have shown that Siamese BERT networks are suitable for text similarity tasks. For our experiment, both documents d s and d t are input to the Transformer sub- by Doc2vec and AvgGlove. In contrast to Doc2vec and AvgGloVe, the document representations are neither fixed nor frozen, but continually learned during the training of the classifier. Different than [34]</ref>, our implemented Siamese architecture is applied to a multi-class classification instead of a binary one.  The architectures of the underlying BERT and XLNet e concatenation with an element-wise difference and product is used</p><formula xml:id="formula_1">([u; v; |u −v |; u * v]</formula><p>). Furthermore, we confirmed the results of Reimers and Gurevych [34]</ref>, i.e., the most crucial component is the element-wise difference |u −v |. Only for Doc2vec the element-wise difference decreases the performance in comparison
singer that published an album called "Poker Face" in 1998 (like Lady Gaga in 2008).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Transformers</head><p>Recently, Transformer-based [37]</ref> neural language models introduced a shift from context-free word embeddings, like GloVe [31]</ref>, to contextual embeddings as i-c.org/ns/1.0"><head n="3.5.3">Vanilla Transformer.</head><p>As the third model category, we employ two language models for deep contextual text representations based on the Transformer architecture [37]</ref>, named BERT [15]</ref> and XLNet [41]</ref>. The two Transformer models are originally designed
e context of word embeddings, analogies are often illustrated using vector arithmetic, e.g., ì w King − ì w Queen = ì w Man − ì w Woman [25]</ref>. Allen and Hospedales [3]</ref> give a mathematical description of analogies as linear relationships between word embeddings. Dai et al. [13]</ref> demonstrate t
the discourse relations between text segments to generate a story for the segments. Moreover, BERT has successfully solved various document classification tasks [1,</ref>29]</ref>. Akkalyoncu Yilmaz et al. [2]</ref> apply BERT to an information retrieval system for an end-to-end search over large document co ion of our results.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data set &amp; Use case</head><p>Existing datasets provide either classifications of single documents (e.g., topic [29]</ref>), relations between sentences or entities (e.g., natural language inference [39]</ref>, word analogies <ref type="bibr" target=
ef>. The Transformer architecture allowed the efficient unsupervised pretraining of language models and led to significant improvements in many NLP benchmarks [26,</ref>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to combine BERT with a Siamese architecture <r Existing datasets provide either classifications of single documents (e.g., topic [29]</ref>), relations between sentences or entities (e.g., natural language inference [39]</ref>, word analogies [25]</ref>, entity relation extraction [42]</ref>), or similarity between text p r unexpected is that BERT generally achieves slightly better results than XLNet. According to Yang et al. [41]</ref>, XLNet surpasses BERT on the related GLUE benchmark [39]</ref>, so we were expecting a similar outcome. We hypothesize that this difference may be attributed to two reasons, pretraining on different corpora, and smaller m
arge document collections. Despite their success in NLP, Transformers have gained little attention in the recommender system community so far and are not even mentioned in a recently published survey [5]</ref>. To our knowledge, Hassan et al. [27]</ref> are one of the first to use BERT to recommend research papers. As opposed to our work
e interested in finding a target document d t that shares the semantic relation r i with d s . We use the term "semantic relation" to indicate connections between two documents above the syntax level [21]</ref>. We model the task of finding the relation r of a document pair (d s , d t ) as a pairwise multi-class document classification problem.</p><p>The semantic rel
se queries are generally referred to as analogical queries [17]</ref>. Especially for complex information needs, the formulation of analogical queries is more intuitive [24]</ref>. A system that supports analogical queries would be particularly beneficial for scientific literature since the discovery of the analogies is crucial for scie is used to illustrate an explanation. Moreover, analogical query solving in the form of "A is to B as C is to ?" is a fundamental aspect of human intelligence [17,</ref>24]</ref>. Chan et al. [10]</ref> emphasize the importance of analogical query solving for scientific progress. They propose a semi-automat
target="#b23">[24]</ref>. A system that supports analogical queries would be particularly beneficial for scientific literature since the discovery of the analogies is crucial for scientific progress [10]</ref>.</p><p>Nonetheless, document similarity measures do not take into account the semantic relations that would underpin such a system. While other NLP tasks, like ical query solving in the form of "A is to B as C is to ?" is a fundamental aspect of human intelligence [17,</ref>24]</ref>. Chan et al. [10]</ref> emphasize the importance of analogical query solving for scientific progress. They propose a semi-automated approach for finding analogies between research pap ). Our task is defined as as multi-class classification of document pairs consisting of multiple sentences. Moreover, the learning characteristic in our task requires considerably larger dataset than [10]</ref> or [20]</ref>. To the best of our knowledge, no established dataset fulfills these requirements.</p><p>3.1.1 Training data. One notation of sufficient training data for other corpora is one of the most challenging tasks. After all, even annotations can be solved efficiently as Chan et al.'s crowdsourcing approach demonstrates [10]</ref>. We are confident that our results are transferable to other domains.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK
or the segments. Moreover, BERT has successfully solved various document classification tasks [1,</ref>29]</ref>. Akkalyoncu Yilmaz et al. [2]</ref> apply BERT to an information retrieval system for an end-to-end search over large document collections. Despite their success in NLP, Transformers have gained l
or the segments. Moreover, BERT has successfully solved various document classification tasks [1,</ref>29]</ref>. Akkalyoncu Yilmaz et al. [2]</ref> apply BERT to an information retrieval system for an end-to-end search over large document collections. Despite their success in NLP, Transformers have gained l
em.</p><p>The semantic relation between documents provides context for similarity and enables analogical queries. To evaluate the presented techniques, we build a dataset using Wikipedia and Wikidata [38]</ref> repositories to illustrate our problem. Wikipedia articles are the seed and target documents, while Wikidata properties provide the semantic relations between
e gained little attention in the recommender system community so far and are not even mentioned in a recently published survey [5]</ref>. To our knowledge, Hassan et al. [27]</ref> are one of the first to use BERT to recommend research papers. As opposed to our work, Hassan et al. use BERT to encode only the paper titles as vectors and t
b9">[10]</ref>.</p><p>Nonetheless, document similarity measures do not take into account the semantic relations that would underpin such a system. While other NLP tasks, like relation extraction (RE) [42]</ref>, deal with relations, they are not concerned with semantic relations between documents. For instance, RE is about relations between entities occurring within lations between sentences or entities (e.g., natural language inference [39]</ref>, word analogies [25]</ref>, entity relation extraction [42]</ref>), or similarity between text pairs (i.e., binary classification [16]</ref>). Our task is defined as as multi-class classificati
ef>. The Transformer architecture allowed the efficient unsupervised pretraining of language models and led to significant improvements in many NLP benchmarks [26,</ref>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to combine BERT with a Siamese architecture <r Existing datasets provide either classifications of single documents (e.g., topic [29]</ref>), relations between sentences or entities (e.g., natural language inference [39]</ref>, word analogies [25]</ref>, entity relation extraction [42]</ref>), or similarity between text p r unexpected is that BERT generally achieves slightly better results than XLNet. According to Yang et al. [41]</ref>, XLNet surpasses BERT on the related GLUE benchmark [39]</ref>, so we were expecting a similar outcome. We hypothesize that this difference may be attributed to two reasons, pretraining on different corpora, and smaller m
singer that published an album called "Poker Face" in 1998 (like Lady Gaga in 2008).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Transformers</head><p>Recently, Transformer-based [37]</ref> neural language models introduced a shift from context-free word embeddings, like GloVe [31]</ref>, to contextual embeddings as i-c.org/ns/1.0"><head n="3.5.3">Vanilla Transformer.</head><p>As the third model category, we employ two language models for deep contextual text representations based on the Transformer architecture [37]</ref>, named BERT [15]</ref> and XLNet [41]</ref>. The two Transformer models are originally designed
firms the overall results. Most relations are correctly identified, while some relations are missing even if they are explicitly mentioned in the text. An analysis of the inner Transformer components [11]</ref> is a subject for future work.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Given the results in Table <ref type="table"
singer that published an album called "Poker Face" in 1998 (like Lady Gaga in 2008).</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Transformers</head><p>Recently, Transformer-based [37]</ref> neural language models introduced a shift from context-free word embeddings, like GloVe [31]</ref>, to contextual embeddings as i-c.org/ns/1.0"><head n="3.5.3">Vanilla Transformer.</head><p>As the third model category, we employ two language models for deep contextual text representations based on the Transformer architecture [37]</ref>, named BERT [15]</ref> and XLNet [41]</ref>. The two Transformer models are originally designed
target="#b23">[24]</ref>. A system that supports analogical queries would be particularly beneficial for scientific literature since the discovery of the analogies is crucial for scientific progress [10]</ref>.</p><p>Nonetheless, document similarity measures do not take into account the semantic relations that would underpin such a system. While other NLP tasks, like ical query solving in the form of "A is to B as C is to ?" is a fundamental aspect of human intelligence [17,</ref>24]</ref>. Chan et al. [10]</ref> emphasize the importance of analogical query solving for scientific progress. They propose a semi-automated approach for finding analogies between research pap ). Our task is defined as as multi-class classification of document pairs consisting of multiple sentences. Moreover, the learning characteristic in our task requires considerably larger dataset than [10]</ref> or [20]</ref>. To the best of our knowledge, no established dataset fulfills these requirements.</p><p>3.1.1 Training data. One notation of sufficient training data for other corpora is one of the most challenging tasks. After all, even annotations can be solved efficiently as Chan et al.'s crowdsourcing approach demonstrates [10]</ref>. We are confident that our results are transferable to other domains.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK
e context of word embeddings, analogies are often illustrated using vector arithmetic, e.g., ì w King − ì w Queen = ì w Man − ì w Woman [25]</ref>. Allen and Hospedales [3]</ref> give a mathematical description of analogies as linear relationships between word embeddings. Dai et al. [13]</ref> demonstrate t
queries in terms of documents and their relations (e.g., find a document with one specific relation to A, but a different relation to B). These queries are generally referred to as analogical queries [17]</ref>. Especially for complex information needs, the formulation of analogical queries is more intuitive [24]</ref>. A system that su or more elements in which their relation is used to illustrate an explanation. Moreover, analogical query solving in the form of "A is to B as C is to ?" is a fundamental aspect of human intelligence [17,</ref>24]</ref>. Chan et al. [10]</ref> emphasize the importance of analogical query solving for scienti
<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To cope with the ever-emerging information overload, digital libraries employ literature recommender systems (LRS) [7]</ref>. These systems recommend related documents with the help of similarity measures, which often only distinguish between similar and dissimilar documents. This sim suggest content, structure, and style as the major dimensions inherent to texts. With approximately 55% of publications using content-based filtering, it accounts for the majority of the LRS research [7]</ref>. Structure and style are not actively being accounted for. Therefore, we focus only on the content.</p><p>Giving its diversity and reach, Wikipedia had been use
x different models using word-based document embeddings from GloVe [31]</ref> and Paragraph Vectors [23]</ref> (as Doc2vec implementation [33]</ref>), and deep contextual language models from BERT [15]</ref> and XLNet [41]</ref> in a vanilla and >). The increase of samples is due to the retrieval of missing relations. The corresponding articles were converted to plain-text from the English Wikipedia dump of November 2019 using the Gensim API [33]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Negative Sampling</head><p>In addition to the nine positive classes from Wikidata, we introd ec), extends word2vec to learn embeddings for word sequences of arbitrary length. In the following, we refer Paragraph Vectors as Doc2vec, since we employ the widely-used implementation of the Gensim [33]</ref> framework. We obtained a 200D document vectors ì d for each Wikipedia article by training Doc2vec's distributed bag of words model (dbow) using both training on 4.2). </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Implementation</head><p>All experiments with Doc2vec and AvgGloVe can be run on CPU in less than 15 minutes using the Gensim [33]</ref> and Scikit-learn [30]</ref> framework. Before training the Doc2Vec model, Gensim preprocesses <ref type="foot" target="#foot_8"
led to significant improvements in many NLP benchmarks [26,</ref>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to combine BERT with a Siamese architecture [9]</ref> for semantic representations of sentences and their similarity <r iamese networks, two inputs are fed through identical sub-networks with shared weights (in this case, the Transformers), and then passed to a classifier or a similarity function. Reimers and Gurevych [34]</ref> have shown that Siamese BERT networks are suitable for text similarity tasks. For our experiment, both documents d s and d t are input to the Transformer sub- by Doc2vec and AvgGlove. In contrast to Doc2vec and AvgGloVe, the document representations are neither fixed nor frozen, but continually learned during the training of the classifier. Different than [34]</ref>, our implemented Siamese architecture is applied to a multi-class classification instead of a binary one.  The architectures of the underlying BERT and XLNet e concatenation with an element-wise difference and product is used</p><formula xml:id="formula_1">([u; v; |u −v |; u * v]</formula><p>). Furthermore, we confirmed the results of Reimers and Gurevych [34]</ref>, i.e., the most crucial component is the element-wise difference |u −v |. Only for Doc2vec the element-wise difference decreases the performance in comparison
arge document collections. Despite their success in NLP, Transformers have gained little attention in the recommender system community so far and are not even mentioned in a recently published survey [5]</ref>. To our knowledge, Hassan et al. [27]</ref> are one of the first to use BERT to recommend research papers. As opposed to our work
led to significant improvements in many NLP benchmarks [26,</ref>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to combine BERT with a Siamese architecture [9]</ref> for semantic representations of sentences and their similarity <r iamese networks, two inputs are fed through identical sub-networks with shared weights (in this case, the Transformers), and then passed to a classifier or a similarity function. Reimers and Gurevych [34]</ref> have shown that Siamese BERT networks are suitable for text similarity tasks. For our experiment, both documents d s and d t are input to the Transformer sub- by Doc2vec and AvgGlove. In contrast to Doc2vec and AvgGloVe, the document representations are neither fixed nor frozen, but continually learned during the training of the classifier. Different than [34]</ref>, our implemented Siamese architecture is applied to a multi-class classification instead of a binary one.  The architectures of the underlying BERT and XLNet e concatenation with an element-wise difference and product is used</p><formula xml:id="formula_1">([u; v; |u −v |; u * v]</formula><p>). Furthermore, we confirmed the results of Reimers and Gurevych [34]</ref>, i.e., the most crucial component is the element-wise difference |u −v |. Only for Doc2vec the element-wise difference decreases the performance in comparison
t="#b32">[33]</ref>), and deep contextual language models from BERT [15]</ref> and XLNet [41]</ref> in a vanilla and Siamese architecture [9]</ref>. Each system is evaluated under specific configurations regarding its concatenation method and sequence length. Third, we introduce a novel dataset composed of f>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to combine BERT with a Siamese architecture [9]</ref> for semantic representations of sentences and their similarity [26]</ref>. In prior work [32]</ref to the two models as vanilla Transformer since their original architecture is unchanged.  3.5.4 Siamese Transformer. We combine the two Transformers (BERT and XLNet) in a Siamese network architecture [9]</ref>. In Siamese networks, two inputs are fed through identical sub-networks with shared weights (in this case, the Transformers), and then passed to a classifier or
<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To cope with the ever-emerging information overload, digital libraries employ literature recommender systems (LRS) [7]</ref>. These systems recommend related documents with the help of similarity measures, which often only distinguish between similar and dissimilar documents. This sim suggest content, structure, and style as the major dimensions inherent to texts. With approximately 55% of publications using content-based filtering, it accounts for the majority of the LRS research [7]</ref>. Structure and style are not actively being accounted for. Therefore, we focus only on the content.</p><p>Giving its diversity and reach, Wikipedia had been use
ref>. The almost exclusive pretraining on Wikipedia most likely causes BERT to surpass XLNet. The effect of domain-specific pretraining on the performance of the language model has already been shown [8]</ref>.</p><p>Our evaluation also shows that the Siamese networks cannot capture the semantic relations as good as vanilla Transformers. In Siamese models, the encodin ons (size of training data, pretraining on in-domain corpus etc.). A reference value would be the F1-score of 0.65, which was achieved by SciBERT on the related task of citation intent classification [8]</ref>. While the effort for the unsupervised pretraining of a language model is reasonable, we recognize the annotation of sufficient training data for other corpora
et [41]</ref>. The Transformer architecture allowed the efficient unsupervised pretraining of language models and led to significant improvements in many NLP benchmarks [26,</ref>39,</ref>43]</ref>. Reimers and Gurevych [34]</ref> proposed to co h [34]</ref> proposed to combine BERT with a Siamese architecture [9]</ref> for semantic representations of sentences and their similarity [26]</ref>. In prior work [32]</ref>, we also utilized a Siamese BERT model to determine the discourse relations between text segments to
d the pendulum determine the location and the length of the shadow. There exists various kinds of causal model which could measure this causal relationship i.e. Linear Structual Equation Models (SEM) (Shimizu et al., 2006)</ref>. Existing methods for disentangled representation learning like β-VAE (Higgins et al., 2017)</ref> might not w observational data has attracted large amount of attention in the past decades (Hoyer et al., 2009;</ref>Zhang &amp; Hyvarinen, 2012;</ref>Shimizu et al., 2006)</ref>. Pearl (2009)</ref> introduce a probabilistic graphical model based framework to learn causality from data. <r f>Shimizu et al., 2006)</ref>. Pearl (2009)</ref> introduce a probabilistic graphical model based framework to learn causality from data. Shimizu et al. (2006)</ref> proposed an effective method called LiNGAM to learn the causal graph and they proved that the model is fully identifiable under the assumptio

hod called LiNGAM to learn the causal graph and they proved that the model is fully identifiable under the assumption that the causal relationship is linear and the noise is non-Gaussian distributed. Zheng et al. (2018)</ref> introduces DAG constraints for graph learning under continuous optimization (NOTEARS). Zhu &amp; Chen (2019)</ref>; <ref type= sal adjacency matrix A is constrained to be a DAG. We introduce the acyclicity constraint. Instead of using traditional DAG constraint that is combinatorial, we adopt a continuous constraint function (Zheng et al., 2018;</ref>Zhu &amp; Chen, 2019;</ref>Ng et al., 2019;</ref>Yu et al., 2019
usal representation as the representations that are structured by a causal graph. Discovering the causal graph from pure observational data has attracted large amount of attention in the past decades (Hoyer et al., 2009;</ref>Zhang &amp; Hyvarinen, 2012;</ref>Shimizu et al., 2006)</ref>. <ref type="bibr" ta


Burgess et al. (2018)</ref> adjust the hyperparameter to force latent codes to be independent of each other. Kim &amp; Mnih (2018)</ref>; Chen et al. (2018)</ref> further improve the independent by reducing total correlation. The theory of disentangled representation learning is still at its early stage. We ggins et al., 2017)</ref> proposes an adaptation framework which adjusts the weight of KL term to balance between independence of disentangled factors and reconstruction performance. While factor VAE (Chen et al., 2018)</ref> proposes a new frame work which focuses solely on the independence of factors.</p><p>The aforementioned unsupervised algorithms do not perform w


hod called LiNGAM to learn the causal graph and they proved that the model is fully identifiable under the assumption that the causal relationship is linear and the noise is non-Gaussian distributed. Zheng et al. (2018)</ref> introduces DAG constraints for graph learning under continuous optimization (NOTEARS). Zhu &amp; Chen (2019)</ref>; <ref type= sal adjacency matrix A is constrained to be a DAG. We introduce the acyclicity constraint. Instead of using traditional DAG constraint that is combinatorial, we adopt a continuous constraint function (Zheng et al., 2018;</ref>Zhu &amp; Chen, 2019;</ref>Ng et al., 2019;</ref>Yu et al., 2019

d GIN Xu et al. (2019)</ref> with random parameters (baselines with only the neighborhood aggregation function), GVAE with GCN encoder Kipf &amp; Welling (2016), DGI with GIN encoder Velickovic et al. (2019)</ref>, and EGI with GIN encoder. We train GVAE, DGI and EGI on one graph from either set (F and B), and test them on the rest of Forest-fire gra observed in other works like Ribeiro et al. ( 2017</ref>) since the networks are small), our t-tests have shown the improvements of EGI to be significant. 55.56% ? 6.83% DGI (GIN) Velickovic et al. (2019)</ref> 57.75% ? 4.47% 62.44% ? 4.46% 68.15% ? 6.24% Mask- GIN Hu et al. (2019a)</ref> 56.37% ? 5.07% 63.78% ? 2.79% 61.85% ? 10.
>A 2 ? B 2 .</formula><p>Proof. Note that, AA T is a principle matrix of BB T , i.e., AA T is obtained by removing the same set of rows and columns from BB T . Then, by Eigenvalue Interlacing Theorem Hwang (2004)</ref> and the fact that A T A and AA T have the same set of non-zero singular values, the matrix operator norm satisfies</p><formula xml:id="formula_11">A 2


<p>Graph neural networks (GNNs) have been intensively studied recently Kipf &amp; Welling (2017)</ref>; Keriven &amp; Peyr? (2019)</ref>; Chen et al. (2019)</ref>; Oono &amp; Suzuki (2020)</ref>; Huang et al. (2018)</ref>, due to their establishe


t="#b14">Hamilton et al. (2017)</ref>; Ying et al. (2018b)</ref>; Velickovic et al. (2018)</ref>, as well as close connections to spectral graph theory Defferrard et al. (2016)</ref>; Bruna et al. (2014)</ref>; Hammond et al. (2011)</ref>. While most GNN archit , researchers introduce the family of graph neural networks (GNNs) that are capable of inductive learning and generalizing to unseen nodes given meaningful node features Kipf &amp; Welling (2017);</p>Defferrard et al. (2016)</ref></p>;</p>Hamilton et al. (2017)</ref></p>. However, most existing GNNs require task-specific labels for train
, ?(g i , x i )), which is directly between the structural input and output of GNN, with a particular focus on the structural information g i . Specifically, we use the Jensen-Shannon MI estimator in Hjelm et al. (2019)</ref>,</p><formula xml:id="formula_2">I (JSD) (G, ?) = E P [-sp (-T D,? (g i , ?(g i , x i )))] -E P? ? [sp (T D,? (g i , ?(g i , x i )))] ,</formula


rget node, thus, we add the constraint 𝑘 (1) ≥ 𝐾 (2) ≥ • • • ≥ 𝐾 (𝐿)  reflecting the number of aspects decrease along with neighbor hops increasing. Inspired by the architecture design of Transformer [31]</ref>, we leverage attention mechanism to learn the weight of source nodes under different aspects. And the importance of neighbor 𝑠 ∈ 𝑁 𝜓 (𝑒) under aspect 𝑘 is cal
b1">[2]</ref>, but also make the downstream process more interpretable which can directly find applications in various fields with semantic data, such as images [5,</ref>6,</ref>13]</ref>, texts [16]</ref> and user behaviors [22]</ref>. For graph-
tream process more interpretable which can directly find applications in various fields with semantic data, such as images [5,</ref>6,</ref>13]</ref>, texts [16]</ref> and user behaviors [22]</ref>. For graph-structure data, GAT performs multi-hea
user-item interaction with rich context information as HIN; and (C) GNN based recommendation methods, which use information propagation way to exploit high-order connectivity in graph.</p><p>• BPR-MF [23]</ref> (A): This is a matrix factorization model optimized by the Bayesian personalized ranking (BPR), which exploits useritem implicit feedback directly. • NeuMF <r
te information from different types of nodes and ignore corresponding semantic relations. Recently, some HIN based GNNs are proposed for information propagation [8,</ref>15,</ref>38,</ref>41]</ref>, but still overlook the different aspects of semantic information between nodes
uch as images [5,</ref>6,</ref>13]</ref>, texts [16]</ref> and user behaviors [22]</ref>. For graph-structure data, GAT performs multi-head attention to jointly attend information from different representation subspaces <ref type="bibr" target="#b
ay an important role for guiding a user in a personalized way of discovering interested products from overwhelming alternatives. Collaborative filtering (CF) based methods (e.g., matrix factorization [18]</ref>) have been extensively used for recommendation, assuming users who have made similar choices tend to have similar preferences in the future. Since CF based me
ledge and is traditionally labor-intensive. Since knowledge graph (KG) can be seen as a special HIN, some works also leverage knowledge-aware embedding to guide the representation of items. Ai et al. [1]</ref> learn the knowledge graph embeddings to find connection paths between users and items. Cao et al. [4]</ref> and Zhang et al. <ref propagation layer at 5 and consider the variants of the model with different iteration times. As shown in Figure 5</ref>, we set the iteration times in the range of [1,</ref>7]</ref> and we have the following observations:</p><p>• More iterations generally leads to better performance before saturation wh
ref type="bibr" target="#b25">[26,</ref>27]</ref> calculate the meta path based similarities between users, and infer the rating score based on similar users. Yu et al. [40]</ref> and Zhao et al. [43]</ref> employ various types of meta paths between users and items in matrix factorization to generate laten
tegrate other context information by transforming the interaction into a feature-rich data instance for user and item. These instances are then used by supervised learning models to predict the score [7,</ref>28]</ref>. However, these methods always treat each user-item record as an independent instance and overlook the relations among t variants of the model with different iteration times. As shown in Figure 5</ref>, we set the iteration times in the range of [1,</ref>7]</ref> and we have the following observations:</p><p>• More iterations generally leads to better performance before saturation which is guaranteed by its convergence pr z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s
tegrate other context information by transforming the interaction into a feature-rich data instance for user and item. These instances are then used by supervised learning models to predict the score [7,</ref>28]</ref>. However, these methods always treat each user-item record as an independent instance and overlook the relations among t variants of the model with different iteration times. As shown in Figure 5</ref>, we set the iteration times in the range of [1,</ref>7]</ref> and we have the following observations:</p><p>• More iterations generally leads to better performance before saturation which is guaranteed by its convergence pr z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s
ei-c.org/ns/1.0"><head>C. Discussion</head><p>The partitioning strategy described in this section is application-agnostic and is implemented in the Customizable Streaming Partitioner (CuSP) framework [36]</ref>. The experimental results in this paper are based on the partitions created by CuSP.</p><p>IV. DISTRIBUTED TRIANGLE COUNTING Figure <ref type="figure" target= ON</head></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup</head><p>We implemented the proposed graph partitioning policy using the Customizable Streaming Partitioner (CuSP) [36]</ref> framework. We modified CuSP to create edge proxies in addition to vertex proxies. We also modified it to treat undirected edges as a single directed edge base
#b6">[7]</ref>, clusters [8]</ref>, [9]</ref>, [10]</ref>, [11]</ref> and GPUs [12]</ref>, [13]</ref>. We briefly discuss this prior work below.</p><p>Triangle counting on shared memory CPUs: Shun et al. <ref type="bi
iangle counting using MapReduce. They rank vertices by degree and distribute them across hosts in a round-robin fashion. Similarly, several other techniques [22]</ref>, [23]</ref>, [24]</ref>, [25]</ref> were also proposed to improve the performance of triangle counting using
triangle counting.</p><p>These problems limit the effectiveness of current implementations of triangle counting. Most implementations are either sequential or shared-memory multicore implementations [4]</ref>, [5]</ref> so they cannot deal with very large graphs unless one uses a very expensive machine with many TBs of DRAM or nonvolatil
http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Triangle counting has been implemented on various platforms including shared-memory CPUs [7]</ref>, clusters [8]</ref>, [9]</ref>, [10]</ref>, [11]</ref> and GPUs <ref type="bibr" target="
.tei-c.org/ns/1.0"><head>A. Local Triangle Counting</head><p>To count triangles locally on each host, we modify an IrGL-based triangle counting implementation [5]</ref>, [37]</ref> to use binary search to find triangles instead of edgelist intersection to improve GPU locality [28]</ref>, <ref type="bibr" ta >I</ref> shows the performance of DistTC on the Graph500 inputs on a single GPU. It also shows the runtime of IrGL-generated single-GPU triangle counting code [5]</ref>, [37]</ref> (denoted IrGL) that was a Graph Challenge 2017 champion. On average, DistTC achieves 1.54? speedup over IrGL. On a single GPU, we do not partition the graph,
gle counting [24]</ref>, [31]</ref> have also been studied. Additionally, triangle counting has been explored for streaming graphs (e.g., [32]</ref>, [33]</ref>, [34]</ref>).</p><p>Our implementation is targeted at static graphs since partitioni
iangle counting using MapReduce. They rank vertices by degree and distribute them across hosts in a round-robin fashion. Similarly, several other techniques [22]</ref>, [23]</ref>, [24]</ref>, [25]</ref> were also proposed to improve the performance of triangle counting using
iangle counting using MapReduce. They rank vertices by degree and distribute them across hosts in a round-robin fashion. Similarly, several other techniques [22]</ref>, [23]</ref>, [24]</ref>, [25]</ref> were also proposed to improve the performance of triangle counting using
ef> and GPUs [12]</ref>, [13]</ref>. We briefly discuss this prior work below.</p><p>Triangle counting on shared memory CPUs: Shun et al. [14]</ref> detail a cache-oblivious parallel triangle counting on shared-memory multicore CPUs. Tangwongsan et al. [7]</ref> present parall
vertices by degree and distribute them across hosts in a round-robin fashion. Similarly, several other techniques [22]</ref>, [23]</ref>, [24]</ref>, [25]</ref> were also proposed to improve the performance of triangle counting using MapReduce framework. PDTL <ref type="bibr" >[30]</ref> implement triangle counting on an FPGA: they use the low-latency capabilities of FPGA to improve energy efficiency over GPU implementations. Approximation techniques for triangle counting [24]</ref>, [31]</ref> have also been studied. Additionally, triangle counting has been explored for streaming graphs (e.g., <ref type="bi
ual try-on of lipstick or puppeteering of virtual avatars where the accuracy of lip and eye contours is critical to realism.</p><p>In contrast to methods that use a parametric model of the human face [1]</ref>, we directly predict the positions of face mesh vertices in 3D. We base our architecture on earlier efforts in this field [5]</ref
the attention mesh submodels to this blend shape network. In order to handle differences between various human faces, we apply Laplacian mesh editing to morph a canonical mesh into the predicted mesh [3]</ref>. This lets us use the blend shape coefficients for different human faces without additional fine-tuning. We demonstrate some results in Figure <ref type="figure
that it is easier to train and distribute since it is internally consistent compared to multiple disparate networks that are chained together.</p><p>We use an architecture similar to one described in [7]</ref>, where the authors build a network that is robust to the initialization provided by different face detectors. Despite the differing goals of the two papers, it
paper, we show that it is possible for a single model to achieve the same quality as the cascaded approach by employing region-specific heads that transform the feature maps with spatial transformers [4]</ref>, while being up to 30 percent faster during inference. We term this architecture as attention mesh. An added benefit is that it is easier to train and distribut s and differentiable interpolations). This allows to train architectures endto-end and enrich the features that are used by the attention mechanism. Specifically, we use a spatial transformer mod-ule [4]</ref> to extract 24 × 24 region features from the 64 × 64 feature map. The spatial transformer is controlled by an affine transformation matrix θ (Equation <ref type= to adapt the region submodels to them.</p><p>Attention mechanism Several attention mechanisms (soft and hard) have been developed for visual feature extraction [2,</ref>4]</ref>. These attention mechanisms sample a grid of 2D points in feature space and extract the features under the sampled points in a differentiable manner (e.g. using
the attention mesh submodels to this blend shape network. In order to handle differences between various human faces, we apply Laplacian mesh editing to morph a canonical mesh into the predicted mesh [3]</ref>. This lets us use the blend shape coefficients for different human faces without additional fine-tuning. We demonstrate some results in Figure <ref type="figure
the attention mesh submodels to this blend shape network. In order to handle differences between various human faces, we apply Laplacian mesh editing to morph a canonical mesh into the predicted mesh [3]</ref>. This lets us use the blend shape coefficients for different human faces without additional fine-tuning. We demonstrate some results in Figure <ref type="figure
paper, we show that it is possible for a single model to achieve the same quality as the cascaded approach by employing region-specific heads that transform the feature maps with spatial transformers [4]</ref>, while being up to 30 percent faster during inference. We term this architecture as attention mesh. An added benefit is that it is easier to train and distribut s and differentiable interpolations). This allows to train architectures endto-end and enrich the features that are used by the attention mechanism. Specifically, we use a spatial transformer mod-ule [4]</ref> to extract 24 × 24 region features from the 64 × 64 feature map. The spatial transformer is controlled by an affine transformation matrix θ (Equation <ref type= to adapt the region submodels to them.</p><p>Attention mechanism Several attention mechanisms (soft and hard) have been developed for visual feature extraction [2,</ref>4]</ref>. These attention mechanisms sample a grid of 2D points in feature space and extract the features under the sampled points in a differentiable manner (e.g. using
the attention mesh submodels to this blend shape network. In order to handle differences between various human faces, we apply Laplacian mesh editing to morph a canonical mesh into the predicted mesh [3]</ref>. This lets us use the blend shape coefficients for different human faces without additional fine-tuning. We demonstrate some results in Figure <ref type="figure
paper, we show that it is possible for a single model to achieve the same quality as the cascaded approach by employing region-specific heads that transform the feature maps with spatial transformers [4]</ref>, while being up to 30 percent faster during inference. We term this architecture as attention mesh. An added benefit is that it is easier to train and distribut s and differentiable interpolations). This allows to train architectures endto-end and enrich the features that are used by the attention mechanism. Specifically, we use a spatial transformer mod-ule [4]</ref> to extract 24 × 24 region features from the 64 × 64 feature map. The spatial transformer is controlled by an affine transformation matrix θ (Equation <ref type= to adapt the region submodels to them.</p><p>Attention mechanism Several attention mechanisms (soft and hard) have been developed for visual feature extraction [2,</ref>4]</ref>. These attention mechanisms sample a grid of 2D points in feature space and extract the features under the sampled points in a differentiable manner (e.g. using
paper, we show that it is possible for a single model to achieve the same quality as the cascaded approach by employing region-specific heads that transform the feature maps with spatial transformers [4]</ref>, while being up to 30 percent faster during inference. We term this architecture as attention mesh. An added benefit is that it is easier to train and distribut s and differentiable interpolations). This allows to train architectures endto-end and enrich the features that are used by the attention mechanism. Specifically, we use a spatial transformer mod-ule [4]</ref> to extract 24 × 24 region features from the 64 × 64 feature map. The spatial transformer is controlled by an affine transformation matrix θ (Equation <ref type= to adapt the region submodels to them.</p><p>Attention mechanism Several attention mechanisms (soft and hard) have been developed for visual feature extraction [2,</ref>4]</ref>. These attention mechanisms sample a grid of 2D points in feature space and extract the features under the sampled points in a differentiable manner (e.g. using
teering.</p><p>AR Makeup Accurate registration of the face mesh is critical to applications like AR makeup where even small errors in alignment can drive the rendered effect into the "uncanny valley" [8]</ref>. We built a lipstick rendering solution (Figure 4</ref>) on top of our attention mesh model by using the contours provided by
or example, a DMA gather will not move the memory stored indices or addresses of the data elements to gather to the requesting core, only the requested elements from the data array.</p><p>Song et al. [11]</ref> propose a graph processor based on sparse matrix algebra, building on the observation that many graph applications can be represented as operations on sparse
imple pipelines, with multi-threading to hide memory latency, see Figure 3</ref>. PIUMA multi-threaded cores (MTC) are round-robin multi-threaded in-order pipelines [6]</ref>. At any moment, each thread can only have one in-flight instruction, which considerably simplifies the core design for better energy efficiency. Single-threaded
in the pipelines. As we will show in the results section, 8 byte accesses and offload memory engines are important contributors to PUMA's performance and energy efficiency.</p><p>The Emu architecture [9]</ref> is a recently proposed architecture for big data analysis, including graph analysis workloads. Similar to PIUMA and Urika-GD, it consists of many small cores wi
tics is reasoning about the relationships between these classified objects, typically represented as a graph. Determining the relationships between entities in a graph is the basis of graph analytics [2]</ref>. Graph analytics poses important challenges on existing processor architectures due to its sparse structure. This sparseness leads to scattered and irregular me
nending streams of data. Computing infrastructure for classification is predominantly oriented toward "dense" compute, such as matrix computations. The continuing exponential growth in generated data [1]</ref> has shifted compute to offload to GPUs and other focused accelerators across multiple domains that are densecompute dominated.</p><p>The next step in both AI an
lso written from scratch. For Xeon, graph applications do not scale well beyond a single node, with even worse performance for small node counts, due to the overhead of the fine-grained communication [13]</ref>. For PIUMA, the application code does not need to change for multinode execution, thanks to the system-wide shared memory. Our simulator can practically simul
nending streams of data. Computing infrastructure for classification is predominantly oriented toward "dense" compute, such as matrix computations. The continuing exponential growth in generated data [1]</ref> has shifted compute to offload to GPUs and other focused accelerators across multiple domains that are densecompute dominated.</p><p>The next step in both AI an
nending streams of data. Computing infrastructure for classification is predominantly oriented toward "dense" compute, such as matrix computations. The continuing exponential growth in generated data [1]</ref> has shifted compute to offload to GPUs and other focused accelerators across multiple domains that are densecompute dominated.</p><p>The next step in both AI an
tions can be represented as operations on sparse matrices. Their architecture has overlaps with PIUMA, such as the absence of caches, and fine-grained communication and memory accesses. Graphicionado [12]</ref> is a graph analysis accelerator, implementing a vertex-centric compute paradigm. While these accelerators are likely more energy efficient for analyzing small
nending streams of data. Computing infrastructure for classification is predominantly oriented toward "dense" compute, such as matrix computations. The continuing exponential growth in generated data [1]</ref> has shifted compute to offload to GPUs and other focused accelerators across multiple domains that are densecompute dominated.</p><p>The next step in both AI an
cesses prevent memory coalescing, branches cause thread divergence and synchronization limits thread progress. Nevertheless, GPUs usually perform better on graph algorithms than CPUs for small graphs [5]</ref>, because they have more threads, which hides memory latency, and much higher memory bandwidth, brute-forcing the inefficient bandwidth utilization. However, GPU
gated gradients. In these frameworks, it is a common practice to share only the gradients in order protect the proprietary data. However, recent work by Zhu et al., "Deep Leakage from Gradient" (DLG) [1]</ref> showed the possibility to steal the private training data from the shared gradients of other participants.</p><p>The main idea of DLG is to generate dummy data initely leaked by sharing gradients of a Neural Network (NN) trained with cross-entropy loss. This enables us to always extract the ground-truth labels and significantly simplify the objective of DLG [1]</ref> in order to extract good-quality data. Hence, we name our approach, Improved DLG (iDLG). The main contributions of our work includes:</p><p>• By revealing the r ct the ground-truth labels from the shared gradients with 100% accuracy, which facilitates the data extraction with better fidelity.</p><p>• We empirically demonstrate the advantages of iDLG over DLG [1]</ref> via comparing the accuracy of extracted labels and the fidelity of extracted data on three datasets.</p><p>The rest of the paper is organised as follows: Sectio G through the experimental evaluation, and Section 4 concludes the paper with discussion.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Recent work by Zhu et al. [1]</ref> presents an approach (DLG) to steal the proprietary data protected by the participants in distributed learning from the shared gradients. In their method, they ype="bibr" target="#b2">3</ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we empirically demonstrate the advantages of our (iDLG) method over DLG [1]</ref>. We perform experiments on the classification task over three datasets: MNIST [8]</ref>, CIFAR-100 [ " target="#b7">[8]</ref>, CIFAR-100 [9]</ref>, and LFW [10]</ref> with 10, 100, and 5749 categories respectively. Following the settings in [1]</ref>, we use the randomly initialized LeNet for all experiments. L-BFGS [11]</ref> with learning rate 1 is used as the optimizer. For zed LeNet for all experiments. L-BFGS [11]</ref> with learning rate 1 is used as the optimizer. For fast training, we resize all images in LFW to 32 × 32.</p><p>For DLG [1]</ref>, as described by the authors, we start the procedure with the randomly initialized dummy data and outputs (x , y ), then iteratively update them to minimize the labels c , and (ii) the fidelity of the extracted Dataset DLG iDLG MNIST 89.9% 100.0% CIFAR-100 83.3% 100.0% LFW 79.1% 100.0% Table 1</ref>: Accuracy of the extracted labels for DLG [1]</ref> and iDLG. Note that iDLG always extracts the correct label as opposed to DLG which extracts wrong labels frequently. threshold of good fidelity. From left to ri
section, we empirically demonstrate the advantages of our (iDLG) method over DLG [1]</ref>. We perform experiments on the classification task over three datasets: MNIST [8]</ref>, CIFAR-100 [9]</ref>, and LFW [10]</ref> with 10, 100, and 5749 categories respectively. Following t
Desc> 	</teiHeader> 	<text xml:lang="en"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In multi-node distributed learning systems such as Collaborative Learning [2,</ref>3,</ref>4]</ref> and Federated Learning [5,</ref><ref type="bibr" targe
t="#b9">[10]</ref> with 10, 100, and 5749 categories respectively. Following the settings in [1]</ref>, we use the randomly initialized LeNet for all experiments. L-BFGS [11]</ref> with learning rate 1 is used as the optimizer. For fast training, we resize all images in LFW to 32 × 32.</p><p>For DLG [1]</ref
"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In multi-node distributed learning systems such as Collaborative Learning [2,</ref>3,</ref>4]</ref> and Federated Learning [5,</ref>6,</ref><ref type="bibr" target te. LG = ∇W − ∇W 2</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F</head><p>Calculate the loss (difference between gradients). 6:</p><p>x ← − x − η∇ x LG Update the dummy datum. 7: end for 3</ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we empirically demonstrate the advantages of our (iDLG) method ove
t="#b9">[10]</ref> with 10, 100, and 5749 categories respectively. Following the settings in [1]</ref>, we use the randomly initialized LeNet for all experiments. L-BFGS [11]</ref> with learning rate 1 is used as the optimizer. For fast training, we resize all images in LFW to 32 × 32.</p><p>For DLG [1]</ref
section, we empirically demonstrate the advantages of our (iDLG) method over DLG [1]</ref>. We perform experiments on the classification task over three datasets: MNIST [8]</ref>, CIFAR-100 [9]</ref>, and LFW [10]</ref> with 10, 100, and 5749 categories respectively. Following t
section, we empirically demonstrate the advantages of our (iDLG) method over DLG [1]</ref>. We perform experiments on the classification task over three datasets: MNIST [8]</ref>, CIFAR-100 [9]</ref>, and LFW [10]</ref> with 10, 100, and 5749 categories respectively. Following t
"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In multi-node distributed learning systems such as Collaborative Learning [2,</ref>3,</ref>4]</ref> and Federated Learning [5,</ref>6,</ref><ref type="bibr" target te. LG = ∇W − ∇W 2</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F</head><p>Calculate the loss (difference between gradients). 6:</p><p>x ← − x − η∇ x LG Update the dummy datum. 7: end for 3</ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we empirically demonstrate the advantages of our (iDLG) method ove
"> 		<body> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In multi-node distributed learning systems such as Collaborative Learning [2,</ref>3,</ref>4]</ref> and Federated Learning [5,</ref>6,</ref><ref type="bibr" target te. LG = ∇W − ∇W 2</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F</head><p>Calculate the loss (difference between gradients). 6:</p><p>x ← − x − η∇ x LG Update the dummy datum. 7: end for 3</ref> </p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we empirically demonstrate the advantages of our (iDLG) method ove
section, we empirically demonstrate the advantages of our (iDLG) method over DLG [1]</ref>. We perform experiments on the classification task over three datasets: MNIST [8]</ref>, CIFAR-100 [9]</ref>, and LFW [10]</ref> with 10, 100, and 5749 categories respectively. Following t
erage dynamic profiling for determining the most useful prefetch candidates, but do not leverage the capabilities of trace-based dataflow analysis to explore timeliness and load classification. Zhang [53]</ref> performs dynamic prefetch optimization based on profiling, however, this work requires an extra thread while running the main application.</p></div> <div xmln
sts a large body of prior research on prefetchers including stream prefetchers [13,</ref>23,</ref>25,</ref>42,</ref>44]</ref>, correlation prefetchers [27,</ref>38,</ref><ref type="bi
aggressively should we prefetch?</p><p>Prior works on compiler assisted prefetching [1,</ref>8,</ref>10,</ref>18,</ref>33,</ref>35,</ref>46,</ref>52]</ref> tching [8]</ref> techniques have been well-studied in prior work. Compiler-based techniques [1,</ref>10,</ref>18,</ref>46]</ref> perform static code analysis to generate prefetch targets. The performance benefits provided by static approaches are l
bsequent branch instruction to exit the prefetch kernel prematurely in the case of a misspeculation. As an alternative, prefetch kernels could be executed as part of a transaction such as Intel's TSX [19]</ref>, however, serialization before and after the transaction would significantly reduce ILP between the main program and the independent prefetch kernel without a
offline, avoiding hardware overheads and enabling it to process and compact dependency chains of millions of instructions. Temporal prefetchers including GHB [38,</ref>49]</ref>, ISB [26]</ref> and MISB [51]</ref> can potentially prefetch arbitrary memory access patterns by
e data structures such as linked-lists at compile time to insert jump pointers [11,</ref>33,</ref>40,</ref>41]</ref> pointing to an element within the same data structure at some distance e.g. several elements ahead in a linked-list. These jump pointers are inserted into the
15,</ref>15,</ref>21,</ref>30,</ref>32,</ref>36,</ref>37,</ref>39,</ref>54]</ref> which have shown significant performanc also be implemented in hardware, we opted against it because of its high complexity and cost and lower flexibility. Prior works, including run-ahead execution [21,</ref>36,</ref>37]</ref>, precomputation threads [12,</ref>54]</ref> or helper thr 12,</ref>15,</ref>21,</ref>30,</ref>32,</ref>36,</ref>37,</ref>39,</ref>54]</ref> to prefetch complex memory access patte
or years and hence limited gains are expected, but nevertheless a 9% IPC gain can save millions of dollars for large WSC providers. Hardware Techniques: Several hardware mechanisms have been proposed [2,</ref>12,</ref>15,</ref>21,</ref>30,</ref><
ef>8,</ref>10,</ref>18,</ref>33,</ref>35,</ref>46,</ref>52]</ref> struggle to address these questions. In particular, they either require manual annotation or are significantly limited </ref> techniques have been well-studied in prior work. Compiler-based techniques [1,</ref>10,</ref>18,</ref>46]</ref> perform static code analysis to generate prefetch targets. The performance benefits provided by static approaches are limited, as only simple structures such a
or years and hence limited gains are expected, but nevertheless a 9% IPC gain can save millions of dollars for large WSC providers. Hardware Techniques: Several hardware mechanisms have been proposed [2,</ref>12,</ref>15,</ref>21,</ref>30,</ref><
>10,</ref>18,</ref>33,</ref>35,</ref>46,</ref>52]</ref> struggle to address these questions. In particular, they either require manual annotation or are significantly limited in the access patterns they can extract imple structures such as Singly-Nested Loop Nests (SNLNs) [50]</ref> or regular strides [29,</ref>35,</ref>52</ref>] can be learned. In contrast, our approach can handle complex dataflows of generic software algorithms and data structures. There exist several works that analy
ef type="bibr" target="#b35">[33]</ref>.</p><p>We introduce a selection of augmentations to known MPNN architectures, which we refer to as Attention MPNN (AMPNN) and Edge Memory Neural Network (EMNN) [34]</ref>, and evaluate them against published benchmark results with a range of metrics. The EMNN network shares architectural similarities to the D-MPNN model publish
ROC-AUC. The higher the y-axis is, the better the model performs effectively pick up on common structural features and learn them as reported in other studies [62,</ref>63]</ref>. However, in the case where missing data is imputed as inactive, these correlations become more difficult to learn, as negative counterexamples examples are ar
ks or citation graphs, approaches designed for use on multiple smaller graphs such as graphs of small molecule are also desired for their potential use in, amongst other things, drug design. Duvenaud [24]</ref> proposed the neural fingerprint method, describing it as an analogue of ECFP, as one of the first efforts in applying graph convolution model on chemistry rel ed for implementation in chemical, pharmaceutical and material science contexts. They were introduced as a framework to generalise several proposed techniques [14,</ref>24,</ref>25,</ref>28,</ref>29,</ref>37,</ref>
e trained models for activity predictions without the risk of reverse-engineering IP-sensitive structural information [31]</ref>[32]</ref>[33]</ref>.</p><p>We introduce a selection of augmentations to known MPNN architectures, which we refer to as Attention MPNN (AMPNN) and Edge Memory Neural Network (EMNN
ician's arsenal for doing QSAR.</p><p>Over the past decade, deep learning has become a staple in the machine learning toolbox of many fields and research areas [9,</ref>10]</ref>. Notably in the pharmaceutical area, in recent years AI has shown incredible growth, and is being used now not just for bioactivity and physical-chemical prope
"#b59">[58]</ref> is a collection of drugs and corresponding potential adverse reactions grouped following MedDRA classifications [59]</ref> according to previous usage [60]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocessing</head><p>Datasets were used both directly as provided from the MolNet repository witho
e trained models for activity predictions without the risk of reverse-engineering IP-sensitive structural information [31]</ref>[32]</ref>[33]</ref>.</p><p>We introduce a selection of augmentations to known MPNN architectures, which we refer to as Attention MPNN (AMPNN) and Edge Memory Neural Network (EMNN
Datasets (shown in Table 6</ref>) were split according to the methods described in the MolNet paper. Datasets were split either randomly, or by Bemis-Murcko scaffold [51]</ref>. In the case of randomly split sets, three sets were produced, split by fixed random seeds. Each dataset was split into train/test/validation sets in the rati
d and arranged by refined nearest-neighbour analysis for benchmarking virtual screening approaches. The HIV dataset [55] comprises classification data for compound anti-HIV activity. The BBBP dataset [56]</ref> contains data regarding compound ability to penetrate the blood-brain barrier. The Tox21 dataset [57]</ref> was released as a d
ef type="bibr" target="#b21">[19]</ref>, and Graph Spatial-Temporal Networks [20]</ref>[21]</ref>[22]</ref>[23]</ref>.</p><p>In GCNs and some other forms of GNNs, information is propagated through a graph in a manner similar to how conventional convolutional neural networks (
"http://www.tei-c.org/ns/1.0"><head>SELU message passing neural network (SELU-MPNN)</head><p>Our first architecture involved the basic MPNN framework, but with the use of the SELU activation function [39]</ref> instead of more traditional batch or layer norm functions. The SELU activation function is parameterised to converge towards a zero mean and unit variance, an
defined on Euclidean domains, including images or audio, convolutional representations such as scattering transforms or certain CNN architectures have been shown to be stable to spatial deformations [32,</ref>4,</ref>38]</ref>. However the notion of deformations is not well-defined on discrete graphs, and do not assume that the similarity kernel is smooth or bounded away from zero. In Section 4, we analyze the stability of GCNs to small deformation of the underlying random graph model. Similar to CNNs [32,</ref>4]</ref>, studying GCNs in the continuous world allows us to define intuitive notions of model deformations and characterize thei rmations, similar to Euclidean domains [32]</ref>. We note that studies of stability are often balanced by discussions on how the representation preserves signal (e.g., [32,</ref>4,</ref>17]</ref>). In our context, the empirical success of GCNs suggests that these representati . In contrast, we have shown that combining them with random models of large graphs allows us to define intuitive notions of deformations and stability in the continuous world like the Euclidean case [32,</ref>4,</ref>38]</ref>, with direct applications in community-based social networks or shape analysis o ly sparse) random graphs, we derive non-asymptotic, fully explicit bounds with relaxed hypotheses.</p><p>Related work on stability. The study of stability to deformations has been pioneered by Mallat [32]</ref> in the context of the scattering transform for signals on Euclidean domains such as images or audio signals [7,</ref><ref type=" setup allows us to define more intuitive geometric perturbations based on deformations of random graph models and to obtain deformation stability bounds that are similar to those on Euclidean domains [32]</ref>. We note that [29]</ref> also considers GCN representations with continuous graph models, but the authors focus on the differen ://www.tei-c.org/ns/1.0"><head n="4">Stability of GCNs to model deformations</head><p>Stability to deformations is an essential feature for the generalization properties of deep architectures. Mallat [32]</ref> studied the stability to small deformations of the wavelet-based scattering transform, which was extended to more generic learned convolutional network, e.g., proportional to the Lebesgue measure and ∇τ ∞ &lt; 1, we have q τ (x) = det(I − ∇τ (x)) −1 ; then, for small enough ∇τ ∞ , we obtain N P (τ ) d ∇τ ∞ , recovering the more standard quantity of Mallat [32]</ref>. In this case, we also have the bound</p><formula xml:id="formula_37">C Pτ 2 d if we assume ∇τ ∞ 1/2.</formula><p>In the rest of the section, we will assume f ">14</ref>); hence we must assume both (A1) and (A2) and obtain a dependence on both ∇τ ∞ and N P (τ ). Once again we focus on invariant c-GCNs with pooling, similar to classical scattering transform [32]</ref>.</p><p>Proposition 4 (Signal deformation). Consider a GCN representation Φ with no bias and a random graph Γ = (P, W, f ). Assume (A1), (A2), and ∇τ ∞ 1/2. We he appendix.</p><p>When P is proportional to the Lebesgue measure, since N P (τ ) is controlled by ∇τ ∞ , the GCN is invariant to translations and stable to deformations, similar to Euclidean domains [32]</ref>. We note that studies of stability are often balanced by discussions on how the representation preserves signal (e.g., [32,</re
get="#b7">[8,</ref>14,</ref>25]</ref>) are deep architectures defined on graphs inspired by classical Convolutional Neural Networks (CNNs [27]</ref>). In the past few years, they have been successfully applied to, for instance, node clustering [10]</ref>, semi-supervised learn 3 (Stability in terms of measure change). We have</p><formula xml:id="formula_102">ΦW,Pτ (f ) − ΦW,P (f ) C 2 Pτ C 1 f L Pτ − L + C 2 f U τ − U<label>(33)</label></formula><p>with C 1 is the same as (27)</ref> and</p><formula xml:id="formula_103">C 2 = θ M−1 ℓ=0 H (ℓ) 2 .</formula><p>Proof. From a simple triangle inequality and the estimate</p><formula xml:id="formu
type="bibr" target="#b0">[1]</ref>. A middle ground, which will be the setting for our analysis, is the so-called relatively sparse case α n ∼ log n/n, for which several non-trivial results are known [28,</ref>24]</ref>, while being more realistic than the dense case.</p><p>Outline and contributions. In this paper, we analyze the conver the convergence of the eigenstructures of the graph adjacency matrix or Laplacian in the context of spectral clustering [3,</ref>43,</ref>28,</ref>41]</ref> or learning with operators [39]</ref>. The theory of graphons <ref type="bibr" target="# >It is known in the literature that using the normalized Laplacian is often more appropriate than the adjacency matrix. If we where to use the latter, a normalization by (α n n) −1 would be necessary [28]</ref>. However, α n is rarely known, and can change from one case to the other. The normalized Laplacian is adaptative to α n and does not require any normalization Z = A1 n /n as input signal [8,</ref>10]</ref>. In this case, using our proofs (Lemma 4 in the appendix) and the spectral concentration in [28]</ref>, it is not difficult to show that a discrete GCN will converge to its countinuous version with the degree function f = d W,P as input. We will see in Prop. 3 fixed. Depending on the case, the input f will change or not.</p><p>Translation-invariant case. We are going to prove Theorem 4 with C defined as (26)</ref> and C ′ as (28)</ref>. Using (25)</ref> and Prop 5, we obtain that</p><formula xml:id="formula_97">W 2 (Φ W,Pτ (f ′ ) ♯ P τ , Φ W,P (f ) ♯ P ) T τ Φ /p><formula xml:id="formula_98">Φ Wτ ,P (f ′ τ ) − Φ W,P (f ) C(C W + C ∇w ) f ∇τ ∞ + C ′ f ′ τ − f ,</formula><p>where C is defined by (26)</ref> and C ′ is defined by (28)</ref>.</p><p>Proof of Prop. 3. When using degree functions as input, using the proof of Prop 5 and the computations of the previous sections we have</p><formula xml d W,P = d Wτ ,P − d W,P C ∇w ∇τ ∞</formula><p>Non Translation-invariant case. We are going to prove Theorem 5 with constants C defined as (26)</ref> and C ′ defined as (28)</ref>. By Assumption (A2) we easily have the following:</p><formula xml:id="formula_100">C −1/2 Pτ f L 2 (Pτ ) f C 1/2 Pτ f L 2 (Pτ )<label>(32)</label></formula><p T τ f + ΦW,Pτ (f ) − ΦW,P (f ) C(C W + C ∇w )C 1/2 Pτ f ∇τ ∞ + (CC 3 Pτ C W + C ′ ) f N P (τ )</formula><p>where C is given by ( 26</ref>) and C ′ is given by (28)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head>F Technical Lemma F.1 Concentration inequalities</head><p>Lemma 4 (Chaining on non-normalized kernel
Alain Savary, 21000 Dijon, France. firstname.name@u-bourgogne.fr applied to their latent representations. This large family of random graph models includes for instance Stochastic Block Models (SBM) [21]</ref>, graphons [30]</ref>, random geometric graphs [36]</ref>, or ε-graphs <ref type="bibr" target="#
bility studies for GCNs use purely discrete metrics that are less intuitive for capturing natural changes in structure [16,</ref>18,</ref>47]</ref>.</p><p>In statistics and machine learning, there is a long history of modelling large graphs with random models, see for instance <ref type="bibr" target="#b4" raphs, by considering certain well-chosen discrete perturbations and metrics [16]</ref>[17]</ref>[18]</ref>47]</ref>, which may however have limited interpretability without an underlying model. In contrast, our continuous setup allows us to define more intuitive geometric pe
dels, and give convergence results when the number of nodes grows in Section 3. In particular, our results are fully non-asymptotic, valid for relatively sparse random graphs, and unlike many studies [43,</ref>39]</ref> we do not assume that the similarity kernel is smooth or bounded away from zero. In Section 4, we analyze the stabilit guish dense graphons are derived in [31]</ref>, however their analysis based on random walks differs greatly from ours. In general, many of these studies are asymptotic [43,</ref>40]</ref>, valid only in the dense case [43,</ref>39,</ref><ref ty andom walks differs greatly from ours. In general, many of these studies are asymptotic [43,</ref>40]</ref>, valid only in the dense case [43,</ref>39,</ref>40,</ref>29,</ref>31]</ref ) satisfy that for all x ∈ X ,</p><formula xml:id="formula_11">W (•, x) ∞ c max , d W,P (x) c min , W (•, x) is (c Lip. , n X )-piecewise Lipschitz.<label>(6)</label></formula><p>Unlike other studies [43,</ref>39]</ref>, we do not assume that W itself is bounded away from 0 or smooth, and thus include important cases such as SBMs (piece om graphs. A large body of works examine the convergence of the eigenstructures of the graph adjacency matrix or Laplacian in the context of spectral clustering [3,</ref>43,</ref>28,</ref>41]</ref> or learning with operators [39]</ref>. The theor
practice, several studies have characterized GNNs according to their power to distinguish (or not) graph isomorphisms [46,</ref>11,</ref>33]</ref> or compute combinatorial graph parameters [12]</ref>. However, such notions usually become moot for large graphs, which are almo
images or audio, convolutional representations such as scattering transforms or certain CNN architectures have been shown to be stable to spatial deformations [32,</ref>4,</ref>38]</ref>. However the notion of deformations is not well-defined on discrete graphs, and most stability studies for GCNs use purel ef type="bibr" target="#b31">[32]</ref>. We note that studies of stability are often balanced by discussions on how the representation preserves signal (e.g., [32,</ref>4,</ref>17]</ref>). In our context, the empirical success of GCNs suggests that these representations maintain good discrimination and appr ng them with random models of large graphs allows us to define intuitive notions of deformations and stability in the continuous world like the Euclidean case [32,</ref>4,</ref>38]</ref>, with direct applications in community-based social networks or shape analysis on point clouds. For this we derived non-a is smooth or bounded away from zero. In Section 4, we analyze the stability of GCNs to small deformation of the underlying random graph model. Similar to CNNs [32,</ref>4]</ref>, studying GCNs in the continuous world allows us to define intuitive notions of model deformations and characterize their stability. Interestingly, for GCNs equi or signals on Euclidean domains such as images or audio signals [7,</ref>2]</ref>, and was later extended to more generic CNN architectures [4,</ref>38]</ref>. A more recent line of work has studied stability properties of GCNs or scattering representations on discrete graphs, b ref type="bibr" target="#b31">[32]</ref> studied the stability to small deformations of the wavelet-based scattering transform, which was extended to more generic learned convolutional network, e.g., [4,</ref>38]</ref>, and tries to establish bounds of the following form for a signal representation Φ(•):</p><formula xml:id="formula_28">Φ
of the graph adjacency matrix or Laplacian in the context of spectral clustering [3,</ref>43,</ref>28,</ref>41]</ref> or learning with operators [39]</ref>. The theory of graphons [30]</ref> defines (dense) graph li
or instance, node clustering [10]</ref>, semi-supervised learning [25]</ref>, or graph regression [22,</ref>19]</ref>, and remain one of the most popular variant of Graph Neural Networks (GNN). We refer the reader to the review papers [6,</ref><re ef type="bibr" target="#b7">[8,</ref>14]</ref>, or GCNs with order-1 filters [25]</ref> which are assimilable to message-passing networks [19]</ref>, see [45,</ref>6]</ref> for reviews. For message-passing networks, note that almost all our resul
ef>19]</ref>, and remain one of the most popular variant of Graph Neural Networks (GNN). We refer the reader to the review papers [6,</ref>45]</ref> for more details.</p><p>Many recent results have improved the theoretical understanding of GNNs. While some architectures have been shown to be universal <ref "bibr" target="#b13">14]</ref>, or GCNs with order-1 filters [25]</ref> which are assimilable to message-passing networks [19]</ref>, see [45,</ref>6]</ref> for reviews. For message-passing networks, note that almost all our results would also be valid by replacing the sum ove
br" target="#b27">[28]</ref> are used to measure the similarity of vertices. Due to the inefficiency of computing paths and cycles with larger networks, IUAD adopts Weisfeiler-Lehman sub-graph kernel [39]</ref> to evaluate the similarity between two vertices. WL-kernel captures topological information to quantify the similarity of vertices in SCN, which can judge how adopted:</p><formula xml:id="formula_7">? (1) j = K h (v a i , v a j ) K h (v a i , v a i ) ? K h (v a j , v a j ) .<label>(4)</label></formula><p>Due to page limitation, more details please refer to [39]</ref>, [40]</ref>.</p><p>For the WL sub-graph kernel, the more similar in topological structures of v a i and v a j are, the larger v
#b10">[11]</ref> and entity Fig. 1:</ref> A running example of the collaboration network, where edges in dashed lines do not belong to the ego-network of "Wei Wang (DUT)". matching [12]</ref>- [15]</ref>, etc., being helpful to many applications in database, information retrieval, and data mining. To date, existing so 6">[7]</ref>, object identification [8]</ref>, duplicate detection [9]</ref>- [11]</ref> and entity matching [12]</ref>- [15]</ref>, etc., which are applied in many scenes widely, such as social network linkage, data integration, database de-dupli

" target="#b23">[24]</ref>, [26]</ref>, [28]</ref>- [31]</ref>, [33]</ref>, [34]</ref>. Zhang et al. model the author disambiguation as a clustering problem after embedding each paper into a low-dimensional space [ in et al. tackle</ref> this problem by splitting vertices in the graph of co-authorships [28]</ref>. Liu et al. introduce a coarse-to-fine multiple clustering framework [34]</ref>. Despite effectiveness, we argue that such methods suffer from the following limitations: (1) the top-down approaches tend to initially mine the low-quality c
on is related to several similar tasks like record linkage [1]</ref>- [3]</ref>, entity resolution [4]</ref>- [7]</ref>, object identification [8]</ref>, duplicate detection [9]</ref>- [11] ELATED WORK</head><p>Our work is related to record linkage [1]</ref>- [3]</ref>, entity resolution [4]</ref>- [7]</ref>, object identification [8]</ref>, duplicate detection [9]</ref>- [11]
" target="#b23">[24]</ref>, [26]</ref>, [28]</ref>- [31]</ref>, [33]</ref>, [34]</ref>. Zhang et al. model the author disambiguation as a clustering problem after embedding each paper into a low-dimensional space [ in et al. tackle</ref> this problem by splitting vertices in the graph of co-authorships [28]</ref>. Liu et al. introduce a coarse-to-fine multiple clustering framework [34]</ref>. Despite effectiveness, we argue that such methods suffer from the following limitations: (1) the top-down approaches tend to initially mine the low-quality c
"figure">1:</ref> A running example of the collaboration network, where edges in dashed lines do not belong to the ego-network of "Wei Wang (DUT)". matching [12]</ref>- [15]</ref>, etc., being helpful to many applications in database, information retrieval, and data mining. To date, existing solutions can be roughly classified into two pe="bibr" target="#b7">[8]</ref>, duplicate detection [9]</ref>- [11]</ref> and entity matching [12]</ref>- [15]</ref>, etc., which are applied in many scenes widely, such as social network linkage, data integration, database de-duplication, and so on. Existing approaches can
ances in author disambiguation primarily focus on unsupervised methods [22]</ref>, [23]</ref>, [28]</ref>, [31]</ref>. Among them, embedding-based approaches achieve state-of-the-art performance [22]</ref>, [23]</r sed on unsupervised methods [22]</ref>, [23]</ref>, [26]</ref>, [28]</ref>- [31]</ref>, [33]</ref>.</p><p>However, most of them are top-down approaches. When these top-down approaches construct the ego-networks, th br" target="#b3">[4]</ref>, [22]</ref>, [24]</ref>, [26]</ref>, [28]</ref>- [31]</ref>, [33]</ref>, [34]</ref>. Zhang et al. model the author disambiguation as a clustering problem af
thods [16]</ref>- [20]</ref> and unsupervised methods [4]</ref>, [21]</ref>- [30]</ref>. Since supervised learning methods require manual efforts to do data annotation and feature engineering, they are less transferable to new domains and are not 2">[23]</ref>. Peng et al. adopt</ref> Generative Adversarial Networks to learn the paper representation of the heterogeneous network, then, HDBScan and AP are used to cluster papers [30]</ref>. Shin et al. tackle</ref> this problem by splitting vertices in the graph of co-authorships [28]</ref>. Liu et
rks; (2) they are designed for dealing with the static data, cannot handle the newly published papers incrementally.</p><p>Fan et al. are conscious of the limitations of existing unsupervised methods [27]</ref>. For multiple papers published by a target name, they do not merge the authors with the target name into a single vertex in the ego-network. However, they do b-graph Kernel. The topological structures of the collaboration network can well reflect the similarity between vertices. Usually, paths, cycles, or kernels [18]</ref>, [27]</ref>, [28]</ref> are used to measure the similarity of vertices. Due to the inefficiency of computing paths and cycles with larger n age of GCN construction.</p><p>(i) Unsupervised Baselines Similar to IUAD, there is a set of unsupervised methods [22]</ref>, [23]</ref>, [27]</ref>, [33]</ref> to disambiguate authors, where NetE achieves the state-ofthe-art performance [23]</r ve disambiguation accuracy, Aminer also leverages human annotations to learn paper embeddings. Furthermore, Aminer disambiguates authors via employing the HAC algorithm to group papers.</p><p>? GHOST [27]</ref>: GHOST is a graph-based method, which devises a path-based similarity metric to evaluate the similarity between papers, and further groups papers into cluster
rks; (2) they are designed for dealing with the static data, cannot handle the newly published papers incrementally.</p><p>Fan et al. are conscious of the limitations of existing unsupervised methods [27]</ref>. For multiple papers published by a target name, they do not merge the authors with the target name into a single vertex in the ego-network. However, they do b-graph Kernel. The topological structures of the collaboration network can well reflect the similarity between vertices. Usually, paths, cycles, or kernels [18]</ref>, [27]</ref>, [28]</ref> are used to measure the similarity of vertices. Due to the inefficiency of computing paths and cycles with larger n age of GCN construction.</p><p>(i) Unsupervised Baselines Similar to IUAD, there is a set of unsupervised methods [22]</ref>, [23]</ref>, [27]</ref>, [33]</ref> to disambiguate authors, where NetE achieves the state-ofthe-art performance [23]</r ve disambiguation accuracy, Aminer also leverages human annotations to learn paper embeddings. Furthermore, Aminer disambiguates authors via employing the HAC algorithm to group papers.</p><p>? GHOST [27]</ref>: GHOST is a graph-based method, which devises a path-based similarity metric to evaluate the similarity between papers, and further groups papers into cluster
ppInfo> 		</encodingDesc> 		<profileDesc> 			<abstract> <div xmlns="http://www.tei-c.org/ns/1.0"><p>The use of deep pre-trained transformers has led to remarkable progress in a number of applications (Devlin et al., 2019)</ref>. For tasks that make pairwise comparisons between sequences, matching a given input with a corresponding label, two approaches are common: Cro ly, substantial improvements to state-of-the-art benchmarks on a variety of language understanding tasks have been achieved through the use of deep pre-trained language models followed by fine-tuning (Devlin et al., 2019)</ref>. In this work we explore improvements to this approach for the class of tasks that require multi-sentence scoring: given an input context, sco measured via two axes: prediction quality and prediction speed, as scoring many candidates can be prohibitively slow.</p><p>The current state-of-the-art focuses on using BERT models for pre-training (Devlin et al., 2019)</ref>, which employ large text corpora on general subjects: Wikipedia and the Toronto Books Corpus (Zhu et al., 2015) ormers Our Bi-, Cross-, and Poly-encoders, described in sections 4.2, 4.3 and 4.4 respectively, are based on large pre-trained transformer models with the same architecture and dimension as BERT-base (Devlin et al., 2019)</ref>, which has 12 layers, 12 attention heads, and a hidden size of 768. As well as considering the BERT pre-trained weights, we also explore our o ions, but could not obtain improved results over the simpler architecture (results not shown).</p><p>We tried two optimizers: Adam (Kingma &amp; Ba, 2015) with weight decay of 0.01 (as recommended by (Devlin et al., 2019)</ref>) and Adamax (Kingma &amp; Ba, 2015) without weight decay; based on validation set performance, we choose to fine-tune with Adam when using the u of the loss evaluated on the valid set every half epoch. In Table 3</ref> we show validation performance when fine-tuning various layers of the weights provided by (Devlin et al., 2019)</ref>, using Adam with decay optimizer. Fine-tuning the entire network is important, with the exception of the word embeddings.</p><p>Fine With the get="#b13">Lample &amp; Conneau (2019)</ref>. When pre-training on Reddit, the input is the context, and the label is the next utterance.</p><p>When pre-training on Wikipedia and Toronto Books, as in Devlin et al. (2019)</ref>, the input is one sentence and the label the next sentence in the text. Each input token is represented as the sum of three embeddings: the tok . Segments for input tokens are 0, and for label tokens are 1.</p><p>Pre-training Procedure Our pre-training strategy involves training with a masked language model (MLM) task identical to the one in Devlin et al. (2019)</ref>. In the pre-training on Wikipedia and Toronto Books we add a next-sentence prediction task identical to BERT training. In the pre-training on R ns="http://www.tei-c.org/ns/1.0"><head n="5.1">Bi-encoders and Cross-encoders</head><p>We first investigate fine-tuning the Bi-and Cross-encoder architectures initialized with the weights provided by Devlin et al. (2019)</ref>, studying the choice of other hyperparameters (we explore our own pre-training schemes in section 5.3). In the case of the Bi-encoder, we can u
tasks of interest (e.g. dialogue) is a likely explanation for these performance gains, in line with previous results showing multi-tasking with similar tasks is more useful than with dissimilar ones (Caruana, 1997)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Inference Speed</head><p>An important motivation for the Poly-encoder architecture
e space wherein typically a dot product, cosine or (parameterized) non-linearity is used to measure their similarity. We refer to these models as Bi-encoders. Such methods include vector space models (Salton et al., 1975)</ref>, LSI (Deerwester et al., 1990)</ref>, supervised embeddings (Bai et al., 2009;</r

tention (Zhang et al., 2018b)</ref>, and most recently transformers (Wolf et al., 2019;</ref>Vig &amp; Ramea, 2019;</ref>Urbanek et al., 2019)</ref>. For the latter, concatenating the two sequences of text results in applying self-attention at every layer. This yields rich interactions bet ttention at every layer. This yields rich interactions between the input context and the candidate, as every word in the candidate label can attend to every word in the input context, and vice-versa. Urbanek et al. (2019)</ref> employed pre-trained BERT models, and fine-tuned both Bi-and Cross-encoders, explicitly comparing them on dialogue and action tasks, and find
scores their match based on any dependencies it wants. This has been explored with Sequential Matching Network CNN-based architectures (Wu et al., 2017)</ref>, Deep Matching Networks (Yang et al., 2018)</ref>, Gated Self-Attention (Zhang et al., 2018b)</ref>, and most recently transformers (Wolf et al.,
"#b4">(Deerwester et al., 1990)</ref>, supervised embeddings (Bai et al., 2009;</ref>Wu et al., 2018)</ref> and classical siamese networks (Bromley et al., 1994)</ref>. For the next utterance prediction tasks we consider in this work, several Bi-encoder neural approaches have been considered, in particular M



ining is a dot product between y ctxt and every candidate embedding, which can scale to millions of candidates on a modern GPU, and potentially billions using nearest-neighbor libraries such as FAISS (Johnson et al., 2019)</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cross-encoder</head><p>The Cross-encoder allows for rich interactions betw
//www.tei-c.org/ns/1.0"><p>In this work, we study leveraging extra text data to improve lowresource end-to-end ASR under cross-lingual transfer learning setting. To this end, we extend our prior work [1]</ref>, and propose a hybrid Transformer-LSTM based architecture. This architecture not only takes advantage of the highly effective encoding capacity of the Transform rget="#b3">4]</ref> and re-scoring stages [5]</ref>. Such techniques not only require external language models but also lead to a slow inference. To tackle this problem, [1]</ref> has proposed long short term memory (LSTM)-based encoderdecoder architecture which allows improving the LM capacity of the decoder using the extra text data. Ho ttention. Therefore, it is not straightforward to employ extra text data to improve the decoder.</p><p>In this work, we propose a hybrid Transformer-LSTM architecture which combines the advantages of [1]</ref> and [6]</ref>. It not only has a high encoding capacity of the Transformer but also benefits from the extra text data due to the L he target language. Lastly, the extra text data is used to boost the decoder of the transferred model.</p><p>The paper is organized as follows. Section 2 describes baseline architectures mentioned in [1]</ref> and [6]</ref>. Then, the proposed techniques are presented in Section 3. Experimental setup and results are presented in Section 4 cludes our work.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Baseline architectures 2.1. LSTM-based encoder-decoder architecture</head><p>A LSTM-based encoder-decoder architecture [1]</ref>, denoted as A1 in the rest of this paper, consists of a Bidirectional LSTM encoder and a LSTM-based decoder which are shown in Fig. 1</ref>. states at time step i − 1 and i respectively, embedding() and proj() are embedding and projection layers respectively. Figure 1</ref>: LSTM-based encoder-decoder architecture (A1) [1]</ref>, where the decoder acts as an independent language model.</p><p>From Equation (1), the LSTM is only conditioned on the previous decoding hidden state and previo M is only conditioned on the previous decoding hidden state and previous decoding output. In other words, the LSTM acts as an independent language model that can be easily updated with text-only data [1]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Transformer encoder-decoder architecture</head><p>Transformer has been proposed in <ref type= th two main steps. In the first step, we merge the extra text and the labeled data together to fine-tune the transferred model. This avoids a so-called catastrophic forgetting problem as mentioned in [1]</ref>. Specifically, at each training iteration, we mix a batch of labeled data consisting of B labeled utterances with a batch of text data consisting of Btext utter denote the ASR loss and LM loss generated by the labeled data and text data respectively. In the second step, the model is further fine-tuned with the labeled data of the target language. Similar to [1]</ref>, we empirically found that the second step is necessary to improve overall performance.</p><p>Step 1: Fine-tune E2E model</p><p>Step  </p></div> <div xmlns="htt
second set is a subset of the first one which consists of 2 million sentences, denoted as T 2.</p><p>For the source language, which is English, we use two subsets of the National Speech Corpus (NSC) [20]</ref> to train source models. The first subset, denoted as S 200h consists of 200 hours, where we also apply speed perturbation based data augmentation. The second
ge model decoder. To further benefit from the labeled data from another language, we employ cross-lingual transfer learning, which is a popular approach to address the limited resource problem in ASR [7,</ref>8,</ref>9,</ref>10,</ref>11]</ref>, on t
ge model decoder. To further benefit from the labeled data from another language, we employ cross-lingual transfer learning, which is a popular approach to address the limited resource problem in ASR [7,</ref>8,</ref>9,</ref>10,</ref>11]</ref>, on t
ty of the decoder using the extra text data. However, it utilized the LSTM structure for the encoder which has shown limited modeling capacity as well as slow training. On the other hand, Transformer [6]</ref> has been a promising approach for E2E ASR due to its high modeling capacity and fast training. However, its decoder closely interacts with the encoder output th rd to employ extra text data to improve the decoder.</p><p>In this work, we propose a hybrid Transformer-LSTM architecture which combines the advantages of [1]</ref> and [6]</ref>. It not only has a high encoding capacity of the Transformer but also benefits from the extra text data due to the LSTM-based independent language model decoder ata is used to boost the decoder of the transferred model.</p><p>The paper is organized as follows. Section 2 describes baseline architectures mentioned in [1]</ref> and [6]</ref>. Then, the proposed techniques are presented in Section 3. Experimental setup and results are presented in Section 4 and 5 respectively. Section 6 concludes our only data [1]</ref>.</p></div> <div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Transformer encoder-decoder architecture</head><p>Transformer has been proposed in [6]</ref> for sequence-to-sequence modeling in natural language processing tasks, then adopted to the ASR task in [12,</ref><ref type="bibr
d data from another resource-rich source language. This is a common scenario in real-world applications.</p><p>The extra text is usually employed to train language models (LM) applied during decoding [2,</ref>3,</ref>4]</ref> and re-scoring stages [5]</ref>. Such techniques not o
We split the labeled data into three sets for training, validation and evaluation. Detailed division is shown in Table 1</ref>. We perform speed perturbation based data augmentation [19]</ref> on the training data. For extra text data, we examine two sets: the first set has over 8 million sentences, denoted as T 1; while the second set is a subset o
en proposed in [6]</ref> for sequence-to-sequence modeling in natural language processing tasks, then adopted to the ASR task in [12,</ref>13]</ref>. The model architecture, denoted as A2, is shown in Fig. 2</ref>. The encoder is shown in the left half of Fig. <ref type="f
architecture</head><p>Transformer has been proposed in [6]</ref> for sequence-to-sequence modeling in natural language processing tasks, then adopted to the ASR task in [12,</ref>13]</ref>. The model architecture, denoted as A2, is shown in Fig. 2</ref>. The encoder is sh
odAtt(Q, K, V ) = sof tmax( QK T d k )V<label>(4)</label></formula><p>where d k is the hidden dimension. Besides, layer normalization [14]</ref> and residual connection [15]</ref> are introduced to each encoder-block for effective training.</p><p>The decoder is shown in the right half of Fig. 2</ref> w
the same sequence regardless of their distance. In contrast, although in theory LMST can model long-range dependence, in practice it faces difficulty to capture dependencies of far-distance elements [17]</ref> which limits its modeling capacity for long sequences such as acoustic signal. Second, by relying entirely on feed-forward components, the Transformer model a
